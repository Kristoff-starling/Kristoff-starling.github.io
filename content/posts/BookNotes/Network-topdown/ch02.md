---
title: "Chapter 2: Application Layer"
linktitle: Chapter 02
type: docs
date: '2022-10-21'
draft: false
featured: false

math: true

menu:
    network-topdown:
        parent: Chapters
        weight: 2
---

- [2.1 Principles of Network Applications](#21-principles-of-network-applications)
  - [2.1.1 Network Application Architectures](#211-network-application-architectures)
  - [2.1.2 Processes Communicating](#212-processes-communicating)
    - [Client and Server Processes](#client-and-server-processes)
    - [The Interface Between the Process and the Computer Network](#the-interface-between-the-process-and-the-computer-network)
    - [Addressing Processes](#addressing-processes)
  - [2.1.3 Transport Services Available to Applications](#213-transport-services-available-to-applications)
    - [Reliable Data Transfer](#reliable-data-transfer)
    - [Throughput](#throughput)
    - [Timing](#timing)
    - [Security](#security)
  - [2.1.4 Transport Services Provided by the Internet](#214-transport-services-provided-by-the-internet)
    - [TCP Services](#tcp-services)
    - [UDP Services](#udp-services)
    - [Services Not Provided by Internet Transport Protocols](#services-not-provided-by-internet-transport-protocols)
  - [2.1.5 Application-Layer Protocols](#215-application-layer-protocols)
  - [2.1.6 Network Applications Covered in This Book](#216-network-applications-covered-in-this-book)
- [2.2 The Web and HTTP](#22-the-web-and-http)
  - [2.2.1 Overview of HTTP](#221-overview-of-http)
  - [2.2.2 Non-Persistent and Persistent Connections](#222-non-persistent-and-persistent-connections)
    - [HTTP with Non-Persistent Connections](#http-with-non-persistent-connections)
    - [HTTP with Persistent Connections](#http-with-persistent-connections)
  - [2.2.3 HTTP Message Format](#223-http-message-format)
    - [HTTP Request Message](#http-request-message)
    - [HTTP Response Message](#http-response-message)
  - [2.2.4 User-Server Interaction: Cookies](#224-user-server-interaction-cookies)
  - [2.2.5 Web Caching](#225-web-caching)
    - [The Conditional GET](#the-conditional-get)
  - [2.2.6 HTTP/2](#226-http2)
    - [HTTP/2 Framing](#http2-framing)
    - [Response Message Prioritization and Server Pushing](#response-message-prioritization-and-server-pushing)
- [2.3 Electronic Mail in the Internet](#23-electronic-mail-in-the-internet)
  - [2.3.1 SMTP](#231-smtp)
  - [2.3.2 Mail Message Formats](#232-mail-message-formats)
  - [2.3.3 Mail Access Protocols](#233-mail-access-protocols)
- [2.4 DNS - The Internet's Directory Service](#24-dns---the-internets-directory-service)
  - [2.4.1 Services Provided by DNS](#241-services-provided-by-dns)
  - [2.4.2 Overview of How DNS Works](#242-overview-of-how-dns-works)
    - [A Distributed, Hierarchical Database](#a-distributed-hierarchical-database)
    - [DNS Caching](#dns-caching)
  - [2.4.3 DNS Records and Messages](#243-dns-records-and-messages)
    - [DNS Message](#dns-message)
    - [Inserting Records into the DNS Database](#inserting-records-into-the-dns-database)
- [2.5 Peer-to-Peer File Distribution](#25-peer-to-peer-file-distribution)
  - [Scalability of P2P Architecture](#scalability-of-p2p-architecture)
  - [BitTorrent](#bittorrent)
- [2.6 Video Streaming and Content Distribution Networks](#26-video-streaming-and-content-distribution-networks)
  - [2.6.1 Internet Video](#261-internet-video)
  - [2.6.2 HTTP Streaming and DASH](#262-http-streaming-and-dash)
  - [2.6.3 Content Distribution Networks](#263-content-distribution-networks)
    - [CDN Operation](#cdn-operation)
    - [Cluster Selection Strategies](#cluster-selection-strategies)
  - [2.6.4 Case Studies: Netflix and YouTube](#264-case-studies-netflix-and-youtube)
    - [Netflix](#netflix)
    - [YouTube](#youtube)
- [2.7 Socket Programming: Creating Network Applications](#27-socket-programming-creating-network-applications)

## 2.1 Principles of Network Applications

开发网络应用的核心是书写可以在不同的终端设备上运行的代码——值得注意的是我们不需要使我们的程序可以在 network core 中运行，因为 network core 中的 router/switch 根本没有应用层。

### 2.1.1 Network Application Architectures

需要注意的是 application architecture 和之前的 network architecture (即应用/传输/网络/链路/物理五层架构) 是不同的。**应用架构 (application architecture)** 由软件开发者提出，用来描述一个网络应用应当以什么样的结构分布在各个终端设备上。现在最流行的两种应用架构是所谓的 client-server 架构和 P2P 架构。

在**客户机-服务器架构 (client-server architecture)** 中，有一台一直运作的主机称为**服务器 (server)**，它的功能是为许许多多的其他主机，称为**客户机 (client)**，提供服务。在 client-server 架构中，不同的客户机之间不会直接建立通讯，他们都只和服务器交互，服务器有一个固定且为大家所知的 IP 地址，客户机可以通过向该 IP 地址发送 packet 的方式与服务器建立通讯。

通常在 client-server 应用中，一个服务器主机很难支撑繁重的业务，所以开发者一般会建立**数据中心 (data center)**。数据中心里有大量的主机，它们合起来对外形成一个虚拟服务器。

在**点对点架构 (peer=to=peer/P2P architecture)** 中，我们不再有服务器和数据中心的概念。用户的主机之间直接建立联系，这种 pair 被称为**同伴 (peer)**。P2P 的一大优势在于其 self-scalability，例如在一个 P2P 文件分享应用中，虽然每个用户索取文件会为网络带来 workload，但每个用户也会将自己的文件贡献给同伴，为网络增添服务能力。此外，P2P 节省了建设服务器等服务基础设施的钱财和精力。不过 P2P 高度去中心化的结构使其在安全性、可靠性等方面存在一定的挑战。

### 2.1.2 Processes Communicating

这个 section 主要讨论位于不同终端设备的程序之间是如何交互的。根据操作系统的术语，事实上并不是程序在交互，而是进程在交互。两个进程处于两个不同终端设备的应用层，它们通过向网络发送报文的方式交换信息。

#### Client and Server Processes

对于每一对通信的进程，我们通常将其中提供服务的进程称为 server，使用服务的进程称为 client。例如在 Web 应用中，网页浏览器是 client 进程，Web server 是 server 进程；在 P2P 文件共享中，下载文件的进程是 client 进程，上传文件的进程是 server 进程。事实上，在 P2P 中，很多情况下一个进程可能同时在上传和下载，但具体到一个固定的 pair 中时它要么是 server 要么是 client。

关于 client side 和 server side 有一个更正式的定义：对于一对正在通信的进程来说，初始化通信会话的那个进程是 client，那个等待它人与自己连接并开启会话的进程是 server。

#### The Interface Between the Process and the Computer Network

应用层的 application 通过**套接字 (socket)** 发送和接收消息。socket 是传输层向应用层提供的 API，它为应用层提供的保证是 application 只要向 socket 传输内容，下层的基础设施就会将内容传输到连接另外一端的 socket。应用开发者不能也不应该直接触碰底层的传输细节，他们只能通过选择传输协议和给定一些参数的方式来定制自己所需的服务。

#### Addressing Processes

发送消息时发送方需要知道接收主机的 **IP 地址 (IP address)**。此外，由于一个主机可以同时运行多个网络应用/进程，我们还需要一个方法来辨别接收消息的进程，这就是**端口号 (port number)** 的功能。端口号有一些convention，比如 Web server 的端口号通常是 80，mail server 通常是 25 等等。

### 2.1.3 Transport Services Available to Applications

application 将消息发送到 socket 之后，下面的传输层协议就要负责将消息传到对面的 socket。大部分的网络提供多种传输协议，不同的协议在各项性能指标上存在差异，我们一般从 reliable data transfer, throughput, timing 和 security 四个维度来衡量一个传输协议。

#### Reliable Data Transfer

packet 在网络传输的过程中可能因为各种原因丢失，对于许多应用 (例如电子邮件、网络银行等)，丢失数据会造成严重的后果。如果一个协议可以保证一端发出的数据可以完整地被另一端接收，那么我们称该协议提供**可靠数据传输 (reliable data transfer)**。

对于一些 loss-tolerable 的应用，比如各种流媒体，它们就不必要选择提供可靠数据传输的协议。丢失一点数据可能只是造成一点画面失真而已，它们更在乎传输的流畅度。

#### Throughput

网络的拥塞程度会对传输的实际吞吐率产生很大的影响。有的传输协议可以向应用层提供 throughput 的保证，例如无论网络多么拥塞我都保证吞吐率不小于 $r$ bits/sec。这样的保证对于一些 bandwidth-sensitive application 及其重要。对于像电子邮件、文件传输这样的 elastic application，即时吞吐率的保证就无关紧要。

#### Timing

类似于 throughput，传输协议也可以提供 timing 保证，例如保证一个 bit 在写入 socket 后可以在 $t$ sec 内传输到另一端的 socket。这种保证对即时应用十分重要。

#### Security

传输协议可以提供一些安全性的保证，例如在发送端对信息加密，接收端再对信息解密，这样中途即使被窃听也不会泄露用户隐私。

### 2.1.4 Transport Services Provided by the Internet

因特网 (或者更一般地，TCP/IP 网络) 提供两种传输协议：TCP 和 UDP。当我们编写网络应用时，我们需要在这两个传输协议中做出选择。

#### TCP Services

TCP 协议为发送和接收双方提供如下服务：

* Connection-oriented service: TCP 会让传输双方在开始正式传输信息之前先交换一些控制信息，这个过程被称为**握手 (handshaking)**。完成握手后，两个进程的 socket 之间会建立起 **TCP 连接 (TCP connection)**。这个 TCP connection 是双向的，即两个进程可以同时互发消息。消息传输完成后，进程必须销毁这个连接。
* Reliable data transfer service: TCP 保证一方发送的数据会不重复不以漏地传输到另一方，且接收消息的顺序和发送消息的顺序相同。

TCP 中还有一些拥塞控制机制，当发送方和接收方之间的网络过于拥塞时，TCP 会暂时挂起发送进程以缓解网络的拥塞程度。该机制并不是直接为通信进程服务的，而是为整个互联网提供的福利。

#### UDP Services

UDP 是一个轻量级的传输协议，它只提供最少的能保证正常运转的服务。UDP 在开始通信之前不会握手；传输不具有可靠性，即不能保证发送的数据一定会被收到；此外，在 UDP 中发送的消息可能会乱序地到达接收方。UDP 中也没有拥塞控制机制，发送方可以以任何 (物理限制以内的) 速率把数据送出去。

> **Securing TCP**
>
> 无论是 TCP 还是 UDP 都不会对数据进行任何加密，这使得用户数据在传输途中随时可能被窃取。因此互联网社区推出了 TCP 的一个增强服务：**Transport Layer Security (TLS)**。有 TLS 增强的 TCP 除了可以提供 TCP 原有的所有服务，还可以提供一些安全服务，例如 encryption, data integrity, end-point authentication 等。
>
> 值得注意的是 TLS 不是和 TCP, UDP 同一级别的传输协议，它只是一个“增强扩展包”。想要使用 TLS 需要在客户端和服务器端都安装 TLS 代码。TLS 提供一套和 TCP 几乎相同的 API 接口，用户把信息传输给 TLS socket 后，TLS 对数据做加密，然后传给 TCP socket，TCP 将数据传到另一端的 TCP socket 后，TCP 把加密数据传给 TLS，TLS 完成解密后将数据通过 TLS socket 提供给上层应用。

#### Services Not Provided by Internet Transport Protocols

值得注意的是无论是 TCP 还是 UDP 都没有提供 throughput 或 timing 的保证，但这并不意味着即时通讯软件无法在互联网中使用，因为应用的开发者尽可能保证了它们的产品在糟糕的网络环境下也能正常运转。

大部分的网络应用 (例如电子邮件、文件传输、远程控制) 都采用 TCP 协议，因为 reliable data transfer 对它们来说非常重要。一些网络电话应用对数据丢失容忍度较高，可能会采取 UDP 协议来绕过 TCP 的拥塞控制和 packet overhead；但由于很多防火墙会拦截大部分的 UDP traffic，所以网络电话应用通常会把 TCP 当作 UDP 失效时的后备选项。

### 2.1.5 Application-Layer Protocols

之前我们讨论的都是下层如何传输 message，但 message 本身的结构和内容也十分重要。**应用层协议 (application-layer protocol)** 负责这一部分。通常来说应用层协议会定义：

* message 的类型 (request/response etc.)；
* 各种类型的 message 的语法、各个字段的语义；
* 一系列规则，定义一个进程应该什么时候以什么方式发送 message。

我们需要注意区分网络应用和应用层协议：后者只是前者的一个组成部分 (不过是很重要的一部分)。以网页为例，网页这个应用包含了文档的格式标准 (HTML)、网页浏览器、网页服务器，以及应用层协议。网页所采用的 HTTP 协议规定了浏览器和服务器交换数据的方式，只是网页这一应用的一个组成部分。

### 2.1.6 Network Applications Covered in This Book

本书讨论 5 个重要的应用：网页、电子邮件、目录服务、视频流和 P2P。

## 2.2 The Web and HTTP

在 20 世纪 90 年代初，因特网仍然只是一个研究员、学者、高校学生远程连接、传输数据的小圈子。但 World Wide Web 这一应用的出现让因特网火爆全球。网页最大的特点就是提供 on demand 的服务，用户可以在任意时刻获取信息，而不是像看电视，听收音机那样要在指定的时间守候。

### 2.2.1 Overview of HTTP

**超文本传输协议 (HyperText Transfer Protocol, HTTP)** 是网页使用的应用层协议，处在整个应用的核心位置。HTTP 分为客户端程序和服务端程序，这两个程序通过交换 HTTP message 通信，HTTP 定义了 message 的结构和消息交换的方式。

首先介绍一些概念：一个 Web page (aka. document) 包含一系列的对象，一个对象就是一个可以通过 URL 索引的文件 (HTML, JPG, Javascript, CSS 等等)。Web page 包含的对象中有一个是 base HTML 文件，该文件通过 URL 去索引别的对象。每个 URL 都有 host name 和 path name 两个部分。例如

```
http://www.someSchool.edu/someDepartment/picture.gif
```

中 `www.someSchool.edu` 是 host name，`/someDepartment/picture.gif` 是 path name。

HTTP 规定的 client-server 交互方式简单来说就是 client 向 server 发送 HTTP request，server 收到后向 client 发送 HTTP response。HTTP 使用 TCP 作为下层的传输协议，因此 TCP connection 建立后，在 client 眼中它只要把 HTTP request 发送到 socket，然后等一会儿这个“神奇的小门”就会把 HTTP response 呈现出来；在 server 眼中它只要从 socket 中取出 HTTP request，分析后把相关的数据用 socket 传回去即可。计算机网络的层状结构使得 HTTP 这样的顶层协议完全不需要担心数据丢失、重新发送等问题，这些细节都由 TCP 以及更下次层的协议栈搞定。

服务器端不会存储任何的额外信息。例如如果 client 连续两次请求同一个文件，server 就会连续发两次，而不会智能地在第二次回复“你已经请求过这个文件了”。因此 HTTP 是一种**无状态协议 (stateless protocol)**。

### 2.2.2 Non-Persistent and Persistent Connections

在许多网络应用中 client 和 server 之间会进行多次通信，于是一个需要思考的问题是应该为每一次通信建立一个 TCP connection 还是用一个 TCP connection 完成多次通信。前者被称为 **non-persistent connection**，后者被称为 **persistent connection**。这两者各有利弊，虽然 HTTP 默认 persistent，但 client/server 可以选择将其配置为 non-persistent。

#### HTTP with Non-Persistent Connections

在 non-persistent 的连接中，client 向 server 索取一个页面 (base HTML + 10 JPG) 会经历如下的过程：

* client 与 server 建立 TCP connection，并向 server 发送 HTTP request。
* server 接收到请求后，将相关的文件传输回去，并告诉 TCP 关闭连接 (连接不会直接关闭，会等 client 接收到文件再关闭)。
* client 接收到文件后 (此时 connection 正式关闭)，发现 HTML 文件中索引了 10 张图片，于是用 step1&2 的方式将 10 张图片拿到手。

可以看到在 non-persistent connection 中，每个 TCP connection 只能传输一个对象。不过上述过程也有一些优化的空间，比如获取图片时 client-server 之间可以并行地开多个 connection 一起传输，这样可以节省时间。

之前的描述中我们简化了建立连接的过程，事实上建立 TCP connection 有一定的 overhead。我们定义 **round-trip time (RTT)** 为一个 packet 从 client 到 server 再回到 client 所需的时间，client 和 server 之间完成一个对象的传输需要经历“三步握手”—— client 向 server 发送一个 segment、server 回复一个 segment (此时连接建立)、client 向 server 发送 request，然后 server 将对象文件以流水线的方式通过 connection 发送回来。获取一个对象总共需要的时间为
$$
2\times RTT+\frac{Size(object)}{\text{server's transmission rate}}
$$

#### HTTP with Persistent Connections

建立 persistent connection 可以免去创建连接的 overhead，而且多次 request 可以用流水线的方式发送，不需要等前一个 request 得到 response 后再发送下一个，因此效率很高。

### 2.2.3 HTTP Message Format

#### HTTP Request Message

一个 HTTP request message 的通用格式如下：

```c++
method URL Version \r\n        // Request line
HeaderFieldName: value \r\n    /*                */
    ...                        /*  Header lines  */
HeaderFieldName: value \r\n    /*                */
\r\n
...                            /*               */
...                            /*  Entity body  */
...                            /*               */
```

request message 的第一行被称为 **request line**，后续的若干行称为 **header line**。下面是一个具体的例子：

```http
GET /somedir/page.html HTTP/1.1
Host: www.someschool.edu
Connection: close
User-agent: Mozilla/5.0
```

Request line 中，GET 是一个 method (最常用)，通常用于从服务器获取内容；URL 指定了服务器中文件的路径；Version 指定了 HTTP 版本。Header line 中，`Host` 指定了主机地址；`Connection: close` 表示建立一个 non-persistent 的连接，本次传输完成后就关闭；`User-agent` 指定了客户端 (浏览器) 的版本，服务器可以根据版本返回更加适配的 message (比如同一个文件的不同版本)。除此之外还有很多的 header line 可以选择。

GET 方法后面没有 entity body，但其他方法后面是可以有 entity body 的，例如 POST 方法通常用于填写网页中的表格，用户填写的内容就放在 entity body 中传给服务器。(注：值得一提的是事实上现在大部分的应用还是使用 GET 方法来传输填表结果，它们会把填写的内容放到 URL 里，比如填写了 apple 和 banana，那么 URL 就会形如 `www.somesite.com/fruitsearch?apple&banana`。)

除了 GET 和 POST，HEAD 方法和 GET 类似，但服务器不会返回请求的对象，通常用于 debugging；PUT 方法用于向服务器上传文件；DELETE 方法用于在服务器中删除文件。

#### HTTP Response Message

一个 HTTP request message 的通用格式如下：

```c++
version StatusCode Phrase \r\n  // Status line
HeaderFieldName: value \r\n     /*                */
    ...                         /*  Header lines  */
HeaderFieldName: value \r\n     /*                */
\r\n
...                             /*               */
...                             /*  Entity body  */
...                             /*               */
```

Response message 的第一行被称为 **status line**，后续的若干行被称为 **header line**。下面是一个具体的例子：

```http
HTTP/1.1 200 OK
Connection: close
Date: Tue, 18 Aug 2015 15:44:04 GMT
Server: Apache/2.2.3 (CentOS)
Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT
Content-Length: 6821
Content-Type: text/html
(data data data data data ...)
```

括号中的 `(data data ...)` 表示 entity body 的内容 (即 client 要的数据)。

status line 中，`HTTP/1.1` 表示了 protocol version，`200 OK` 是 status code 和对应的状态描述。常见的 status code 如下：

* `200 OK`：请求成功。
* `301 Moved Permanently`：请求的资源已经被永久移除。该资源的新地址会在 header line 区域中以 `Location: ...` 的形式给出。
* `400 Bad Request`：请求无法解析。
* `404 Not Found`：请求的东西不存在。
* `505 HTTP Version Not Supported`：HTTP 协议版本不支持。

header line 中，比较有意思的一些 line 包括：`Connection: close` 告诉 client 该消息传输完成后 TCP connection 就会被关闭；`Date:` 中的日期指的是服务器接收到请求，将资源提取出来的时间 (而不是文件的创建时间)；`Content-Type` 指明了返回文件的类型，文件的类型由该字段决定而不由其扩展名决定。

浏览器的版本、类型，用户配置，以及当前本地是否有 cached 的对象旧版本……这些因素都会影响 client 发送 request 时包含哪些 header line，在服务器端影响因素是类似的。

### 2.2.4 User-Server Interaction: Cookies

我们之前提到 HTTP 是一个 stateless 的协议，但很多时候服务器希望能识别用户以及记录用户的状态，从而提供更好的服务/将一些用户写入黑名单。HTTP 使用 cookie 完成该功能。

Cookie 技术包含 4 个组成部分：(1) HTTP response message 中的 cookie header line (2) HTTP request message 中的 cookie header line (3) 浏览器负责管理的本地 cookie file (4) 服务器端存储 cookie 相关信息的数据库。 Cookie 的工作流程如下：

* 假设一个新用户第一次访问某网站 (发送 request message)，该网站识别到这是一个新用户后，会在数据库中为该用户创建一个 cookie id、在数据库中存储一些用户相关的信息，并在 response message 中加入一条 cookie header line，格式为 `Set-cookie: cookie-id`。
* 浏览器处理 response message 发现形如 `Set-cookie` 的 header line 后，会把该服务器分配的 cookie id 存入本地的一个 cookie file 中。
* 之后这个用户如果再访问该网站，浏览器会检索 cookie file，发现有对应的 cookie id 则会以 `Cookie: cookie-id` 的形式在 request message 中添加一个 cookie header line。服务器处理 request message 时则可以根据 cookie-id 在数据库中调取该用户相关的信息。

尽管 Cookie 可以优化用户的上网体验，但其在隐私泄漏上的问题也使其倍受争议。

### 2.2.5 Web Caching

Web cache (也称 proxy server) 通常由 ISP 购买和安装，其作用和计算机系统中的 cache 类似：当用户希望从真正的服务器获取文件时，它会和 proxy server 建立 TCP connection，proxy server 会首先检查自己本地有没有该文件，如果有就直接传回给用户，如果没有则会与真正的服务器建立一个 TCP connection，获取文件后一方面传回给用户，一方面在自己本地留一个副本以便后续用户直接取用。

Web cache 有两点好处：一方面它与用户机器建立连接、传输数据的速度更快，可以优化用户的 delay；另一方面在一个小局域网中安装 web cache 可以防止大量的请求外溢到因特网中，从而减少因特网的流量压力，减少整个网络的 queuing delay 等等。

#### The Conditional GET

所有的类 cache 策略都要考虑数据一致性的问题。HTTP 协议提供了 conditional GET 这一机制来使 cache 完成和服务器的同步。具体来说，当 cache 希望确认自己手上的副本是否是最新版时，它会向真正的服务器发送一个 GET request，其中增加一个 header line：`If-modified-since: xxx`。服务器检查本地文件的最后修改时间，如果正好匹配则会返回空消息告诉 cache 副本已是最新 (status code 为 `304 Not Modified`)，否则会将新版本传回。

### 2.2.6 HTTP/2

2015 年标准化的 HTTP/2 相较于 HTTP/1.1 的主要优势是它能够只使用一个 TCP connection 完成 response multiplexing。

HTTP/1.1 默认使用 persistent TCP connection，即只使用一个 TCP connection 从一个服务器获取多个文件。这样的做法存在一个 **Head of Line (HOL) blocking** 的问题：假设当前网页的第一个 object 是一个特别大的视频，后面跟着的是一堆小的 object，那么 HTTP/1.1 按顺序传输会导致在第一个 object 上花费很多时间，从而整个网页很久都完全显现不出来。为了绕过这个问题，HTTP/1.1 会开很多个 TCP connection 来并行传输。不过多个 TCP connection 会共享带宽，这使得网络应用会尽可能“多开一点” TCP connection 以占取更大份额的带宽 (比如两个应用各开一个，那么一人一半带宽，但如果有人恶意开了 10 个连接，他就能占据 10/11 的带宽)。

#### HTTP/2 Framing

HTTP/2 解决这个问题的方法类似于操作系统的分时多任务：在 HTTP/1.1 中一个 response message 没法拆开，但 HTTP/2 允许将一个大的 message 拆成若干个 frame，然后多个 message 轮流一人一个 frame 地传输，这样小 message 就可以很快地传完。

<img src="https://kristoff-starling.github.io/img/HTTP1vs2-frame.png" style="zoom:50%;" />

该策略的技术难点是如何将大的 message 拆分。HTTP/2 里专门设计了一个 framing sub-layer，负责 message 的拆分和重组。

#### Response Message Prioritization and Server Pushing

HTTP/2 在“分时多任务”的基础上支持一定程度的“用户自定义”，例如用户可以为各个 request 设置优先级、依赖关系等等。

HTTP/2 的另一个特性是允许 server 对一个 request 返回多个 response。例如用户请求一个网页，服务器自动分析发现这个网页附带一些 object，就可以 response 时 push 一些额外的 object 给客户端，这样在用户发出 object 请求之前就返回文件，省去了一些延迟。

## 2.3 Electronic Mail in the Internet

电子邮件系统主要由三个部分组成：**user agent**, **mail server** 和**简单邮件传输协议 (Simple Mail Transfer Protocol, SMTP)**。每个电子邮件用户都在自己的 mail server 上有自己的**邮箱 (mailbox)**。user agent 可以理解为在用户主机上和自己的 mail server 交互，操控邮箱的软件。假设 Alice 给 Bob 发送邮件，首先 Alice 的 user agent 将邮件上传到 Alice 的邮箱中，然后 mail server 负责将邮件发送到 Bob 的 mail server (更准确地说，是将该邮件 append 到 **message queue** 中，等待发送)，Bob 的 mail server 接收到邮件后将其存放在 Bob 的邮箱中。当 Bob 打开自己的 user agent 查看邮件时，user agent 将邮件内容从 mail server 上抓取下来。如果 Alice 的 mail server 迟迟无法发送成功，它在尝试多次后会删除这个 message 并向 Alice 返回发送失败。

SMTP 协议负责的是不同 mail server 之间传输的部分。它使用 TCP 提供的 reliable data transfer service 传输邮件。SMTP 有 client 和 server 两个端，每个 mail server 既要运行 client 也要安装 server，它发送邮件时是 client，接收邮件时是 server。

### 2.3.1 SMTP

SMTP 是比 HTTP 古老得多的应用层协议。因此它有一些“过时的特征”，例如它要求整个 mail message 都要使用 7-bit 的 ASCII 码传输，这使得使用 SMTP 前后需要有 encoding/decoding 的额外步骤。

SMTP 工作的基本流程为：

* mail server 将待发送的邮件放入 message queue 后，安装在 mail server 上的 SMTP 客户端发现有新邮件，于是根据其内容与目标地址建立 TCP connection，连接目标机器的 25 号端口。
* TCP connection 建立后双方会经过一个握手过程，该过程中双方会交换邮件的发送人、接收人等信息。
* 握手完成后，正式开始邮件内容的传输。

下面是一个具体的例子：

```plaintext
S: 220 hamburger.edu
C: HELO crepes.fr
S: 250 Hello crepes.fr, pleased to meet you
C: MAIL FROM: <alice@crepes.fr>
S: 250 alice@crepes.fr ... Sender ok
C: RCPT TO: <bob@hamburger.edu>
S: 250 bob@hamburger.edu ... Recipient ok
C: DATA
S: 354 Enter mail, end with "." on a line by itself
C: (data)
C: (data)
C: .
S: 250 Mesage accepted for delivery
C: QUIT
S: 221 hmburger.edu closing connection
```

这里所有的行都是 client/server 直接通过 TCP 传输的内容。client 在这里使用了 `HELO` `MAIL FROM` `RCPT TO` `DATA` `QUIT` 等命令，server 对于每条命令都会返回 reply code 以及 (optional) 一些英文解释。

值得注意的是 SMTP 使用 persistent TCP connection，即两个 mail server 之间可以通过一个 TCP connection 传输多封邮件。每封邮件的传输都从 `MAIL FROM` 开始，到传输完数据后的 `.` 结束。传输完所有邮件后 client 再使用 `QUIT` 退出。

### 2.3.2 Mail Message Formats

SMTP 对邮件内容的格式也有一定的要求。一封邮件除了其主体内容外还有若干 header line，其中 `From` 和 `To` 这两个 header line 必须有，`Subject` 等 header line 是可选的。一封典型的邮件内容如下：

```plaintext
From: alice@crepes.fr
To: bob@hamburger.edu
Subject: Searching for the meaning of life.

(body) (body) (body) ...
```

需要注意的是之前提到的 `MAIL FROM` `RCPT TO` 和这里的 `From` 和 `To` 不一样：前者是两个 mail server 握手阶段使用的命令，后者是邮件本身内容的一部分。

### 2.3.3 Mail Access Protocols

有人认为 Bob (接收者) 没有必要拥有一个额外的 mail server，他自己的终端设备就可以是 server，这样发送者直接把邮件发送到它的终端设备上就好。但一个问题是用户的终端设备并不一定一直处于联网状态 (比如没信号，或者没电关机了)，这样发送者就会发送失败。因此我们总是需要一台 24 小时待命的服务器负责接收邮件，Bob 在自己 available 的时候再去查看邮件。

mail server 向 mail server 发送邮件使用 SMTP 协议，Alice (发送者) 向自己的 mail server 上传邮件也可以使用 SMTP 协议 (或者 HTTP) 协议，但在 Bob (接收者) 这一端，他不能使用 SMTP 协议，因为他需要的是一个 pull 操作，而 SMTP 是一个 push 协议。一般情况下，如果接收者使用网页版的 e-mail 或者手机应用，user agent 会使用 HTTP 协议来获取邮件；另外一种方式 (例如 Microsoft Outlook)，则是使用 **Internet Mail Access Protocol (IMAP)** 协议来获取邮件。这两个协议都可以让 Bob 对位于 mail server 中的自己的邮箱里的内容进行访问、修改、标记等等。

## 2.4 DNS - The Internet's Directory Service

一台主机在网络中有多种”称呼方法“，最常见的 identifier 是 **hostname**，例如 `www.facebook.com`。hostname 对人类非常友好，但提供的信息有限，其不固定的长度也不便于路由器处理。因此网络实现中更普遍使用的 identifier 是 **IP 地址 (IP address)**。IP 地址 (IPv4) 共占 4 个字节，用 4 个 `[0,256)` 的整数表示。IP 地址有着严格的等级结构，就像 postal address 一样，越往后得到的信息越详细越细节。

### 2.4.1 Services Provided by DNS

**域名系统 (domain name system, DNS)** 的主要任务是将 hostname 翻译成对应的 IP 地址。DNS 是一个应用层协议，在服务器端它有一群分布式的 DNS server 存储域名信息。DNS 协议基于 UDP 运行，默认端口号是 53。

DNS 通常被 HTTP, SMTP 等其他应用层协议使用，例如 HTTP 协议想要发送 request message 时，会启动 DNS 应用的客户端，将域名发送给 DNS server，DNS server 返回对应的 IP 地址，然后 HTTP 通过 IP 地址建立 TCP connection。DNS 解析的步骤是通信过程的一个额外的 delay。

除了域名解析，DNS 还提供以下的服务：

* Host aliasing：一台有着比较复杂的 hostname 的机器还可以有一些更好记的别名。原本的 hostname 称为 **canonical hostname**，别名则称为 alias hostname。DNS 提供将 alias hostname 翻译成 canonical hostname (以及 IP 地址) 的服务。
* Mail server aliasing：和 host aliasing 类似，mail server 也可以有更好记的别名，DNS 提供翻译服务。
* Load distribution：有很多网页背后会使用一群服务器来提供支持，每台服务器有各自的 IP 地址，但它们共享一个 hostname。当 DNS 解析这样的 hostname 时，它会返回一个 IP 地址的 list，不过每次请求它返回的结果都会 shift 一下，这是因为大部分的协议通常选择 list 的第一个 IP 地址发送请求，每次 shift 一下可以使得各个服务器均匀地承受流量。

### 2.4.2 Overview of How DNS Works

最简单的想法是使用一台 DNS server 处理所有的请求，可惜这样简单的设计至少有如下的一些问题：

* A single point of failure：只要这台 DNS server 挂了，全球的 DNS 服务就都挂了。
* Traffic volume：这台服务器承受全球的 DNS request 的流量，会导致严重的 delay。
* Distant centralized database：地球上总有一些地区离这台服务器很远，这些地区使用 DNS 服务会有很高的 delay。
* Maintenance：这一台服务器需要大得惊人的容量来存储所有的 IP 地址，还需要不断更新。

因此，分布式成为了 DNS server 必须的选择。

#### A Distributed, Hierarchical Database

为了解决上面的问题，DNS 使用了大量的服务器，以 hierarchical 的方式组织起来分布在全世界。DNS 等级体系中共有三类服务器：

* Root DNS server：全球共有 1000 多个，它们是 13 个不同的 root server 的复制，它们的主要任务是根据顶级域名提供对应的 TLD server 的 IP 地址。
* Top-level domain (TLD) server：每一个顶级域名——如 `com` `org` `net` `edu`，以及国家顶级域名——如 `us` `cn` `jp` `fr` 都各自有对应的 TLD server (或 server cluster)。它们的主要任务是根据下一级域名提供 authoritative server 的 IP 地址。
* Authoritative DNS server：每一个接入公网的组织都必须提供外界可访问的 DNS 记录，这些记录保存在组织的 authoritative DNS server 上。

除了这三类服务器，还有一类服务器称为 **local DNS server** (aka. default name server)，它不属于等级体系中但也非常重要，可以理解为主机使用 DNS 服务的 proxy server。

一台主机通过 DNS 服务查询另一台主机的 IP 地址的过程大致如下图所示。该查询过程是 iterative + recursive 形式的。Local DNS server 作为 requesting server 的代表，顺序地向各个层级的 DNS server 发送请求，最终将结果返回给 requesting server。

<img src="https://kristoff-starling.github.io/img/DNS-example1.png" style="zoom:33%;" />

该查询过程也可以是 fully recursive 的，每一个服务器都把整个任务交给下一级服务器，并将最终结果返回给上一层服务器。

<img src="https://kristoff-starling.github.io/img/DNS-example2.png" style="zoom:33%;" />

可以看到不论是哪种顺序，在该例子中 requesting server 总是需要 8 次消息传输才能获得 IP 地址，效率不高。

#### DNS Caching

DNS caching 是减少 DNS 查询过程 delay 的一项关键技术。各个层级的 DNS server 内部都有 cache 维护hostname 到 IP 地址的映射表。这样如果有多次对同一个 hostname 的查询，DNS server 就不用把查询下放到底层的 authoritative server 而可以直接返回。不过由于 hostname 的 IP 地址是可以变的，通常 DNS server 两天就会 flush 一次 cache。

Cache 中除了存储 hostname 的 IP 地址，还可以存储一些 DNS server 的 IP 地址，这样的好处是可以绕过上级 server 直接发送查询给下层 server。

### 2.4.3 DNS Records and Messages

各级 DNS server 完成了对分布式 DNS 数据库的抽象。DNS 数据库中存储的数据称为 **resource record (RR)**。一条 RR 是一个四元组 `(Name, Value, Type, TTL)`。其中 `TTL` 表示该数据的生存周期，即服务器应该过多久将其从 cache 中 flush 掉。剩下的三个属性：

* 若 `Type=A`，则 `Name` 是一个 hostname，`Value` 是一个 IP 地址，A record 是 hostname-IP mapping。
* 若 `Type=NS`，则 `Name` 是一个 domain，`Value` 是保存了该 domain 下所有 host 地址的 authoritative server 的 hostname。NS record 用于指引 DNS server 继续深入 query chain。
* 若 `Type=CNAME`，则 `Name` 是一个 alias hostname，`Value` 保存了对应的 canonical hostname。CNAME record 用于 host aliasing 的翻译。
* 若 `Type=MX`，则 `Name` 是一个 mail server 的别名，`Value` 保存了对应的 canonical hostname。MX record 用于 mail server aliasing 的翻译。

如果一个 DNS server 是某个 hostname 的 authoritative server，那么它里面会存储该 hostname 的 A record。如果一个 DNS server 不是某个 hostname 的 authoritative server，那么它会存储包括了该 hostname 的 domain 的 NS record，以及一条记录 NS record 中主机的 IP 地址的 A record。

#### DNS Message

DNS message 的格式如下：

```plaintext
Identification              Flags                       //
Number of questions         Number of answer RRs        //    12 bytes
Number of authority RRs     Number of additional RRs    //
----------------------------------------------------------------------
Questions 
(variable number of questions)   // Name, type field for a query
----------------------------------------------------------------------
Answers 
(variable number of RRs)         // RRs in response to query
----------------------------------------------------------------------
Authority
(variable number of RRs)         // Records for authoritative servers
----------------------------------------------------------------------
Additional information
(variable number of RRs)         // Additional info that may be used
```

query 和 reply message 有着相同的格式：

* header section 共 12 个字节，由一系列的字段组成。第一个字段是 16 bit 的 identifier，reply message 的 identifier 是对应 query 的 identifier，这样 client 就可以把请求和回复对应上；Flag 字段包括指明这是 query 还是 reply 的 flag，DNS server 是否是 authoritative server 的 flag，要求是否使用 recursion 的 flag 等。此外还有 4 个计数的字段。
* question section 包含询问信息，主要有询问的 name 和 type。
* answer section 由 reply message 使用，包含一条或多条 resource record。
* authority section 包含其他 authoritative server 的 record。
* additional section 包含其他的有用信息，比如某些 canonical hostname 的 IP 地址。

#### Inserting Records into the DNS Database

想要新建网站的人需要通过 registrar 获得域名且需要提供自己的 hostname 和 IP 地址，数据库管理员负责将数据录入数据库。

> **DNS Vulnerabilities**
>
> 对 DNS 的攻击主要有以下几类：
>
> * DDoS 攻击：历史上发生过两次重大的针对 DNS 的 DDoS 攻击：一次攻击针对所有的 root DNS server，由于 root server 有较好的保护机制，且大多数的 local DNS server 的 cache 可以绕过 root server 直接走下层，所以该攻击没有取得好的效果。另一次攻击针对 top-level domain DNS server，这次攻击就比较有效。
> * man-in-the-middle attack：截获 DNS query，并返回一个虚假的 reply 给用户。
> * DNS poisoning attack：和中间人攻击类似，不过这种攻击的目的是将 DNS server 将错误的信息写入 cache，直接污染数据库。

## 2.5 Peer-to-Peer File Distribution

前面章节介绍的所有应用都是 client-server 模式的，应用的正常运转需要一直处于运行状态的服务器。在 P2P 模式中，互相连接的 host 可以直接交互，节省了一些 overhead。

### Scalability of P2P Architecture

考虑如下的一个简化的场景：有 $N$ 个节点需要服务器上的一个文件，该文件的大小为 $F$ bits。服务器上传的速度是 $u_s$，第 $i$ 台客户机下载的速度是 $d_i$，上传的速度是 $u_i$。

在 client-server 架构中，没有人帮助服务器分发文件，所以 $N$ 个节点共 $NF$ bits 的数据都要由服务器自己上传。此外每个节点下载自己的文件需要时间。假设上传和下载可以并行地完成，令 $d_{min}=\min\\{d_1,\cdots, d_n\\}$，则
$$
D_{cs}\geq \max\left\\{\frac{NF}{u_s},\frac{F}{d_{min}}\right\\}
$$
在 P2P 架构中，一方面第一份文件需要服务器自己上传，一方面每个节点下载自己的文件需要时间，一方面每个节点在下载的同时也参与到上传中，后续的上传工作可以合力完成。所以
$$
D_{P2P}\geq \max\left\\{\frac{F}{u_s},\frac{F}{d_{min}},\frac{NF}{u_s+\sum_{i=1}^nu_i}\right\\}
$$
可以证明在精巧的设计下两个时间都可以达到下界。可以看到 client-server 模式下时间是关于 $N$ 的线性函数， P2P 模式下时间关于 $N$ 的函数上升速度缓慢且有极限，所以 P2P 模式的 scalability 更好。

### BitTorrent

BitTorrent 是当下最流行的 P2P 文件分发协议之一。这里简单介绍一些 BitTorrent 的机理。在 BitTorrent 中参与一个文件 distribution 的 peer 的集合称为一个 torrent。每个 torrent 中都有一个节点称为 tracker，一个节点新加入 torrent 时会到 tracker 那里注册，tracker 会每隔一段时间检查每个节点是否还在 torrent 中并更新 active list。

对于一个新加入的节点，tracker 会随机选择一些 peer 并将其 IP 地址发送给新节点，新节点会尝试和这些 peer 建立 TCP connection，成功建立 connection 的 peer 被称为 neighboring peer。由于 torrent 中随时会有节点退出也随时会有新节点加入，一个节点的 neighboring peer 集合是动态变化的。

文件的共享以 chunk (256KB) 为单位。在任意时刻，一个节点手里会有该文件的某些 chunk，它的目标是收集自己还没有的其他 chunk，所以每隔一段时间节点会向自己的 neighbor 询问他们手里拥有哪些 chunk，并根据信息向一些 neighbor 发送索求 chunk 的申请。于是对于每个节点来说，它有两件事情需要考虑：一是应当先去索要哪些 chunk，二是如何应付别的节点发送过来的 request。

* 对于第一个问题，BitTorrent 采取 **rarest first** 的策略，即优先申请那些自己没有的，且在 neighbor 中出现次数最少的 chunk。这样的好处是可以让那些比较稀有的 chunk 迅速在网络中传播开来，提高文件分享的速率。

* 对于第二个问题，BitTorrent 采取了一个非常聪明的 trading algorithm，称为 tit-for-tat。每个节点会实时维护自己的所有 neighbor 向自己传输文件的速率 (每过 10s 刷新，更准确地说是在一个 time interval 内传输的数据量)，并选择排名前 4 高的节点向它们发送数据。排名前 4 的 neighbor 被称为 **unchoked**。此外每过 30s 节点会随机选择一个自己的 neighbor 并向其发送数据 (不论其排名如何)，这个节点被称为 **optimistically unchoked**。除了这 4+1 个 neighbor，剩下的 neighbor 都被称为 choked，它们无法获得该节点的数据。

    unchoked 和 optimistically unchoked 各自有道理。unchoked 的选择使得节点之间倾向于互相帮助互惠共利，同时一定程度上避免了一些只索取不付出的“吸血节点”来捣乱。optimistically unchoked 的选择可以理解为向一个“陌生”节点示好，尝试与其建立“外交关系”，如果陌生节点积极的予以反馈，那么这对节点就可能逐渐地将对方升级为自己的 top 4。此外，一个刚进入网络的节点手里没有任何 chunk，无法向外界提供数据，所以刚开始不可能成为任何节点的 top 4。optimistically unchoked 可以让这些萌新节点免费获得一些初始成本，帮助其快速融入网络。

## 2.6 Video Streaming and Content Distribution Networks

### 2.6.1 Internet Video

Video 的本质是 sequence of images，其最显著的特点就是 high bit rate，因此视频会消耗大量存储，视频的传输会消耗大量的流量。当然，我们可以通过压缩技术来获得同一个视频的不同码率的版本，码率越高，视频质量越高，消耗资源也越大。

### 2.6.2 HTTP Streaming and DASH

在 HTTP streaming 中，视频文件和普通的文件无异，有一个可以索引的 URL。client 可以通过 HTTP GET 指令来获取视频。由于视频较长获取较慢，通常客户端会准备一个 client application buffer，GET 指令不断获取数据存入 buffer，当 buffer 中的数据量超过一个阈值时，客户端程序就会开始播放——从 buffer 中抓取 video frame、解压、呈现在用户屏幕上。这样客户端就实现了边下载边观看。

HTTP streaming 的一个问题是：无论当前用户的网络状况如何，它都只能获取固定码率的视频，因此网速不好时视频播放容易卡顿。**动态自适应流媒体 (Dynamic Adaptive Streaming over HTTP, DASH)** 技术致力于缓解该问题。在 DASH 中一个视频会有多个不同码率的版本，以不同的 URL 存放在 server 中。此外 server 里有一个 **manifest file** 提供了可选择的码率版本和对应的 URL。一个完整的视频被划分成了若干小的 chunk，client 首先会获取 manifest file，了解不同的码率版本，然后根据当前的网络状况选择一个合适的码率版本用 HTTP GET 获取一个 chunk，获取的过程中客户端同时收集本次获取的网速等信息，从而决定下一个 chunk 选哪个版本。这样，DASH 允许了 client 在多个不同版本的视频中自由切换。

### 2.6.3 Content Distribution Networks

Content provider 需要建立 data center 来存储提供给用户的视频资源。正如 DNS server 只建一个有诸多弊端，如果服务商只建一个超大的 data center，就会有部分地区延时高、单点崩溃意味着全盘崩溃等问题。因此几乎所有的 video-streaming 公司都采用了 **Content Distribution Network (CDN)**，建立一个分布式的服务器群，服务器的选址通常有如下两种策略：

* Enter Deep：将服务器打入到 access network 内部，海量部署小服务器，尽可能靠近用户以减小用户的 delay 并提高 throughput。这种方式成本和后续维护的代价都比较高。
* Bring Home：建立数量较少规模较大的服务器，部署在 IXP 中。这种方式代价较低但用户体验也相对较差。

通常来说 CDN 不会让每台服务器都存储所有资源的副本，而是让服务器扮演 cache 的角色。如果用户索求的资源在当前服务器中没有，服务器会向上层做 pull request，得到后发送给用户的同时在自己本地留一个副本。

#### CDN Operation

这里以一个例子讲述 CDN 的运行过程。假设 content provider 公司 NetCinema 使用了第三方 CDN 公司 KingCDN 的服务。NetCinema 的一个视频的 URL 是 `video.netcinema.com/abc`，那么用户获取视频的流程如下：

* 用户访问该视频链接时，用户主机发出了一条关于 `vidio.netcinema.com` 的 DNS request。
* 用户的 Local DNS server (LDNS) 一层层访问到 NetCinema 公司的 authoritative server 并将其发送请求。authoritative server 注意到该域名的前缀是 `video`，知道视频其实是交给 KingCDN 托管的，所以它返回了 KingCDN 的域名给用户的 LDNS，从而将用户 redirect 到 KingCDN。
* LDNS 收到了一个新域名，于是它再次发送 DNS query，一层层访问到了 KingCDN 的 authoritative server，authoritative server 会选择一个 CDN server 并将其 IP 地址返回给 LDNS。
* LDNS 将 IP 地址给用户后，用户主机与指定的 CDN server 建立 TCP connection 并获取视频。

#### Cluster Selection Strategies

上述过程中有一步“选择一个 CDN server”，这其中很有讲究。CDN deployment 的核心便是 cluster selection strategy。CDN 的 authoritative server 接收到 LDNS 的 DNS query 时可以获知用户的 IP 地址，从而获得一些用户相关的信息。authoritative server 可以根据这些信息选择一个“最好“的 CDN server。

最简单常用的一个策略是 **geographically closest**。地理距离近通常意味着传输时间短，但这个策略有时不灵光——第一，地理距离短并不一定意味着 link 少；第二，有些用户的 LDNS 和终端设备之间可能隔了很远；第三，该策略完全没有考虑网络的动态状况。因此，除了该策略外 CDN 还可以通过一些 real-time measurement 来影响 CDN server 分配的决策。

### 2.6.4 Case Studies: Netflix and YouTube

#### Netflix

Netflix 的特色在于它有一个巨大的 Amazon cloud 处于核心位置，Amazon cloud 负责视频的处理，不同版本的生成，并将内容推送到 CDN server 中。由于 Netflix 建立了自己的 private CDN network，CDN operation 的步骤不像上一节那样有一个 redirect 的过程，Amazon cloud 可以直接指定 CDN server。此外，Netflix 使用的是 push cache，即 Amazon cloud 会在非高峰时间将内容主动推送到 CDN server 上，而不是让 CDN server 动态地在 cache miss 时索取。

#### YouTube

类似于 Amazon cloud，Google data center 会完成视频的处理，版本生成等工作。YouTube 也有自己的 private CDN network。和 Netflix 不同的地方在于：YouTube 使用 pull cache，以及 YouTube 不支持 DASH，只能让用户手动选择码率后使用 HTTP streaming。

## 2.7 Socket Programming: Creating Network Applications

略