<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">
  <meta name="msvalidate.01" content="2370EBA239781ABCE950FABB5C4177B1" />

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Yuyao Wang">

  
  
  
    
  
  <meta name="description" content="Unbiasedness $\fbox{Definition 20.1}$ 设 $\hat\theta(X_1,\cdots, X_n)$ 是 $\theta$ 的一个估计量。$\Theta$ 为 $\theta$ 的取值范围。如果对于任意 $\theta\in \Theta$，有 $$ E[\hat\theta(X_1,\cdots, X_n)]=\theta $$ 则称 $\hat\theta$ 是 $\theta$ 的无偏估计量。
注：该式子的意思在于，虽然 $\theta$ 的估计量因为采样的原因可能和真实值有偏差，但采样次数足够多以后 $\hat\theta\rightarrow\theta$，即无偏性意味着没有系统误差。
【例】设 $X_1,\cdots, X_n$ 来自总体 $X$，且$E[X^j]=\mu_j$ 存在，则 $A_j=\frac{1}{n}\sum_{k=1}^nX_k^j$ 是 $\mu_j$ 的无偏估计。这是因为 $$ E[A_j]=E\left[\frac{1}{n}\sum_{k=1}^nX_k^j\right]=\frac{1}{n}\sum_{k=1}^nE[X_k^j]=\frac{1}{n}\cdot nE[X^j]=E[X^j] $$ 【例】设 $X_1,\cdots, X_n$ 来自总体 $X$，且 $D(X)=\sigma^2$ 存在，则样本方差 $S^2$ 是 $\sigma^2$ 的无偏估计。这是因为 $$ \begin{align} S^2&amp;=\frac{1}{n-1}\sum_{k=1}^n(X_k-\overline{X})^2\\ &amp;=\frac{1}{n-1}\sum_{k=1}^n(X_k^2-2X_k\overline{X}&#43;\overline{X}^2)\\ &amp;=\frac{1}{n-1}\left(\sum_{k=1}^nX_k^2-2\overline{X}\sum_{k=1}^nX_k&#43;\sum_{k=1}^n\overline{X}^2\right)\\ &amp;=\frac{1}{n-1}\left(\sum_{k=1}^nX_k^2-2n\overline{X}^2&#43;n\overline{X}^2\right)\\ &amp;=\frac{1}{n-1}\sum_{k=1}^nX_k^2&#43;\frac{n}{n-1}\overline{X}^2 \end{align} $$ 从而 $$ \begin{align} E[S^2]&amp;=\frac{1}{n-1}\sum_{k=1}^nE[X_k^2]-\frac{n}{n-1}E[\overline{X}^2]\\ &amp;=\frac{1}{n-1}\sum_{k=1}^n(\sigma^2&#43;\mu^2)-\frac{n}{n-1}E\left[\left(\frac{1}{n}\sum_{k=1}^nX_k\right)^2\right]\\ &amp;=\frac{n}{n-1}(\sigma^2&#43;\mu^2)-\frac{1}{n(n-1)}\left(\sum_{k=1}^nE[X_k^2]&#43;2\sum_{1\leq i&lt;j\leq n}E[X_iX_j]\right)\\ &amp;=\frac{n}{n-1}(\sigma^2&#43;\mu^2)-\frac{1}{n(n-1)}\cdot n(\sigma^2&#43;\mu^2)-\frac{2}{n(n-1)}\binom{n}{2}E[X]^2\\ &amp;=\sigma^2&#43;\mu^2-\mu^2\\ &amp;=\sigma^2 \end{align} $$ $E[S^{*2}]=E[\frac{n-1}{n}S^2]=\frac{n-1}{n}\sigma^2$，因此二阶中心矩不是方差的无偏估计。不过 $\lim_{n\rightarrow \infty}E[S^{*2}]=\sigma^2$，所以称 $S^{*2}$ 是 $\sigma^2$ 的渐进无偏估计。">

  
  <link rel="alternate" hreflang="en-us" href="https://kristoff-starling.github.io/post/writing-technical-content-copy/">

  


  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="https://kristoff-starling.github.io/post/writing-technical-content-copy/">

  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Yuyao Wang&#39;s Homepage">
  <meta property="og:url" content="https://kristoff-starling.github.io/post/writing-technical-content-copy/">
  <meta property="og:title" content="Lecture : Criterion of Estimator | Yuyao Wang&#39;s Homepage">
  <meta property="og:description" content="Unbiasedness $\fbox{Definition 20.1}$ 设 $\hat\theta(X_1,\cdots, X_n)$ 是 $\theta$ 的一个估计量。$\Theta$ 为 $\theta$ 的取值范围。如果对于任意 $\theta\in \Theta$，有 $$ E[\hat\theta(X_1,\cdots, X_n)]=\theta $$ 则称 $\hat\theta$ 是 $\theta$ 的无偏估计量。
注：该式子的意思在于，虽然 $\theta$ 的估计量因为采样的原因可能和真实值有偏差，但采样次数足够多以后 $\hat\theta\rightarrow\theta$，即无偏性意味着没有系统误差。
【例】设 $X_1,\cdots, X_n$ 来自总体 $X$，且$E[X^j]=\mu_j$ 存在，则 $A_j=\frac{1}{n}\sum_{k=1}^nX_k^j$ 是 $\mu_j$ 的无偏估计。这是因为 $$ E[A_j]=E\left[\frac{1}{n}\sum_{k=1}^nX_k^j\right]=\frac{1}{n}\sum_{k=1}^nE[X_k^j]=\frac{1}{n}\cdot nE[X^j]=E[X^j] $$ 【例】设 $X_1,\cdots, X_n$ 来自总体 $X$，且 $D(X)=\sigma^2$ 存在，则样本方差 $S^2$ 是 $\sigma^2$ 的无偏估计。这是因为 $$ \begin{align} S^2&amp;=\frac{1}{n-1}\sum_{k=1}^n(X_k-\overline{X})^2\\ &amp;=\frac{1}{n-1}\sum_{k=1}^n(X_k^2-2X_k\overline{X}&#43;\overline{X}^2)\\ &amp;=\frac{1}{n-1}\left(\sum_{k=1}^nX_k^2-2\overline{X}\sum_{k=1}^nX_k&#43;\sum_{k=1}^n\overline{X}^2\right)\\ &amp;=\frac{1}{n-1}\left(\sum_{k=1}^nX_k^2-2n\overline{X}^2&#43;n\overline{X}^2\right)\\ &amp;=\frac{1}{n-1}\sum_{k=1}^nX_k^2&#43;\frac{n}{n-1}\overline{X}^2 \end{align} $$ 从而 $$ \begin{align} E[S^2]&amp;=\frac{1}{n-1}\sum_{k=1}^nE[X_k^2]-\frac{n}{n-1}E[\overline{X}^2]\\ &amp;=\frac{1}{n-1}\sum_{k=1}^n(\sigma^2&#43;\mu^2)-\frac{n}{n-1}E\left[\left(\frac{1}{n}\sum_{k=1}^nX_k\right)^2\right]\\ &amp;=\frac{n}{n-1}(\sigma^2&#43;\mu^2)-\frac{1}{n(n-1)}\left(\sum_{k=1}^nE[X_k^2]&#43;2\sum_{1\leq i&lt;j\leq n}E[X_iX_j]\right)\\ &amp;=\frac{n}{n-1}(\sigma^2&#43;\mu^2)-\frac{1}{n(n-1)}\cdot n(\sigma^2&#43;\mu^2)-\frac{2}{n(n-1)}\binom{n}{2}E[X]^2\\ &amp;=\sigma^2&#43;\mu^2-\mu^2\\ &amp;=\sigma^2 \end{align} $$ $E[S^{*2}]=E[\frac{n-1}{n}S^2]=\frac{n-1}{n}\sigma^2$，因此二阶中心矩不是方差的无偏估计。不过 $\lim_{n\rightarrow \infty}E[S^{*2}]=\sigma^2$，所以称 $S^{*2}$ 是 $\sigma^2$ 的渐进无偏估计。"><meta property="og:image" content="https://kristoff-starling.github.io/post/writing-technical-content-copy/featured.jpg">
  <meta property="twitter:image" content="https://kristoff-starling.github.io/post/writing-technical-content-copy/featured.jpg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-07-12T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2019-07-12T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://kristoff-starling.github.io/post/writing-technical-content-copy/"
  },
  "headline": "Lecture : Criterion of Estimator",
  
  "image": [
    "https://kristoff-starling.github.io/post/writing-technical-content-copy/featured.jpg"
  ],
  
  "datePublished": "2019-07-12T00:00:00Z",
  "dateModified": "2019-07-12T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Yuyao Wang"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Yuyao Wang's Homepage",
    "logo": {
      "@type": "ImageObject",
      "url": "https://kristoff-starling.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Unbiasedness $\\fbox{Definition 20.1}$ 设 $\\hat\\theta(X_1,\\cdots, X_n)$ 是 $\\theta$ 的一个估计量。$\\Theta$ 为 $\\theta$ 的取值范围。如果对于任意 $\\theta\\in \\Theta$，有 $$ E[\\hat\\theta(X_1,\\cdots, X_n)]=\\theta $$ 则称 $\\hat\\theta$ 是 $\\theta$ 的无偏估计量。\n注：该式子的意思在于，虽然 $\\theta$ 的估计量因为采样的原因可能和真实值有偏差，但采样次数足够多以后 $\\hat\\theta\\rightarrow\\theta$，即无偏性意味着没有系统误差。\n【例】设 $X_1,\\cdots, X_n$ 来自总体 $X$，且$E[X^j]=\\mu_j$ 存在，则 $A_j=\\frac{1}{n}\\sum_{k=1}^nX_k^j$ 是 $\\mu_j$ 的无偏估计。这是因为 $$ E[A_j]=E\\left[\\frac{1}{n}\\sum_{k=1}^nX_k^j\\right]=\\frac{1}{n}\\sum_{k=1}^nE[X_k^j]=\\frac{1}{n}\\cdot nE[X^j]=E[X^j] $$ 【例】设 $X_1,\\cdots, X_n$ 来自总体 $X$，且 $D(X)=\\sigma^2$ 存在，则样本方差 $S^2$ 是 $\\sigma^2$ 的无偏估计。这是因为 $$ \\begin{align} S^2\u0026amp;=\\frac{1}{n-1}\\sum_{k=1}^n(X_k-\\overline{X})^2\\\\ \u0026amp;=\\frac{1}{n-1}\\sum_{k=1}^n(X_k^2-2X_k\\overline{X}+\\overline{X}^2)\\\\ \u0026amp;=\\frac{1}{n-1}\\left(\\sum_{k=1}^nX_k^2-2\\overline{X}\\sum_{k=1}^nX_k+\\sum_{k=1}^n\\overline{X}^2\\right)\\\\ \u0026amp;=\\frac{1}{n-1}\\left(\\sum_{k=1}^nX_k^2-2n\\overline{X}^2+n\\overline{X}^2\\right)\\\\ \u0026amp;=\\frac{1}{n-1}\\sum_{k=1}^nX_k^2+\\frac{n}{n-1}\\overline{X}^2 \\end{align} $$ 从而 $$ \\begin{align} E[S^2]\u0026amp;=\\frac{1}{n-1}\\sum_{k=1}^nE[X_k^2]-\\frac{n}{n-1}E[\\overline{X}^2]\\\\ \u0026amp;=\\frac{1}{n-1}\\sum_{k=1}^n(\\sigma^2+\\mu^2)-\\frac{n}{n-1}E\\left[\\left(\\frac{1}{n}\\sum_{k=1}^nX_k\\right)^2\\right]\\\\ \u0026amp;=\\frac{n}{n-1}(\\sigma^2+\\mu^2)-\\frac{1}{n(n-1)}\\left(\\sum_{k=1}^nE[X_k^2]+2\\sum_{1\\leq i\u0026lt;j\\leq n}E[X_iX_j]\\right)\\\\ \u0026amp;=\\frac{n}{n-1}(\\sigma^2+\\mu^2)-\\frac{1}{n(n-1)}\\cdot n(\\sigma^2+\\mu^2)-\\frac{2}{n(n-1)}\\binom{n}{2}E[X]^2\\\\ \u0026amp;=\\sigma^2+\\mu^2-\\mu^2\\\\ \u0026amp;=\\sigma^2 \\end{align} $$ $E[S^{*2}]=E[\\frac{n-1}{n}S^2]=\\frac{n-1}{n}\\sigma^2$，因此二阶中心矩不是方差的无偏估计。不过 $\\lim_{n\\rightarrow \\infty}E[S^{*2}]=\\sigma^2$，所以称 $S^{*2}$ 是 $\\sigma^2$ 的渐进无偏估计。"
}
</script>

  

  


  


  





  <title>Lecture : Criterion of Estimator | Yuyao Wang&#39;s Homepage</title>

  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Yuyao Wang&#39;s Homepage</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Yuyao Wang&#39;s Homepage</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/courses"><span>Courses</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/yuyao_CV.pdf"><span>CV</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      

      

    </ul>

  </div>
</nav>


  <article class="article">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Lecture : Criterion of Estimator</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Jul 12, 2019
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    2 min read
  </span>
  

  
  
  

  
  

</div>

  














</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 480px;">
  <div style="position: relative">
    <img src="/post/writing-technical-content-copy/featured_huc72159e0fc0d14b85f60d34436a630f0_266353_720x0_resize_q90_lanczos.jpg" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <h2 id="unbiasedness">Unbiasedness</h2>
<p>$\fbox{Definition 20.1}$ 设 $\hat\theta(X_1,\cdots, X_n)$ 是 $\theta$ 的一个估计量。$\Theta$ 为 $\theta$ 的取值范围。如果对于任意 $\theta\in \Theta$，有
$$
E[\hat\theta(X_1,\cdots, X_n)]=\theta
$$
则称 $\hat\theta$ 是 $\theta$ 的无偏估计量。</p>
<p>注：该式子的意思在于，虽然 $\theta$ 的估计量因为采样的原因可能和真实值有偏差，但采样次数足够多以后 $\hat\theta\rightarrow\theta$，即无偏性意味着没有系统误差。</p>
<p>【例】设 $X_1,\cdots, X_n$ 来自总体 $X$，且$E[X^j]=\mu_j$ 存在，则 $A_j=\frac{1}{n}\sum_{k=1}^nX_k^j$ 是 $\mu_j$ 的无偏估计。这是因为
$$
E[A_j]=E\left[\frac{1}{n}\sum_{k=1}^nX_k^j\right]=\frac{1}{n}\sum_{k=1}^nE[X_k^j]=\frac{1}{n}\cdot nE[X^j]=E[X^j]
$$
【例】设 $X_1,\cdots, X_n$ 来自总体 $X$，且 $D(X)=\sigma^2$ 存在，则样本方差 $S^2$ 是 $\sigma^2$ 的无偏估计。这是因为
$$
\begin{align}
S^2&amp;=\frac{1}{n-1}\sum_{k=1}^n(X_k-\overline{X})^2\\
&amp;=\frac{1}{n-1}\sum_{k=1}^n(X_k^2-2X_k\overline{X}+\overline{X}^2)\\
&amp;=\frac{1}{n-1}\left(\sum_{k=1}^nX_k^2-2\overline{X}\sum_{k=1}^nX_k+\sum_{k=1}^n\overline{X}^2\right)\\
&amp;=\frac{1}{n-1}\left(\sum_{k=1}^nX_k^2-2n\overline{X}^2+n\overline{X}^2\right)\\
&amp;=\frac{1}{n-1}\sum_{k=1}^nX_k^2+\frac{n}{n-1}\overline{X}^2
\end{align}
$$
从而
$$
\begin{align}
E[S^2]&amp;=\frac{1}{n-1}\sum_{k=1}^nE[X_k^2]-\frac{n}{n-1}E[\overline{X}^2]\\
&amp;=\frac{1}{n-1}\sum_{k=1}^n(\sigma^2+\mu^2)-\frac{n}{n-1}E\left[\left(\frac{1}{n}\sum_{k=1}^nX_k\right)^2\right]\\
&amp;=\frac{n}{n-1}(\sigma^2+\mu^2)-\frac{1}{n(n-1)}\left(\sum_{k=1}^nE[X_k^2]+2\sum_{1\leq i&lt;j\leq n}E[X_iX_j]\right)\\
&amp;=\frac{n}{n-1}(\sigma^2+\mu^2)-\frac{1}{n(n-1)}\cdot n(\sigma^2+\mu^2)-\frac{2}{n(n-1)}\binom{n}{2}E[X]^2\\
&amp;=\sigma^2+\mu^2-\mu^2\\
&amp;=\sigma^2
\end{align}
$$
$E[S^{*2}]=E[\frac{n-1}{n}S^2]=\frac{n-1}{n}\sigma^2$，因此二阶中心矩不是方差的无偏估计。不过 $\lim_{n\rightarrow \infty}E[S^{*2}]=\sigma^2$，所以称 $S^{*2}$ 是 $\sigma^2$ 的渐进无偏估计。</p>
<p>【例题】设 $X_1,\cdots, X_n$ 来自总体 $X\sim U[0,\theta]$，令 $M_n=\max_{1\leq k\leq n}X_k$，求证：$\hat\theta=\frac{n+1}{n}M_n$ 是 $\theta$ 的无偏估计。</p>
<blockquote>
<p>证明：$X$ 的分布函数为
$$
F(x)=\begin{cases}
0&amp;,x\leq 0\\
\frac{x}{\theta}&amp;,0\leq x\leq \theta\\
1&amp;,x&gt;\theta
\end{cases}
$$
从而 $M_n$ 的分布函数为
$$
F_n(x)=\begin{cases}
0&amp;,x\leq 0\\
\left(\frac{x}{\theta}\right)^n&amp;,0\leq x\leq \theta\\
1&amp;,x&gt;\theta
\end{cases}
$$
密度函数：
$$
p_n(x)=\begin{cases}
\frac{n}{\theta}\left(\frac{x}{\theta}\right)^{n-1}&amp;,0\leq x\leq \theta\\
0&amp;,otherwise
\end{cases}
$$
从而
$$
E[\hat\theta]=E\left[\frac{n+1}{n}M_n\right]=\frac{n+1}{n}\int_0^\theta x\cdot \frac{n}{\theta}\left(\frac{x}{\theta}\right)^{n-1}dx=\theta
$$</p>
</blockquote>
<p>注：$2\overline{X}$ 也是 $\theta$ 的无偏估计，这说明无偏估计可能是不唯一的。</p>
<p>即是 $\hat\theta$ 是 $\theta$ 的无偏估计，$g(\hat\theta)$ 也未必是 $g(\theta)$ 的无偏估计，下面是一个例子：</p>
<p>【例】设 $\hat\theta$ 是 $\theta$ 的无偏估计，即 $E[\hat\theta]=\theta$，且 $D(\hat\theta)&gt;0$，那么我们发现
$$
E[\hat\theta^2]=D(\hat\theta)+E[\hat\theta]^2=D(\hat\theta)+\theta^2\geq \theta^2
$$
因而 $(\hat\theta)^2$ 不是 $\theta^2$ 的无偏估计。</p>
<h2 id="mean-square-error-criterion">Mean Square Error Criterion</h2>
<p>$\fbox{Definition 20.2}$ 记 $M(\hat\theta,\theta)\triangleq E[(\hat\theta-\theta)^2]$ 为均方误差。</p>
<p>注：(1) $\hat\theta$ 是随机变量，我们希望对于任意 $\theta$，$M(\hat\theta,\theta)$ 尽量小。</p>
<p>(2)
$$
\begin{align}
M(\hat\theta,\theta)&amp;=E[(\hat\theta-\theta)^2]=E[(\hat\theta-E[\hat\theta]+E[\hat\theta]-\theta)^2]\\
&amp;=E[(\hat\theta-E[\hat\theta])^2]+2E[(\hat\theta-E[\hat\theta])(E[\hat\theta]-\theta)]+E[(E[\hat\theta]-\theta)^2]\\
&amp;=D(\hat\theta)+(E[\hat\theta]-\theta)^2
\end{align}
$$
(注：$\hat\theta$ 是一个随机变量，$\theta$ 是一个数。)</p>
<p>当 $\hat\theta$ 是 $\theta$ 的无偏估计时，$M(\hat\theta,\theta)=D(\hat\theta)$。</p>
<p>【例】设 $X_1,\cdots, X_n$ 来自总体 $X\sim U[0,\theta]$，现比较 $\hat{\theta_0}=2X_1$，$\hat{\theta_1}=2\overline{X}$ 和 $\hat{\theta_2}=\frac{n+1}{n}M_n$ 的均方误差。注意到这三者都是无偏估计，从而
$$
\begin{align}
M(\hat\theta_0,\theta)&amp;=D(\hat\theta_0)=D(2X_1)=4D(X)=\frac{4\theta^2}{12}=\frac{\theta^2}{3}\\
M(\hat\theta_1,\theta)&amp;=D(\hat\theta_1)=D(2\overline{X})=4D\left(\frac{1}{n}\sum_{k=1}^nX_k\right)=\frac{4}{n^2}\sum_{k=1}^nD(X_k)=\frac{4}{n}\cdot\frac{\theta^2}{12}=\frac{\theta^2}{3n}\\
M(\hat\theta_2,\theta)&amp;=D(\hat\theta_2)=\left(\frac{n+1}{n}\right)^2D(M_n)=\left(\frac{n+1}{n}\right)^2(E[M_n^2]-E[M_n]^2)\\
&amp;=\left(\frac{n+1}{n}\right)^2\left(\int_0^\theta x^2\frac{n}{\theta}\left(\frac{x}{\theta}\right)^{n-1}dx-\left(\frac{n}{n+1}\theta\right)^2\right)\\
&amp;=\left(\frac{n+1}{n}\right)^2\left(\frac{n}{n+2}\theta^2-\left(\frac{n}{n+1}\right)^2\theta^2\right)\\
&amp;=\frac{1}{n(n+2)}\theta^2
\end{align}
$$
注：(1) 对比 $\hat\theta_1$ 和 $\hat\theta_0$ 可知，增加采样数可以提高估计量的精度。</p>
<p>(2) 注意到 $M_n$ 是极大似然估计，类似地可算得 $M(M_n,\theta)\sim\frac{\theta^2}{n^2}$。而 $2\overline{X}$ 是矩估计，故在本例中极大似然估计优于矩估计。</p>
<h2 id="consistency">Consistency</h2>
<p>$\fbox{Definitino 20.3}$ 设 $\hat\theta_n(X_1,\cdots, X_n)$ 是 $\theta$ 的一个估计量，若对于任意 $\theta\in \Theta$，有 $\hat\theta_n\overset{P}{\rightarrow}\theta$，则称 $\hat\theta_n$ 是 $\theta$ 的一致估计量。</p>
<p>注：(1) 矩估计具有一致性，在一定条件下可以证明极大似然估计也具有一致性。</p>
<p>(2) 不具有一致性 (增加采样数不能提高精度) 的估计量不可取。</p>
<p>【例】设 $X_1,\cdots, X_n$ 来自总体 $X\sim U[0,\theta]$，则 $\hat\theta_1=2\overline{X}$，$\hat\theta_2=\frac{n+1}{n}M_n$  和 $\hat\theta_3=M_n$ 都具有一致性。这是因为</p>
<p>(1) $\hat\theta_1=\frac{2}{n}\sum_{k=1}^nX_k$，$X_1,\cdots,X_n$ 独立同分布且方差一致有界，所以 $\hat\theta_1$ 服从大数定律，即对于任意 $\varepsilon&gt;0$，
$$
\begin{align}
&amp;\quad\space\lim_{n\rightarrow\infty}P\left(\left|\hat\theta_1-\frac{2}{n}\sum_{k=1}^nE[X_k]\right|&gt;\varepsilon\right)=0\\
&amp;\Rightarrow\lim_{n\rightarrow\infty}P\left(\left|\hat\theta_1-\frac{2}{n}\cdot n\frac{\theta}{2}\right|&gt;\varepsilon\right)=0\\
&amp;\Rightarrow\lim_{n\rightarrow\infty}P\left(\left|\hat\theta_1-\theta\right|&gt;\varepsilon\right)=0
\end{align}
$$
所以 $\hat\theta_1\overset{P}{\rightarrow}\theta$。</p>
<p>(2) $E[\hat\theta_2]=\theta$，$D(\hat\theta_2)=\frac{1}{n(n+2)}\theta^2$，由切比雪夫不等式得
$$
P\left(\left|\hat\theta_2-\theta\right|&gt;\varepsilon\right)=P\left(\left|\hat\theta_2-E[\hat\theta_2]\right|&gt;\varepsilon\right)\leq\frac{1}{\varepsilon^2}D(\hat\theta_2)=\frac{\theta^2}{\varepsilon^2}\frac{1}{n(n+2)}\overset{n\rightarrow \infty}{\longrightarrow}0
$$
(3) $E[\hat\theta_3]=\frac{n}{n+1}\theta$，$D(\hat\theta_3)=\frac{n}{(n+1)^2(n+2)}\theta^2$。
$$
\begin{align}
P\left(\left|\hat\theta_3-\theta\right|&gt;\varepsilon\right)&amp;=P\left(\left|\hat\theta_3-\frac{n}{n+1}\theta-\frac{1}{n+1}\theta\right|&gt;\varepsilon\right)\\
&amp;\overset{triangle}{\leq} P\left(\left|\hat\theta_3-\frac{n}{n+1}\theta\right|+\left|\frac{1}{n+1}\theta\right|&gt;\varepsilon\right)\\
&amp;\leq P\left(\left{\left|\hat\theta_3-\frac{n}{n+1}\theta\right|&gt;\frac{\varepsilon}{2}\right}\cup\left{\frac{1}{n+1}\theta&gt;\frac{\varepsilon}{2}\right}\right)\\
&amp;\leq P\left(\left|\hat\theta_3-\frac{n}{n+1}\theta\right|&gt;\frac{\varepsilon}{2}\right)+P\left(\frac{1}{n+1}\theta&gt;\frac{\varepsilon}{2}\right)
\end{align}
$$
当 $n\rightarrow \infty$ 时，后一项趋于 0，前一项现在的形式是 $\hat\theta_3-E[\hat\theta_3]$ 的形式，因此可以运用切比雪夫不等式：
$$
P\left(\left|\hat\theta_3-\frac{n}{n+1}\theta\right|&gt;\frac{\varepsilon}{2}\right)\leq \frac{4}{\varepsilon^2}D(\hat\theta_3)=\frac{4n}{(n+1)^2(n+2)}\theta^2\overset{n\rightarrow\infty}{\longrightarrow}0
$$</p>

    </div>

  

  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.f8eb5cb10262ef4a670903a5cb3e03ae.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    <span id="busuanzi_container_site_pv">
        Total Visit: <span id="busuanzi_value_site_pv"></span>
    </span>

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
