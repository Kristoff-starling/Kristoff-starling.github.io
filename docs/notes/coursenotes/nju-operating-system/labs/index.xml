<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Labs | Yuyao Wang&#39;s Homepage</title>
    <link>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/</link>
      <atom:link href="https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/index.xml" rel="self" type="application/rss+xml" />
    <description>Labs</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 13 Dec 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Labs</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/</link>
    </image>
    
    <item>
      <title>Lab 00: AM Game</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab00/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab00/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;该实验的主要目的是在 abstract-machine 抽象的 bare-metal 上编写一个小游戏。笔者实现的小游戏是贪吃蛇。&lt;/p&gt;
&lt;h2 id=&#34;designation&#34;&gt;Designation&lt;/h2&gt;
&lt;h3 id=&#34;api&#34;&gt;API&lt;/h3&gt;
&lt;p&gt;我们需要使用的比较重要的 AM 的接口有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;putch()&lt;/code&gt; 及其封装版本 &lt;code&gt;puts()&lt;/code&gt; ，负责向控制台输出字符和字符串。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AM_TIMER_UPTIME&lt;/code&gt; ，对该抽象寄存器进行读取可以获得系统启动以来运行时间的微秒数。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AM_INPUT_KEYBRD&lt;/code&gt;，对该抽象寄存器进行读取可以获得一个 AM_INPUT_KEYBRD_T 结构体，其中存储了当前是否有按键被按下，被按下的按键编码等。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AM_GPU_CONFIG&lt;/code&gt;，对该抽象寄存器进行读取可以获得 VGA 的基本信息，包括窗口宽高的像素数量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AM_GPU_FBDRAW&lt;/code&gt;，对该抽象寄存器写入一个 AM_GPU_FBDRAW_T 结构体可以向 VGA 输出一个方格的颜色。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;game-logic&#34;&gt;Game Logic&lt;/h3&gt;
&lt;p&gt;一个游戏的基本框架为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;while (1)
{
    while (uptime() &amp;lt; next_frame);
    
    while ((key = read_key() != AM_KEY_NONE)
    	kbd_event(key);
    
    game_process();
    screen_update();
    next_frame += 1000 / FPS;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于贪吃蛇游戏：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在 kbd_event() 中，我们需要处理 ESC 按键，令其调用 halt()，以及四个方向键用于控制贪吃蛇的行走方向。笔者还设置了按 &lt;code&gt;R&lt;/code&gt; 键重新开始游戏的功能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 game_process() 中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们需要维护贪吃蛇每一节身体的位置，并将头部按照当前方向移动一格，判断有没有出现撞墙或者吃了自己的情况，如果出现了，在游戏主循环中应该停止画面更新。&lt;/li&gt;
&lt;li&gt;我们需要维护食物，如果食物和蛇头重合，则应该分数+1，并随机一个位置 (不能和蛇重合) 重新放置食物。&lt;/li&gt;
&lt;li&gt;为了逐步增加游戏的难度，笔者维护 &lt;code&gt;FPS = 5 + (score / 2)&lt;/code&gt;，即每多得两分，贪吃蛇的移动速度便会加快一级。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 screen_update() 中，我们可以将背景涂成黑色，将边缘涂成橙色，将蛇身涂成绿色，蛇头涂成蓝色，食物涂成红色。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Lab 01: Physical Memory Manager</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab01/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab01/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;该实验的目标是实现一个 (内核使用的) 堆区的内存分配器。以下主要记录一些有趣的设计/性能调优经历。&lt;/p&gt;
&lt;h2 id=&#34;designation&#34;&gt;Designation&lt;/h2&gt;
&lt;p&gt;维护堆区的数据结构应该放在堆区里，所以我们不应该开静态数组保存维护堆区的链表等，而应该将链表节点就存储在空闲的内存块上 (反正空闲的内存块当前也没有有效信息)。&lt;/p&gt;
&lt;p&gt;由于 kfree() 只传入了要释放内存块的起始地址，而没有传入 size，所以我们应当在 kalloc() 的时候记录每个释放出去的内存块的大小。笔者最初的实现是维护了一个分配出去的内存块的链表，kfree() 到来时，在链表里查找给定的地址是否存在以及对应的大小。但这样效率太低，于是笔者使用了在地址前打魔数的方法。笔者定义了一个如下的 header：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define ALLOC_MAGIC 0x1234567;
typedef struct __header_t {
    size_t sz;
    union {
        uintptr_t magic;
        struct __header_t *next;
    };
}header_t;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;每个内存块前都有一个这样的 header。这个 header 的好处是：未分配内存和已分配内存可以共用这个 header，当内存块处于未分配状态时，内存块被放在链表中，union 字段存放的是下一个链表节点的地址；当内存块处于已分配状态时，union 字段存放魔数。一个 kfree() 地址来临时，只要查看其前一个 &lt;code&gt;uintptr_t&lt;/code&gt; 中是不是 ALLOC_MAGIC，就能确定这个地址合不合法，再往前看就能获得内存块的 size。&lt;/p&gt;
&lt;p&gt;(注：使用 header 的方法有一个弱点：原本在堆区中 1B 的内存加上 header 后变得很大。此外，由于对齐的原因，我们无法将多个大小相同的内存块“挨在一起”存放在堆区中，中间有很多“洞”。)&lt;/p&gt;
&lt;p&gt;由于 pmm 会被并发地执行，所以访问共享数据结构要上锁。&lt;/p&gt;
&lt;h2 id=&#34;defensive-programming&#34;&gt;Defensive Programming&lt;/h2&gt;
&lt;p&gt;笔者认为以下的防御性编程是有意义的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 kalloc(), kfree() 中加入足够的对地址性质，空间大小分析的 panic(), panic_on() 等，这有助于提前发现 failure。&lt;/li&gt;
&lt;li&gt;笔者实现的自旋锁中记录了当前拥有锁的 CPU 编号，这样在 acquire() 和 release() 前检查当前是否拥有锁，可以有效防御 AA-deadlock 和一些意料之外的情况。&lt;/li&gt;
&lt;li&gt;kalloc()/kfree() 结束时应该将对应内存区间 memset 成奇怪数值，这样后续使用时如果忘了清零/地址溢出，读到垃圾数据可以加快 failure 出现的速度，减少排查 bug 的时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但以上防御性编程对效率有一定影响，因此笔者在提交 OJ 的版本中没有编译这些 (尤其是第三条) 防御性编程。&lt;/p&gt;
&lt;h2 id=&#34;performance-tuning&#34;&gt;Performance Tuning&lt;/h2&gt;
&lt;p&gt;该实验对效率有一定的要求，笔者主要使用 Linux perf 工具对代码的运行时间/并行度进行观测。本地 Workload 的信息为：$60%$ 的 128K 以内内存分配，$30%$ 的 pagesize 内存分配，$10%$ 的大内存分配。释放的频率和分配相仿。每个核做 400,000 次分配和回收。&lt;/p&gt;
&lt;p&gt;笔者做过如下优化：&lt;/p&gt;
&lt;h3 id=&#34;fast-path&#34;&gt;Fast Path&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;将整个堆区分成 &lt;code&gt;cpu_count()&lt;/code&gt; 份，每个 CPU 核只在自己的那一份的链表中 alloc() 和 free() (free 时根据地址还到相应的资源区中)，因为一个核的 kalloc() 可能在另一个核中 kfree()，所以即使分成了多份，访问数据结构依旧要上锁。如果本地资源不足，则从别的资源区偷资源。该做法有一定效率提升，但不明显。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;slab。笔者对 1KB 以下内存分配的每种大小都开了一个单独的链表，对 pagesize (4KB) 也开了一个链表。slab 的核心做法是：没有资源时走 slow path，从全局资源中批发很多小块串成链表；有资源时直接从链表头取一个小块。这里每次走 slow path 批发多少个小块是一个需要调整的参数，不同的参数会对效率和失败率产生影响。&lt;/p&gt;
&lt;p&gt;这里的一个细节是：笔者希望每个核从自己的 slab 中获取资源，释放时将资源释放到自己的 slab 中，这样 fast path 不需要上锁。但提交 OJ 发现 smp=2 时就会出现 low memory usage，这很可能是因为 OJ 上两个核的任务不对称，如一个核专门 kalloc()，一个核专门 kfree()，导致资源全部堆积在第二个核的 slab 里无法利用。因此笔者不得不对 slab 的访问上锁，本地 slab 没有资源时去偷别人的 slab 的资源。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为了减少 slab 上的锁拥堵，笔者尝试了以下两种“玄学”优化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个核 kalloc() 时随机一个 slab 取资源，kfree() 时随机一个 slab 还资源 (其实两个都随机和只随机一个效果是一样的)。该策略只需要访问一个 slab，比之前的偷资源策略要高效一些，且打破了”不对称任务“约束，不会 low memory usage。该优化在本地 workload 中显著减少了锁的拥堵程度。&lt;/li&gt;
&lt;li&gt;为了进一步减少锁的拥堵 (毕竟两个核随机到一个 slab 的概率还是不小的)，笔者给每个核选定一个 target slab (这是一个 permutation)，每个核向 target slab 索取资源，释放时归还到 target slab 中。为了避免“不对称任务”约束，每进行一定次数的分配后，shuffle 一下 target slab 的 permutation。该优化在本地的 workload 中相较前一种方法确实进一步减少了锁的拥堵程度，但没有看到明显的效率提升。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;slow-path&#34;&gt;Slow Path&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;为了防止 (可以避免的) 过于破碎的内存，链表中应当有合并机制，即插入一个节点后，将其与左右邻居比较，若端点重合则合并节点。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OSTEP 中提到过 best/first/next fit 等多种寻找可用节点的策略，如果使用 first fit，一段时间后堆区的前部就会出现较多破碎内存，后部相对完整，使搜索相对较慢。next fit 理论上会有更好的表现，但笔者没有在本地测试中观测到明显的效率提升。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为了进一步减少破碎内存，笔者使用如下策略：一个内存块如果被分配完后剩余空间过少 (小于一个阈值)，则不选择切分这个内存块，而是将整块给当前分配。这样可以减少链表中容量很小的内存块个数。该优化在本地 workload 中体现出了效果。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在一次 alloc() 失败后，记录这次的需求大小，在下一次 free() 来临之前，如果再出现大于之前失败最小值的 alloc()，可以不遍历链表直接返回 NULL。注意 free() 之后要将记录变量清空。该优化在失败率比较高的 workload 中体现出了效果。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;笔者发现完全抛弃链表，只用一个全局指针维护堆区，对于一个分配寻找全局指针最近的下一个对齐点 (结合 slab，kfree() 直接放到 slab 中) 的方法不会在 OJ 中报 low memory usage。这样复杂的链表操作被大幅简化。该优化在本地 workload 中体现出巨大效果。(注：如果很小的内存 alloc 和很大的内存 alloc 交替出现，该方法会浪费很多内存。该方法属于用失败率换效率的一个尝试。)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;即使笔者结合 Fast Path 和 Slow Path 中能想到的最优的实现，也无法通过旧版 OJ 上 &lt;code&gt;smp=8&lt;/code&gt; 的测试用例。在本地 workload 下笔者的最优实现可以在 1.5s 到 2s 完成 8 核的所有任务。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lab 02: Kernel Multi-Threads</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab02/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab02/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;该实验的主要内容是实现内核线程的调度。本实验报告主要记录一些有趣的设计和测试方法。&lt;/p&gt;
&lt;h2 id=&#34;designation&#34;&gt;Designation&lt;/h2&gt;
&lt;h3 id=&#34;spinlock&#34;&gt;spinlock&lt;/h3&gt;
&lt;p&gt;在 L2 中我们需要实现一个相较于 L1 更加精细的自旋锁。在引入了中断机制后，我们在临界区内需要关闭中断，否则一旦持有锁的线程被调度下了 CPU 一整个时间片就会卡住。我们需要小心地维护中断的嵌套。我们需要一个 per-cpu 的变量来记录中断嵌套的层数，在第一层的时候关闭中断，并在最后一层被解开时打开中断。&lt;/p&gt;
&lt;h3 id=&#34;inline-assembly&#34;&gt;Inline Assembly&lt;/h3&gt;
&lt;p&gt;笔者的初代实现使用了內联汇编进行栈切换 (模仿 xv6 的设计)，因而是架构相关的 (笔者针对 x86-64 和 x86 各写了一遍汇编)。在这种实现下，一次线程切换 (以时钟中断为例) 会经历如下历程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;经过 AM 中的一些代码后，上下文保存在了栈上的 Context 结构体中，进入 os-&amp;gt;trap。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;os-&amp;gt;trap 根据中断原因，进入时钟中断的 handler。时钟中断要求当前线程主动让出 CPU。handler 会通过一个 swtch() 函数 (內联汇编) 跳转到 scheduler 线程，该函数原理类似 setjmp 和 longjmp，恢复寄存器现场并切换栈。scheduler 线程使用自己的独立的栈 (即不是线程的内核栈)，每个 CPU 核一个。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;调度器线程是一个死循环，它不断选择状态为 RUNNABLE 的线程并调用 swtch() 函数切换过去。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;目标线程返回自己的 Context 结构体。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种写法下，每个 os-&amp;gt;trap 最终返回的 Context 结构体就是传进来的那个，因此不需要对 Context 做额外的保存。这其中有一些细节需要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scheduler 线程必须打开中断，比如当前所有 input_task 线程都处于睡眠状态，我们只有让调度器线程响应键盘中断信号，才能唤醒这些 input_task 线程。&lt;/li&gt;
&lt;li&gt;CPU 上锁之前的中断开关情况是一个 proc local 的状态，在调用 swtch() 切换前必须保存下来：比如在笔者的实现中，我们可能是在中断处理程序中 yield，这时 intena 是关中断状态；而信号量的 sleep() 中也会调用 swtch()，这时 intena 是开中断状态。&lt;/li&gt;
&lt;li&gt;不使用 AM API 的最大坏处是：我们必须手动维护第一次进入一个线程的过程，因为我们之后切换到一个线程依赖的是它之前有一个 swtch() 到 scheduler 的现场，但一个进程刚被创建时没有现场。笔者的解决方法是：伪造一个寄存器现场完成栈切换，并通过一个內联汇编的 wrapper call 直接跳转到目标函数执行 (类似 M2)。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;semaphore&#34;&gt;Semaphore&lt;/h3&gt;
&lt;p&gt;笔者为每个信号量准备了一把锁，这样可以用类似条件变量的方式实现信号量。sem_wait() 和 sem_post() 共用信号量的锁，sleep() 通过线程的锁来保证原子性。这其中的关键细节在于 sleep() 中先获取线程锁再释放信号量锁，这样对于 wait() 函数来说，sleep() 释放锁、线程睡眠 (修改线程的状态) 和线程切换这几个步骤就是原子的。&lt;/p&gt;
&lt;p&gt;有了信号量之后，我们可以使用 binary semaphore 作为一个睡眠锁，在长临界区的代码片段中睡眠锁可以提升效率。&lt;/p&gt;
&lt;h2 id=&#34;testing&#34;&gt;Testing&lt;/h2&gt;
&lt;h3 id=&#34;producer-consumer&#34;&gt;Producer Consumer&lt;/h3&gt;
&lt;p&gt;在多核上多线程跑生产者消费者是一种比较好的暴露并发 bug 的好方法。在测试集的参数上笔者有如下心得：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们并不需要将括号打印在屏幕上肉眼检查，可以选择写一个 python 程序接收 oslab 的输出自动检查，或者在 oslab 的括号输出函数中直接修改一个全局计数器并执行检查。&lt;/li&gt;
&lt;li&gt;创建较多的线程，将括号的嵌套层数调得浅一些 (比如 5 以内) 比较有利于测试并发正确性，因为嵌套层数浅时更容易触发错误，以及生产者/消费者的睡眠条件更容易满足，程序的并发行更高。&lt;/li&gt;
&lt;li&gt;创建较小的线程可能有利于检查死锁错误。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dev-test-suite&#34;&gt;dev Test Suite&lt;/h3&gt;
&lt;p&gt;一次完整的输入输出会经过如下步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;tty_reader&lt;/code&gt; 线程向 tty 输出命令行提示符，然后调用 tty 的 read() 函数。tty 的 read() 函数要等待 tty_cook() 的信号，因此暂时挂起。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每当用户按下一个键，硬件会生成一个中断，dev 测试集中的 input_notify() 函数负责处理这个中断，它会发送一个 kbdirq 信号，唤醒正在睡眠的 &lt;code&gt;input_task&lt;/code&gt; 线程。&lt;code&gt;input_task&lt;/code&gt; 线程从设备寄存器中读取按键的内容，更新当前的键盘按键状态，调用 push_event() 将按键事件放入 &lt;code&gt;in-&amp;gt;events[]&lt;/code&gt; 队列中，并发送一个 event_sem 信号。此外，时钟中断也会发送 kbdirq 信号唤醒 &lt;code&gt;input_task&lt;/code&gt; 线程，如果一段时间内没有任何按键，&lt;code&gt;input_task&lt;/code&gt; 会 push 一个空的按键事件并发送 event_sem，向别的线程提供一个伪时钟。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;tty_task&lt;/code&gt; 线程会不断调用 input_read() 函数读取键盘输入，input_read() 会调用 pop_event() 从 &lt;code&gt;in-&amp;gt;events[]&lt;/code&gt; 队列中取出一个按键事件返回，对于一个普通的按键事件，&lt;code&gt;tty_task&lt;/code&gt; 会调用 tty_cook() 函数将字符加入一个和读取线程共享的队列 (保护该队列的锁是 &lt;code&gt;tty-&amp;gt;lock&lt;/code&gt;)，并调用 &lt;code&gt;ttydev-&amp;gt;ops-&amp;gt;write&lt;/code&gt; 将字符回显在 tty 上。&lt;/p&gt;
&lt;p&gt;tty_cook() 调用 tty_enqueue() 函数将字符放入队列 &lt;code&gt;tty-&amp;gt;queue&lt;/code&gt;，如果遇到换行符 &lt;code&gt;\n&lt;/code&gt;，tty_cook() 会发送 cooked 信号来唤醒 &lt;code&gt;tty_reader&lt;/code&gt; 线程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;tty_read() 函数被唤醒后，会将队列里的字符拷贝到指定的地址。然后 &lt;code&gt;tty_reader&lt;/code&gt; 线程打印相应的长度信息。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注：tty_read() 打印信息和字符回显的先后无法保证。这里理应有的顺序是：在字符回显完成后 &lt;code&gt;tty_reader&lt;/code&gt; 被唤醒并打印信息；&lt;code&gt;tty_reader&lt;/code&gt; 打印出下一个命令行提示符之后再进行字符回显示。如果要获得更好的体验可能需要一些同步机制。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lab 03: User Level Processes</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab03/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab03/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;该实验的主要内容是实现用户进程。用户进程可以理解为套上了虚拟内存的线程，因此我们需要引入 VME 系列的 API。本实验报告主要记录一些有趣的设计和遇到的 bug。&lt;/p&gt;
&lt;h2 id=&#34;designation&#34;&gt;Designation&lt;/h2&gt;
&lt;h3 id=&#34;ucontext&#34;&gt;ucontext()&lt;/h3&gt;
&lt;p&gt;由于笔者在 L2 中选择了通过汇编执行栈切换和执行流切换的操作，因此在 L3 的开始要做一些额外的改进。在 L2 中没有虚拟内存和页表切换的概念，因此第一次进入一个线程的时候我们可以很容易地通过一个內联汇编的 wrapper call 直接跳转到线程代码执行。但引入了用户进程后，初始上下文结构体的创建变得比较困难，返回用户态也需要做更多的事情 (比如页表切换，弹栈等)，因此笔者希望使用 AM 的 API。这就产生了一些矛盾。&lt;/p&gt;
&lt;p&gt;幸运的是，笔者发现 AM 中 &lt;code&gt;trap64.S&lt;/code&gt; 中的汇编函数 &lt;code&gt;__am_iret()&lt;/code&gt; 是有 label 的，这意味着笔者只需要抄写一些 AM 的头文件，就可以调用 &lt;code&gt;__am_iret()&lt;/code&gt; 来完成用户态的返回。 笔者最终的代码是这样权衡的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因为调度器 swtch() 的原理是恢复内核线程执行的上下文，所以我们仍然需要一个类似于 xv6 中 forkret() 函数那样的东西作为一个进程第一次进入用户态的跳板。创建进程时，我们需要伪造一个内核线程的执行现场来让调度器跳转到一个函数 task_start()。&lt;/li&gt;
&lt;li&gt;在 task_start() 中，我们需要完成 AM 中从 user_handler() 返回到调用 &lt;code&gt;__am_iret()&lt;/code&gt; 之间做的事情，即切换用户页表和栈指针。然后调用 &lt;code&gt;__am_iret()&lt;/code&gt; 完成最后的工作即可 (弹栈+&lt;code&gt;iretq&lt;/code&gt; 返回用户态)。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;page-table-walk&#34;&gt;Page Table Walk&lt;/h3&gt;
&lt;p&gt;VME 对外的接口没有 page table walk，这让进程的复制变得困难：我们无法创建出一个和父进程页表一模一样的子进程页表。一种选择是在内核代码中对着 &lt;code&gt;vme.c&lt;/code&gt; 中的 ptwalk() 写一个功能类似的函数，但笔者使用了比较简单的实现：在每个进程中额外维护了一个链表，记录了该进程拥有的所有虚拟页面以及其对应的物理地址和保护参数。链表这样扁平的结构会使得将来的查找效率变低，但比较容易写对且比较简单。&lt;/p&gt;
&lt;h3 id=&#34;waitexit&#34;&gt;wait()/exit()&lt;/h3&gt;
&lt;p&gt;xv6 book 中花了大量篇幅讲解这两个 API，因为这里处理稍有不慎就可能导致 data race 或死锁。在 oslab 中该问题的难度大幅下降，因为我们不需要在 exit() 时将孤儿进程 reparent 给 init，但仍需要非常小心。&lt;/p&gt;
&lt;p&gt;笔者在书写代码时注意了锁的全局拓扑序问题：笔者规定任意一处代码如果要同时获得两个进程的锁，必须先获得父进程的锁再获得子进程的锁，这样一定程度上避免了死锁风险。&lt;/p&gt;
&lt;h3 id=&#34;copy-on-write-fork&#34;&gt;Copy-on-write Fork&lt;/h3&gt;
&lt;p&gt;实现 cow fork 的基本思路为：在父进程 fork 时，将页面的写入权限去掉，并让父子进程的页表指向同一个物理页面。将来如果某个进程对该页面写入，则会触发 page fault，在 page fault handler 中我们新申请一个页面，将原页面的内容复制一份，修改当前进程的页表使其指向新页面，并重新赋予其写入权限。&lt;/p&gt;
&lt;p&gt;cow fork 会带来一些额外的细节，比如我们需要对每个页面维护一个 reference count 表示当前有多少个进程使用这个页面。在释放一个进程时我们不能直接释放它所有的物理页面，而是要修改其 reference count，只有一个页面的 reference count 变为 0 时才能释放。笔者的设计是将 reference count 的增加工作放在 fork() 和 pgmap() 中，将 reference count 的减少工作放在 kfree() 中，由 kfree() 判断当前减完 rfcnt 后是否需要执行真正的 free()，这样设计的好处在于之前写的涉及 free 的代码不需要修改。&lt;/p&gt;
&lt;p&gt;需要格外注意的是在引入 cow fork 后，一个页面就不只是一个进程的“资产”了，在处理页面 metadata 相关的信息时要记得上锁。&lt;/p&gt;
&lt;h3 id=&#34;mmap&#34;&gt;mmap()&lt;/h3&gt;
&lt;p&gt;用户进程的虚拟地址空间理应以页为原子单位，因此笔者将 mmap() 参数中的 length 向 pgsize 上取整。分配时我们要确定一个地址 addr 是否满足 &lt;code&gt;[addr, addr + length)&lt;/code&gt; 与当前地址空间没有冲突，由于无法直接访问页表，该检查笔者通过之前提到的链表完成，这一部分效率比较低下。&lt;/p&gt;
&lt;p&gt;mmap() 要注意 MAP_PRIVATE 和 MAP_SHARED 两种页面的性质差异。对于前者，fork 时要进行 copy-on-write 的处理，去掉写入权限并在 page fault handler 中进一步处理；对于后者，fork 时不需要做改动。父子进程对于 MAP_SHARED 的页面的读写的安全性由用户自己保证。&lt;/p&gt;
&lt;h2 id=&#34;interesting-bugs&#34;&gt;Interesting Bugs&lt;/h2&gt;
&lt;h3 id=&#34;dfs-fork&#34;&gt;dfs-fork()&lt;/h3&gt;
&lt;p&gt;笔者在移植 dfs-fork 时遇到了用户态指针跑飞的情况。经过检查发现跑飞的地址就是 &lt;code&gt;dfs-fork.c&lt;/code&gt; 中 map[] 数组的地址。经过仔细检查，笔者发现 Makefile 中的命令&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;x86_64-linux-gnu-ld -static --omagic --pic-executable --no-dynamic-linker --gc-sections -o _init -e _start trampoline.o ./printf.o ./init.o
x86_64-linux-gnu-objcopy -S -j .text* -j.rodata* -j .data* -j .bss* --set-section-flags .bss=alloc,contents -O binary _init
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;前者并不能保证整个程序静态链接，map[] 的地址被放在了 GOT 中。在后续的 objcopy 中，只有代码节、数据节、.bss 节被保留了下来，从而 map[] 的地址丢失了。&lt;/p&gt;
&lt;p&gt;在 dfs-fork 的全局数组前加上 static 修饰就可以将数组放到数据节中，从而解决这个问题。&lt;/p&gt;
&lt;h3 id=&#34;page-table-teardown&#34;&gt;Page Table Teardown&lt;/h3&gt;
&lt;p&gt;笔者在移植 dfs-fork 进行多核测试时曾经遇到神秘的 CPU reset。经过排查发现这涉及一个比较微妙的页表问题。假设一个核上父进程正在 wait()，另一个核上子进程在 exit()。根据笔者的设计，子进程 exit() 后会唤醒正在等待的父进程，然后跳转到调度器线程。但需要注意的是调度器线程现在使用的仍然是“子进程”的页表。父进程醒来后发现有僵尸子进程，于是回收资源，回收时调用 unprotect() 销毁子进程的页表，从而导致另一个核的调度器线程 crash。&lt;/p&gt;
&lt;p&gt;如果在 L2 中没有使用內联汇编做栈切换，我们应该会有一个“等待下一次进入 os_trap 再释放上一次进入 os_trap 的进程的锁” 的操作，这个操作在 L3 中同时可以确保页表不会被提前 teardown。但笔者的 L2 设计的特殊性导致了这里必须处理这样一个相似的问题。笔者的解决方法非常简单：用户进程在陷入内核后执行的都是内核代码，因此我们可以在 os_trap 的开头把页表切换成内核页表，这样就不会 crash 了。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
