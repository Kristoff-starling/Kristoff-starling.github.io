<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lectures | Yuyao Wang&#39;s Homepage</title>
    <link>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/</link>
      <atom:link href="https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/index.xml" rel="self" type="application/rss+xml" />
    <description>Lectures</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 23 Aug 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Lectures</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/</link>
    </image>
    
    <item>
      <title>Stanford-CS143 Lecture 06: Syntax-Directed Translation</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec06/</link>
      <pubDate>Tue, 23 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec06/</guid>
      <description>&lt;h2 id=&#34;error-handling&#34;&gt;Error Handling&lt;/h2&gt;
&lt;p&gt;Purpose of the compiler:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;u&gt;to detect non-valid programs&lt;/u&gt;&lt;/li&gt;
&lt;li&gt;to translate the valid ones.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The error handler should&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Report errors accurately and clearly&lt;/li&gt;
&lt;li&gt;Recover from an error quickly&lt;/li&gt;
&lt;li&gt;Not slow down compilation too much.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;panic-mode&#34;&gt;Panic Mode&lt;/h3&gt;
&lt;p&gt;When an error is detected, the parser discards tokens until one with a clear role is found and continues from there. The tokens &amp;ldquo;with a clear role&amp;rdquo; are referred to as &lt;strong&gt;syncrhonizing tokens&lt;/strong&gt; and typically are the statement or expression terminators.&lt;/p&gt;
&lt;p&gt;For example, the expression &lt;code&gt;(1++2)+3&lt;/code&gt; is invalid. When the parser sees the second &lt;code&gt;+&lt;/code&gt;, it knows that it&amp;rsquo;s invalid to have 2 consecutive &lt;code&gt;+&lt;/code&gt; and enters panic mode. In panic mode, a possible recovery strategy is to skip ahead to next integer and then continue, i.e., continue at &lt;code&gt;2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In Bison, we can use the special terminal &lt;code&gt;error&lt;/code&gt; to describe how much input to skip. For example, if we write
$$
E\to \text{int}\space |\space E+E\space |\space (E)\space |\space \text{error int}\space |\space (\text{error})
$$
when the parser enters panic mode, &lt;code&gt;error&lt;/code&gt; will match any number of characters and the rule &lt;code&gt;error int&lt;/code&gt; will let the parser continue at the next integer.&lt;/p&gt;
&lt;h3 id=&#34;error-productions&#34;&gt;Error Productions&lt;/h3&gt;
&lt;p&gt;Another way to handle errors is to specify known common mistakes into the grammar. For example, it&amp;rsquo;s common for programmers to forget &lt;code&gt;*&lt;/code&gt; (i.e. &lt;code&gt;5x&lt;/code&gt; instead of &lt;code&gt;5 * x&lt;/code&gt;), so we can write
$$
E\to\space &amp;hellip;\space |\space E\space E
$$
The &lt;code&gt;E E&lt;/code&gt; is responsible for matching errors.&lt;/p&gt;
&lt;p&gt;The disadvantages of error productions is that it significantly slows down the compilation.&lt;/p&gt;
&lt;h3 id=&#34;error-correction&#34;&gt;Error Correction&lt;/h3&gt;
&lt;p&gt;Some compilers support error correction. When it encounters an error, it will find a correct &amp;ldquo;nearby&amp;rdquo; program through exhaustive search or token insertions/deletions.&lt;/p&gt;
&lt;p&gt;The disadvantages of error correction:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hard to implement.&lt;/li&gt;
&lt;li&gt;slows down parsing of correct programs.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;nearby&amp;rdquo; is not necessarily &amp;ldquo;the intended&amp;rdquo; program.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;abstract-syntax-trees&#34;&gt;Abstract Syntax Trees&lt;/h2&gt;
&lt;p&gt;For an expression &lt;code&gt;5+(12+3)&lt;/code&gt;, we have a parse tree:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD

s1((E)) --&amp;gt; s2((E))
s1 --&amp;gt; s8((+))
s1 --&amp;gt; s3((E))
s2 --&amp;gt; s4((5))
s3 --&amp;gt; s5((&amp;quot;(&amp;quot;))
s3 --&amp;gt; s6((E))
s3 --&amp;gt; s7((&amp;quot;)&amp;quot;))
s6 --&amp;gt; s9((E))
s6 --&amp;gt; s10((+))
s6 --&amp;gt; s11((E))
s9 --&amp;gt; s12((12))
s11 --&amp;gt; s14((3))

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the parse tree contains too much unnecessary information: parentheses, single-successor nodes etc. Therefore in compilers we use the abstract syntax tree (abbr: AST) instead.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD

s1(a) --&amp;gt; s2((5))
s1 --&amp;gt; s3(a)
s3 --&amp;gt; s4((12))
s3 --&amp;gt; s5((3))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;recursive-descent-parsing&#34;&gt;Recursive Descent Parsing&lt;/h2&gt;
&lt;p&gt;In this algorithm, the parse tree is constructed from the top and from left to right. The general procedure is: we continuously check the left-most unchecked node:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If it&amp;rsquo;s an unterminal, we try the productions in order and recursively do the parsing.&lt;/li&gt;
&lt;li&gt;If it&amp;rsquo;s an terminal, we compare the node with the current character in the input string (backtracking is needed if they fail to match).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;recursive-descent-algorithm&#34;&gt;Recursive Descent Algorithm&lt;/h3&gt;
&lt;p&gt;Let TOKEN be the type of tokens. Let the global &lt;code&gt;next&lt;/code&gt; pointer to the next input token.&lt;/p&gt;
&lt;p&gt;Some needed boolean functions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool term(TOKEN tok)  // whether a given token terminal matches the input
bool Sn();            // whether the n-th production of S works
bool S();             // whether there exists any production of S that works
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example: productions for arithmetic expressions with &lt;code&gt;+&lt;/code&gt; &lt;code&gt;*&lt;/code&gt; and parentheses:
$$
\begin{align}
E&amp;amp;\to T\space |\space T+E\\
T&amp;amp;\to \text{int}\space |\space \text{int}\space *\space T\space |\space (E)
\end{align}
$$
Our code should be&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool term(TOKEN tok) { return *next++ = tok; }

bool E1() { return T(); }
bool E2() { return T() &amp;amp;&amp;amp; term(PLUS) &amp;amp;&amp;amp; E(); }
bool T1() { return term(INT); }
bool T2() { return term(INT) &amp;amp;&amp;amp; term(TIMES) &amp;amp;&amp;amp; T(); }
bool T3() { return term(OPEN) &amp;amp;&amp;amp; E() &amp;amp;&amp;amp; term(CLOSE); }

bool E() {
    TOKEN *save = next;
    return (next = save, E1()) || (next = save, E2());
}

bool T() {
    TOKEN *save = next;
    return (next = sava, T1()) || (next = save, T2()) || (next = save, T3());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To start the parser, set &lt;code&gt;next&lt;/code&gt; to the first character of the input string and call &lt;code&gt;E()&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;left-recursion&#34;&gt;Left Recursion&lt;/h2&gt;
&lt;p&gt;Consider the following grammar: $S\to S\alpha\space |\space \beta$, which accepts strings with $\beta$ at the beginning and arbitrary $\alpha$  after. If we write the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;bool S1() { return S() &amp;amp;&amp;amp; term(ALPHA); }
bool S2() { return term(BETA); }
bool S() {
    TOKEN *save = next;
    return (next = save, S1()) || (next = save, S2());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The program will result in infinite loop (&lt;code&gt;S()&lt;/code&gt; calls &lt;code&gt;S1()&lt;/code&gt;, &lt;code&gt;S1()&lt;/code&gt; calls &lt;code&gt;S()&lt;/code&gt; and so on). The problem is that the grammar is left recursive - the derivation generate strings from right to left, but our parser scans from left to right. We need to rewrite the grammars as right recursive:
$$
\begin{align}
S&amp;amp;\to \beta S&#39;\\
S&#39;&amp;amp;\to \alpha S&#39;\space |\space \epsilon
\end{align}
$$
In principle, grammars can be transformed to right recursive ones automatically. But in practice people manually do the transformation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stanford-CS143 Lecture 05: Introduction to Parsing</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec05/</link>
      <pubDate>Mon, 22 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec05/</guid>
      <description>&lt;p&gt;Regular expression is the weakest formal language. There are lots of languages that cannot be represented by regular expression. e.g. $\{(^i)^i:i\geq 1\}=\{(),(()), ((())),&amp;hellip;\}$ (the set of balanced parentheses).&lt;/p&gt;
&lt;p&gt;The parser takes the output of lexer, i.e. sequence of tokens as input, and outputs the parse tree of the program.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Cool code: &lt;code&gt;if x = y then 1 else 2 fi&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parser input/lexer output: &lt;code&gt;IF ID = ID THEN INT ELSE INT FI&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parser output:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;IF-THEN-ELSE---+----=---+---ID
               |        |
               +---INT  +---ID
               |
               +---INT
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;context-free-grammars&#34;&gt;Context-Free Grammars&lt;/h2&gt;
&lt;p&gt;The parser must distinguish between valid and invalid strings of tokens. Therefore we need a language, and a method, for describing valid strings of tokens.&lt;/p&gt;
&lt;p&gt;Programming languages have recursive structure, which makes parsing difficult, and context-free grammars are a natural notation for this recursive structure.&lt;/p&gt;
&lt;p&gt;A CFG consists of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A set of terminals, denoted as $T$.&lt;/li&gt;
&lt;li&gt;A set of non-terminals, denoted as $N$.&lt;/li&gt;
&lt;li&gt;A start symbol $s\in N$.&lt;/li&gt;
&lt;li&gt;A set of productions. Each production is of format $X\to Y_1,\cdots, Y_n$, where $X\in N$, $Y_i\in T\cup N\cup {\epsilon}$. Productions can be read as rules, meaning that LHS can be replaced by RHS.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example: all balanced parentheses sequence: $T={(,)},N={s}$, two rules:
$$
\begin{align}
s &amp;amp;\to (s)\\
s &amp;amp;\to \epsilon
\end{align}
$$
The way to understand a CFG:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Begin with a string with only the start symbol $S$.&lt;/li&gt;
&lt;li&gt;Replace any non-terminal $X$ in the string by the right-hand side of some production $X\to Y_1,\cdots Y_n$.&lt;/li&gt;
&lt;li&gt;Repeat (2) until there are no non-terminals.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Formally, we use $\alpha_1\overset{*}{\to}\alpha_2$ to represent that string $\alpha_1$ can be transformed to string $\alpha_2$ in 0 or more steps (applying productions). Let $G$ be a context-free grammar with start symbol $S$, then the language $L(G)$ of $G$ is
$$
L(G)=\{a_1a_2\cdots a_n|\forall i.a_i\in T \wedge S\overset{*}{\to}a_1\cdots a_n\}
$$
Terminals have no productions. In parsing terminals are usually tokens.&lt;/p&gt;
&lt;p&gt;Some parsing examples:
$$
\begin{align}
\text{EXPR} &amp;amp;\to id\\
&amp;amp;\quad |\space if\space \text{EXPR}\space then\space \text{EXPR}\space else\space \text{EXPR}\space fi\\
&amp;amp;\quad |\space while\space \text{EXPR}\space loop\space \text{EXPR}\space pool\\
&amp;amp;\quad |\space \cdots
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;derivations&#34;&gt;Derivations&lt;/h2&gt;
&lt;p&gt;A derivation is a sequence of productions: $s\to \alpha_1\to \alpha_2\to \cdots$. Derivations can be represented as parse trees. For example, the arithmetic expression $id*id+id$ has a derivation
$$
E\to E+E\to E*E+E\to id*E+E\to id*id+E\to id*id +id
$$
and the parse tree is&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
s1((E)) --&amp;gt; s2((E))
s1((E)) --&amp;gt; s3(+)
s1 --&amp;gt; s4((E))
s2 --&amp;gt; s5((E))
s2 --&amp;gt; s6(*)
s2 --&amp;gt; s7((E))
s4 --&amp;gt; s8((id))
s5 --&amp;gt; s9((id))
s7 --&amp;gt; s10((id))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Terminals are on the leaves of the parse tree and the in-order traversal of leaves results in the original string.&lt;/p&gt;
&lt;p&gt;For one string, there are various derivations. The most commonly used ones are left-most and right-most derivations. But one string has only one parse tree.&lt;/p&gt;
&lt;h2 id=&#34;ambiguity&#34;&gt;Ambiguity&lt;/h2&gt;
&lt;p&gt;A grammar is ambiguous if it has more than one parse tree for some string.&lt;/p&gt;
&lt;p&gt;For example, &lt;code&gt;id * id + id&lt;/code&gt; has two different computing orders (&lt;code&gt;*&lt;/code&gt;-first v.s. &lt;code&gt;+&lt;/code&gt;-first). There are mainly two ways to handle with ambiguity:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Rewrite grammar unambiguously. Write
$$
\begin{align}
E&amp;amp;\to E&#39;+E\space |\space E&#39;\\
E&#39;&amp;amp;\to id*E&#39;\space |\space id\space |\space (E)*E&#39;\space |\space (E)
\end{align}
$$
instead of one production ( $E$ can represent arbitrary $E&#39;$s summing together, $E&#39;$ is responsible for &lt;code&gt;*&lt;/code&gt; )&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enforces precedence of operators (&lt;code&gt;*&lt;/code&gt; over &lt;code&gt;+&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next example illustrates that it&amp;rsquo;s difficult to write unambiguous grammars. It&amp;rsquo;s common for us to write the grammar for &amp;ldquo;if-then-else&amp;rdquo; like this:
$$
\begin{align}
E&amp;amp;\to if\space E\space then\space E\\
&amp;amp;\quad |\space if\space E\space then\space E\space else\space E\\
&amp;amp;\quad |\space \text{OTHERS}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;However, the statement &lt;code&gt;IF E1 THEN IF E2 THEN E3 ELSE E4&lt;/code&gt; is ambiguous following the above grammar because we don&amp;rsquo;t know whether &lt;code&gt;ELSE E4&lt;/code&gt; belongs to the inner &lt;code&gt;IF&lt;/code&gt; or the outer &lt;code&gt;IF&lt;/code&gt;. Usually, we want the &lt;code&gt;ELSE&lt;/code&gt; statement to match the nearest unmatched &lt;code&gt;IF&lt;/code&gt;, i.e. the statement should be understood as &lt;code&gt;IF E1 THEN(IF E2 THEN E3 ELSE E4)&lt;/code&gt;. To solve this, we need to define &amp;ldquo;MIF&amp;rdquo; (matched IF) and &amp;ldquo;UIF&amp;rdquo; (unmatched IF) in the grammar:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
E&amp;amp;\to \text{MIF}\space |\space \text{UIF}\space\\
\text{MIF} &amp;amp;\to if\space E\space then\space \text{MIF}\space else\space \text{MIF}\\
&amp;amp;\quad |\space \text{OTHERS}\\
\text{UIF} &amp;amp;\to if\space E\space then\space E\\
&amp;amp;\quad |\space if\space E\space then\space \text{MIF}\space else\space \text{UIF}\\
&amp;amp;\quad |\space \text{OTHERS}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s impossible to automatically convert an ambiguous grammar to an unambiguous one, and it&amp;rsquo;s also hard to manually write those complicated grammars. Besides, ambiguous grammar are more natural and concise, so the common practice is to &lt;strong&gt;choose more natural grammar along with disambiguating declarations&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Most tools allow precedence and associativity declarations to disambiguate grammars. Take &lt;code&gt;id * id + id&lt;/code&gt; as an example, the natural grammar
$$
\begin{align}
E&amp;amp;\to E + E\\
&amp;amp;\quad |\space E * E\\
&amp;amp;\quad |\space (E)
\end{align}
$$
along with declarations&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%left +
%left *
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;can erase ambiguity. The declarations say that both &lt;code&gt;+&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt;  are left associative, and because &lt;code&gt;*&lt;/code&gt;&amp;rsquo;s declaration comes later, &lt;code&gt;*&lt;/code&gt; has higher priority than &lt;code&gt;+&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stanford-CS143 Lecture 04: Implementation of Lexical Analysis</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec04/</link>
      <pubDate>Wed, 10 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec04/</guid>
      <description>&lt;p&gt;Summary of (extended) regular expression rules:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At least one: $A^{+}\triangleq AA^*$&lt;/li&gt;
&lt;li&gt;Union: $A | B \triangleq A + B$&lt;/li&gt;
&lt;li&gt;Option: $A?\triangleq A+\epsilon$&lt;/li&gt;
&lt;li&gt;Range: $[a- z]\triangleq a+b+\cdots+z$&lt;/li&gt;
&lt;li&gt;Excluded range: $[$^$a- z]\triangleq$ complement of $[a- z]$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lexical-specification&#34;&gt;Lexical Specification&lt;/h2&gt;
&lt;p&gt;The procedure of lexical analysis:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Write a rexp for the lexemes of each token class, i.e., number, identifier, keywords etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Construct $R$, matching all lexemes i.e. $R = R_1 + R_2 + \cdots$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let input be $x_1x_2\cdots x_n$, for each $1\leq i\leq n$, check whether $x_1\cdots x_i\in L(R)$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Which prefix to choose?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sometimes we may have $x_1\cdots x_i\in L(R)$, $x_1\cdots x_j\in L(R)$ and $i\neq j$ (e.g. &lt;code&gt;==&lt;/code&gt; and &lt;code&gt;=&lt;/code&gt;). In this situation we follow the &amp;ldquo;&lt;strong&gt;maximal munch&lt;/strong&gt;&amp;rdquo; principle, i.e., we always choose the longer one.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;What if no rule matches?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Compilers should do error handling instead of crashing when there is an lexical error. A common way to handle this is to define an extra set $\text{Error}\triangleq \text{all strings}$ and give it the lowest priority.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If success, then we know that $x_1\cdots x_i\in L(R_j)$ for some $j$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Which token to choose?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sometimes we may have $x_1\cdots x_i\in L(R_j)$, $x_1\cdots x_i\in L(R_k)$ and $j\neq k$. (e.g. &lt;code&gt;if&lt;/code&gt; is a keyword, but it also satisfies the definition of identifiers). In this situation we choose the one with higher priority.&lt;/p&gt;
&lt;p&gt;(Actually, usually in the definition of identifiers keywords are explicitly excluded.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remove $x_1\cdots x_i$ from input and go to (3).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;finite-automata&#34;&gt;Finite Automata&lt;/h2&gt;
&lt;p&gt;A regular expression $R$ formally defines a set of strings $L(R)$. However, we need an implementation to identify that given a string $s$, whether $s\in L(R)$. Finite automata is a good implementation model.&lt;/p&gt;
&lt;p&gt;A finite automaton consists of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An input alphabet $\Sigma$&lt;/li&gt;
&lt;li&gt;A finite set of states $S$&lt;/li&gt;
&lt;li&gt;A start state $n$&lt;/li&gt;
&lt;li&gt;A set of accepting states $F\subseteq S$&lt;/li&gt;
&lt;li&gt;A set of transitions $\text{state1}\overset{input}{\to}\text{state2}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given an input string, If we reach the end of input and we&amp;rsquo;re an accepting state, the automaton &lt;strong&gt;accept&lt;/strong&gt; the string. The automaton &lt;strong&gt;reject&lt;/strong&gt; a string if 1) we&amp;rsquo;re not in an accepting state. 2) we get stuck (no transition).&lt;/p&gt;
&lt;p&gt;The language of a finite automaton is the set of accepted strings.&lt;/p&gt;
&lt;p&gt;Example: a finite automaton accepting strings with any number of 1 and a 0 at the end.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR

s1((A))
s2(B)
s1 --&amp;gt; |0|s2
s1 --&amp;gt; |1|s1

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There&amp;rsquo;s a special transition called $\epsilon$ transition: $A\overset{\epsilon}{\to}B$. This transition doesn&amp;rsquo;t consume any character, i.e., we can choose to go to $B$ from $A$ with no condition.&lt;/p&gt;
&lt;p&gt;There are 2 kinds of FA:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deterministic Finite Automata (DFA)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One transition per input label per state&lt;/li&gt;
&lt;li&gt;No $\epsilon$-moves&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Nondeterministic Finite Automata (NFA)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can have multiple transitions for one input label in a given state&lt;/li&gt;
&lt;li&gt;Can have $\epsilon$-moves&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actually, the first condition is not essential because we can use $\epsilon$-moves to transform it into a normal one. Here&amp;rsquo;s an example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
s1(1) --&amp;gt; |1|s2(2)
s1 --&amp;gt; |1|s3(3)

s4(1) --&amp;gt; |e|s5(N/A)
s4 --&amp;gt; |e|s6(N/A)
s5 --&amp;gt; |1|s7(2)
s6 --&amp;gt; |1|s8(3)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A crucial difference between DFA and NFA is that given an input, after receiving several characters, we&amp;rsquo;re in a certain state in DFA while we may be in a set of possible states in NFA. An NFA accepts a string if there exists a path that reaches an accepting state.&lt;/p&gt;
&lt;p&gt;NFA, DFA and regular expressions have the equivalent power of representing languages. Usually DFA are faster to execute (there&amp;rsquo;s no choice to consider), but NFA is much smaller (exponentially smaller).&lt;/p&gt;
&lt;h2 id=&#34;regular-expressions-to-nfas&#34;&gt;Regular Expressions to NFAs&lt;/h2&gt;
&lt;p&gt;Target: lexical specification $\to$ regular expressions $\to$ NFA $\to$ DFA $\to$ table-driven implementation of DFA&lt;/p&gt;
&lt;p&gt;The way we transform regular expressions to NFAs is to design an NFA for each RE rule.&lt;/p&gt;
&lt;p&gt;We denote the NFA for expression A as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
s1((st)) --&amp;gt; s2([A&#39;s NFA]) --&amp;gt; s3[ed]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;$\epsilon$:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
s1((st)) --&amp;gt; |e| s2[ed]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A character $a$:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
s1((st)) --&amp;gt; |a| s2[ed]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Rule $AB$:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
s1((A&#39;s st)) --&amp;gt; s2([A&#39;s NFA]) --&amp;gt; s3(A&#39;s ed) --&amp;gt;|e| s4(B&#39;s st) --&amp;gt; s5([B&#39;s NFA]) --&amp;gt; s6[B&#39;s ed]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Rule $A + B$:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
s1((st)) --&amp;gt; |e| s2(A&#39;s st)
s1 --&amp;gt; |e| s3(B&#39;s st)
s2 --&amp;gt; s4([A&#39;s NFA])
s3 --&amp;gt; s5([B&#39;s NFA])
s4 --&amp;gt; s6(A&#39;s ed)
s5 --&amp;gt; s7(B&#39;s ed)
s6 --&amp;gt; |e| s8[ed]
s7 --&amp;gt; |e| s8[ed]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Rule $A^*$:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
s1((st)) --&amp;gt; |e| s2(A&#39;s st) --&amp;gt; s3([A&#39;s NFA]) --&amp;gt; s4(A&#39;s ed) --&amp;gt;|e| s5[ed]
s4 --&amp;gt; |e| s1
s1 --&amp;gt; |e| s5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example: $(1+0)^*1$:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://kristoff-starling.github.io/img/stanford-compiler-lec4-2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nfa-to-dfa&#34;&gt;NFA to DFA&lt;/h2&gt;
&lt;p&gt;An NFA may be in many states at any time. However, for a n-state NFA, there are at most $2^N-1$ different subsets of states, which is finite. That&amp;rsquo;s the core idea of how to transform NFA to DFA.&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ ($\epsilon$-closure) The $\epsilon$-closure of a node $q$ in NFA, denoted as $\epsilon\text{-closure}(q)$, is the set of nodes that can be reached from $q$ by walking through only $\epsilon$ edges. For example, in the NFA above, $\epsilon\text{-closure}(q_6)={q_0,q_1,q_2,q_4,q_7,q_8}$.&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ For a set of states $X$ and a character $a$ in NFA, $a(X)\triangleq {y|\exists x\in X, x\overset{a}{\to}y}$.&lt;/p&gt;
&lt;p&gt;Components of an NFA:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;states: a set $S$.&lt;/li&gt;
&lt;li&gt;start: a state $s\in S$.&lt;/li&gt;
&lt;li&gt;final: a set $F\subseteq S$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Corresponding DFA:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;states: nonempty subsets of $S$.&lt;/li&gt;
&lt;li&gt;start: $\epsilon\text{-closure}(s)$.&lt;/li&gt;
&lt;li&gt;final: ${X\subseteq S|X\cap F\neq \emptyset}$.&lt;/li&gt;
&lt;li&gt;transitions: $X\overset{a}{\to}Y$ exists iff $Y=\epsilon\text{-closure}(a(X))$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example: $(1+0)^*1$:&lt;/p&gt;
&lt;img src=&#34;https://kristoff-starling.github.io/img/stanford-compiler-lec4-1.png&#34; alt=&#34;image-20220814145242811&#34; style=&#34;zoom: 33%;&#34; /&gt;
&lt;h2 id=&#34;implementing-finite-automata&#34;&gt;Implementing Finite Automata&lt;/h2&gt;
&lt;p&gt;A DFA can be represented as a 2D table. States and input symbols are the two dimensions and the contents of the table are transition. Pseudocode can be written based on this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;i = 0;
state = initial;
while (input[i] != &#39;\0&#39;) {    
    state = table[state][input[i]];    
    i++;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the table is too huge, we can directly use NFA: the table should add a column representing $\epsilon$ transitions and all the contents are set of states instead of states.&lt;/p&gt;
&lt;p&gt;Although NFA&amp;rsquo;s table is more concise, the simulation is more expensive because we have to maintain a set of current states.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stanford-CS143 Lecture 03: Lexical Analysis</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec03/</link>
      <pubDate>Sun, 10 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec03/</guid>
      <description>&lt;p&gt;Token classes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In English: nouns, verbs, adjactives etc.&lt;/li&gt;
&lt;li&gt;In programming languages: identifiers, keywords, &amp;ldquo;()&amp;rdquo; etc.
&lt;ul&gt;
&lt;li&gt;Identifier: strings of letters or digits, staring with a letter (variable names).&lt;/li&gt;
&lt;li&gt;Integer: a non-empty string of digits (leading zeroes are allowed).&lt;/li&gt;
&lt;li&gt;Keywords: &amp;ldquo;if&amp;rdquo;, &amp;ldquo;else&amp;rdquo;, &amp;ldquo;begin&amp;rdquo; etc.&lt;/li&gt;
&lt;li&gt;Whitespace: a non-empty sequence of blanks, newlines and tabs&lt;/li&gt;
&lt;li&gt;Operator: relational operators like &lt;code&gt;==&lt;/code&gt; &lt;code&gt;&amp;lt;&lt;/code&gt; &lt;code&gt;&amp;gt;&lt;/code&gt; etc.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;(&lt;/code&gt; &lt;code&gt;)&lt;/code&gt; &lt;code&gt;;&lt;/code&gt; &lt;code&gt;=&lt;/code&gt; : these are special token classes which consist of only one string.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A key-value pair of format &lt;code&gt;&amp;lt;class, string&amp;gt;&lt;/code&gt; is called a token. The lexical analyzer takes in a string(program) and outputs tokens to the parser. For example：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input: &lt;code&gt;foo=42&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Output: &lt;code&gt;&amp;lt;identifier, &amp;quot;foo&amp;quot;&amp;gt;&lt;/code&gt; , &lt;code&gt;&amp;lt;operator, &amp;quot;=&amp;quot;&amp;gt;&lt;/code&gt; , &lt;code&gt;&amp;lt;integer, &amp;quot;42&amp;quot;&amp;gt;&lt;/code&gt; (note: here &amp;ldquo;42&amp;rdquo; is a string, not a number!)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An implementation of LA must do two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Recognize substrings corresponding to tokens, which are called lexemes.&lt;/li&gt;
&lt;li&gt;Idenfity the token class of each lexeme.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;la-examples&#34;&gt;LA Examples&lt;/h2&gt;
&lt;p&gt;FORTRAN rule: whitespace is insignificant. So &lt;code&gt;VAR1&lt;/code&gt; is the same as &lt;code&gt;VA  R  1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;An Example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-fortran&#34;&gt;DO 5 I = 1, 25
DO 5 I = 1.25
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first line is a do-loop where variable &lt;code&gt;I&lt;/code&gt; iterates from 1 to 25. The second line, however, is a variable definition - &lt;code&gt;DO5I = 1.25&lt;/code&gt;. When we scan the string from left to right, at tht point we finish &amp;ldquo;DO&amp;rdquo; we&amp;rsquo;re not sure whether it&amp;rsquo;s a keyword, we must look ahead to see whether there&amp;rsquo;s a comma. Therefore, &lt;strong&gt;&amp;ldquo;lookahead&amp;rdquo; may be required to decide where one token ends and the next token begins&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;lookahead&amp;rdquo; is a universal need even in modern PLs. For example,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;if (i == j) x = 1; else x = 2;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;when we encounter &lt;code&gt;=&lt;/code&gt;, we need to look ahead to decide whether it&amp;rsquo;s a double-equal; when we encounter &lt;code&gt;e&lt;/code&gt; we need to look ahead to decide whether it&amp;rsquo;s a variable name or a keyword.&lt;/p&gt;
&lt;p&gt;PL/1 rule: keywords are not reserved (i.e. keywords can be used as variable names).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;IF ELSE THEN THEN = ELSE; ELSE ELSE = THEN
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;rsquo;s challenging to recognize which &lt;code&gt;ELSE&lt;/code&gt;&amp;amp;&lt;code&gt;THEN&lt;/code&gt; are variables.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DECLARE(ARG1, ..., ARGN)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we&amp;rsquo;re not sure whether &lt;code&gt;DECLARE&lt;/code&gt; is a keyword or an array reference. Since it can have arbitrary number of arguments, an &lt;u&gt;unbounded lookahead&lt;/u&gt; will be required.&lt;/p&gt;
&lt;h2 id=&#34;regular-languages&#34;&gt;Regular Languages&lt;/h2&gt;
&lt;p&gt;We must specify what set of strings is in a token class, and the solution is to use regular languages.&lt;/p&gt;
&lt;p&gt;2 base cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Single character: $c\triangleq {c}$&lt;/li&gt;
&lt;li&gt;Epsilon: $\epsilon\triangleq {&#39;&#39;}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3 compound expressions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Union: $A+B\triangleq \{a|a\in A\}\cup \{|b\in B\}$&lt;/li&gt;
&lt;li&gt;Concatenation: $AB\triangleq \{ab|a\in A,b\in B\}$&lt;/li&gt;
&lt;li&gt;Iteration: $A^* \triangleq \left\{\bigcup_{i\geq 0}A^i \right\}$, here $A^0=\epsilon$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\fbox{Definition 3.1}$ The &lt;strong&gt;regular expressions&lt;/strong&gt; over $\Sigma$ are the smallest set of expressions including:
$$
\begin{align}
R::=&amp;amp;\quad\space \epsilon\\
&amp;amp;|\quad c, c\in \Sigma\\
&amp;amp;|\quad R + R\\
&amp;amp;|\quad RR\\
&amp;amp;|\quad R^*
\end{align}
$$&lt;/p&gt;
&lt;h2 id=&#34;formal-languages&#34;&gt;Formal Languages&lt;/h2&gt;
&lt;p&gt;$\fbox{Definition 3.2}$ Let $\Sigma$ be a set of characters (an &lt;strong&gt;alphabet&lt;/strong&gt;), a &lt;strong&gt;language&lt;/strong&gt; over $\Sigma$ is a set of strings of characters drawn from $\Sigma$.&lt;/p&gt;
&lt;p&gt;e.g. Alphabet = English characters, Language = sentences (maybe we need a strict definition of valid sentences)&lt;/p&gt;
&lt;p&gt;e.g. Alphabet = ASCII, Language = C programs (this is rigorous, the language is exactly what C compilers accept)&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;meaning function&lt;/strong&gt; $L:\text{expression}\to \text{set of strings}$ is a mapping that maps syntax to semantics. For example, the rigorous way of defining regular expression symbols are:
$$
\begin{align}
L(\epsilon)&amp;amp;={&#39;&#39;}\\
L(c)&amp;amp;={c}\\
L(A+B)&amp;amp;=L(A)\cup L(B)\\
L(AB)&amp;amp;={ab:a\in L(A),b\in L(B)}\\
L(A^*)&amp;amp;=\bigcup_{i\geq 0}L(A^i)
\end{align}
$$
The mappings between expressions and meanings are not 1-to-1. it&amp;rsquo;s many-to-1: e.g. $L(11+10)=L(1(1+0))$. This is the foundation of optimization: we can use simpler expressions to do exactly the same thing. But meaning functions should never be 1-to-many, indicating that the language is ambiguous.&lt;/p&gt;
&lt;p&gt;Meaning function makes clear what is syntax and what is semantics. It allows us to consider notation as a separate issue. It&amp;rsquo;s important to think about syntax/notation separately. For example, Roman numerals and Arabic numerals are two systems having the same semantics, but the latter is popular because of its simplicity in syntax.&lt;/p&gt;
&lt;h2 id=&#34;lexical-specifications&#34;&gt;Lexical Specifications&lt;/h2&gt;
&lt;h3 id=&#34;lexemes&#34;&gt;Lexemes&lt;/h3&gt;
&lt;p&gt;We use regular expressions to specify lexemes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Keywords: if/else/then/&amp;hellip;&lt;/p&gt;
&lt;p&gt;$\text{Keywords}=\text{if}+\text{else}+\text{then}+\cdots$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Integer: a non-empty string of digits.&lt;/p&gt;
&lt;p&gt;$\text{digit}=0+1+2+3+\ldots+8+9$，$\text{Integer}=\text{digit}\space \text{digit}^*$.&lt;/p&gt;
&lt;p&gt;Representing non-empty strings is a common need, so we denote $A^+\triangleq AA^*$. Therefore we can also write $\text{Integer}=\text{digit}^+$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Identifier: strings of letters of digits, starting with a letter.&lt;/p&gt;
&lt;p&gt;$\text{letter}=a+b+\cdots+y+z+A+B+\cdots+Y+Z$. There is a convenient notation for ranges: $\text{letter}=[a- z]+[A- Z]=[a- zA- Z]$.&lt;/p&gt;
&lt;p&gt;$\text{Identifier}=\text{letter}\space (\text{letter}+\text{digit})^*$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Whitespace: a non-empty sequence of blanks, newlines and tabs.&lt;/p&gt;
&lt;p&gt;$\text{Whitespace}=(\text{&#39; &amp;lsquo;}+\text{&#39;\n&amp;rsquo;}+\text{&#39;\t&#39;})^+$.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;example-pascal-numbers&#34;&gt;Example: Pascal Numbers&lt;/h3&gt;
&lt;p&gt;$$
\begin{align}
\text{num} &amp;amp;= \text{digits}\space\space \text{opt_fraction}\space\space \text{opt_exponent}\\
\text{opt_fraction}&amp;amp;=(\text{&#39;.&#39;}\space\space \text{digits})+\epsilon\\
\text{opt_exponent}&amp;amp;=(\text{&amp;lsquo;E&amp;rsquo;}\space (\text{&#39;+&#39;}+\text{&#39;-&#39;}+\epsilon)\space \text{digits})+\epsilon\\
\text{digits}&amp;amp;=\text{digit}^+\\
\text{digit}&amp;amp;=[0-9]
\end{align}
$$&lt;/p&gt;
&lt;p&gt;We observe that &amp;ldquo;$+\epsilon$&amp;rdquo; in regular expressions indicates &amp;ldquo;optional&amp;rdquo;, i.e. the elements before can be either present or absent. For convenience, we denote $A?\triangleq A+\epsilon$, so the rules above can be rewritten as
$$
\begin{align}
\text{opt_fraction} &amp;amp;= (\text{&#39;.&#39;}\space \text{digits})?\\
\text{opt_exponent} &amp;amp;= (\text{&amp;lsquo;E&amp;rsquo;}\space (\text{&#39;+&#39;}+\text{&#39;-&#39;})?\space \text{digits})?
\end{align}
$$
It&amp;rsquo;s worth notice that regular expressions defines the set of strings we want, but we still need an implementation, i.e. given a string $s$ and a regular expression $R$, we want to know whether $s\in L(R)$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stanford-CS143 Lecture 02: Cool Overview</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec02/</link>
      <pubDate>Sun, 03 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec02/</guid>
      <description>&lt;p&gt;Cool (Classroom Object Oriented Language).&lt;/p&gt;
&lt;p&gt;5 programming assignments (all the 4 layers should be plug compatible)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;write a cool program&lt;/li&gt;
&lt;li&gt;lexical analysis&lt;/li&gt;
&lt;li&gt;parsing&lt;/li&gt;
&lt;li&gt;semantic analysis&lt;/li&gt;
&lt;li&gt;code generation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;example-hello-world&#34;&gt;Example: Hello World&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Main {
    i : IO &amp;lt;- new IO;
    main():Int { { i.out_string(&amp;quot;Hello World!\n&amp;quot;); 1; } };
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A cool program (&lt;code&gt;*.cl&lt;/code&gt;) should have class Main. A class contains several methods and attributes. Here &lt;code&gt;i&lt;/code&gt; is an attribute with type IO. &lt;code&gt;main()&lt;/code&gt; is a method with return value type &lt;code&gt;Int&lt;/code&gt;. The method contains a block of statements enclosed in parentheses. Each statement should end with a semi-colon. Notice that we write &lt;code&gt;1;&lt;/code&gt; instead of &lt;code&gt;return 1;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Some equivalent code snippets:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Main {
    i : IO &amp;lt;- new IO;
    main():IO { i.out_string(&amp;quot;Hello World!\n&amp;quot;) };
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Main {
    i : IO &amp;lt;- new IO;
    main():Object { i.out_string(&amp;quot;Hello World!\n&amp;quot;) };
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Main {
    main():Object { (new IO).out_string(&amp;quot;Hello World\n&amp;quot;) };
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Main inherits IO {
    main():Object { self.out_string(&amp;quot;Hello World\n&amp;quot;) };
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here &amp;ldquo;inherit&amp;rdquo; means that class Main inherits all the attributes and methods of class IO. In the fourth code snippet, the &amp;ldquo;self&amp;rdquo; can be omitted.&lt;/p&gt;
&lt;h2 id=&#34;example-factorial&#34;&gt;Example: Factorial&lt;/h2&gt;
&lt;p&gt;An example program that reads from stdin, adds 1 and writes to stdout:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Main inherits A2I{
    main() : Object {
        (new IO).out_string( i2a(a2i((new IO).in_string()) + 1).concat(&amp;quot;\n&amp;quot;) )
    };
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;New grammar: i2a() and a2i() in &lt;code&gt;atoi.cl&lt;/code&gt; implements ascii-integer transformation. concat() can concatenate 2 strings together. If you want to compile a library, just list all the file names to the compiler.&lt;/p&gt;
&lt;p&gt;A recursive version of &lt;code&gt;fact.cl&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Main inherits A2I {
    
    main() : Object {
        (new IO).out_string( i2a(a2i(fact((new IO).in_string()))).concat(&amp;quot;\n&amp;quot;) )
    };
    
    fact(i: Int): Int {
        if (i = 0) then 1 else i * fact(i-1) fi
    };
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;New grammar: &lt;code&gt;if-then-else-fi&lt;/code&gt; structure.&lt;/p&gt;
&lt;p&gt;An iterative version of &lt;code&gt;fact.cl&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class Main inherits A2I {
    
    main() : Object {
        (new IO).out_string( i2a(a2i(fact((new IO).in_string()))).concat(&amp;quot;\n&amp;quot;) )
    };
    
    fact(i: Int): Int {
        let fact: Int &amp;lt;- 1 in {
            while (not (i = 0)) loop
                {
                    fact &amp;lt;- fact * i;
                    i &amp;lt;- i - 1;
                }
            pool;
            fact;
        }
    };
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;New grammar: &lt;code&gt;while-loop-pool&lt;/code&gt; structure, &lt;code&gt;let&lt;/code&gt; to define a local variable.&lt;/p&gt;
&lt;p&gt;Pay attention that &lt;code&gt;=&lt;/code&gt; in cool is a comparison operator, assignment operator should be &lt;code&gt;&amp;lt;-&lt;/code&gt; !&lt;/p&gt;
&lt;h2 id=&#34;example-list&#34;&gt;Example: list&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class List {
    item: String;
    next: List;
    
    init(i: String, n: List): List {
        {
            item &amp;lt;- i;
            next &amp;lt;- n;
            self;
        }
    };
    
    flatten(): String {
        if (isvoid next) then
            item
        else
            item.concat(next.flatten())
        fi
    };
};

class Main inherits IO {
    main(): Object {
        let hello: String &amp;lt;- &amp;quot;Hello &amp;quot;,
            world: String &amp;lt;- &amp;quot;World!&amp;quot;,
            newline: String &amp;lt;- &amp;quot;\n&amp;quot;,
            nil: List,
            list: List &amp;lt;- 
                  (new List).init(hello,
                      (new List).init(world,
                          (new List).init(newline, nil)))
        in
            out_string(list.flatten())
    };
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;New grammar: define multiple variables at the same time, the &amp;ldquo;isvoid&amp;rdquo; function.&lt;/p&gt;
&lt;p&gt;A more sophisticated flatten() function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;class List {
    item: String;
    next: List;
    
    init(i: String, n: List): List {
        {
            item &amp;lt;- i;
            next &amp;lt;- n;
            self;
        }
    };
    
    flatten(): String {
        let string: String &amp;lt;-
            case item of
                i: Int =&amp;gt; i2a(i);
                s: String =&amp;gt; s;
                o: Object =&amp;gt; { abort(); &amp;quot;&amp;quot;; };
            esac
        in
            if (isvoid next) then
                string
            else
                string.concat(next.flatten())
            fi
    };
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;New grammar: &lt;code&gt;case of - esac&lt;/code&gt; structure, abort() function&lt;/p&gt;
&lt;p&gt;Note: the &lt;code&gt;&amp;quot;&amp;quot;&lt;/code&gt; is used to convince the type checker that the return value is of type String.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stanford-CS143 Lecture 01: Introduction</title>
      <link>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec01/</link>
      <pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec01/</guid>
      <description>&lt;p&gt;Interpreters: it takes in program and data and and immediately generates output (an on-line process).&lt;/p&gt;
&lt;p&gt;Compilers: it takes in program and generates an executable (assembly/bytecode). The executable takes in data and generates output (an off-line process).&lt;/p&gt;
&lt;h2 id=&#34;the-structure-of-compilers&#34;&gt;The Structure of Compilers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Lexical Analysis: divide program text into &amp;ldquo;words&amp;rdquo; or &amp;ldquo;tokens&amp;rdquo;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-basic&#34;&gt;if x == y then z = 1; else z = 2;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;tokens: &lt;code&gt;if&lt;/code&gt; &lt;code&gt;x&lt;/code&gt;  &lt;code&gt;==&lt;/code&gt; &lt;code&gt;z&lt;/code&gt; &lt;code&gt;then&lt;/code&gt; &lt;code&gt;z&lt;/code&gt; &lt;code&gt;=&lt;/code&gt; &lt;code&gt;1&lt;/code&gt; &lt;code&gt;;&lt;/code&gt; &lt;code&gt;else&lt;/code&gt; &lt;code&gt;z&lt;/code&gt; &lt;code&gt;=&lt;/code&gt; &lt;code&gt;2&lt;/code&gt; &lt;code&gt;;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parsing: understand the sentence structure.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-basic&#34;&gt;if x == y then z = 1; else z = 2;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;if-then-else-+-predicate---relation-+-&#39;x&#39;
             |                      |
             |                      +-&#39;==&#39;
             |                      |
             |                      +-&#39;y&#39;
             |
             +-then-stmt---assign-+-&#39;z&#39;
             |                    |
             |                    +-&#39;1&#39;
             |
             +-else-stmt---assign-+-&#39;z&#39;
                                  |
                                  +-&#39;2&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Semantic Analysis: understand the &amp;ldquo;meaning&amp;rdquo; of sentences.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s too hard for compilers and compilers usually only perform limited semantic analysis to catch inconsistencies, they don&amp;rsquo;t know what programs are supposed to do.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The Complexity of Semantics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Jack said that Jack forgot his homework at home&amp;rdquo;. We even don&amp;rsquo;t know how many people are involved in this sentence without contexts.&lt;/p&gt;
&lt;p&gt;Programming languages define strict rules to avoid such ambiguities. e.g.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;{
 int jack = 3;
 {
     int jack = 4;
     cout &amp;lt;&amp;lt; jack; // should print 4
 }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Optimization: automatically modify programs so that they run faster and use less memory, power, network resources etc.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The complexity of Optimizations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;X = Y * 0&lt;/code&gt; is the same as &lt;code&gt;X = 0&lt;/code&gt; ? It&amp;rsquo;s not necessarily correct! If &lt;code&gt;X&lt;/code&gt; &lt;code&gt;Y&lt;/code&gt; are floating points and &lt;code&gt;Y&lt;/code&gt; is NAN, then NAN * 0 = NAN, instead of zero.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code Generation: a translation into another language (assembly usually).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The proportions of each phase have changed since FORTRAN:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FORTRAN: &lt;code&gt;LLLLLL PPPPPP SS OOOOOO GGGGGG&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Modern: &lt;code&gt;LL PP SSSSSS OOOOOOOOOO GG&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-economy-of-programming-languages&#34;&gt;The Economy of Programming Languages&lt;/h2&gt;
&lt;h3 id=&#34;why-so-many-pls&#34;&gt;Why so many PLs?&lt;/h3&gt;
&lt;p&gt;Application domains have distinctive/conflicting needs. It&amp;rsquo;s hard to design one system for all.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scientific computing: good floating points, good array/tensor operations, parallelism etc. (FORTRAN)&lt;/li&gt;
&lt;li&gt;business applications: persistence, report generation, data analysis etc. (SQL)&lt;/li&gt;
&lt;li&gt;systems programming: control of low-level resources, real-time constraints (C/C++)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;why-new-pls&#34;&gt;Why new PLs?&lt;/h3&gt;
&lt;p&gt;Claim: Programmer training is the dominant cost for a programming language. (Lots of people need to learn this language!)&lt;/p&gt;
&lt;p&gt;Corollaries:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Widely-used languages are slow to change.&lt;/li&gt;
&lt;li&gt;Easy to start a new language (zero user at the start).&lt;/li&gt;
&lt;li&gt;New languages are usually adopted to fill a void (it&amp;rsquo;s easy for new language to adapt to new situations).&lt;/li&gt;
&lt;li&gt;New languages tend to look like old languages (to reduce the training cost).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;whats-a-good-pl&#34;&gt;What&amp;rsquo;s a good PL?&lt;/h3&gt;
&lt;p&gt;Thers is no universally accepted metric for language design.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
