[{"authors":["admin"],"categories":null,"content":"I am Yuyao Wang (王宇峣), a junior in Computer Science (Elite Class) at Nanjing University. My research interest lies in topics related to the correctness, programmability and performance of computer systems.\nI have been attached to programming and algorithm design since middle school and aspire to bring elegant solutions for tackling real-world problems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://kristoff-starling.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am Yuyao Wang (王宇峣), a junior in Computer Science (Elite Class) at Nanjing University. My research interest lies in topics related to the correctness, programmability and performance of computer systems.","tags":null,"title":"Yuyao Wang","type":"authors"},{"authors":["Xingyu Du"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0d6933ca0ad9ac5c9273ee629802d4af","permalink":"https://kristoff-starling.github.io/authors/xingyudu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/xingyudu/","section":"authors","summary":"","tags":null,"title":"Xingyu Du","type":"authors"},{"authors":null,"categories":null,"content":"Table of Contents Chapter 01: Computer Networks and the Internet Chapter 02: Application Layer ","date":1666310400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1666310400,"objectID":"2575b8d873b8a1635316f61a7b16cacb","permalink":"https://kristoff-starling.github.io/notes/booknotes/network-topdown/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/booknotes/network-topdown/","section":"notes","summary":" ","tags":null,"title":"Computer Networking: A Top-Down Approach","type":"docs"},{"authors":null,"categories":null,"content":"Table of Contents Chapter 01: Introduction Chapter 02: The Untyped Lambda Calculus Chapter 03: Programming in the Untyped Lambda Calculus Chapter 04: The Church-Rosser Theorem Chapter 05: Combinatory Algebras Chapter 06: Simply-typed Lambda Calculus, Propositional Logic, and the CurryHoward Isomorphism Chapter 07: Polymorphism Chapter 08: Weak and Strong Normalization Chapter 09: Type Inference Chapter 10: Denotational Semantics Chapter 11: The Language PCF Chapter 12: Complete Partial Orders Chapter 13: Denotational Semantics of PCF ","date":1664928000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1664928000,"objectID":"3fcbc6b6eb2f27e584dabb39263b2629","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-formal-semantics/material/lambda-calculus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-formal-semantics/material/lambda-calculus/","section":"notes","summary":"\\\"This is a set of lecture notes that developed out of courses on the lambda calculus that I taught at the University of Ottawa in 2001 and at Dalhousie University in 2007.\\\" —— Peter Selinger","tags":null,"title":"Peter Selinger's Lecture Notes on Lambda Calculus","type":"docs"},{"authors":null,"categories":null,"content":"Table of Contents Lecture 01: Introduction Lecture 02: Happens-before Memory Model Lecture 03: Operational Semantics for Concurrency Lecture 04: Declarative Semantics for Concurrency ","date":1664841600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1664841600,"objectID":"2a0653b08a9cbc36b05b7dc71c957388","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-concurrency/lectures/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-concurrency/lectures/","section":"notes","summary":" ","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":"","date":1663200000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1663200000,"objectID":"374c8d28ad1c9f7af1c7bf6f506abeee","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-software-analysis/lectures/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-software-analysis/lectures/","section":"notes","summary":"","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":"","date":1663113600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1663113600,"objectID":"40328b85b93aeb0a52aa557afe34b0e6","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-formal-semantics/lectures/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-formal-semantics/lectures/","section":"notes","summary":"","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":" Introduction Cool Overview Lexical Analysis Implementation of Lexical Analysis Introduction to Parsing Syntax-Directed Translation Top-Down Parsing \u0026amp; Bottom-Up Parsing I Bottom-Up Parsing II Semantic Analysis \u0026amp; Type Checking I Type Checking II Run-time Environments Code Generation Operational Semantics Intermediate Code \u0026amp; Local Optimization Global Optimization Register Allocation Automatic Memory Management ","date":1661212800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1661212800,"objectID":"5d06d28104c09ae7aa5b926d2cac8927","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/lectures/","section":"notes","summary":"lexical analysis + parsing + semantics analysis + optimization + code generation","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":"该课程的 Lab 从 baremetal 开始逐渐搭建一个可以在多核 CPU 上并发运行、支持用户进程的操作系统。\n","date":1607817600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1607817600,"objectID":"21ec7694bef83cf5b0502ed09adae287","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/labs/","section":"notes","summary":"该课程的 Lab 从 baremetal 开始逐渐搭建一个可以在多核 CPU 上并发运行、支持用户进程的操作系统。","tags":null,"title":"Labs","type":"docs"},{"authors":null,"categories":null,"content":"该课程的 lectures 按照 Concurrency - Visualization - Persistence 的顺序，介绍了操作系统中的基本概念和前沿技术。\n","date":1607817600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1607817600,"objectID":"3d067a47e16053fa3926033cf64be639","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/","section":"notes","summary":"该课程的 lectures 按照 Concurrency - Visualization - Persistence 的顺序，介绍了操作系统中的基本概念和前沿技术。","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":"MiniLabs 是一些彼此相互独立的小实验，旨在从设计的角度理解操作系统提供的 API 并利用这些 API 实现一些有趣的程序。\n","date":1607817600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1607817600,"objectID":"0f7655e75b3bab2f2deb8b47a8f5f3d7","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/minilabs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/minilabs/","section":"notes","summary":"MiniLabs 是一些彼此相互独立的小实验，旨在从设计的角度理解操作系统提供的 API 并利用这些 API 实现一些有趣的程序。","tags":null,"title":"MiniLabs","type":"docs"},{"authors":null,"categories":null,"content":"","date":1607817600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1607817600,"objectID":"e1937f596829b06912cb810b6d4414f2","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/","section":"notes","summary":"","tags":null,"title":"NJU-22020170 Probability and Mathematical Statistics","type":"docs"},{"authors":null,"categories":null,"content":"Table of Contents Introduction I. Visualization\nA Dialogue on Virtualization The Abstraction: The Process Interlude: Process API Mechanism: Limited Direct Execution Scheduling: Introduction Scheduling: The Multi-Level Feedback Queue Scheduling: Propositional Share Multiprocessor Scheduling (Advanced) Summary Dialogue on CPU Virtualization A Dialogue on Memory Virtualization The Abstraction: Address Spaces Interlude: Memory API Mechanism: Address Translation Segmentation Free-Space Management Paging: Introduction Paging: Faster Translations (TLBs) Paging: Smaller Tables Beyond Physical Memory: Mechanisms Beyond Physical Memory: Policies Complete Virtual Memory Systems Summary Dialogue on Memory Virtualization II. Concurrency\nA Dialogue on Concurrency Concurrency: An Introduction Interlude: Thread API Locks Lock-based Concurrent Data Structures Condition Variables Semaphores Common Concurrency Problems Event-based Concurrency (Advanced) Summary Dialogue on Concurrency III. Persistence\nA Dialogue on Persistence I/O Devices Hard Disk Drives Redundant Arrays of Inexpensive Disks (RAIDs) Interlude: Files and Directories File System Implementation Locality and The Fast File System Crash Consistency: FSCK and Journaling Log-structured File Systems Flash-based SSDs Data Integrity and Protection Summary Dialogue on Persistence A Dialogue on Distribution Distributed Systems Sun\u0026rsquo;s Network File System (NFS) The Andrew File System (AFS) Summary Dialogue on Distribution ","date":1607817600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1607817600,"objectID":"f00baa52fc8a713c00655fb4b2b9940e","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/booknotes/ostep/","section":"notes","summary":"The book is centered around three conceptual pieces that are fundamental to operating systems: virtualization, concurrency, and persistence. In understanding the conceptual, you will also learn the practical, including how an operating system does things like schedule the CPU, manage memory, and store files persistently.","tags":null,"title":"Operating Systems: Three Easy Pieces","type":"docs"},{"authors":null,"categories":null,"content":"","date":1607817600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1607817600,"objectID":"e3aa4b99855ec6dec0bb7ea9f421b367","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/","section":"notes","summary":"","tags":null,"title":"Solutions to OJ","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"0bb0517f08f022089f459897b2e0b5d5","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/homework/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/homework/","section":"notes","summary":"","tags":null,"title":"Homework","type":"docs"},{"authors":null,"categories":null,"content":"Labs for MIT-6.S081 include 11 independent tasks aiming at adding functionalities to xv6.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"948ecda12c0288c0191088b06770dfd0","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/labs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/labs/","section":"notes","summary":"Labs for MIT-6.S081 include 11 independent tasks aiming at adding functionalities to xv6.","tags":null,"title":"Labs","type":"docs"},{"authors":null,"categories":null,"content":"Table of Contents Lab 01: Variables \u0026amp; Functions, Control Lab 02: Higher-Order Function, Lambda Expressions Lab 04: Recursion, Tree Recursion, Python Lists Lab 05: Python Lists, Trees Lab 06: Mutability and Iterators Lab 07: Object-Oriented Programming ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"d6d74d9ba84f4cb0ea5fcdbaaed41ac0","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/labs/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/labs/","section":"notes","summary":"Labs include WWPD problems which focus on student's understanding of Python execution procedure and coding prlblems which focus on student's programming skills.","tags":null,"title":"Labs","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"2e983bd0deac7a2c83b0d0a442ba9af2","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/","section":"notes","summary":"","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"f535b09dd8654f24632de5ad88c5ed0f","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/","section":"notes","summary":"","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"17082a0b208b49488845e9016d984e95","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/","section":"notes","summary":"","tags":null,"title":"Lectures","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"719f3ebb42200ebd6634f258d0011403","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-ics/pa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-ics/pa/","section":"notes","summary":"","tags":null,"title":"Programming Assignments","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"0dbf121cfe5840e0d840af27f9d7c5f8","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/pa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/pa/","section":"notes","summary":"","tags":null,"title":"Programming Assignments","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"289dfafecefe8104ac35d52d0ff8b86f","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/projects/","section":"notes","summary":"","tags":null,"title":"Projects","type":"docs"},{"authors":null,"categories":null,"content":"Table of Contents Functional Programming in Coq (Basics) Proof by Induction (Induction) Working with Structured Data (Lists) Polymorphism and Higher-Order Functions (Poly) More Basic Tactics (Tactics) Logic in Coq (Logic) Inductively Defined Propositions (IndProp) Total and Partial Maps (Maps) The Curry-Howard Correspondence (ProofObjects) Induction Principles (IndPrinciples) Properties of Relations (Rel) Simple Imperative Programs (Imp) Lexing and Parsing in Coq (ImpParser) An Evaluation Function for Imp (ImpCEvalFun) Extracting OCaml from Coq (Extraction) More Automation (Auto) A Streamlined Treatment of Automation (AltAuto) ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"327a339eeb413b7d569dde88bc6210a0","permalink":"https://kristoff-starling.github.io/notes/booknotes/softwarefoundations/lf/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/booknotes/softwarefoundations/lf/","section":"notes","summary":"Logical Foundations is the entry-point to the series. It covers functional programming, basic concepts of logic, computer-assisted theorem proving, and Coq.","tags":null,"title":"Volume 1: Logical Foundations","type":"docs"},{"authors":null,"categories":null,"content":"算法的设计与实现同等重要——前者更倾向于在“数学”层面给出抽象的想法，后者则是将想法切实地转换成一行行的代码。拔尖班课程体系中没有一门“程序设计基础”课，课程设计者的想法是“编程这种简单的工程任务不需要教”。这个说法即正确又有失偏颇：简单的语法规则自然没有赘述的必要，各种教程和手册已经一应俱全；但如何写出高质量的代码，合理地设计程序布局却是一门很大的学问。很多大学的程序设计课都停留在了语法介绍层面而忽略了这点。\n需要承认的是，在 OJ 程序这种几十几百行的“玩具代码”中大谈“面向对象编程”、“面向切口编程”等各种概念多少有些不妥。但即使在这样小规模的程序中仍然有很多值得注意的设计细节。本系列文章将尽可能展示一些这样的经验。事实上，这些小经验在真正大规模的软件工程中也有以小见大的启示作用。\nSystem is art, not science.\n","date":1686096000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1686096000,"objectID":"887fecf2f26d3cec0fafdd5ea262999c","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/coding/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/coding/","section":"courses","summary":" ","tags":null,"title":"Coding","type":"docs"},{"authors":null,"categories":null,"content":"该系列文章针对 OJ 中较难的习题给出提示和解法。\n阅读题解前请确保你已经独立思考过这些题目！ ","date":1686096000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1686096000,"objectID":"8e32b6ef6b418a158fcccefe7f4f29ce","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/","section":"courses","summary":" ","tags":null,"title":"OJ习题讲解","type":"docs"},{"authors":null,"categories":null,"content":"基础算法入门。\n","date":1686096000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1686096000,"objectID":"bfdc6436078dbe6e546ca1358a49a856","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/algorithms/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/algorithms/","section":"courses","summary":" ","tags":null,"title":"算法\u0026数据结构","type":"docs"},{"authors":null,"categories":null,"content":"该文章主要介绍 C/C++ 最基础的语法知识以及最基本的程序架构。本文力求让编程小白也能读懂并上手，因此会略去一些较为复杂的背景知识和细节。\n阅读本文前，你应当已经配置好了一个可以书写代码并编译、运行代码的环境。 ","date":1667260800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1667260800,"objectID":"a8b310516b5df76edb8f6564bfd2c70e","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/","section":"courses","summary":"该文章主要介绍 C/C++ 最基础的语法知识以及最基本的程序架构。本文力求让编程小白也能读懂并上手，因此会略去一些较为复杂的背景知识和细节。","tags":null,"title":"C/C++基础入门","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"817588e3803ca2164a1c836caccc6f18","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/cser0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/cser0/","section":"courses","summary":"no summary","tags":null,"title":"一个CSer应当掌握的基础技能合集","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://kristoff-starling.github.io/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":" 题意概述\n给定一张 $n$ 个点 $m$ 条边的图 $G=(V, E)$，要求将图上的顶点二染色，使得\n$$ \\max_{(u, v)\\in E, color(u)=color(v)} w(u, v) $$\n最小。\n基于并查集的思路 这是一道经典的并查集练习题，我们出题的本意是希望大家使用并查集解决。考虑如下最自然的思路：按边权从大到小排序，然后按顺序将边一条一条插入到图中，直到图无法被二染色。你可能会思考为何不能在加边的时候顺便给节点染上色，每次判断新边连接的两个节点是否同色。该做法在连接不同的连通块时会出现问题，例如\n新加入的红色边其实并没有导致问题，我们只要将下面连通块的染色方案换一下就行。但我们每次加边创建出新连通块时无法确定怎么给它染色，因此这条路行不通。我们应该转而去维护点之间的同类关系而不是强行染色，而维护同类关系正是并查集所擅长的。\n本题的难点在于：每条边描述的都是“两个点不能属于同一阵营”，如何将其转化为对同类关系的描述？这里有一个非常精妙的技巧。我们创建 $2n$ 个节点，1~n 是原本的节点，n+1~2n 这些节点，$n+i$ 是 $i$ 的“假想敌”。这样如果 $i$ 和 $j$ 之间有边，我们要做的就是在并查集中将 $i$ 和 $n+j$ 合并，$j$ 和 $n+i$ 合并。容易发现“假想敌”的设计非常好地实现了“敌人的敌人是朋友”：如果 $i$ 和 $j$，$k$ 和 $j$ 有边，那么 $i$ 和 $k$ 都会与 $n+j$ 在并查集中合并，从而 $i$ 和 $k$ 属于同一阵营。在每条边 $(i, j)$ 加入之前，我们只需在并查集中查询 $i$ 和 $j$ 的关系，然后按照上面的方法更新关系即可。假设 $n$ 和 $m$ 同阶，理论时间复杂度为 $O(n\\alpha(n))$。\n基于二分答案的思路 如果你仔细阅读了二分答案章节的讲义，你会发现该问题满足二分答案问题的所有“套路”，尤其是最关键的一点：这是一个最小化最大值的问题。因此我们只需二分答案 $mid$，然后关注由原图中边权大于 $mid$ 的边构成的子图。我们要保证这些边不会落到同一个颜色中，所以要判断该图是否可以二染色。你可以参考 I-Final-C，用一遍搜索完成可二染色判断。假设 $n$ 和 $m$ 同阶，则时间复杂度为 $O(n\\log n)$。\n","date":1686096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686096000,"objectID":"4325086cf03b0c86ae536f56b44ff0b6","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-6-c/","publishdate":"2023-06-07T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-6-c/","section":"courses","summary":"题意概述\n给定一张 $n$ 个点 $m$ 条边的图 $G=(V, E)$，要求将图上的顶点二染色，使得\n$$ \\max_{(u, v)\\in E, color(u)=color(v)} w(u, v) $$\n最小。\n基于并查集的思路 这是一道经典的并查集练习题，我们出题的本意是希望大家使用并查集解决。考虑如下最自然的思路：按边权从大到小排序，然后按顺序将边一条一条插入到图中，直到图无法被二染色。你可能会思考为何不能在加边的时候顺便给节点染上色，每次判断新边连接的两个节点是否同色。该做法在连接不同的连通块时会出现问题，例如\n新加入的红色边其实并没有导致问题，我们只要将下面连通块的染色方案换一下就行。但我们每次加边创建出新连通块时无法确定怎么给它染色，因此这条路行不通。我们应该转而去维护点之间的同类关系而不是强行染色，而维护同类关系正是并查集所擅长的。\n本题的难点在于：每条边描述的都是“两个点不能属于同一阵营”，如何将其转化为对同类关系的描述？这里有一个非常精妙的技巧。我们创建 $2n$ 个节点，1~n 是原本的节点，n+1~2n 这些节点，$n+i$ 是 $i$ 的“假想敌”。这样如果 $i$ 和 $j$ 之间有边，我们要做的就是在并查集中将 $i$ 和 $n+j$ 合并，$j$ 和 $n+i$ 合并。容易发现“假想敌”的设计非常好地实现了“敌人的敌人是朋友”：如果 $i$ 和 $j$，$k$ 和 $j$ 有边，那么 $i$ 和 $k$ 都会与 $n+j$ 在并查集中合并，从而 $i$ 和 $k$ 属于同一阵营。在每条边 $(i, j)$ 加入之前，我们只需在并查集中查询 $i$ 和 $j$ 的关系，然后按照上面的方法更新关系即可。假设 $n$ 和 $m$ 同阶，理论时间复杂度为 $O(n\\alpha(n))$。","tags":null,"title":"【问题求解II-HW6.C】关押罪犯","type":"docs"},{"authors":null,"categories":null,"content":"二分答案是一种充分利用答案的离散特性和问题的单调特性，用 $O(\\log n)$ 倍的时间复杂度的代价将最优化问题转化为判定问题的思想。这句话有些抽象，我们通过一道例题来展示二分答案思想的运用。\n例题\n给定一个长度为 $n(1\\leq n\\leq 10^5)$ 的正整数数列和一个整数 $k$，要求将数列划分成连续的 $k$ 份 (形象地来说，将其切成 $k$ 段)，对每一段中的数求和，要求最大的和最小，并输出这个和。\n这题困难的地方在于你很难确定第一刀切在哪里——如果切的太靠后，这一段的和本身可能就太大了；如果切的太靠前，后面的段可能包含的数过多，会导致后面的段的和太大。该题最优化的要求使得我们每一步既要瞻前也要顾后，从而难以下手。\n我们利用这个问题来解释二分答案思想的合适使用场景：\n答案的离散性：最终答案一定是一个 $[1, \\sum a_i]$ 之间的整数，可选的答案是有限个。 问题的单调性：如果 $s$ 满足题目的要求，即存在一个划分方案满足最大和小于等于 $s$，那么所有大于 $s$ 的值都满足条件。在单调性的基础上，你可以看出 $[1, \\sum a_i]$ 中的整数存在一个“分界线”，小于分界线的数都给不出划分方案 (无法成为答案)，大于等于该分界线的都可以给出划分方案。我们要找的就是这个“分界线”。 二分答案 (以原问题为最小化问题为例，最大化问题相反) 的框架如下\nl, r, ans = 答案的下限, 答案的上限, 0 while l \u0026lt;= r: mid = (l + r) \u0026gt;\u0026gt; 1 if check(mid): # mid 是合法的 ans = mid # 作为备选答案 r = mid - 1 # 尝试往左寻找更小的答案 else: l = mid + 1 # “分界线”在右侧 在本问题中，通过二分答案，我们可以将每轮的问题转化为：是否存在一个划分方案，使得每段的和都不超过 $mid$？这个问题存在简单的贪心解法，我们尽可能让当前段容纳更多的数，直到再加入一个数就超过限制了的时候，我们划一刀开启新的一段。最终是否合法取决于能否用不超过 $k$ 段把所有的数容纳进来。\n二分答案的外层框架提供了 $O(\\log \\sum a_i)$ 的代价，里面每一轮检查都是 $O(n)$ 的，因此总时间复杂度为 $O(n\\log \\sum a_i)$。\n套路\n虽然硬背套路是高考生才做的事，但我们在这里仍然给出可使用二分答案思想解决的问题通常具有的典型特征，供大家作为参考：\n答案的离散性、问题的单调性。 问题最后求的是“最小值的最大值”或“最大值的最小值”。 ","date":1686096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686096000,"objectID":"75bb7796886538d0fb0b700d103c5ffb","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/algorithms/answer-binary-search/","publishdate":"2023-06-07T00:00:00Z","relpermalink":"/courses/problemsolving22/algorithms/answer-binary-search/","section":"courses","summary":"二分答案是一种充分利用答案的离散特性和问题的单调特性，用 $O(\\log n)$ 倍的时间复杂度的代价将最优化问题转化为判定问题的思想。这句话有些抽象，我们通过一道例题来展示二分答案思想的运用。\n例题\n给定一个长度为 $n(1\\leq n\\leq 10^5)$ 的正整数数列和一个整数 $k$，要求将数列划分成连续的 $k$ 份 (形象地来说，将其切成 $k$ 段)，对每一段中的数求和，要求最大的和最小，并输出这个和。\n这题困难的地方在于你很难确定第一刀切在哪里——如果切的太靠后，这一段的和本身可能就太大了；如果切的太靠前，后面的段可能包含的数过多，会导致后面的段的和太大。该题最优化的要求使得我们每一步既要瞻前也要顾后，从而难以下手。\n我们利用这个问题来解释二分答案思想的合适使用场景：\n答案的离散性：最终答案一定是一个 $[1, \\sum a_i]$ 之间的整数，可选的答案是有限个。 问题的单调性：如果 $s$ 满足题目的要求，即存在一个划分方案满足最大和小于等于 $s$，那么所有大于 $s$ 的值都满足条件。在单调性的基础上，你可以看出 $[1, \\sum a_i]$ 中的整数存在一个“分界线”，小于分界线的数都给不出划分方案 (无法成为答案)，大于等于该分界线的都可以给出划分方案。我们要找的就是这个“分界线”。 二分答案 (以原问题为最小化问题为例，最大化问题相反) 的框架如下","tags":null,"title":"二分答案","type":"docs"},{"authors":null,"categories":null,"content":"《算法导论》中提到基于路径压缩和按秩合并的并查集更新和查询的均摊时间复杂度为 $O(\\alpha(n))$，其中 $\\alpha$ 为反阿克曼函数。实践中大家通常写只带有路径压缩的并查集，因为按秩合并写起来更加麻烦 (虽然只需要几行)。我们承认只带有路径压缩的并查集时间复杂度会退化为 $O(\\log n)$1，但这样的数据不太容易构造，且 $\\log n$ 其实也相当好了。然而，对于新手来说，路径压缩可能也相当难实现，因此本讲义向大家展示并查集的实现技巧。\n并查集和树状数组是许多程序员心爱的数据结构，因为它们思维巧妙，功能强大，且优秀的实现极其简洁。这里我们给出一份完整的带有路径压缩和按秩合并的并查集模板：\nnamespace DSU { int pre[MAXN], rnk[MAXN]; void init() { for (int i = 1; i \u0026lt;= n; i++) pre[i] = i, rnk[i] = 1; } int find_anc(int x) { if (pre[x] != x) pre[x] = find_anc(pre[x]); return pre[x]; } void merge(int x, int y) { x = find_anc(x); y = find_anc(y); if (rnk[x] \u0026gt; rnk[y]) pre[y] = x; else { if (rnk[x] == rnk[y]) rnk[y]++; pre[x] = y; } } } 你需要重点关注的是 find_anc() 函数，它只用一行就在查询集合代表元的同时完成了路径压缩，本质上是在找到代表元之后将路径上所有的节点直接挂到根下。\n如果你觉得麻烦，可以省略按秩合并的部分 (但要付出一点点复杂度的代价，通常可以接受)。还有一些程序员会选择用启发式合并代替按秩合并 (即维护每个集合的元素个数，每次将小的集合合并到大的集合当中)，可以证明路径压缩+启发式合并也可以做到 $O(\\alpha(n))$1。\n如果你感兴趣，可以参考 这篇博文 详细了解。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1686096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686096000,"objectID":"d0681e8650b4447f8511a16aead306ca","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/coding/dsu/","publishdate":"2023-06-07T00:00:00Z","relpermalink":"/courses/problemsolving22/coding/dsu/","section":"courses","summary":"《算法导论》中提到基于路径压缩和按秩合并的并查集更新和查询的均摊时间复杂度为 $O(\\alpha(n))$，其中 $\\alpha$ 为反阿克曼函数。实践中大家通常写只带有路径压缩的并查集，因为按秩合并写起来更加麻烦 (虽然只需要几行)。我们承认只带有路径压缩的并查集时间复杂度会退化为 $O(\\log n)$1，但这样的数据不太容易构造，且 $\\log n$ 其实也相当好了。然而，对于新手来说，路径压缩可能也相当难实现，因此本讲义向大家展示并查集的实现技巧。\n并查集和树状数组是许多程序员心爱的数据结构，因为它们思维巧妙，功能强大，且优秀的实现极其简洁。这里我们给出一份完整的带有路径压缩和按秩合并的并查集模板：\nnamespace DSU { int pre[MAXN], rnk[MAXN]; void init() { for (int i = 1; i \u0026lt;= n; i++) pre[i] = i, rnk[i] = 1; } int find_anc(int x) { if (pre[x] !","tags":null,"title":"并查集","type":"docs"},{"authors":null,"categories":null,"content":" 题意概述\n有两块 Cache 和 $n$ 个程序，每个程序有一个类别 (共有 $k$ 种类别)，在同一块 Cache 上连续执行相同种类的程序第二次只需 $hot_i$ 的时间，否则需要 $cold_i$ 的时间。问串行执行所有程序所需的最小时间。 $n, k\\leq 5000$。 本题摘自 Codeforces 1799D1。你可以点击网站右侧的 Tutorial 查看官方题解 (官方题解从最朴素的时间复杂度为 $O(nk^2)$ 的动态规划讲起，逐步优化，清晰易懂，非常建议同学们仔细阅读)。这里我们给出一个另外的解法，比官方解法更加简洁高效。\n我们首先可以发现一个贪心性质。对于某一个类型为 $t$ 的程序来说，如果它只需要花 $hot_t$ 的时间执行，那么情况一定是：在这个程序之前最近的一个类型为 $t$ 的程序在某块 Cache 上 (不妨记为 Cache 0) 执行之后，它们中间的程序都在 Cache 1 上执行，然后当前程序在 Cache 0 上执行。为什么当前程序不可能“继承\u0026quot;更早的 $t$ 类型程序使用的 Cache 呢？假设这种情况发生了，如下图：\n在这个例子中，当前的1类型程序“继承”了更早的同类型程序，它们中间还夹着一个1类型程序。那么我们没有道理不把中间的这个1类型程序拉到下面的 Cache 上执行——一方面，这个1类型程序的左右都不是1类型，将它挪下来甚至可能让上面这块 Cache 多命中一次 (虽然图示例子不符合这个情况，1 的左右程序类型不一样)，另一方面，把这个程序拉下来可以让它享受 $hot_1$ 的执行时间。因此这是一笔稳赚不赔的买卖。\n我们在这个性质的基础上进行动态规划。为了方便叙述，我们首先约定一些记号：\n令 $last_i$ 表示在第 $i$ 个程序之前最近的一个和 $i$ 同类型的程序的位置。该数组不难获取，具体细节留给大家思考。 令 $sum_{l, r}$ 表示将 $[l+1, r]$ 这个区间里的程序按顺序在同一块 Cache 上执行所需的总时间，注意我们不计算第 $l$ 个程序的执行时间，将第 $l$ 个程序纳入讨论是为了确定第 $l+1$ 个程序能否享受到 Cache hit 的加速。该记号可以通过前缀和实现。 令 $dp(i, 0/1)$ 表示当前看到第 $i$ 个程序，第 $i$ 个程序使用的 Cache 和第 $i-1$ 个程序一样 (用第二维的 1 表示)/不一样 (0) 的情况下，最小的执行时间。令第 $i$ 个程序的类型为 $t$，分以下两种情况讨论：\n第 $i$ 个程序没有享受到 Cache hit，花了 $cold_t$ 的时间执行：这种情况下我们完全不用在意前面是哪两个程序留在了 Cache 里，因为我们没打算 Cache hit。因此 $$ dp(i, 0) = dp(i, 1) = \\min\\{dp(i-1, 0), dp(i-1, 1)\\} + cold_t $$ 第 $i$ 个程序享受到了 Cache hit，花了 $hot_t$ 的时间执行：根据我们之前发现的结论，它一定是继承了和它最近的相同类型程序的 Cache，然后中间的其他程序在另一块 Cache 上执行，这里又分两种情况： 上一个同类型的程序是第 $i-1$ 个，则此时满足“和前一个程序使用了同一块 Cache”，因此更新 $dp(i, 1)$： $$ dp(i, 1) = \\min\\{dp(i - 1, 0), dp(i - 1, 1)\\} + hot_t $$\n上一个同类型的程序不是第 $i-1$ 个，则此时更新 $dp(i, 0)$: $$ dp(i, 0) = dp(last_i + 1, 0) + sum_{last_i+1, i - 1} + hot_t $$\n注意一个细节：$dp(last_i+1, 0)$ 只能从 0 状态转移来，因为我们要强制 $[last_i + 1, i - 1]$ 的程序换到另一块 Cache 上。在这种情况中，你也可以体会到为什么状态设计中有这么一个看似奇怪的“和前一个程序是否使用同一块 Cache”。\n对上述所有情况取 min 即可。你可能会有疑问：第一种情况计算的是不是不太精细，随便放也是有可能命中的？但命中情形下的最优解一定会被第二类情况覆盖到，所以第一种计算的粗糙一些问题不大。第一种情况存在的意义是保证 Cache miss 下达到最小时间的情况被覆盖到 (有点玄妙，请仔细体会)。\n最终答案为 $\\min\\{dp(n, 0), dp(n, 1)\\}$，时间复杂度和空间复杂度均为 $O(n+k)$。\n","date":1686009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686009600,"objectID":"0c421bafd88d81d5eee603debcc42f18","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-6-b/","publishdate":"2023-06-06T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-6-b/","section":"courses","summary":"题意概述\n有两块 Cache 和 $n$ 个程序，每个程序有一个类别 (共有 $k$ 种类别)，在同一块 Cache 上连续执行相同种类的程序第二次只需 $hot_i$ 的时间，否则需要 $cold_i$ 的时间。问串行执行所有程序所需的最小时间。 $n, k\\leq 5000$。 本题摘自 Codeforces 1799D1。你可以点击网站右侧的 Tutorial 查看官方题解 (官方题解从最朴素的时间复杂度为 $O(nk^2)$ 的动态规划讲起，逐步优化，清晰易懂，非常建议同学们仔细阅读)。这里我们给出一个另外的解法，比官方解法更加简洁高效。\n我们首先可以发现一个贪心性质。对于某一个类型为 $t$ 的程序来说，如果它只需要花 $hot_t$ 的时间执行，那么情况一定是：在这个程序之前最近的一个类型为 $t$ 的程序在某块 Cache 上 (不妨记为 Cache 0) 执行之后，它们中间的程序都在 Cache 1 上执行，然后当前程序在 Cache 0 上执行。为什么当前程序不可能“继承\u0026quot;更早的 $t$ 类型程序使用的 Cache 呢？假设这种情况发生了，如下图：","tags":null,"title":"【问题求解II-HW6.B】Cache调度","type":"docs"},{"authors":null,"categories":null,"content":" 题意概述\n有一个 $n$ 层的高楼。存在一个未知的分界楼层 $X$，在 $1\u0026hellip;X$ 层扔鸡蛋落地不会碎；在 $X+1$ 层以及更高的楼层扔鸡蛋落地会碎。问用 $k$ 个鸡蛋最少扔几次可以确定 $X$。 $n\\leq 10^4, k\\leq 100$。 引子 这是一个十分有趣的问题。我们首先思考扔鸡蛋到底意味着什么：\n一个鸡蛋如果在 $x$ 层扔下去没碎，说明 $X\\geq x$，否则 $X\u0026lt;x$。 鸡蛋碎与不碎是有区别的：如果所有鸡蛋都碎了但我们仍没有找出 $X$，那就寄了。 基于这些观察，我们先进行一些简单情况的思考：\n如果我们手里只有一个鸡蛋，那么我们没有犯错空间，只能从一楼开始一层一层往上扔，次数为 $O(n)$。 如果我们手里有两个鸡蛋，那我们的策略应该是这样的：用第一个鸡蛋把一个大致的范围框出来——例如选择在 $l_1=1, l_2, \\cdots, l_m=n$ 这些点扔鸡蛋，把范围缩小到某个 $[l_i, l_{i+1})$ 后，再用第二个鸡蛋一层层试过去。这个策略很像之前提过的“分块”。如果我们选取那些 $\\sqrt n$ 的倍数位置作为第一轮的节点，则抛鸡蛋次数为 $O(\\sqrt n)$。 …… 动态规划 (I) 我们可以看到“用前面的鸡蛋的牺牲为后面的鸡蛋缩小范围”是一个核心思路。对于更多数量的鸡蛋，硬想已经很难想得清楚。考虑使用动态规划。\n一个非常直接的动态规划状态设计是：令 $dp(k, n)$ 表示手里有 $k$ 个鸡蛋，要确定 $n$ 层大楼的答案，最少需要扔几次 (这个状态设计和原问题的描述是完全一致的)。转移考虑第一次应该在哪一层扔鸡蛋。如果第一次在第 $i$ 层扔鸡蛋，有两种情况：\n鸡蛋碎了，则需要用 $k-1$ 个鸡蛋在 $1\\cdots i-1$ 层确定答案。 鸡蛋没碎，则需要用 $k$ 个鸡蛋在 $i\\cdot n$ 层确定答案。 这两种情况会落入哪一种是我们无法预知的，但为了保证找出答案，求次数时应该对其取 max。不过第一次在哪里扔是我们可以决定的，所以我们可以遍历所有可能的第一层，对所有情况取 min (请仔细体会取min/max的逻辑)。因此状态转移方程为\n$$ dp(k, n) = \\min_{1\\leq i\\leq n}\\left(\\max\\{dp(k-1,i-1)+1, dp(k, n-i+1)+1\\}\\right) $$\n该算法的空间复杂度为 $O(kn)$，时间复杂度为 $O(kn^2)$。对于本题来说仍需要优化。\n基于状态转移方程单调性的优化 我们将 $dp(k, n)$ 看作关于 $k$ 和 $n$ 的二元函数，来观察它的单调性。容易发现它关于 $n$ 是单调增的 (大楼高度增加扔的次数肯定更多)。再次观察上述的状态转移方程，可以发现随着 $i$ 的增大，第一项 $dp(k-1, i-1)$ 一直在变大，第二项 $dp(k, n-i+1)$ 一直在变小。如果画成图的话大概是这样：\n可以看到，状态转移方程中的函数 (绿色) 是单峰的 (即形如二次函数)。它在红色和蓝色线相等的地方取到最小值。因此对于每个 $dp(k, n)$，我们可以通过二分查找而不是一一枚举的方式寻找取到最小值的点 (红色减蓝色的结果是单调的)，时间复杂度优化至 $O(kn\\log n)$。(注意：图上的红色和蓝色线是连续的，而实际问题中 dp 数组是离散的，因此你实际需要找的是“红色和蓝色差值最小的地方”。)\n基于决策单调性的优化 在这个思路的基础上还可以进一步优化。我们令 $M_{k, n}$ 表示使得 $dp(k, n)$ 取到最小值的状态转移方程中的那个 $i$。朴素方法通过枚举确定 $M_{k, n}$，第一版优化通过二分查找确定 $M_{k, n}$，这里我们利用决策单调性均摊 $O(1)$ 地确定 $M_{k, n}$。\n如果把 $M_{k, n}$ 看作关于 $k$ 和 $n$ 的函数，我们容易发现它关于 $n$ 是单调递增的。\n直觉上，大楼的总层数增高了，那么第一次扔鸡蛋的位置肯定应该相对应地调高，否则如果鸡蛋没碎，上面待探索的层数就会太多。 严谨地计算上，对于 $dp(k, n)$ 问题，$M_{k, n}$ 满足 $dp(k-1, M_{k, n}) = dp(k, n-M_{k, n}+1)$。那么对于 $dp(k, n+1)$ 问题， $$ dp(k-1, M_{k,n}) = dp(k, n-M_{k, n}+1) \\overset{dp关于n的单调性}{\\leq} dp(k, (n+1) - M_{k, n} + 1) $$ 因此必然有 $M_{k, n+1}\\geq M_{k, n}$。 $M_{k, n}$ 是每轮的最优点，也称为决策点。所以 $M_{k, n}$ 满足的单调性质称为决策单调性。基于决策单调性，对于每个 $k$，我们在计算 $M_{k, n}$ 时，不用从 1 开始枚举，而可以从 $M_{k, n-1}$ 开始枚举。因为 $dp(k, *)$ 一层中所有的 $M_{k, *}$ 的枚举合起来复杂度为 $O(n)$，所以算法的总时间复杂度降至 $O(kn)$。\n动态规划 (II) 动态规划 (I) 的优点在于它选择从一个非常自然的状态设计出发解决问题，整个思维过程没有大的跃迁点。但缺点在于对优化能力的要求较高，如果水平不足很可能卡在 $O(kn^2)$ 的位置无法前进。这里我们介绍另一种动态规划的状态设计，它的状态和转移都有点“神之一手”的意味，但一旦想到整个问题就变得非常简单。\n令 $dp(k, m)$ 表示用 $k$ 个鸡蛋扔 $m$ 次，最多可以在多高的楼层范围内确定答案 (例如 $dp(1, m)=m$，因为一个鸡蛋只能从1楼开始一层层往上)。考虑如何转移：在这种状态设计下，我们可以精确地确定第一次该在哪里扔鸡蛋。因为鸡蛋如果碎了，我们就要用 $k-1$ 个鸡蛋在 $m-1$ 次内找出答案，而这个条件下能确定的最大层数恰好是 $dp(k-1, m-1)$。所以我们第一轮应该在第 $dp(k-1, m-1) + 1$ 层扔鸡蛋。另外，如果鸡蛋没碎，我们还可以用 $k$ 个鸡蛋扔 $m-1$ 次，从而最多可以再向上探索 $dp(k, m-1)$ 层，因此状态转移方程为\n$$ dp(k, m) = dp(k-1, m-1) + 1 + dp(k, m-1) $$\n剩下的问题是，对于每个 $k$，$m$ 要枚举到多大？由于 $dp(k, m)$ 关于 $m$ 单调递增，所以我们只要枚举到 $dp(k, m)\\geq n$ 的 $m$ 即可。一件显然的事情是 $m\\leq n$，因此复杂度的一个上界是 $O(kn)$，这已经足够优秀了1。\n基于“信息论”的思路 这个解法的思路比较清奇，仅供大家欣赏。令 $f(k, m)$ 表示用 $k$ 个鸡蛋，扔 $m$ 次可以确定答案的最多楼层数，我们其实可以不借助任何基础推导，直接给出数学结果2:\n$$ f(k, m) = \\sum_{i=1}^k\\binom{m}{i} $$\n它的道理来自以下的分析：\n用 $k$ 个鸡蛋扔 $m$ 次这个实验的本质，是建立一个从仅包含0和1的状态字符串到最终答案的映射。这里 01 串至多 $m$ 位，表示每次扔鸡蛋的结果，0 是碎了，1 是没有碎。因为我们只有 $k$ 个鸡蛋，所以 01 串里至多只能有 $k$ 个 0。注意两个细节：\n如果从头到尾鸡蛋都没有碎过，那么我们不可能知道答案 (因为没有上界)，所以全 1 的串无效。 如果串中有 $k$ 个 0，那么最后一个必须是 0 (因为鸡蛋碎完了就没有鸡蛋可扔了)。 因此合法的状态共有\n$$ \\sum_{i=1}^{k-1}\\binom{m}{i} + \\sum_{i=k}^m\\binom{i-1}{k-1} $$\n其中前面一个求和表示包含小于 $k$ 个 0 的合法字符串的个数，后面一个求和表示恰好 $k$ 个 0 的合法字符串的个数。后面一类由于固定了一个 0 在字符串末尾，所以只有 $k-1$ 个可支配的 0 (注：我们认为组合数 $n$ 选 $m$ 如果 $n\u0026lt;m$ 则值为 0，这与广义组合数的定义相容)。通过简单的数学推导你可以发现 $\\displaystyle \\sum_{i=k}^m\\binom{i-1}{k-1}=\\binom{m}{k}$ (将第一项 $\\displaystyle\\binom{k-1}{k-1}$ 改写为 $\\displaystyle \\binom{k}{k}$，然后采用“滚雪球法”)，或者你也可以通过思维推导发现如果在这种字符串的末尾添加占位符将其长度补到 $m$，本质上就是 $\\displaystyle \\binom{m}{k}$。总之，合法的状态总数为\n$$ \\sum_{i=1}^k\\binom{m}{i} $$\n鸡蛋落地的结果序列必须可以和楼层建立一一映射，否则一定存在无法分辨的两个楼层 (可以参考使用决策树证明基于比较的排序算法的复杂度下界的过程来理解这句话)，所以答案的上界是 $\\sum_{i=1}^k\\binom{m}{i}$。又因为每次鸡蛋碎与不碎会将我们引导到两个不相交的区域 ($[1, x-1]$ 和 $[x, n]$) 进行下一步操作，所以这个上界是可以做到的。因此 $f(k, m)=\\sum_{i=1}^k\\binom{m}{i}$。进一步地，你可以发现我们在此处定义 0 为碎的巧妙之处：将所有状态串按照字典序从小到大排序，排在第 $i$ 位的字符串恰好就是确定第 $i$ 层的扔法。\n有了这个结果，我们可以直接二分 $m$，然后计算 $f(k, m)$ 并与 $n$ 比较。时间复杂度 $O(k\\log n)$。\nLeetCode的 官方题解 不加证明地给出了 $O(k\\sqrt[k]{n})$ 的复杂度。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n事实上，第二种解法里的动态规划状态转移方程本身长的就很像二项式系数的递推式。如果你对这个转移方程进行差分等数学处理，也可以得到如下的结果。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1685232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685232000,"objectID":"f10101819b3bcc5a659489ed98ef4778","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-5-a/","publishdate":"2023-05-28T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-5-a/","section":"courses","summary":"题意概述\n有一个 $n$ 层的高楼。存在一个未知的分界楼层 $X$，在 $1\u0026hellip;X$ 层扔鸡蛋落地不会碎；在 $X+1$ 层以及更高的楼层扔鸡蛋落地会碎。问用 $k$ 个鸡蛋最少扔几次可以确定 $X$。 $n\\leq 10^4, k\\leq 100$。 引子 这是一个十分有趣的问题。我们首先思考扔鸡蛋到底意味着什么：\n一个鸡蛋如果在 $x$ 层扔下去没碎，说明 $X\\geq x$，否则 $X\u0026lt;x$。 鸡蛋碎与不碎是有区别的：如果所有鸡蛋都碎了但我们仍没有找出 $X$，那就寄了。 基于这些观察，我们先进行一些简单情况的思考：\n如果我们手里只有一个鸡蛋，那么我们没有犯错空间，只能从一楼开始一层一层往上扔，次数为 $O(n)$。 如果我们手里有两个鸡蛋，那我们的策略应该是这样的：用第一个鸡蛋把一个大致的范围框出来——例如选择在 $l_1=1, l_2, \\cdots, l_m=n$ 这些点扔鸡蛋，把范围缩小到某个 $[l_i, l_{i+1})$ 后，再用第二个鸡蛋一层层试过去。这个策略很像之前提过的“分块”。如果我们选取那些 $\\sqrt n$ 的倍数位置作为第一轮的节点，则抛鸡蛋次数为 $O(\\sqrt n)$。 …… 动态规划 (I) 我们可以看到“用前面的鸡蛋的牺牲为后面的鸡蛋缩小范围”是一个核心思路。对于更多数量的鸡蛋，硬想已经很难想得清楚。考虑使用动态规划。","tags":null,"title":"【问题求解II-HW5.A】高楼抛鸡蛋","type":"docs"},{"authors":null,"categories":null,"content":" 题意概述\n给定两个字符串 $s, t$，求两者的最长公共子序列的长度。 $1\\leq |s|\\leq 10^6, 1\\leq |t|\\leq 10^3$。 求字符串的最长公共子序列长度是一个经典的动态规划入门问题。该问题有如下非常经典的状态设计和转移“套路”：\n令 $dp(i, j)$ 表示 $s[1\u0026hellip;i]$ 和 $t[1..j]$ 这两个串的最长公共子序列长度，那么最终答案显然为 $dp(|s|, |t|)$。转移考虑 $s[i]$ 和 $t[j]$ 是否在最长公共子序列中：\n若 $s[i]$ 不在最长公共子序列中，则可以从 $dp(i-1, j)$ 转移来。 若 $t[j]$ 不在最长公共子序列中，则可以从 $dp(i, j-1)$ 转移来。 若 $s[i]$ 和 $t[j]$ 都在公共子序列中 (注意它们是最后一个字符，所以它们一定要能匹配上 (相同))，则可以从 $dp(i-1, j-1)+1$ 转移来。 对以上三种情况取最大值即可。该动态规划的时间复杂度和空间复杂度均为 $O(|s||t|)$。\n本题的特别之处在于 $s$ 很长而 $t$ 很短，且 $|s||t|$ 超出了我们能够承受的范围 (无论是时间还是空间)，因此前面提到的传统做法不太奏效。本题希望让大家明白的是：对于求极值的动态规划问题，状态和值之间通常可以互相转化。一个动态规划问题通常有若干个变量 (记为 $m$ 个)，动态规划状态会固定住其中的 $m-1$ 个变量，动态规划的值则是剩下的那个变量的极值。对于大部分人来说，最自然的选择是将题目要求的那个变量作为动态规划的值，但有时为了缩减状态数，我们会选择“看起来别扭”的设计，将取值空间小的那些变量作为动态规划的状态。\n以本题为例，本题的变量有三个：$s$ 的前缀长度，$t$ 的前缀长度，最长公共子序列的长度。因为本题求的是第三个，所以前面提到的传统状态设计最容易让人理解。但在本题的数据范围下，你会发现 $s$ 的前缀长度有 $10^6$ 种可能，而后两者的取值空间都是 $10^3$，因此我们来设计如下一种“看起来很奇怪的状态”：\n令 $dp(i, j)$ 表示考虑 $t[1\u0026hellip;i]$，如果想要获得长度为 $j$ 的最长公共子序列，$s$ 的前缀至少要取到哪里 (如果做不到则值为 $|s|+1$)。虽然听起来很拗口，但转移仍然可行。考虑以下情形：\n最长公共子序列不包含 $t[i]$，则可以从 $dp(i-1, j)$ 直接转移来。 最长公共子序列包含 $t[i]$，从 $dp(i-1, j-1)$ 转移来。记 $x=dp(i-1, j-1)$，现在的状况是：$s[1\u0026hellip;x]$ 和 $t[1\u0026hellip;i-1]$ 有一个长度为 $j-1$ 的公共子串。我们要从 $x+1$ 往后继续延伸，找到第一个和 $t[i]$ 相同的字符匹配上从而达到要求。因此我们可以预处理一个数组 $nxt(i, ch)$ 表示从 $s[i]$ 开始第一个字符 $ch$ 出现在哪里 (这并不困难，留给大家作为思考)。 我们把取值空间小的两个状态作为动态规划的状态，把最大的那个作为值。值是不需要在执行过程中枚举的，因此我们有效优化了复杂度。该做法的时间复杂度和空间复杂度均为 $O(|t|^2)$。\n","date":1685059200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685059200,"objectID":"cc90acd344b38c29bba0801833024da4","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-5-b/","publishdate":"2023-05-26T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-5-b/","section":"courses","summary":"题意概述\n给定两个字符串 $s, t$，求两者的最长公共子序列的长度。 $1\\leq |s|\\leq 10^6, 1\\leq |t|\\leq 10^3$。 求字符串的最长公共子序列长度是一个经典的动态规划入门问题。该问题有如下非常经典的状态设计和转移“套路”：\n令 $dp(i, j)$ 表示 $s[1\u0026hellip;i]$ 和 $t[1..j]$ 这两个串的最长公共子序列长度，那么最终答案显然为 $dp(|s|, |t|)$。转移考虑 $s[i]$ 和 $t[j]$ 是否在最长公共子序列中：\n若 $s[i]$ 不在最长公共子序列中，则可以从 $dp(i-1, j)$ 转移来。 若 $t[j]$ 不在最长公共子序列中，则可以从 $dp(i, j-1)$ 转移来。 若 $s[i]$ 和 $t[j]$ 都在公共子序列中 (注意它们是最后一个字符，所以它们一定要能匹配上 (相同))，则可以从 $dp(i-1, j-1)+1$ 转移来。 对以上三种情况取最大值即可。该动态规划的时间复杂度和空间复杂度均为 $O(|s||t|)$。","tags":null,"title":"【问题求解II-HW5.B】最长公共子序列","type":"docs"},{"authors":null,"categories":null,"content":" 题意概述\n有一个容积为 $v$ 的背包和 $n$ 个物品，第 $i$ 个物品的体积是 $v_i$，价值是 $w_i$。求用背包最多能装下多少价值的物品。 $n\\leq 500, v\\leq 10^9, \\sum w_i\\leq 10^6$。 本题虽然是经典的 01 背包问题 (它被称为 01 背包是因为每个物品要么选要么不选，只有两种状态)，但仍然有一些值得注意的细节。和 2-5-B 类似地，本题也需要仔细斟酌状态的选取。01 背包的一种常见状态设计是：令 $dp(i, j)$ 表示考虑到第 $i$ 个物品，使用容积为 $j$ 的背包，最多可以获得多少价值。转移考虑第 $i$ 个物品是否放进背包。方程是容易写出的：\n$$ dp(i, j) = \\max\\{dp(i-1, j), dp(i-1, j-v_i) + w_i\\} $$\n时间总复杂度为 $O(nv)$。但本题中 $v$ 的取值范围很大，这样做无法通过。\n考虑将值域更小的价值作为状态，将值域大的容积作为动态规划的值，重新设计：令 $dp(i, j)$ 表示考虑到第 $i$ 个物品，想要选取出总价值为 $j$ 的物品，至少需要多少容积。最终所有容积不超过 $v$ 的状态的 $j$ 的最大值即为题目所求。转移仍然考虑第 $i$ 个物品是否选择：\n$$ dp(i, j) = \\min\\{dp(i-1, j), dp(i-1, j-w_i) + v_i\\} $$\n看上去和之前的方程式长得差不多，但现在时间复杂度变为了 $O(n\\cdot \\sum w_i)$。而且在做第 $i$ 轮时，第二维实际只需要枚举到 $\\sum_{k=1}^iw_k$，因此实际实现时会有一个十分可观的小于 1 的常数因子，足够通过。\n另外一个需要考虑的问题是: $O(n\\cdot \\sum w_i)$ 的空间复杂度似乎过高，使用了太多的内存。这里我们为大家介绍“滚动数组”的技术：观察状态转移方程，我们容易发现 $dp(i, *)$ 只使用了 $dp(i-1, *)$ 来更新自己的结果，因此在做 $dp(i+, *)$ 时仍然存留这 $dp(i-2, *)$ 以及更之前的数据就是对空间的浪费。因此我们的 dp 数组可以只开两行：$dp(previous, *)$ 和 $dp(current, *)$。current 层依赖 previous 层获取结果，然后 previous 和 current 互换，依次类推。采用滚动数组的代码通常会写成如下形式：\nint dp[2][MAXN]; int previous = 0, current = 1; for (int i = 1; i \u0026lt;= n; i++) { // DP logic: dp[current][...] = compute(dp[previous][...]) swap(previous, current); } 滚动数组是压缩空间的通用技术，不过就本题而言，我们还可以做得更激进一些，只需要开一维数组即可，这样代码书写起来也更加方便。你可以参考 2-3-C 关于空间优化的部分进行思考。\n背包问题是 NP-Complete 问题\n不少同学疑惑的问题是：背包问题存在如此简明的动态规划算法可以高效解决，为什么它通常被归入“难问题”的行列呢？这是因为我们给出的动态规划算法有效的前提是物品的总体积/总价值不太大。换句话说，我们目前暂时无法给出一个只和物品数量 $n$ 相关的时间复杂度。这样的不仅依赖输入的数量，还依赖输入值的大小的“多项式”算法称为伪多项式算法 (pseudo-polynomial algorithm)。大家会在问题求解IV中学习这方面的内容。\n","date":1685059200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685059200,"objectID":"450dbeca38e0702572b607357cf3f3ce","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-5-c/","publishdate":"2023-05-26T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-5-c/","section":"courses","summary":"题意概述\n有一个容积为 $v$ 的背包和 $n$ 个物品，第 $i$ 个物品的体积是 $v_i$，价值是 $w_i$。求用背包最多能装下多少价值的物品。 $n\\leq 500, v\\leq 10^9, \\sum w_i\\leq 10^6$。 本题虽然是经典的 01 背包问题 (它被称为 01 背包是因为每个物品要么选要么不选，只有两种状态)，但仍然有一些值得注意的细节。和 2-5-B 类似地，本题也需要仔细斟酌状态的选取。01 背包的一种常见状态设计是：令 $dp(i, j)$ 表示考虑到第 $i$ 个物品，使用容积为 $j$ 的背包，最多可以获得多少价值。转移考虑第 $i$ 个物品是否放进背包。方程是容易写出的：","tags":null,"title":"【问题求解II-HW5.C】背包问题","type":"docs"},{"authors":null,"categories":null,"content":"调试理论 为什么 debug 如此困难？因为 bug 的传播链总是非常长。我们给出如下三个概念：\nFault: 这是 bug 产生的地方，例如你失手打错了循环变量或者逻辑运算符。 Error: 这是 bug 第一次导致程序的内部状态与正确状态发生偏离的地方 (例如某个变量的值不正确)。 Failure: 这是你最早能观测到 bug 的地方，例如你的程序输出了错误的结果，或者发生了段错误。 Debug 的本质就是在观测到 Failure 后向前追溯找到 Fault 的过程。\n我们通过一个例子来体会这三个概念：\nfor (int i = 1; i \u0026lt;= n; i++) for (int j = i + 2; j \u0026lt;= n; j++) if (a[i] \u0026gt; a[j]) swap(a[i], a[j]); // lots of other code for (int i = 1; i \u0026lt;= n; i++) printf(\u0026quot;%d \u0026quot;, a[i]); 上面的代码块展示了一个选择法排序的实现。在这个例子中\nFault 发生在第二行：j 应当从 i + 1 开始循环而不是 i + 2。 Error 发生的地方很难确定，在某些输入下，这个“错误”的选择法排序仍然能输出正确的结果。但如果在某一轮， a[i+1] 恰好是最小值而 j 略过了 i+1，导致该轮结束后 a[i] 存储的不是 a[i...n] 中的最小值，那么 a 数组的数据的状态就与正确状态发生了偏离，产生了 Error。 Failure 发生在打印的地方，你发现在某些输入下输出的序列并不是有序的。 通过这个例子，我们可以从理论角度总结出 bug 难找的一些原因和启发性的调试思路：\nFault 并不一定能立刻转化成 Error，甚至在某些输入下不会产生 Error。 $\\Longrightarrow$ 我们需要生成更多的输入对程序进行全方面检查。Differential testing 中包含的自动化测试的思想可以视作一种解决方案。 对于程序员来说，容易观察到的是 Fault 和 Failure (前者在源代码中，后者有明显的症状)，而 Error 难以观测，因为程序的内部状态 (内存，寄存器，etc.) 不是直接可见的，且程序员不容易想清楚一个正确的中间状态应该长什么样。$\\Longrightarrow$ 我们需要想办法以人类可以理解的方式让程序员观测到程序的内部状态。 从 Error 到 Failure 往往要经过很多代码，因此 debug 时需要向前看很多代码。$\\Longrightarrow$ 我们需要想办法让 Error 迅速地暴露为 Failure。 分析清楚了 debug 困难的原因，我们就可以对症下药，给出一些有针对性的调试技巧。由于大家对计算机的底层细节尚不了解，本讲义主要总结一些在源代码层面/通过工具可以轻松完成的技巧。\n打印 打印是最朴素也最有效的 debug 方法之一，它的理论依据是调试理论的第二条困难——打印可以帮助我们查看程序的中间状态。以之前的选择法排序为例，在看到最终排序结果错误时，你最可能采取的 debug 方法就是在循环中添加打印语句，在每轮内层循环结束后查看当前数组的情况，于是你容易发现在某个特定的轮次元素顺序错误，这也就帮你从 failure 追溯到 error 了。\nGDB GDB 是程序员人手一个的王牌调试器，它的理论依据也是调试理论的第二条，但它比打印更加灵活和强大——你可以在任何一个你想要的时刻让程序暂停，然后查看任何你想要看的程序状态 (各个变量的值，寄存器的值，内存的值，……)。如果你喜欢 CLI，你可以用命令行打开 gdb，但我们更推荐你使用一些与图形化界面集成在一起的 gdb 工具 (例如 vscode 的 gdb)，它可以给你带来更好的调试体验。\nGDB 唯一的缺点是上手难度比较高，我们这里给出 官方手册 ，其中有完整的文档 (将近 1000 页 🤯)，还有 cheatsheet。不过在大语言模型时代，让 LLM 帮助你阅读 1000 多页的手册总是不坏的，如果你有任何使用问题，你可以写一个 prompt 丢给 ChatGPT，它通常能给你非常不错的建议。这里我们总结几条目前对于大家来说比较重要的 GDB feature:\n断点 (breakpoint): 你可以在程序中打断点，程序运行到断点后就会暂停，供你查询各种程序状态。 打印：你可以用打印任何你想要的内容，但如果你使用 CLI，你可能要学习各种小技巧让 GDB 输入人类可以理解的内容 (如 p/s p/i p/x 等)，多问问 ChatGPT/多读手册。 监视点 (watchpoint)：你可以给某个变量/某个地址打监视点，在之后运行的过程中一旦监视点的值发生变化 GDB 就会暂停下来供你调试。 为了说服你克服学习新事物的惰性并多用 GDB，这里我们展示一个 GDB 极其好用的场景。假设你的程序 error.cpp 发生了段错误，寻找到底是哪条语句触发了段错误本身就不是一件简单的事情。但如果你使用 GDB，你可以使用 -g 参数编译代码，然后启动 GDB 运行可执行文件。\ng++ -o error error.cpp -g \u0026amp;\u0026amp; gdb ./error 之后直接输入 run 命令运行，你可以看到段错误发生，然后使用 where 命令查看函数调用链，你可以清楚地看到源程序中触发段错误的行号，这极大加速了 debug 的过程。\n防御性编程 防御性编程 (defensive programming) 指的是在程序中加入一些显式的断言 (assertion) 来对程序的状态进行检查。这恰恰对应了调试理论中的第三条困难的解决方案。我们以书写平衡树的旋转操作为例：\nvoid rotate(Node *u) { // 结构约束 assert(u-\u0026gt;parent == u /* u is root */ || u-\u0026gt;parent-\u0026gt;left == u || u-\u0026gt;parent-\u0026gt;right == u); assert(!u-\u0026gt;left || u-\u0026gt;left-\u0026gt;parent == u); assert(!u-\u0026gt;right || u-\u0026gt;right-\u0026gt;parent == u); // 数值约束 assert(!u-\u0026gt;left || u-\u0026gt;left-\u0026gt;val \u0026lt; u-\u0026gt;val); // rotation code } assert(expr) 的语义是：如果其中包含的逻辑表达式 expr 值为假，则抛出异常 (在没有 error handler 的情况下这通常会使得程序直接终止，注意程序终止是一种 Failure)。例子中的这些 assertion 描述了一个平衡树节点理应满足的性质，它们看上去非常地显然，但如果你的程序有 bug，你的错误很可能被这些 assertion 抓住。这使得你可以从尽可能接近 Error 的地方出发寻找 Fault。\n防御性编程的代价在于，作为程序员你需要额外写很多代码，以及有些 assertion 在抓 error 方面很有价值，有些则可能无关紧要，这其中的判断力需要你不断积累经验。我们的建议是：能加尽可能多加，写几条 assertion 的时间和深夜 debug 到头秃的时间相比不值一提。\nSanitizers 手写 assertion 终究还是太过繁琐。例如从极其严谨的角度来说，你应当将数组封装成这样：\nclass Array { int N = 1000, a[1000]; public: void store(int pos, int value) { assert(0 \u0026lt;= pos \u0026amp;\u0026amp; pos \u0026lt; N); a[pos] = value; } int access(int pos) { assert(0 \u0026lt;= pos \u0026amp;\u0026amp; pos \u0026lt; N); return a[pos]; } }; 这两条 assertion 可以帮助你检查对数组的越界操作，但如果把程序写成这样，那程序员可别活了。有没有什么工具可以帮我们在每次访问数组时自动检查是否越界？\n计算机世界的两条公理\n机器永远是对的，未测试代码永远是错的。 你如果发现自己有某种需求，一定有某种工具可以帮助你实现它。 根据公理第二条，这样的工具应该是存在的。这里我们为大家介绍 Address Sanitizer (它好像应当被翻译成地址消毒剂，但我从未见过这样的表达)。Address Sanitizer (ASAN) 可以检查 C/C++ 程序中与内存访问相关的错误，主流的编译器/IDE，例如 Visual Studio, GCC, Clang 都支持 ASAN。下面是一个例子：\n// error.cpp #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; int a[10]; int main () { a[11] = 1; return 0; } 该程序在 main() 函数中包含了对全局数组的越界读取。虽然直接编译运行这个程序(通常)不会导致段错误，但这样的操作仍然是危险的，因为它属于 undefined behavior。我们来看看使用 ASAN 会得到什么样的结果 (在编译命令中加上 -fsanitize=address 即可使用 ASAN)：\n\u0026gt; g++ -o error error.cpp -fsanitize=address \u0026amp;\u0026amp; ./error ==40526==ERROR: AddressSanitizer: global-buffer-overflow on address 0x55c41dbbdf6c at pc 0x55c41dbb928b bp 0x7ffda7143ce0 sp 0x7ffda7143cd0 WRITE of size 4 at 0x55c41dbbdf6c thread T0 #0 0x55c41dbb928a in main (error+0x228a) #1 0x7ff6ab1a0564 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x28564) #2 0x55c41dbb918d in _start (error+0x218d) 0x55c41dbbdf6c is located 4 bytes to the right of global variable 'a' defined in 'error.cpp:5:5' (0x55c41dbbdf40) of size 40 SUMMARY: AddressSanitizer: global-buffer-overflow (error+0x228a) in main Shadow bytes around the buggy address: 0x0ab903b6fb90: f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 0x0ab903b6fba0: f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 0x0ab903b6fbb0: f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 0x0ab903b6fbc0: f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 0x0ab903b6fbd0: f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 f9 00 00 00 00 =\u0026gt;0x0ab903b6fbe0: 01 f9 f9 f9 f9 f9 f9 f9 00 00 00 00 00[f9]f9 f9 0x0ab903b6fbf0: f9 f9 f9 f9 00 00 00 00 00 00 00 00 00 00 00 00 0x0ab903b6fc00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x0ab903b6fc10: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x0ab903b6fc20: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 0x0ab903b6fc30: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 Shadow byte legend (one shadow byte represents 8 application bytes): Addressable: 00 Partially addressable: 01 02 03 04 05 06 07 Heap left redzone: fa Freed heap region: fd Stack left redzone: f1 Stack mid redzone: f2 Stack right redzone: f3 Stack after return: f5 Stack use after scope: f8 Global redzone: f9 Global init order: f6 Poisoned by user: f7 Container overflow: fc Array cookie: ac Intra object redzone: bb ASan internal: fe Left alloca redzone: ca Right alloca redzone: cb Shadow gap: cc ==40526==ABORTING 可以看到 ASAN 提醒我们全局数组越界，甚至告诉了我们是在第五行定义的 a 数组合法范围向右偏移 4 字节的地方发生了越界访问。有了这些信息 debug 将会变得非常方便 (更重要的是，它告诉了我们 bug 的存在！)。\n为什么这样就有段错误了？\nint main () { int a[10]; a[11] = 1; // 等等，怎么换成 a[100] = 1 就又没有段错误了 😵‍💫 return 0; } 非常好的观察！解释清楚这个问题需要较多的计算机底层知识，如果你真的感兴趣，可以上网搜索 Stack Canary 相关的内容。\n","date":1684368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684368000,"objectID":"d1e7ec53320f64aab36e7aa476cf8810","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/coding/defense/","publishdate":"2023-05-18T00:00:00Z","relpermalink":"/courses/problemsolving22/coding/defense/","section":"courses","summary":"调试理论 为什么 debug 如此困难？因为 bug 的传播链总是非常长。我们给出如下三个概念：\nFault: 这是 bug 产生的地方，例如你失手打错了循环变量或者逻辑运算符。 Error: 这是 bug 第一次导致程序的内部状态与正确状态发生偏离的地方 (例如某个变量的值不正确)。 Failure: 这是你最早能观测到 bug 的地方，例如你的程序输出了错误的结果，或者发生了段错误。 Debug 的本质就是在观测到 Failure 后向前追溯找到 Fault 的过程。\n我们通过一个例子来体会这三个概念：\nfor (int i = 1; i \u0026lt;= n; i++) for (int j = i + 2; j \u0026lt;= n; j++) if (a[i] \u0026gt; a[j]) swap(a[i], a[j]); // lots of other code for (int i = 1; i \u0026lt;= n; i++) printf(\u0026quot;%d \u0026quot;, a[i]); 上面的代码块展示了一个选择法排序的实现。在这个例子中","tags":null,"title":"调试艺术","type":"docs"},{"authors":null,"categories":null,"content":" Premature optimization is the root of all evil. \u0026ndash; Donald Knuth\n性能优化的需求非常普遍——在 OJ 层面，这主要体现为将 TLE 的程序改到 AC。本文旨在对于 OJ 层面的性能优化问题给予一些最基本的指导。\n计算程序的运行时间 衡量一个程序的性能的指标有很多，其中最简单、最直接的方式就是运行时间，因此你至少应该学会如何计算一个程序的运行时间。\n如果你使用类 unix 系统，你可以直接使用 time 命令。 如果你使用的系统没有可以直接测算时间的命令，你可以使用 C/C++ 库的 time() 函数来打印运行时间，具体的使用方法请自行上网搜索。 “对抗”式的输入构造策略 假设你写了一个如下的快速排序程序：\nvoid quick_sort(int l, int r) { if (l == r) return; int pos = partition(l, r, a[l]); quick_sort(l, pos - 1); quick_sort(pos + 1, r); } 这个每次选择第一个数作为 pivot 的快速排序程序在随机数据上可以给到 $O(n\\log n)$ 的时间复杂度，但假设你现在是一个“找茬”的人，为了让这个程序跑得很慢，你一定会构造一个很长且原本有序的数列，这样每次 partition() 只能去掉 pivot 一个数，从而时间复杂度退化到 $O(n^2)$。\n对于算法题来说，我们通常在意的是算法的“最坏时间复杂度”。所以测试程序性能时，你应该代入“找茬”的角色，去思考什么样的输入能将程序卡到最慢。这也是 online judge 对大家的程序进行性能测试时需要考虑的点。\n寻找程序运行的时间瓶颈 假设你写了一个如下的排序程序：\nint a[100000]; int main () { for (int i = 1; i \u0026lt;= n; i++) scanf(\u0026quot;%d\u0026quot;, a + i); for (int i = 1; i \u0026lt;= n; i++) for (int j = i + 1; j \u0026lt;= n; j++) if (a[i] \u0026gt; a[j]) swap(a[i], a[j]); } 并发现它在处理 $n=10^5$ 的数列时超时了。此时你有两个优化方案：\n用“快速输入输出”章节中的 getchar() 方法代替 scanf() 进行读入。 修改排序算法，使用归并排序。 你一定会采纳第二条建议，因为这个程序运行的时间瓶颈在核心排序算法的部分——它的复杂度达到了 $O(n^2)$，而输入部分是线性的。换句话说，对着仅占总运行时间 $1%$ 的部分优化，即使你让该部分快了一倍，它对整个程序的优化效果也是微乎其微的。因此，在做性能优化时你应该先仔细分析哪个部分是耗时最长的，对着耗时最长的 critical path 优化才能取得最显著的效果。至于如何找出运行时间最慢的部分，对于 OJ 程序来说，最简单的方法是注释掉某些部分，然后观察程序的运行时长有无显著的变化。\n再举一个例子：\nfor (int i = 1; i \u0026lt;= n; i++) { a[i] = 0; for (int j = i + 1; j \u0026lt;= n; j++) a[i] += compute(b[j]); a[i] %= MOD; } 假设你通过定位确定了这个程序段是效率瓶颈，此时你有两个优化方案：\n将 a[i] %= MOD 改写为效率更高的减法 (内层循环也要同步修改)。 优化函数 compute() 的效率。 你仍然应该选择第二条方案。虽然取模的效率不高，但这条语句不在最内层循环。换句话说，从时间复杂度的角度来讲，取模操作被执行了 $O(n)$ 次，而 compute() 被执行了 $O(n^2)$ 次。因此，我们最需要关注的，是效率瓶颈模块的最内层语句。\nProfiling: The Real World\n在真实世界中，profiling 也是被广泛使用的一项技术。\n“Computer Architecture: A Quantitative Approach 这本书对于计算机体系结构的 insight 可以简单概括为两条：(1)处理器也是一个编译器。(2) 木桶效应。” —— jyy\n这里的“木桶效应”指的是：一个计算机系统的真实性能由最短的那块木板决定。因此优化工程师的日常工作便是盯着 profiling report，找“最短的木板”，尝试让它变长一点，再去寻找新的短板。\n现实世界中 profiling 的工具有很多 (比“注释-测试”的 OJ 程序法要方便)，它们的主要原理是运行大量的单元测试/压力测试，然后统计每个“基本单元”运行时长占总时长的比例。这里的“基本单元”对于工作在不同层级的人来说有不同的颗粒度。对于软件系统的开发者，“基本单元”可能是颗粒度较粗的高级语言语句、函数甚至模块；对于编译器/硬件开发者，“基本单元”则是中间代码、机器指令甚至是微指令。\n","date":1684108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684108800,"objectID":"e91ad23c6e9cce43e59f0eb75c911fca","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/coding/profiling/","publishdate":"2023-05-15T00:00:00Z","relpermalink":"/courses/problemsolving22/coding/profiling/","section":"courses","summary":"Premature optimization is the root of all evil. \u0026ndash; Donald Knuth\n性能优化的需求非常普遍——在 OJ 层面，这主要体现为将 TLE 的程序改到 AC。本文旨在对于 OJ 层面的性能优化问题给予一些最基本的指导。\n计算程序的运行时间 衡量一个程序的性能的指标有很多，其中最简单、最直接的方式就是运行时间，因此你至少应该学会如何计算一个程序的运行时间。\n如果你使用类 unix 系统，你可以直接使用 time 命令。 如果你使用的系统没有可以直接测算时间的命令，你可以使用 C/C++ 库的 time() 函数来打印运行时间，具体的使用方法请自行上网搜索。 “对抗”式的输入构造策略 假设你写了一个如下的快速排序程序：","tags":null,"title":"性能优化","type":"docs"},{"authors":null,"categories":null,"content":"cdq分治是一种常用的分治思想，最早由 陈丹琦 整理和总结 ( 原文地址)。这种思想从 high-level 层面来说十分简单和抽象：当我们希望解决某个问题 solve(l, r) 时，我们可以考虑如下的分治步骤：\n解决 solve(l, mid)。 考虑 [l, mid] 对 [mid+1, r] 的贡献。 解决 solve(mid+1, r)。 第一步和第三步非常简明，但第二步的“贡献”非常抽象，需要具体问题具体分析。这里我们以二维偏序和三维偏序为例示范一些“贡献”的计算方法。\n二维偏序问题指对于一个二元组序列 $(a_1, b_1), (a_2, b_2),\\cdots, (a_n, b_n)$，求满足 $a_i\u0026lt;a_j$ 且 $b_i\u0026lt;b_j$ 的数对 $(i, j)$ 的个数。显然我们如果将二元组按照 $a_i$ 从小到大排序，那么该问题就转化为了 $b_i$ 序列的逆序数问题。我们尝试套用cdq分治的“模板”来解决它。令 $solve(l, r)$ 表示区间 $[l, r]$ 内的逆序对个数，最终答案显然为 $solve(1, n)$。$solve(l, r)$ 分为三个步骤：\n$solve(l, mid)$：递归解决. 计算下标在 $[l, mid]$ 中的数对 $[mid+1, r]$ 中的数的贡献。换言之，我们需要计算满足 $i\\in [l, mid], j\\in [mid+1, r]， b_i\u0026gt;b_j$ 的 $(i, j)$-pair 个数。 $solve(mid+1, r)$：递归解决。 重点关注第二条。虽然看上去还是在数“逆序对”，但它比原问题简单了很多——因为 $[l, r]$ 的数被鲜明地分成了 $[l, mid]$ 和 $[mid+1, r]$ 两类。换言之，每个数 $b_i$ 可以被看作 $(0, b_i)$ 或者 $(1, b_i)$，取决于它在左半边还是右半边，我们只关心 0 的那一类 $b_i$ 比 1 的那一类 $b_i$ 大的数目。我们可以通过按照 $b_i$ 做一遍归并排序，然后统计每个 0 前面有多少个 1 的方法来解决。使用主定理分析容易得知该算法的时间复杂度为 $O(n\\log n)$。\n在进入三维偏序之前，我们先尝试总结 cdq 分治降低问题难度的本质：它通过分治递归处理子问题，然后在当前层面上只考虑左对右的贡献，从而将某一维度的排序问题转换成了 0/1 的二元问题。\n再来看三维偏序问题。三维偏序问题和二维偏序定义类似，只不过每个元素都换成了三元组 $(a_i, b_i, c_i)$。我们如法泡制，对第一维排序后套用 cdq 分治，相当于将所有的三元组转换成了 $(0/1, b_i, c_i)$。由于还剩下两维，直接下手有点困难 (除非你掌握了某些高级的数据结构)，但我们可以在 cdq 分治上再套一层 cdq 分治：具体来说，我们可以对 $b_i$ 这一维度做归并排序，然后对其 cdq 分治，这样在第三维上每个三元组实际上被转化成了 $(0/1, 0/1, c_i)$，我们只需要考虑所有形如 $(0, 0, c_1)$ 对 $(1, 1, c_2)$ 的贡献即可。总时间复杂度 $O(n\\log^2n)$。\n致歉\n本讲义写的相当糟糕——cdq分治难度较大，思想比较微妙，笔者功力有限，用语言难以描述清楚。我们提供两份额外的参考资料，一是 OIWiki 上对于 cdq 分治的讲解，二是一份 cdq 套 cdq 的三维偏序的参考实现，希望尽可能帮助感兴趣的同学理解。\nCode :: Click to expand struct node { int x,y,z; int nx,ny,nz; bool operator == (const node cp) { return (x==cp.x) \u0026amp;\u0026amp; (y==cp.y) \u0026amp;\u0026amp; (z==cp.z); } }p[100048],a[100048],b[100048],c[100048]; int n; int ans = 0; bool cmp(node x,node y) { if (x.x!=y.x) return x.x\u0026lt;y.x; if (x.y!=y.y) return x.y\u0026lt;y.y; return x.z\u0026lt;y.z; } void cdq2(int left,int right) { if (left==right) return; int i,k1,k2,pt,mid=(left+right)\u0026gt;\u0026gt;1; cdq2(left,mid);cdq2(mid+1,right); int cnt=0; for (k1=left,k2=mid+1,pt=left;pt\u0026lt;=right;pt++) { if (k2\u0026gt;right || (k1\u0026lt;=mid \u0026amp;\u0026amp; k2\u0026lt;=right \u0026amp;\u0026amp; b[k1].z\u0026lt;=b[k2].z)) { if (!b[k1].nx) cnt++; c[pt]=b[k1++]; } else { if (b[k2].nx) ans += cnt; c[pt]=b[k2++]; } } for (i=left;i\u0026lt;=right;i++) b[i] = c[i]; } void cdq1(int left,int right) { if (left==right) return; int i,k1,k2,pt,mid=(left+right)\u0026gt;\u0026gt;1; cdq1(left,mid); cdq1(mid+1,right); for (k1=left,k2=mid+1,pt=left;pt\u0026lt;=right;pt++) { if (k2\u0026gt;right || (k1\u0026lt;=mid \u0026amp;\u0026amp; k2\u0026lt;=right \u0026amp;\u0026amp; a[k1].y\u0026lt;=a[k2].y)) { b[pt]=a[k1++]; b[pt].nx=0; } else { b[pt]=a[k2++]; b[pt].nx=1; } } for (i=left;i\u0026lt;=right;i++) a[i] = b[i]; cdq2(left,right); } int main () { int i; n=getint();i=getint(); for (i=1;i\u0026lt;=n;i++) {p[i].x=getint();p[i].y=getint();p[i].z=getint();} sort(p+1,p+n+1,cmp); for (i=1;i\u0026lt;=n;i++) a[i] = p[i]; cdq1(1, n); } ","date":1683936000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683936000,"objectID":"a136d56090b9f031ec1e2ddcf19331b0","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/algorithms/cdq/","publishdate":"2023-05-13T00:00:00Z","relpermalink":"/courses/problemsolving22/algorithms/cdq/","section":"courses","summary":"cdq分治是一种常用的分治思想，最早由 陈丹琦 整理和总结 ( 原文地址)。这种思想从 high-level 层面来说十分简单和抽象：当我们希望解决某个问题 solve(l, r) 时，我们可以考虑如下的分治步骤：\n解决 solve(l, mid)。 考虑 [l, mid] 对 [mid+1, r] 的贡献。 解决 solve(mid+1, r)。 第一步和第三步非常简明，但第二步的“贡献”非常抽象，需要具体问题具体分析。这里我们以二维偏序和三维偏序为例示范一些“贡献”的计算方法。\n二维偏序问题指对于一个二元组序列 $(a_1, b_1), (a_2, b_2),\\cdots, (a_n, b_n)$，求满足 $a_i\u0026lt;a_j$ 且 $b_i\u0026lt;b_j$ 的数对 $(i, j)$ 的个数。显然我们如果将二元组按照 $a_i$ 从小到大排序，那么该问题就转化为了 $b_i$ 序列的逆序数问题。我们尝试套用cdq分治的“模板”来解决它。令 $solve(l, r)$ 表示区间 $[l, r]$ 内的逆序对个数，最终答案显然为 $solve(1, n)$。$solve(l, r)$ 分为三个步骤：","tags":null,"title":"cdq分治","type":"docs"},{"authors":null,"categories":null,"content":"对于整数 $a, b\u0026lt;p$，计算 $(a/b)\\text{ mod }p$ 可以转化为计算 $a\\cdot b^{-1}\\text{ mod }p$，这里 $b^{-1}$ 称为 $b$ 在模 $p$ 下的逆元，可以证明当 $p$ 为质数时，$b^{-1}$ 在 $[0, p)$ 范围内是唯一的。逆元的数学推导会在后续的理论课程中给出，这里不做赘述 (如果你不懂也暂时不必深究)。本文主要阐述人们通常是如何书写计算逆元的代码。\n当 $p$ 为质数时，计算逆元最简单的方法之一是使用费尔马小定理。由于\n$$a^{p-1}\\equiv 1(\\text{mod }p)$$\n所以令 $a^{-1}=a^{p-2}\\text{ mod }p$，则有 $a\\cdot a^{-1}\\equiv 1(\\text{mod }p)$。这里的 $a^{-1}$ 即为 $a$ 在模 $p$ 意义下的逆元。你可以使用快速幂算法快速计算 $a^{p-2}$ 的值，时间复杂度为 $O(\\log p)$。\n另外一种常见的需求是计算 $[1, n]$ 中所有数的逆元。如果对每个数用费尔马小定理计算逆元，时间复杂度将达到 $O(n\\log p)$，有时不可接受。前人发明过一些非常精巧的算法递推地 $O(n)$ 求出所有数的逆元，如果你感兴趣可以参考 这篇博客。但我们更推荐你采用如下非常简洁的做法：\n顺序递推求出 $1!, 2!, \\cdots, n!$。 使用快速幂计算 $(n!)^{-1}$。 从后往前递推算出所有阶乘的逆元 (注：$(k!)^{-1}\\cdot k=((k-1)!)^{-1}$)。 对于 $x$，$x^{-1}=(x-1)!\\cdot (x!)^{-1}$。 该做法虽然看上去多了几遍递推，但时间复杂度仍为 $O(n)$，且通常拥有更加优秀的常数因子 (即在实际运行中效率可能反而比链接中的一遍递推要高，因为链接中的做法有大量的取模操作)。\nReference :: click to expand const int MOD = 998244353; int fac[MAXN], ifac[MAXN], inv[MAXN]; void init_inv() { fac[0] = 1; for (int i = 1; i \u0026lt;= n; i++) fac[i] = 1ll * fac[i - 1] * i % MOD; ifac[n] = quick_pow(fac[n], MOD - 2); for (int i = n - 1; i \u0026gt;= 0; i--) { ifac[i] = 1ll * ifac[i + 1] * (i + 1) % MOD; inv[i + 1] = 1ll * fac[i] * ifac[i + 1] % MOD; } } ","date":1683936000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683936000,"objectID":"32bb2b55470b7972ae86caa913006ceb","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/coding/mulinv/","publishdate":"2023-05-13T00:00:00Z","relpermalink":"/courses/problemsolving22/coding/mulinv/","section":"courses","summary":"对于整数 $a, b\u0026lt;p$，计算 $(a/b)\\text{ mod }p$ 可以转化为计算 $a\\cdot b^{-1}\\text{ mod }p$，这里 $b^{-1}$ 称为 $b$ 在模 $p$ 下的逆元，可以证明当 $p$ 为质数时，$b^{-1}$ 在 $[0, p)$ 范围内是唯一的。逆元的数学推导会在后续的理论课程中给出，这里不做赘述 (如果你不懂也暂时不必深究)。本文主要阐述人们通常是如何书写计算逆元的代码。\n当 $p$ 为质数时，计算逆元最简单的方法之一是使用费尔马小定理。由于\n$$a^{p-1}\\equiv 1(\\text{mod }p)$$","tags":null,"title":"逆元","type":"docs"},{"authors":null,"categories":null,"content":" 题面描述\n有 $n$ 个包，第 $i$ 个包里有 $A_i$ 个黑球和 $B_i$ 个白球。问有多少种方法选取两个包，再将包中的球排成一排。同色的球之间不可区分，选择不同的包被视为不同方案。 $n\\leq 2\\times 10^5, A_i, B_i\\leq 2000$。 该题面描述与原题背景不太相同，但容易看出它们讨论的问题是一样的。本题解法比较精巧，供大家欣赏。\n如果我们枚举选择哪两个包，那么选取第 $i$ 个包和第 $j$ 个包的情况下，问题会被转化为将 $A_i+A_j$ 个黑球和 $B_i+B_j$ 个白球排成一排有多少种方案，这等价于在 $A_i+A_j+B_i+B_j$ 个位置中选择 $A_i + A_j$ 个位置放黑球。因此最终答案可以写为 $$ \\sum_{i,j\\in \\{1,\\cdots, n\\}, i\u0026lt;j} \\binom{A_i+A_j+B_i+B_j}{A_i+A_j} $$ 即使我们可以通过预处理 $O(1)$ 地求解组合数，直接计算该表达式的时间复杂度也会达到 $O(n^2)$。本题 $n\\leq 2\\times 10^5$，无法通过。\n本题的关键在于一步精妙的模型转化。通常我们认为能够写出 closed form 的数学表达式是优美的，但这里我们反其道而行之，将上面表达式中的组合数转化为一个具体的动态规划问题。考虑如下问题：\n在一张 $n\\times m$ 的方格纸上，从 $(0, 0)$ 走到 $(n, m)$ 有多少种方案？\n很容易看出该问题的答案是 $\\binom{n+m}{n}$，即从 $(0, 0)$ 到 $(n, m)$ 一共要走 $n$ 条横向边和 $m$ 条竖向边，从 $n+m$ 步中选 $n$ 步走横的。不过我们还有一个“笨方法”：令 $dp(i, j)$ 表示从 $(0, 0)$ 走到 $(i, j)$ 的方案数，显然 $(i, j)$ 可以从 $(i-1, j)$ 或 $(i, j-1)$ 转移来，因此 $$ dp(i, j)= \\begin{cases} 1\u0026amp;, (i, j) = (0, 0)\\\\ dp(i-1, j) + dp(i, j-1)\u0026amp;, otherwise \\end{cases} $$ 注意上述状态转移方程没有考虑边界问题。 回到原问题，对于 $\\binom{A_i+A_j+B_i+B_j}{A_i+A_j}$，我们可以套用走方格纸问题，将其转化为从 $(-A_i, -B_i)$ 到 $(A_j, B_j)$ 的方案数，并通过动态规划递推解决。我们看似用一个 $O(|A_i|^2)$ 的算法替代了 $O(1)$ 的组合数求解，但动态规划的递推过程是可以叠加的。我们不需要单独对每组点对跑动态规划，我们可以给地图上所有的负坐标 $(-A_i, -B_i)$ 打上 1，然后从地图的左下角开始一遍推到右上角，然后在所有的正坐标位置收取答案。这样我们花一趟完成了 $n^2$ 次动态规划，时间复杂度降低到 $O(|A_i|^2)$。\n这个过程有一点抽象，如果你没有完全理解，可以简单构造一个 3 个点的样例手动模拟一下算法，看看一个负坐标上的标记是如何同时贡献到所有的正坐标上，以及不同的标记是如何叠加的。\n此外还有一些细节需要注意：\nC/C++ 中无法直接支持负数下标，你可以考虑给所有的坐标加上一个偏移量 offset 转化成正数。 上述递推过程会出现 $(-A_i, B_i)$ 向 $(A_i, B_i)$ 贡献的情况，相当于选取了两个一样的包，需要 $O(n)$ 地单独计算并扣除。 对于任意一对 $(i, j)$，上述递推过程会同时计算 “$(-A_i, -B_i)$ 向 $(A_j, B_j)$ 贡献” 和 “$(-A_j, B_J)$ 向 $(A_i, B_i)$ 贡献”，即重复计算了两次。因此扣除第二点中的数量后还需要除以 2。 在模意义下如何除以 2 不是一个简单的问题，你可以上网搜索“逆元”或 \u0026ldquo;modular multiplicative inverse\u0026rdquo;。现阶段你不需要过深地理解背后的数论原理，因为后续的理论课程会涉及。 ","date":1683504000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683504000,"objectID":"c4ab7a48abfbb51707e1a7fbf06b9fbc","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-4-c/","publishdate":"2023-05-08T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-4-c/","section":"courses","summary":"题面描述\n有 $n$ 个包，第 $i$ 个包里有 $A_i$ 个黑球和 $B_i$ 个白球。问有多少种方法选取两个包，再将包中的球排成一排。同色的球之间不可区分，选择不同的包被视为不同方案。 $n\\leq 2\\times 10^5, A_i, B_i\\leq 2000$。 该题面描述与原题背景不太相同，但容易看出它们讨论的问题是一样的。本题解法比较精巧，供大家欣赏。\n如果我们枚举选择哪两个包，那么选取第 $i$ 个包和第 $j$ 个包的情况下，问题会被转化为将 $A_i+A_j$ 个黑球和 $B_i+B_j$ 个白球排成一排有多少种方案，这等价于在 $A_i+A_j+B_i+B_j$ 个位置中选择 $A_i + A_j$ 个位置放黑球。因此最终答案可以写为 $$ \\sum_{i,j\\in \\{1,\\cdots, n\\}, i\u0026lt;j} \\binom{A_i+A_j+B_i+B_j}{A_i+A_j} $$ 即使我们可以通过预处理 $O(1)$ 地求解组合数，直接计算该表达式的时间复杂度也会达到 $O(n^2)$。本题 $n\\leq 2\\times 10^5$，无法通过。","tags":null,"title":"【问题求解II-HW4.C】烧烤","type":"docs"},{"authors":["Jiawei Liu","Chunqiu Steven Xia","Yuyao Wang","Lingming Zhang"],"categories":null,"content":"","date":1682985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682985600,"objectID":"3cfc5701454ab464c988c28ef37ea43e","permalink":"https://kristoff-starling.github.io/publication/evalplus/","publishdate":"2023-05-02T00:00:00Z","relpermalink":"/publication/evalplus/","section":"publication","summary":"","tags":null,"title":"Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation","type":"publication"},{"authors":null,"categories":null,"content":" 题意概述\n给定数列 $a_1, \\cdots, a_n$，求区间 $(l, r)$，使得\n$$ \\left(\\min_{i=l}^r a_i\\right)\\cdot \\left(\\max_{i=l}^r a_i\\right)\\cdot \\left(\\text{OR}_{i=l}^r a_i\\right) \\cdot (r - l + 1) $$\n最大。\n$n\\leq 10^6$。\n遇到复杂的表达式不要慌，应当仔细观察它的性质。我们很容易发现该表达式的一个特点：除了 $\\min$ 这个操作，其他的三项都是随着区间的扩大而增加的。换句话说，如果没有 $\\min$ 这一项，这题的答案就是整个数列。\n接下来我们考虑如何对付这个棘手的 $\\min$。$\\min$ 的一大特点在于它是有限的——任何一个区间的 $\\min$ 一定是原数列中的一个数，因此所有可能的 $\\min$ 最多只有 $n$ 种。如果我们把所有的区间按照 $\\min$ 的位置归类，那么根据之前的结论，享有同一个 $\\min$ 的区间集合中，只有最长的那个才可能是答案的候选区间。\n到这里，我们的问题转化成了：枚举数列中的每个数 $a_i$ 作为最小值的情况，我们希望找到以此为最小值的最长区间，即从 $a_i$ 出发向左向右扩展，把所有 $\\geq a_i$ 的数纳入到区间中，直到碰到边界/比 $a_i$ 小的数。但这件事仍然不容易，如果暴力地向左向右查看，复杂度仍然会达到 $O(n^2)$。\n考虑这样一种精巧的做法：我们不按照下标的顺序依次枚举 $a_i$，而是按照 $a_i$ 值从小到大的顺序枚举 $a_i$。这样在枚举到任意 $a_i$ 的时刻整个数列的格局如下：\n其中蓝色的格子代表已经被枚举过的数，红色的是当前枚举的数。我们发现所有蓝色的数一定比当前数小(小于等于)，所有白色的数一定比当前的数大。因此要寻找“最长区间”，我们只要在“蓝色数”的下标数列中寻找比当前下标小的最大数和比当前下标大的最小数即可。你可以借助 C++ STL 的 set 容器以及 lower_bound 方法来轻松完成这件事，时间复杂度降低到 $O(n\\log n)$。\n遇到大小相同的数怎么办？\n其实不用担心这个问题。你可以按照任意顺序处理大小相同的数，因为先处理的数对应的区间可以包括后处理的数，所以后处理的数被先处理的数“卡住”区间边界也无关紧要了。\n或者你也可以采取类似分治的做法，每次找完当前区间的最小值后将区间拆分成左右两个区间分别处理 (因为后续的区间不应该跨越这个最小值)。至于如何寻找一个区间最小值的位置，你可以在维护 ST 表时同时维护最小值位置，具体细节留给大家自己思考。\n剩下的最后一件事情是：对于每个最小值，我们找到了它对应的最长区间后，如何求该区间的最大值/同或和/长度。长度是容易的，剩下的两样恰好是 ST 表擅长的内容。你只需要预处理 ST 表即可 $O(1)$ 地查询。整个算法的时间复杂度为 $O(n\\log n)$。\n","date":1682726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682726400,"objectID":"5a7db4bb35b604b9b57905f4f93fc04a","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-3-a/","publishdate":"2023-04-29T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-3-a/","section":"courses","summary":"题意概述\n给定数列 $a_1, \\cdots, a_n$，求区间 $(l, r)$，使得\n$$ \\left(\\min_{i=l}^r a_i\\right)\\cdot \\left(\\max_{i=l}^r a_i\\right)\\cdot \\left(\\text{OR}_{i=l}^r a_i\\right) \\cdot (r - l + 1) $$\n最大。\n$n\\leq 10^6$。\n遇到复杂的表达式不要慌，应当仔细观察它的性质。我们很容易发现该表达式的一个特点：除了 $\\min$ 这个操作，其他的三项都是随着区间的扩大而增加的。换句话说，如果没有 $\\min$ 这一项，这题的答案就是整个数列。","tags":null,"title":"【问题求解II-HW3.A】签到题","type":"docs"},{"authors":null,"categories":null,"content":" 题意描述\n给定一棵 $n$ 个节点的数和 $m$ 个点对，每个点对染不同的颜色。要求找出树中的一条边，使得砍掉这条边后得到的两棵树中没有颜色相同的节点 (即颜色相同的点对不能被划分到同一棵树中)。求满足条件的边的最大编号，若不存在输出 -1。 $n\\leq 10^5$。 树上任意两个点之间有且仅有一条简单路径。并且我们容易发现：如果要把两个点分到两棵树中，那么选择的这条边必须在连接这两个点的路径上。因此该问题被转化为了对树上的 $m$ 条路径求交。以下我们介绍三种做法供大家参考。\n做法1: 基于LCA的路径标记 对于树上的任意两个点 $u$, $v$，从 $u$ 到 $v$ 的路径总可以被拆分为 $u\\to lca(u, v)$ 和 $lca(u,v)\\to v$ 两条直上直下的链。我们希望可以快速给链上所有的边打一个 +1 标记，这样最后只需要找有 $m$ 个标记的边即可。\n如果对每条路径上的所有边暴力打 +1 标记的话，总复杂度为 $O(\\sum_{i=1}^m len(u_i\\to v_i))$，最坏情况下可以达到 $O(mn)$，不可接受。\n以 $o(t)$ 的代价给 $t$ 条边打上标记似乎是一件“违反物理”的事情。但我们向大家展示如下的技巧做到这一点：\n我们不把操作作用在边上，而是作用在点上，每个点与连向它父亲的边对应 (根节点没有对应的边)。 对于路径 $(u, v)$： $mark(u) + 1$。 $mark(v) + 1$。 $mark(lca(u, v)) - 2$。 每个点最终的标记 $Mark(u) = \\sum_{v\\in subtree(u)} mark(v)$ (即以 $u$ 为根的子树中所有节点的 mark 之和)。 这个技巧有一个很炫酷的名字，叫“树上差分”。你可以对一条路径按照上述操作做一遍，然后验证一下处于各个位置的节点的 Mark，你会发现只有 $(u, v)$ 路径上的节点 (除了 LCA) Mark 为 1，其他的都是 0。这恰好符合我们在边上打标记的需求。此外，这个标记系统是可以累加的，即你不需要每次计算 Mark，而是可以把 $m$ 条边的 mark 做完之后再一起计算 Mark。这样我们在 $O(m+n)$ 的时间内完成了打标记的动作。加上预处理和计算 LCA 的复杂度，该算法的总时间复杂度为 $O((n+m)\\log n)$。\n做法2: 将树上路径求交转化为一维的区间求交 把第一个点对所在的路径 $(u_1, v_1)$ 抓出来，考虑剩下的 $m-1$ 条路径在 $(u_1, v_1)$ 上的相交部分。想象一下容易发现，如果把树中的一条链 $(u_1, v_1)$ 提出来，“用手拎着两端提在空中”，那么整个树的格局会像一个晾衣绳，晾衣绳上的每个点挂了一个树，如下图所示。\n给 $(u_1, v_1)$ 这条链上的点重新标号 $x_1, x_2,\\cdots, x_t$。对于其他任意一个点对 $(u_i, v_i)$，如果 $u_i, v_i$ 在同一个 $x_p$ 的树下 (如图中红色所示)，那么 $(u_i, v_i)$ 这条路径将完全在 $x_p$ 的子树内部，从而和 $(u_1, v_1)$ 没有边的交集；如果 $u_i, v_i$ 在不同的子树 $x_p, x_q (p\u0026lt;q)$ 下 (如图中蓝色所示)，那么 $(u_1, v_1)$ 和 $(u_i, v_i)$ 这两条链将会有 $(x_p, x_q)$ 这一段是公共的。\n对于 $(u_2, v_2), \\cdots, (u_m, v_m)$ 中的每一对，我们都可以检查 $u_i, v_i$ 在哪棵子树中，从而算出它和 $(u_1, v_1)$ 的交集。这时问题已经被转化成了在一维序列 $x_1, \\cdots, x_t$ 上的区间交集问题。剩下的一点点细节非常简单，留给大家思考。\n这个做法颇有“大道至简”的意味——没有“倍增求LCA”“树上差分“这样炫酷的技术，就是平平无奇的几遍搜索，就给出了更优秀的时间复杂度 $O(n)$。在这里我们也想给大家传递一个价值观：\n高级算法和高级数据结构就像武林中的重武器，而你分析问题、转化问题的能力则像内功。内功和武器是相辅相成的，内功不足却想耍大刀，适得其反。比起盲目地学习很多炫酷的技术，我们更希望大家能充分锻炼自己的思维能力，这才是成为一个优秀的算法设计师的正道。\n做法3: 一个神奇的随机算法 这个做法有些“过于”精巧，大家只需欣赏即可。\n为每个数对 $(u_i, v_i)$ 随机一个数 $c_i$，并将 $c_i$ 打在 $u_i, v_i$ 两个节点上。对于每条边，砍掉它合法的充分必要条件是这条边下面的子树恰好包含 $c_1, c_2, \\cdots, c_m$ 各一个。这件事并不容易检查，但我们直接对子树上的数值求异或和，并通过检查子树异或和是否等于所有 $c_i$ 的异或和的方式来“判定”子树是否满足要求。时间复杂度 $O(n)$。\n看上去有点雷人。下面尝试用不太严谨的方式论证该做法错误的概率极小：\n异或的性质是：$x\\otimes x = 0$ (其中 $\\otimes$ 常用于表示异或算符)。因此如果一个子树同时包含了一对点 $(u_i, v_i)$ 中的两个或零个，那么它最终的异或和将缺少 $c_i$ 这一项。因此要使得上述随机算法错误，一定存在一个 $\\{1, 2, \\cdots,m\\}$ 的子集 $\\{k_1, k_2, \\cdots k_t\\}$ 满足 $\\bigotimes_{i=1}^t c_{k_i} = 0$，且恰好存在一条边能把这个子集精准地“选出来”。\n对于一个集合，若该集合中的数在 $[0, 2^k)$ 之间随机，那么不论这个集合中元素的个数有多少，该集合的异或和为 0 的概率都是 $\\frac{1}{2^k}$ (考虑每个二进制位，有若干个要么是 0 要么是 1 的数，但不论有多少，其中有偶数个 1 的概率都是 $\\frac{1}{2}$)。\n我们可以不严谨地认为，树上的每条边相当于独立地在 $\\{1, 2, \\cdots, m\\}$ 中选一次子集 (说它不严谨是因为 ①不同的边选出的集合之间存在互相包含关系，并不是独立的； ②该过程和 $2m$ 个数在树上的分布有关，并不是随机选取。但总体可以感受到在概率上两者是同阶的)。因此该算法正确的概率\n$$ P(correct)\\sim \\left(1-\\frac{1}{2^k}\\right)^{\\min(2^m, n)} $$\n本题中 $n\\sim 10^5$。简单计算可知，当 $k=32$ 时正确率已经达到 $99.997\\%$，当 $k=64$ 时该算法正确率将极其接近 $100\\%$ (64位恰好是 long long 的范围，在 long long 范围内随机整数并不困难)。\n虽然从理论计算科学的角度，有错误率的随机算法和确保正确的算法之间存在本质区别，但在实际中，如果算法错误的概率已经远小于硬件出错的概率，那么该算法的可用性便已经很高。对于这道题来说，我们确实容易设计出简单高效的线性算法，但事实上，绝大多数问题是难的 (关于难的定义，以及 P, NP, NP-hard 相关的概念大家会在第四学期学习)，对于难问题，很多时候我们只能从近似角度尝试解决。\n","date":1682726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682726400,"objectID":"94ca20800ef42e9ecb499a520cfd8fa8","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-3-b/","publishdate":"2023-04-29T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-3-b/","section":"courses","summary":"题意描述\n给定一棵 $n$ 个节点的数和 $m$ 个点对，每个点对染不同的颜色。要求找出树中的一条边，使得砍掉这条边后得到的两棵树中没有颜色相同的节点 (即颜色相同的点对不能被划分到同一棵树中)。求满足条件的边的最大编号，若不存在输出 -1。 $n\\leq 10^5$。 树上任意两个点之间有且仅有一条简单路径。并且我们容易发现：如果要把两个点分到两棵树中，那么选择的这条边必须在连接这两个点的路径上。因此该问题被转化为了对树上的 $m$ 条路径求交。以下我们介绍三种做法供大家参考。\n做法1: 基于LCA的路径标记 对于树上的任意两个点 $u$, $v$，从 $u$ 到 $v$ 的路径总可以被拆分为 $u\\to lca(u, v)$ 和 $lca(u,v)\\to v$ 两条直上直下的链。我们希望可以快速给链上所有的边打一个 +1 标记，这样最后只需要找有 $m$ 个标记的边即可。","tags":null,"title":"【问题求解II-HW3.B】砍树","type":"docs"},{"authors":null,"categories":null,"content":" 题意概述\n给定 $n$ 个英文单词，两个单词可以接在一起当且仅当前一个单词的最后一个字母和后一个单词的第一个字母相同。问最少删除多少个单词可以让剩下的单词全部接龙。 $n\\leq 10^5$。 从本次作业开始我们会逐渐向大家介绍简单的动态规划 (dynamic programming) 设计。动态规划是一项“很难教”的技术，因为它没有什么特别的理论基础，好的状态设计和转移优化也没有固定的模式，需要大家多看、多想、多总结。我们通过“单词接龙”这道题来向大家展示好的状态设计是如何显著减少算法时间复杂度的。\n首先，删除尽量少的单词等价于选择尽量多的可接龙单词，因此我们将问题转化为寻找原单词序列的最长可接龙子序列。我们首先考虑如下最容易想到的状态：令 $dp(i)$ 表示以第 $i$ 个单词结尾的最长可接龙子序列的长度。为了计算这个状态，我们需要在 i-th 前找到另外一个单词，满足可以和 i-th 接上。因此转移方程可以写为 $$ dp(i) = 1 + \\max_{k\\in [1, i-1], word_k \\to word_i} dp(k) $$ 其中 $word_i\\to word_j$ 表示第 $i$ 个词的最后一个字母和第 $j$ 个词的第一个字母相同。式子最前方的 1 表示第 $i$ 个单词贡献的序列长度。计算完所有的 dp 值之后，$\\max_{k=1}^n dp(k)$ 即为答案。\n这自然是一个正确的算法，但计算 $dp(i)$ 时需要依次枚举前面的所有单词，从而时间复杂度达到了 $O(n^2)$，在本题的数据规模下不可接受。\n优化状态设计的动机是：我们最关心的其实是单词的开头/结尾字母，而小写字母一共只有 26 个。因此我们应该在这方面作文章，把每次遍历前面所有单词的过程节省掉。考虑如下状态：令 $dp(i, ch)$ 表示在前 $i$ 个单词中，以字符 $ch$ 结尾的最长可接龙子序列的长度 (注意！不再要求一定以 $word_i$ 结尾！)。转移考虑对以下两种情况取 max：\n最长子序列不包括第 $i$ 个单词: $dp(i-1, ch)$。 最长子序列包括第 $i$ 个单词，且第 $i$ 个单词确实以 $ch$ 结尾: 设第 $i$ 个单词的开头字符为 $ch\u0026rsquo;$，则这种情况的最长序列长度为 $dp(i-1, ch\u0026rsquo;) + 1$。 因此状态转移方程可以写为\n$$ dp(i, ch) = \\begin{cases} \\max\\{dp(i-1, ch), dp(i-1, \\text{start}(word_i)) + 1\\} \u0026amp;, \\text{end}(word_i) = ch\\\\ dp(i-1, ch)\u0026amp;, \\text{otherwise} \\end{cases} $$\n可以看到，虽然状态的数量上升到了 $O(n|\\Sigma|)$，但转移的代价变成了 $O(1)$，所以总时间复杂度降低到了 $O(|\\Sigma|n)$，其中 $\\Sigma$ 为字符集，在本题中 $|\\Sigma|=26$，可以通过。\n有没有什么小技巧可以略微优化一下复杂度？\n上述状态转移方程中，我们每次只会对一个 $ch$ 更新 dp，其余的都是照抄。而且 $dp(i, ch)$ 的计算只会用到 $dp(i-1, ch)$ 的结果，因此我们可以把状态的第一维省掉，把代码写成如下形式：\ndp = [0] * MAX_CHARACTER # 长度为 |Sigma| 的数组 for i in range(1, n + 1): # 此时的 dp[ch] 存储的是方程式中 dp(i-1, ch) 的值 startch, endch = strings[i].start, strings[i].end dp[endch] = max(dp[endch], dp[startch] + 1) # 根据转移方程，此时 dp[endch] 的值是 dp(i, ch) 的值 # 又因为其他的 dp[ch] 不需要改变，所以自动“升级”成了 dp(i, ch) # 至此，dp[ch] 存储了方程式中 dp(i, ch) 的值 可以看到，省掉了第一维之后，动态规划的时间复杂度下降到了 $O(n)$，空间复杂度下降到了 $O(|\\Sigma|)$ (不考虑存储字符串的额外代价)。如果字符集的大小达到了很大的级别 (比如 unicode 中的所有字符)，那么这一简单的优化可以节省大量的时间和存储。\n第一个 dp 思路真的是“死胡同”吗？\n再来重温一下状态转移方程\n$$ dp(i) = 1 + \\max_{k\\in [1, i), word_k \\to word_i} dp(k) $$\n在考虑 $dp(i)$ 的转移时，我们在意的是所有的那些结尾字母与 $word_i$ 开头字母相同的位置的 dp 的最大值。每次把 1 到 i-1 扫一遍效率太低，但注意我们在做到 $dp(i)$ 时，之前的所有 dp 值已经求好了，因此我们可以额外对每种结尾字母维护当前最大值，从而实现 $O(1)$ 转移。\n形式化地，令 $$ maxdp(i, ch)\\triangleq \\max_{k\\in [1, i],\\text{end}(word_k)=ch} dp(k) $$ 则我们可以同时写出 dp 和 maxdp 的状态转移方程\n$$ \\begin{align} dp(i) \u0026amp;= 1 + maxdp(i-1, \\text{start}(word_i))\\\\ maxdp(i, ch) \u0026amp;= \\begin{cases} \\max\\{maxdp(i-1, ch), dp(i)\\} \u0026amp;, \\text{end}(word_i) = ch\\\\ maxdp(i-1, ch) \u0026amp;, \\text{otherwise} \\end{cases} \\end{align} $$\n两个转移都是 $O(1)$ 的，而且由于 $dp(i)$ 只用到 $maxdp(i-1, ch)$，所以我们可以用和类似的技巧将 maxdp 的第一维度省去，将代码写成类似下面的模样：\nfor i in range(1, n + 1): startch, endch = strings[i].start, strings[i].end dp[i] = 1 + maxdp[startch] maxdp[endch] = max(maxdp[endch], dp[i]) 你又可以发现一件事情：$dp(i)$ 在当前循环算完立即使用，且后续再也不会使用，所以可以把 $dp(i)$ 省略：\nfor i in range(1, n + 1): startch, endch = strings[i].start, strings[i].end maxdp[s.endch] = max(maxdp[endch], 1 + maxdp[startch]) 和之前的代码对比一下，你会发现除了数组名字不一样，其他完全一样。我们用两条看上去不太相同的思考路径得到了相同的结果，但实际上它们的本质是一致的：\n动态规划状态设计就像给当前时刻做一张“快照”。你需要想清楚快照中保存怎样的性质可以完整地刻画当前的状态并为后续所用。在此基础上，记录的性质应当越少越好。 在这个问题中，每个接龙字符串序列的最后一个字符是最本质地刻画特征的性质，而最后一个字符串的下标并不是 ($i+1$ 往后的状态并不关心 $[1,i]$ 中结尾为 $ch$ 的最长接龙字符串序列的最后一个字符串是 $[1, i]$ 中的哪一个)。这就是第一个 dp 方向错误的根本原因。\n大家日后要做的，就是稳准狠地抓住一个状态最本质的性质。\n","date":1682726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682726400,"objectID":"b8b97011770ffcb9bab0a02a3f9d98f5","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-3-c/","publishdate":"2023-04-29T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-3-c/","section":"courses","summary":"题意概述\n给定 $n$ 个英文单词，两个单词可以接在一起当且仅当前一个单词的最后一个字母和后一个单词的第一个字母相同。问最少删除多少个单词可以让剩下的单词全部接龙。 $n\\leq 10^5$。 从本次作业开始我们会逐渐向大家介绍简单的动态规划 (dynamic programming) 设计。动态规划是一项“很难教”的技术，因为它没有什么特别的理论基础，好的状态设计和转移优化也没有固定的模式，需要大家多看、多想、多总结。我们通过“单词接龙”这道题来向大家展示好的状态设计是如何显著减少算法时间复杂度的。\n首先，删除尽量少的单词等价于选择尽量多的可接龙单词，因此我们将问题转化为寻找原单词序列的最长可接龙子序列。我们首先考虑如下最容易想到的状态：令 $dp(i)$ 表示以第 $i$ 个单词结尾的最长可接龙子序列的长度。为了计算这个状态，我们需要在 i-th 前找到另外一个单词，满足可以和 i-th 接上。因此转移方程可以写为 $$ dp(i) = 1 + \\max_{k\\in [1, i-1], word_k \\to word_i} dp(k) $$ 其中 $word_i\\to word_j$ 表示第 $i$ 个词的最后一个字母和第 $j$ 个词的第一个字母相同。式子最前方的 1 表示第 $i$ 个单词贡献的序列长度。计算完所有的 dp 值之后，$\\max_{k=1}^n dp(k)$ 即为答案。","tags":null,"title":"【问题求解II-HW3.C】单词接龙","type":"docs"},{"authors":null,"categories":null,"content":"在计算机世界中，所有与2的次幂相关的事情总是充满魔力的——即便是很大的数，对2取对数后也会落入我们容易处理的范围。之前介绍过的快速幂算法其实就是倍增思想的一种运用。这里我们以计算树上最近公共祖先 (lowest common ancestor, LCA) 为例再次展示倍增思想的强大。\n树\n如果你对“树”一无所知，你可以参考 维基百科 中的解释。这里强调一些简明的入门概念。\n树是一个有 $n$ 个顶点和 $n-1$ 条边构成的连通图 (连通指整个图只有“一块”，即任意两点之间都存在路径可达)。容易发现，树中是不会有环的。 如果选择一个节点作为树根 (root)，那么整棵树会形成一个层次结构。树上的每个节点到根有且仅有一条路径，这个路径的长度称为节点的深度。 在有根树中，每个节点“上面”相邻的只有一个节点，称为该节点的父亲。每个节点“下面”相邻的有一堆节点 (也可能没有)，称为该节点的孩子。一个节点A的父亲，父亲的父亲，…… 一直向上到根这条链上所有的节点都是A的祖先。 对于树中的两个节点 $u, v$，$LCA(u, v)$ 指的是 $u$ 和 $v$ 的所有公共祖先中最深的那个 (也可以说是离 $u, v$ 最近的那个)。下面是一个例子:\n暴力地求解LCA不算困难，总体思想是：我们先让深度大的节点往上爬，爬到和另一个节点相同深度，然后让 $u$ 和 $v$ 一直向上爬，直到它们相遇。下面的代码非常易懂\nint LCA_bruteforce(int u, int v) { if (depth[u] \u0026lt; depth[v]) swap(u, v); while (depth[u] \u0026gt; depth[v]) u = father[u]; while (u != v) { u = father[u]; v = father[v]; } return u; } 该算法的问题在于：如果树的深度很大 (例如达到了和 $n$ 同阶)，那么每次求解两个节点的 LCA 都需要 $O(n)$ 的时间。如果我们需要多次求解多个点对的 LCA (例如 $q$ 次)，就需要 $O(qn)$ 的时间。在 $q$ 较大的情况下这不可接受。\n接下来我们向大家展示如何利用倍增思想优化 LCA 的求解：\n令 $anc(u,i)$ 表示节点 $u$ 向上爬 $2^i$ 步之后到达的节点编号，如果 $depth(u)\u0026lt;2^i$ 则 $anc(u,i)=0$。我们发现 $anc(u,i)$ 是容易计算的：\n$$ anc(u, i)= \\begin{cases} father(u)\u0026amp;, i=0\\\\ anc(anc(u, i-1), i-1)\u0026amp;, i \\geq 1 \\end{cases} $$\n简单来说，向上爬 $2^n$ 步的结果等于先向上爬 $2^{n-1}$ 步，再向上爬 $2^{n-1}$ 步的结果。如果我们按照 $i$ 从小到大的顺序计算所有节点的 $anc(u,i)$，那么可以递推地完成计算过程。在实际实现时我们通常树搜索的过程中完成 anc 数组的计算，详见最后的参考代码。\n有了 anc 数组后，“向上跳”的流程就可以被大幅加速。我们先假设 $u, v$ 深度相同，这时我们不需要每次向上爬一格，而可以用 anc “赌一把大的”：\nfor (int i = 20; i \u0026gt;= 0; i--) if (anc[u][i] != anc[v][i]) { u = anc[u][i]; v = anc[v][i]; } 这里巧妙地利用了整数二进制拆分的唯一性：假设 $depth(u)-depth(LCA(u, v))=d$，且 $$ d-1 = 2^{a_1} + 2^{a_2} + \\cdots + 2^{a_k}, a_1\u0026gt;a_2\u0026gt;\\cdots\u0026gt;a_k $$ 那么上述循环正好会在 $i=a_1, a_2,\\cdots, a_k$ 的地方“向上跳”。之所以是 $d-1$ 而不是 $d$ 是因为我们要求 anc[u][i] != anc[v][i]，只有这样我们才能确保没有“跳过头”，因此上述循环结束后 $u, v$ 都会正好在 LCA 的下面 (孩子)。我们强烈建议你手画一个例子体会这个过程。\n还剩下一个问题：如果 $u, v$ 深度不同该怎么办。和暴力做法的思路一样，我们可以让深度大的节点向上爬，爬到和另一个节点同深度。不过在 anc 数组的加持下，我们不再需要一个一个地爬了：\n// 假设 depth[u] \u0026gt;= depth[v] for (int i = 20; i \u0026gt;= 0; i--) if (depth[anc[u][i]] \u0026gt;= depth[v]) u = anc[u][i]; 你仍然可以用整数拆分的方式证明：$u$ 只会在 $depth(u)-depth(v)$ 的二进制表示中为 1 的那些位置向上跳，且循环结束后 $u$ 会和 $v$ 同深度。\n我们来分析这个倍增做法的复杂度：它尝试用 $2^k, 2^{k-1},\\cdots, 2^1, 2^0$ 去覆盖 $u, v$ 到 LCA 的深度差距，因此只需要 $O(\\log n)$ 的时间即可完成一次查询。虽然预处理 anc 表需要 $O(n\\log n)$ 的时间，但在查询次数较多的情况下，$O(n\\log n + q\\log n)$ 就会比 $O(n + qn)$ 更有优势。\n通用思想\n从更抽象的层面来说，倍增思想成功的关键很多时候是一种“单一的扩展可能”：\n在快速幂的例子中，$*2$ 这件事非常固定，这使得 $2^n$ 可以通过重复 $*2$ 得到； 在 LCA 的例子中，每个节点的父亲只有一个，这使得往上 $n$ 层的祖先可以通过重复 u=father[u] 得到； …… 这段话看起来有点玄学，但如果你接触了更多可以通过倍增思想解决的问题结构，回过头看可能会对此有更深的理解。\n更快地求解LCA?\n虽然 $O(\\log n)$ 的效率已经足够令人满意，但事实上在充分预处理的情况下，我们可以 $O(1)$ 地完成一对点的 LCA 查询。如果你对此感兴趣，可以尝试搜索 ST 表、dfs 序等关键词。我们会在合适的时机向大家展示这种技术。\n以下是一份参考代码：\nLCA::click to expand const int MAXN = 2e5 + 10; vector\u0026lt;int\u0026gt; v[MAXN]; // vector 存储了每个节点相邻点的编号 int depth[MAXN]; // depth 存储了每个节点的深度 int anc[MAXN][21]; // 2 ^ 21 \u0026gt; MAXN void dfs(int x, int fa) { // 搜索到 x 时 x 的所有祖先都已经被访问过，anc 数组已被计算 // 因此现在就可以计算 x 的 anc 数组 anc[x][0] = fa; for (int i = 1; i \u0026lt;= 20; i++) anc[x][i] = anc[anc[x][i - 1]][i - 1]; // 搜索 for (int y : v[x]) if (y != fa) // 相邻的节点不是父亲，那就是孩子，向下搜索 { depth[y] = depth[x] + 1; dfs(y, x); // y 是 x 的孩子，x 是 y 的父亲 } } int query_lca(int x, int y) { if (depth[x] \u0026lt; depth[y]) swap(x, y); for (int i = 20; i \u0026gt;= 0; i--) if (depth[anc[x][i]] \u0026gt;= depth[y]) x = anc[x][i]; // 此时有 depth[x] = depth[y] if (x == y) return x; for (int i = 20; i \u0026gt;= 0; i--) if (anc[x][i] != anc[y][i]) { x = anc[x][i]; y = anc[y][i]; } // 注意不等号条件，此时 x, y 一定都是 LCA 的孩子, LCA = anc[x][0] = anc[y][0] return anc[x][0]; } ","date":1682035200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682035200,"objectID":"f8689680d647b15dea7bfb3a65d22a16","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/algorithms/lca/","publishdate":"2023-04-21T00:00:00Z","relpermalink":"/courses/problemsolving22/algorithms/lca/","section":"courses","summary":"在计算机世界中，所有与2的次幂相关的事情总是充满魔力的——即便是很大的数，对2取对数后也会落入我们容易处理的范围。之前介绍过的快速幂算法其实就是倍增思想的一种运用。这里我们以计算树上最近公共祖先 (lowest common ancestor, LCA) 为例再次展示倍增思想的强大。\n树\n如果你对“树”一无所知，你可以参考 维基百科 中的解释。这里强调一些简明的入门概念。\n树是一个有 $n$ 个顶点和 $n-1$ 条边构成的连通图 (连通指整个图只有“一块”，即任意两点之间都存在路径可达)。容易发现，树中是不会有环的。 如果选择一个节点作为树根 (root)，那么整棵树会形成一个层次结构。树上的每个节点到根有且仅有一条路径，这个路径的长度称为节点的深度。 在有根树中，每个节点“上面”相邻的只有一个节点，称为该节点的父亲。每个节点“下面”相邻的有一堆节点 (也可能没有)，称为该节点的孩子。一个节点A的父亲，父亲的父亲，…… 一直向上到根这条链上所有的节点都是A的祖先。 对于树中的两个节点 $u, v$，$LCA(u, v)$ 指的是 $u$ 和 $v$ 的所有公共祖先中最深的那个 (也可以说是离 $u, v$ 最近的那个)。下面是一个例子:","tags":null,"title":"最近公共祖先-倍增","type":"docs"},{"authors":null,"categories":null,"content":" 已知一个数列 $a_1, \\cdots, a_n$。给定 $l, r$，问区间 $a_l, \\cdots a_r$ 的某种值。\nST表是一种处理上述格式的区间查询问题的利器。这类问题通常被称为 RMQ (range minimum query)，但实际上 ST 表可以应对的问题远不止最小值这一种。\n大家已经或多或少地接触过一些区间查询问题，例如求区间的和。以 $+$, $xor$ (异或操作) 这类算符为代表的操作的特点在于可以简明地写出逆运算。例如\na + x - x = a a ^ x ^ x = a 满足这种特性的算符使用前缀技术可以高效地求解区间查询： $$ \\begin{align} \u0026amp;pre(n)\\triangleq op_{k=1}^n a_k \\\\ \u0026amp;op(l, r) = pre(r)\\space op^{-1}\\space pre(l-1) \\end{align} $$\n但有些算符，例如 $\\max, \\min, or$ (同或操作)，它们不存在简明的逆运算符，从而无法用前缀技术解决区间问题 (例如，知道 $\\max_{i\\in [1, r]}a_i$ 和 $\\max_{i\\in [1, l-1]}a_i$ 对求解 $[l, r]$ 内的最大值没什么帮助)。但这些算符又具有加法、异或所不具备的特性——重复操作不会对结果带来影响：\n$\\max(a, b) = \\max(\\max(\\max(a, b), b), b)$ $a | b = a | b | b | b$ ST表正适合用于解决这类算符的区间查询问题。ST表的本质是倍增思想 (由此可见倍增思想运用之广)。下面的讲解以最小值为例，但可以容易地扩展到其他算符上：\n令 $ST(i, j)$ 表示区间 $[i, i + 2^j)$ 的最小值。容易发现对于一个数列来说，按照 $j$ 的顺序从小到大计算 ST 可以递推地高效求解：\n$$ ST(i, j)= \\begin{cases} a_i\u0026amp;, j = 0\\\\ \\min(ST(i, j-1), ST(i + 2^{j-1}, j-1))\u0026amp;, j \\geq 1 \\end{cases} $$\n简单来说，长度为 $2^j$ 的区间的最小值可以用已经求好的两个长度为 $2^{j-1}$ 的区间的最小值求 $\\min$ 得到。如果 $i + 2^{j-1}$ 超出了 $n$，那么可以不考虑后一半的贡献。\n预处理好所有长度为2的次幂的区间的最小值，对于任意区间 $[l, r]$ 的最小值，我们可以用如下方式 $O(1)$ 地求解：令 $k$ 为最大的满足 $2^k\\leq r-l+1$ 的整数，那么 $$ \\min_{i=l}^r a_i = \\min(ST(l, k), ST(r - 2^k + 1, k)) $$ 它的思想是：$[l, l + 2^k)$ 和 $[r - 2^k + 1, r + 1)$ 这两个部分重叠的区间完整地覆盖了 $l[l, r]$，因此拿着它们的最小值求 min 即可得到全区间的最小值。在这里你可以看出 $\\min$ 算符的“重复操作不影响结果”的特性对该做法的正确性保证至关重要。\n最后一个简单的小问题是：如何求 $k$。从数学的角度，你可以使用数学库中的 $\\log$ 函数，但更常见的做法是线性预处理所有可能长度对应的 $k$ 值：\nK[1] = 0; for (int i = 2; i \u0026lt;= n; i++) K[i] = K[i \u0026gt;\u0026gt; 1] + 1; 你可以用数学归纳法来证明该做法的正确性。\n总结：\nST 表可以在 $O(n\\log n)$ 的预处理复杂度下，$O(1)$ 地求解任意区间的值。 算符需要保证具有“重复操作不影响结果”的特性。 ST 表无法处理带修改的情况。 真的要具有“可重复贡献”性吗?\n如果你仔细学习了LCA章节的讲义，可能会想：如果把区间 $[l, r]$ 通过二进制拆分的方式拆成若干互不相交的，长度为2的次幂的区间的并，不就可以在 $O(\\log n)$ 的时间内完成任意算符的区间查询了么？\n非常好的想法！而且确实是正确的。只不过一般没有人会这么做——ST表不支持修改的特性是硬伤，它的“卖点”主要是 $O(1)$ 的效率。因此如果要花费 $O(\\log n)$ 的代价才能完成区间求值，它的价值就十分有限了。我们会在合适的时机向大家展示支持修改的 $O(\\log n)$ 地完成各种区间操作的技术。\n","date":1682035200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682035200,"objectID":"57d25d3f8fa30b497e34c56134e4c50c","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/algorithms/st/","publishdate":"2023-04-21T00:00:00Z","relpermalink":"/courses/problemsolving22/algorithms/st/","section":"courses","summary":"已知一个数列 $a_1, \\cdots, a_n$。给定 $l, r$，问区间 $a_l, \\cdots a_r$ 的某种值。\nST表是一种处理上述格式的区间查询问题的利器。这类问题通常被称为 RMQ (range minimum query)，但实际上 ST 表可以应对的问题远不止最小值这一种。\n大家已经或多或少地接触过一些区间查询问题，例如求区间的和。以 $+$, $xor$ (异或操作) 这类算符为代表的操作的特点在于可以简明地写出逆运算。例如\na + x - x = a a ^ x ^ x = a 满足这种特性的算符使用前缀技术可以高效地求解区间查询： $$ \\begin{align} \u0026amp;pre(n)\\triangleq op_{k=1}^n a_k \\\\ \u0026amp;op(l, r) = pre(r)\\space op^{-1}\\space pre(l-1) \\end{align} $$","tags":null,"title":"ST表","type":"docs"},{"authors":null,"categories":null,"content":"大家比较熟悉的输入输出有两种：\nint x; scanf(\u0026quot;%d\u0026quot;, \u0026amp;x); // C style printf(\u0026quot;%d\\n\u0026quot;, x); std::cin \u0026gt;\u0026gt; x; // C++ style std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; endl; 如果输入/输出量过大，以至于输入输出部分成为算法问题实现的效率瓶颈，那么采取合适的方法进行快速输入/输出就变得非常重要。本章节介绍若干种常见的输入输出优化。\n输入输出函数背后的实现非常复杂，其效率与缓冲区设计、操作系统、磁盘IO等多个环节息息相关。因此本章节会尽可能略去原理的讲解 (或者以补充链接的形式给出)。如果你无法理解这其中的奥妙，不用担心，先把写法学会，等你学过了计算机体系结构/计算机系统基础/操作系统后就会对它们有更深刻的认识。 关闭与 stdio 的同步 一种 主流的说法 是: cin 比 scanf 读入要慢。在选择接受这条“定理”之前，你应当自己做个实验来验证一下：\nint N = 30000000; int a[N]; int main () { for (int i = 0; i \u0026lt; N; i++) cin \u0026gt;\u0026gt; a[i]; for (int i = 0; i \u0026lt; N; i++) scanf(\u0026quot;%d\u0026quot;, a + i); } 将 $N$ 设置成一个很大的数，并用 cin 和 scanf 分别跑一遍测试时间。不出意外的话你会发现这条定理确有其正确之处。但事实上 cin 比 scanf 看上去慢的一个主要原因是：cin 花了很多代价进行缓冲区同步，从而让你可以在混用 cin 和 scanf 的情况保证程序的正确性。我们可以通过在 main() 函数开头显式地添加一句 ios::sync_with_stdio(false); 的方式来关闭这种同步。关闭同步后，你如果再尝试一次上述的效率实验，会发现 cin 和 scanf 其实没什么差别。\n需要注意的是：一旦手动关闭了同步，你就不能再混用两种风格的输入函数。你可以尝试运行下面的例子：\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main () { ios::sync_with_stdio(false); int a, b, c; cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; scanf(\u0026quot;%d\u0026quot;, \u0026amp;c); cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; ' ' \u0026lt;\u0026lt; b \u0026lt;\u0026lt; ' ' \u0026lt;\u0026lt; c \u0026lt;\u0026lt; endl; return 0; } 你会发现该程序会给你意想不到的结果。\n使用 getchar() 代替 scanf() C库提供的 scanf() 函数功能丰富，例如可以用 %d %s %p %x，甚至正则表达式，去匹配各种类型的数据。但功能丰富的代价就是效率不够高。如果你确定当前场景下需要读入的一定是某种特定类型的数据 (例如整数)，那么可以考虑使用 getchar() (其功能为读入一个字符) 来手写一个读入函数，这通常能获得更好的效率。下面展示一个读入 int 类型整数的函数：\nint getint() { char ch; int res; bool f; while (!isdigit(ch = getchar()) \u0026amp;\u0026amp; ch != '-'); // 过滤所有不是数字和\u0026quot;-\u0026quot;的字符 if (ch=='-') f = false, res = 0; else f = true, res = ch - '0'; // 判断正负性 while (isdigit(ch = getchar())) res = res * 10 + ch - '0'; // 读取数字并计算 return f ? res : -res; } 使用 \\n 代替 endl 有的时候，你会发现 cout \u0026lt;\u0026lt; \u0026quot;\\n\u0026quot;; 比 cout \u0026lt;\u0026lt; endl; 要快。这是因为 endl 会强制冲刷缓冲区，在缓冲区没满的时候多次冲刷会让效率变低。( 参考链接 )\n什么是缓冲区?\n了解缓冲区设计的动机需要对计算机系统中的 memory hierarchy 有一定了解，这里尝试尽可能短和通俗地解释清楚这个概念。\n假设你人在宿舍，要去图书馆借书。上午要去借A，下午要去借B，晚上去借C，于是你跑了三趟图书馆，这非常耗时。假设你是一个先知，上午就知道了自己要借 ABC 三本书，为了节省跑图书馆的时间，你在宿舍楼下放了一个书架，上午你一次性抱了三本书回来放在楼下的书架上，后面每次你需要书了就只需要下楼从书架上拿即可。还书也是相同的道理，你发现与其跑三趟，不如把要还的书先放在书架上，等手里所有的书都看完了再把书架上的书一起还到图书馆。\n这个例子里\n从图书馆借书/还书就是输入输出。相比较 a[i]=b[j] a++ 这样的操作，执行一次输入输出是十分耗时的。 书A/B/C是数据，或者说即将读入/准备输出的字符。 书架是缓冲区。缓冲区就像一个大数组，暂存读入和输出数据。所谓的“冲刷缓冲区”就是将书架里的书全部还回图书馆/将缓冲区的数据真正输出。 因此，使用 endl 就像每次往书架上放书时都强制把书架上所有的书放回图书馆，效率自然不高。\n使用 fread()/fwrite() 一般只有在读入/输出量极大的时候我们才会考虑使用 fread()/fwrite() 完成输入输出。如果延用之前借书的例子，fread() 和 fwrite() 相当于手动开辟一个巨大的书架，这个书架比 scanf()/cin 的书架大的多，从而显著减少了“把书从图书馆搬到书架”的次数。\n这里提供一份使用 fread/fwrite 的代码供参考。\nfastio class ::click to expand struct fastio { static const int S=1e7; char rbuf[S+48],wbuf[S+48];int rpos,wpos,len; fastio() {rpos=len=wpos=0;} inline char Getchar() { if (rpos==len) rpos=0,len=fread(rbuf,1,S,stdin); if (!len) return EOF; return rbuf[rpos++]; } template \u0026lt;class T\u0026gt; inline void Get(T \u0026amp;x) { char ch;bool f;T res; while (!isdigit(ch=Getchar()) \u0026amp;\u0026amp; ch!='-') {} if (ch=='-') f=false,res=0; else f=true,res=ch-'0'; while (isdigit(ch=Getchar())) res=res*10+ch-'0'; x=(f?res:-res); } inline void getstring(char *s) { char ch; while ((ch=Getchar())\u0026lt;=32) {} for (;ch\u0026gt;32;ch=Getchar()) *s++=ch; *s='\\0'; } inline void flush() {fwrite(wbuf,1,wpos,stdout);fflush(stdout);wpos=0;} inline void Writechar(char ch) { if (wpos==S) flush(); wbuf[wpos++]=ch; } template \u0026lt;class T\u0026gt; inline void Print(T x,char ch) { char s[20];int pt=0; if (x==0) s[++pt]='0'; else { if (x\u0026lt;0) Writechar('-'),x=-x; while (x) s[++pt]='0'+x%10,x/=10; } while (pt) Writechar(s[pt--]); Writechar(ch); } inline void printstring(char *s) { int pt=1; while (s[pt]!='\\0') Writechar(s[pt++]); } }io; 需要注意： 因为 fread() 和 fwrite() 开辟了大数组作为缓冲区一次性搬入很多数据，所以 fread()/fwrite() 不能和其他使用自带 buffer 的IO方法混用。换句话说，你只能从通过操作自定义的缓冲区的方式来输入输出。\n","date":1681862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681862400,"objectID":"eedc13bbd1a53aa5be1e38d0cacf28c3","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/coding/fastio/","publishdate":"2023-04-19T00:00:00Z","relpermalink":"/courses/problemsolving22/coding/fastio/","section":"courses","summary":"大家比较熟悉的输入输出有两种：\nint x; scanf(\u0026quot;%d\u0026quot;, \u0026amp;x); // C style printf(\u0026quot;%d\\n\u0026quot;, x); std::cin \u0026gt;\u0026gt; x; // C++ style std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; endl; 如果输入/输出量过大，以至于输入输出部分成为算法问题实现的效率瓶颈，那么采取合适的方法进行快速输入/输出就变得非常重要。本章节介绍若干种常见的输入输出优化。\n输入输出函数背后的实现非常复杂，其效率与缓冲区设计、操作系统、磁盘IO等多个环节息息相关。因此本章节会尽可能略去原理的讲解 (或者以补充链接的形式给出)。如果你无法理解这其中的奥妙，不用担心，先把写法学会，等你学过了计算机体系结构/计算机系统基础/操作系统后就会对它们有更深刻的认识。 关闭与 stdio 的同步 一种 主流的说法 是: cin 比 scanf 读入要慢。在选择接受这条“定理”之前，你应当自己做个实验来验证一下：","tags":null,"title":"快速输入输出","type":"docs"},{"authors":null,"categories":null,"content":"分块的思想被应用在生活的方方面面：举一个最简单的例子，大家上小学的时候通常班级里的座位被分成若干个“组”。每组有一个小组长 (传说中的“一道杠”)，班里有班干部 (传说中的“二道杠\u0026quot;)。班长在统计人数的时候，最便捷的方法就是让各个小组长统计自己组内的人数，汇总到班长手中再做一次简单加法。\n在算法设计中，分块的思想也常常被使用。空说无益，我们通过一个比 OJ 练习题更复杂的问题来解释分块思想的运用：\n给定数列 $a_1, \\cdots, a_n$，高效实现 $q$ 次以下两种操作：\n1 l r x：给区间 $[l, r]$ 中的数统一加上 $x$。 2 l r：查询 $\\sum_{k=l}^r a_k$ 的值。 暴力修改和统计有着相同的问题：如果给定的区间很长，那么操作执行就相当缓慢。总时间复杂度可以达到 $O(qn)$。\n我们来考虑如下的一种分块策略：将数列分成若干个长度为 $m$ 的小段 (第一段是 $[0,m)$，第二段是 $[m, 2m)$，依次类推，我们假设 $n$ 可以被 $m$ 整除)，命名为 $B_1, B_2, \\cdots, B_b$。我们为每个块分配一个累加标记 $t_i$，表示这个块上的数被整体加了多少，再维护一个和标记 $s_i$，表示在不考虑累加标记的情况下块内的数的和。那么\n对于给 $[l, r]$ 上的数加 $x$ 这件事，我们可以把 $[l,r]$ 这个大区间拆分为：\n$[l, l_1]$，开头的一段，是某个块的后缀 $[l_1+1, r_1]$，这一段正好对应若干个完整的块。 $[r_1+1, r]$，结尾的零碎一段，是某个块的前缀。 对于 $[l, l_1]$ 和 $[r_1, r]$，我们一个一个地给每个数 +x (别忘了同步更新该块对应的 $s_i$)。对于中间的若干个完整的块，我们直接把 +x 标记打在对应的 $t_i$ 上 (即 \"ti += x\")。 对于求 $\\sum_{k=1}^ra_k$，我们仍然可以把区间拆成上述的三个部分。对于开头和结尾的零碎区间，我们一个一个地累加，对于中间的若干个完整的块，我们发现一个块的实际的和可以通过如下方式算出： $$ sum_i = s_i + t_i * m $$ 将中间完整块的 $sum_i$ 累加起来即可。 为了更清楚地说明上述思想，我们给出修改和查询操作的简单伪代码：\nPseudocode :: Click to expand void modify(int l, int r, int x) { decompose [l, r] into [l, l1], [l1, r1] and [r1, r] suppose [l1, r1] = Bp, Bp+1, ..., Bq // 开头零碎段 for (int i = l; i \u0026lt;= l1; i++) { a[i] += x; s[p-1] += x; } // 中间完整段 for (int i = p; i \u0026lt;= q; i++) t[i] += x; // 结尾零碎段 for (int i = r1 + 1; i \u0026lt;= r; i++) { a[i] += x; s[q+1] += x; } } int query(int l, int r) { decompose [l, r] into [l, l1], [l1, r1] and [r1, r] suppose [l1, r1] = Bp, Bi+1, ..., Bq int sum = 0; // 开头零碎段 for (int i = l; i \u0026lt;= l1; i++) sum += a[i]; // 中间完整段 for (int i = p; i \u0026lt;= q; i++) sum += s[i] + t[i] * m; // 结尾零碎段 for (int i = r1 + 1; i \u0026lt;= r; i++) sum += a[i]; return sum } 接下来我们考虑这个块的长度应当如何设计。我们容易发现块如果太大，那么一个修改/查询区间首尾的零碎部分就可能太长；如果块太小，那么一个修改/查询区间就可能包含太多的块。具体的，在块大小为 $m$ 时，整个数列被划分成 $n/m$ 个块，那么在一次操作中，首尾的零碎部分的求和复杂度可以达到 $2m = O(m)$，累加区间中间包含的整块的信息的时间复杂度最多可以达到 $O(n/m)$ ，于是有 $$ \\arg\\min_m \\left\\{O(m), O(n/m)\\right\\} \\Longrightarrow m=\\sqrt n $$ 所以，将块的大小定义在 $\\sqrt n$ 附近是最合理的选择，这也是分块思想通常被称为“根号暴力”的原因。可以算出，在我们的分块算法下，解决原问题的复杂度被降低到了 $O(q\\sqrt n)$。\n数列上分块是分块思想最常见的应用，但分块的应用不仅停留在这种线性结构上。从抽象层面说，如果你发现你可以将某一些东西绑成一个整体，然后将某些操作统一在整体层面，那么便可以考虑分块。分块被称为是一种优雅的暴力，因为它没有复杂的数据结构设计，看上去就是一些加加减减，便举重若轻地解决了问题。\n","date":1680912000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680912000,"objectID":"4d15dce6e0390c7daff13f1ddb54a104","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/algorithms/chunking/","publishdate":"2023-04-08T00:00:00Z","relpermalink":"/courses/problemsolving22/algorithms/chunking/","section":"courses","summary":"分块的思想被应用在生活的方方面面：举一个最简单的例子，大家上小学的时候通常班级里的座位被分成若干个“组”。每组有一个小组长 (传说中的“一道杠”)，班里有班干部 (传说中的“二道杠\u0026quot;)。班长在统计人数的时候，最便捷的方法就是让各个小组长统计自己组内的人数，汇总到班长手中再做一次简单加法。\n在算法设计中，分块的思想也常常被使用。空说无益，我们通过一个比 OJ 练习题更复杂的问题来解释分块思想的运用：\n给定数列 $a_1, \\cdots, a_n$，高效实现 $q$ 次以下两种操作：\n1 l r x：给区间 $[l, r]$ 中的数统一加上 $x$。 2 l r：查询 $\\sum_{k=l}^r a_k$ 的值。 暴力修改和统计有着相同的问题：如果给定的区间很长，那么操作执行就相当缓慢。总时间复杂度可以达到 $O(qn)$。\n我们来考虑如下的一种分块策略：将数列分成若干个长度为 $m$ 的小段 (第一段是 $[0,m)$，第二段是 $[m, 2m)$，依次类推，我们假设 $n$ 可以被 $m$ 整除)，命名为 $B_1, B_2, \\cdots, B_b$。我们为每个块分配一个累加标记 $t_i$，表示这个块上的数被整体加了多少，再维护一个和标记 $s_i$，表示在不考虑累加标记的情况下块内的数的和。那么","tags":null,"title":"分块——优雅的暴力","type":"docs"},{"authors":null,"categories":null,"content":" 题意概述\n给定一个长度为 $2n$ 的数列，保证所有数的和是奇数。两个人轮流取数，每次只能取数列的第一个或最后一个数。问双方都采取最优策略的情况下谁能获得胜利。\n为了说明这道题目的合理性，我们介绍策梅洛定理 (以下是摘自 Wikipedia 的解释)：\nIn game theory, Zermelo\u0026rsquo;s theorem is a theorem about finite two-person games of perfect information in which the players move alternately and in which chance does not affect the decision making process. It says that if the game cannot end in a draw, then one of the two players must have a winning strategy (i.e. can force a win).\n简单来说，一个双方轮流行动的游戏如果满足\n在有限步内结束。 场上所有信息对双方公开。 没有随机因素。 没有平局。 那么必然存在先手必胜策略或后手必胜策略。常见的棋类竞技运动如象棋、围棋都是有必胜策略的 (只不过搜索空间太大人们找不到)；当然飞行棋没有必胜策略，因为扔骰子这件事情带来了随机因素。\n回到这道题，如果撇除那条充满诱导性的提示，大家很可能想到的是使用如下的一个递推过程计算谁必胜：令 $s(l, r)$ 表示用区间 $[l, r)$ 中的数玩这个游戏，先手拿到的数的和最多可以比后手多多少。那么有\n$$ s(l, r)=\\begin{cases} 0, \u0026amp;l=r\\\\ \\max(\\\\ \\qquad s(l+2, r) + a_l - a_{l+1},\\\\ \\qquad s(l+1, r-1) + a_l - a_{r-1},\\\\ \\qquad s(l+1, r-1) + a_{r-1} - a_l,\\\\ \\qquad s(l, r-2) + a_{r-1} - a_{r-2}\\\\ ), \u0026amp;l \u0026lt; r \\end{cases} $$\n这个公式看上去复杂，但其实只是枚举了两个人从数列里各取一个数的四种情况： (头,头)，(头,尾)，(尾,头)，(尾,尾)。如果我们认为区间的长度代表这个问题的规模的话，那么我们的递推公式就成功将大规模的问题转化为了小规模的同质问题。如果按照区间长度从小到大的顺序递推，你可以在 $O(n^2)$ 的时间复杂度内计算出 $s(1,2n+1)$，并根据 $s(1,2n+1)$ 的正负性判断谁必胜。\n上面的过程本质上是一个动态规划 (dynamic programming)，如果你没有完全看懂也不要紧 (毕竟还没学)。我们出这道题的根本目的是为了展示一个更妙的想法：\n称 kk 取一个数，ff 再取一个数的两次操作为一轮。考虑每个数在原数列中的下标的奇偶性，我们容易发现：因为任意时刻剩余的数列一定是原数列的一个连续的子区间，所以每一轮开始时，剩余的数列在原数列中的位置一定是 “奇偶奇偶……” 或者 “偶奇偶奇……”。此时 kk 有着挑选奇偶的权利：如果 kk 拿走奇数位置的数，那么 ff 只能从两个偶数位置的数里选一个，反之亦然。\n因为每一轮 kk 都有挑选奇偶的权利，所以 kk 有能力拿走原数列中所有奇数位置的数，或者原数列中所有偶数位置的数。而“所有奇数位置的数的和”与“所有偶数位置的数的和”必定有一个更大，所以 kk 一定能把大的那组拿走，把小的留给 ff。所以这个游戏 kk 必胜。\n这道题旨在展示：通过充分动脑筋，一个看似复杂的问题可以解得非常简单。\n","date":1680825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680825600,"objectID":"a93e434823c989e2a9c2daa6d695afb8","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-2-a/","publishdate":"2023-04-07T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-2-a/","section":"courses","summary":"题意概述\n给定一个长度为 $2n$ 的数列，保证所有数的和是奇数。两个人轮流取数，每次只能取数列的第一个或最后一个数。问双方都采取最优策略的情况下谁能获得胜利。\n为了说明这道题目的合理性，我们介绍策梅洛定理 (以下是摘自 Wikipedia 的解释)：\nIn game theory, Zermelo\u0026rsquo;s theorem is a theorem about finite two-person games of perfect information in which the players move alternately and in which chance does not affect the decision making process.","tags":null,"title":"【问题求解II-HW2.A】取数游戏","type":"docs"},{"authors":null,"categories":null,"content":" 题意概述\n给定一个 $n\\times m$ 的棋盘和象棋棋子马的初始位置，问经过 $k$ 步到达棋盘上任意点的方案数。\n$n,m\\leq 15, k\\leq 10^5$。\n邻接矩阵是描述图的一种常见方法：$\\text{ga}(i,j)=1$ 当且仅当图中点 $i,j$ 之间有边。它之所以被称为“矩阵”，是因为矩阵的乘法恰好可以用于描述图上的游走。\n令 $A_k$ 为一个 $n$ 阶矩阵，其中 $A_k(i,j)$ 表示从点 $i$ 走 $k$ 步到点 $j$ 的方案数，那么我们可以发现 $A_0=I,A_1=\\text{ga}$。更一般地，我们可以发现\n$$ \\forall p, q. A_{p+q}=A_p\\cdot A_q $$\nProof: 考虑任意点对 $i,j$，从 $i$ 走 $p+q$ 步到 $j$ 可以被分解成两个阶段：\n从 $i$ 走 $p$ 步到某一个节点 $k$。 从 $k$ 走 $q$ 步到 $j$。 因此我们可以枚举这个中间节点 $k$，再根据加法/乘法原理有如下递推式： $$ A_{p+q}(i,j)=\\sum_{k=1}^n A_p(i,k)\\cdot A_q(k,j) $$\n容易发现这恰好是矩阵乘法的计算公式，从而原命题得证。$\\square$\n因此，$A_k=\\text{ga}^k$。至于如何将原问题转化为一个图上的游走问题，想必你能够自己解决。\n","date":1680134400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680134400,"objectID":"a13e8da39233c7e39f2077c59ec17861","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/2-1-c/","publishdate":"2023-03-30T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/2-1-c/","section":"courses","summary":"题意概述\n给定一个 $n\\times m$ 的棋盘和象棋棋子马的初始位置，问经过 $k$ 步到达棋盘上任意点的方案数。\n$n,m\\leq 15, k\\leq 10^5$。\n邻接矩阵是描述图的一种常见方法：$\\text{ga}(i,j)=1$ 当且仅当图中点 $i,j$ 之间有边。它之所以被称为“矩阵”，是因为矩阵的乘法恰好可以用于描述图上的游走。\n令 $A_k$ 为一个 $n$ 阶矩阵，其中 $A_k(i,j)$ 表示从点 $i$ 走 $k$ 步到点 $j$ 的方案数，那么我们可以发现 $A_0=I,A_1=\\text{ga}$。更一般地，我们可以发现","tags":null,"title":"【问题求解II-HW1.C】新马走日","type":"docs"},{"authors":null,"categories":null,"content":"如何论证你写的程序是正确的？这是一个历史悠久且难以回答的问题。通常来说有两种思路：\nVerification: 形式化验证简单来说是通过数学手段证明你的程序的行为符合预期。这是对程序正确性的强而有力的证明，但通常非常困难、局限性很大、scalability 较差，因此更多用于对于安全/可靠性要求非常严苛的场景，如自动驾驶，火星车等。问题求解一中提到的“通过 loop invariant 证明循环正确性”可以认为是 verification 的一种非常简单的形式。由于 verificaton 需要大量的程序语言(PL)/形式化方法(FM)的背景知识，且对于简单算法问题来说颇有大材小用之嫌，故在这里不作赘述。 Testing: 测试是更加常用的检查程序是否有漏洞的方法，其核心思想是构造大量的输入并检查目标程序在这些输入上的输出是否符合预期。测试有着天然的局限性：它只能证明你的程序有 bug，但无法证明你的程序没有 bug (OJ 的本质也是测试，因此在 OJ 上通过的程序并不一定是对的 而且由于助教太懒数据太水很可能确实是错的)。不过我们总可以认为，如果我们构造的输入足够多且足够丰富，那么通过了所有测试的程序的可靠性相对会很高。 这里我们介绍一种简单易行的测试技术：differential testing (如果你曾经参加过算法竞赛，“对拍”的本质就是 DiffTest)。DiffTest 的核心思想是针对同一个问题完成两份不同的实现，然后构造大量的输入喂给两份实现观察它们的输出是否相同 (就像你每天早晨和同桌对作业答案，虽然你们都不能保证自己做的是对的，但做错且错得一样的概率毕竟很小，如果你们的解题思路不一样就更小了)。为了避免过于空洞，我们以“计算Fibonacci第n项”这个问题为例说明如何在 OJ 算法题上进行 DiffTest。\n假设你已经写好了一个使用矩阵快速幂优化 Fibonacci 计算的程序 fib.cpp，现在希望对其进行测试。我们很容易写一个朴素版的 fib_bruteforce.cpp 来实现同样的功能 (虽然它能处理的 $n$ 规模较小)：\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int MOD = 998244353; int main () { int n, f0 = 0, f1 = 1, f2; cin \u0026gt;\u0026gt; n; for (int i = 2; i \u0026lt;= n; i++) { f2 = (f0 + f1) % MOD; f0 = f1; f1 = f2; } printf(\u0026quot;%d\\n\u0026quot;, f2); return 0; } 根据我们的预期，对于任意 $n$，如果 fib.cpp 和 fib_bruteforce.cpp 都给出了答案，那么答案应该是相同的。这个问题的好处在于测试数据形式非常简单：只有一个数。因此我们很容易写出一个数据生成程序 gen_data.cpp (注意我们的朴素版本无法处理过大的 $n$)：\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main () { int limit = 10000000; mt19937 mt(time(nullptr)); cout \u0026lt;\u0026lt; mt() % limit + 1 \u0026lt;\u0026lt; endl; return 0; } mt19937 class 是一个非常高效的伪随机数生成器。你也可以使用 rand() 等其他函数来生成随机数 (注意设置随机种子，否则可能每次生成的随机数都一样)。\n有了两份实现和一个数据生成器，接下来的任务就是写一个脚本来做如下循环：\nwhile True { DataGenerator \u0026gt;\u0026gt; data data \u0026gt;\u0026gt; Program1 \u0026gt;\u0026gt; output1 data \u0026gt;\u0026gt; Program2 \u0026gt;\u0026gt; output2 compare output1 and output2 } 如果你会在 Windows 下写 Batch/Powershell 脚本，你应该可以给出一个上述伪代码的轻巧实现；如果你使用类 Unix 系统，你大概率也可以给出一个 bash 脚本。如果你啥也不会，可以考虑使用下面给出的这份 Python 程序进行测试。\n一份 Difftest Python 实现 [Click to expand] \u0026quot;\u0026quot;\u0026quot; usage: difftest.py [-h] --impl IMPL IMPL --gen GEN [--num NUM] [--time TIME] optional arguments: -h, --help show this help message and exit --impl IMPL IMPL two source code files --gen GEN data generator, cpp or python --num NUM number of tests --time TIME time limit for each test, in seconds \u0026quot;\u0026quot;\u0026quot; import os, subprocess import atexit objs = [] def compile(*progs): for prog in progs: assert os.path.exists(prog), f\u0026quot;{prog} not exist\u0026quot; if prog.endswith(\u0026quot;.cpp\u0026quot;): obj = f\u0026quot;obj-{prog}\u0026quot; objs.append(obj) p = subprocess.run(f\u0026quot;g++ -o {obj} {prog} -O2\u0026quot;, shell=True) assert p.returncode == 0, f\u0026quot;{prog} failed to be compiled, make sure that g++ is in your enviroment path\u0026quot; def destructor(): for obj in objs: if os.path.exists(obj): os.remove(obj) def run(prog: str, tl: float, data: str): cmd = f\u0026quot;./obj-{prog}\u0026quot; if prog.endswith(\u0026quot;.cpp\u0026quot;) else f\u0026quot;python3 {prog}\u0026quot; p = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE) try: stdout, _ = p.communicate(input=data.encode(), timeout=tl) except subprocess.TimeoutExpired: p.kill() raise Exception(f\u0026quot;{prog} exceed {tl}s time limit\u0026quot;) return stdout.decode() def dump(data, o1, o2): with open(\u0026quot;input\u0026quot;, \u0026quot;w\u0026quot;) as f: f.write(data) with open(\u0026quot;output1\u0026quot;, \u0026quot;w\u0026quot;) as f: f.write(o1) with open(\u0026quot;output2\u0026quot;, \u0026quot;w\u0026quot;) as f: f.write(o2) def cmp(data, o1, o2): t1, t2 = o1.strip().split(\u0026quot;\\n\u0026quot;), o2.strip().split(\u0026quot;\\n\u0026quot;) if len(t1) != len(t2): dump(data, o1, o2) return False for line1, line2 in zip(t1, t2): if line1.strip() != line2.strip(): dump(data, o1, o2) return False return True if __name__ == \u0026quot;__main__\u0026quot;: import argparse parser = argparse.ArgumentParser() parser.add_argument(\u0026quot;--impl\u0026quot;, nargs=2, required=True, help=\u0026quot;two source code files\u0026quot;) parser.add_argument(\u0026quot;--gen\u0026quot;, type=str, required=True, help=\u0026quot;data generator, cpp or python\u0026quot;) parser.add_argument(\u0026quot;--num\u0026quot;, type=int, default=100, help=\u0026quot;number of tests\u0026quot;) parser.add_argument(\u0026quot;--time\u0026quot;, type=float, default=5.0, help=\u0026quot;time limit for each test, in seconds\u0026quot;) args = parser.parse_args() atexit.register(destructor) compile(args.impl[0], args.impl[1], args.gen) for i in range(args.num): data = run(args.gen, args.time, \u0026quot;\u0026quot;) res1 = run(args.impl[0], args.time, data) res2 = run(args.impl[1], args.time, data) assert cmp(data, res1, res2), \u0026quot;Wrong answer, input/output files dumped\u0026quot; print(f\u0026quot;Test {i+1} OK!\u0026quot;) DiffTest 显然比自己出数据，运行程序，再手动验证结果要高效得多。用正确的工具和方法做事能让你事半功倍。\n","date":1679961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679961600,"objectID":"168ea62655884b644312eeb673a8cf22","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/coding/difftest/","publishdate":"2023-03-28T00:00:00Z","relpermalink":"/courses/problemsolving22/coding/difftest/","section":"courses","summary":"如何论证你写的程序是正确的？这是一个历史悠久且难以回答的问题。通常来说有两种思路：\nVerification: 形式化验证简单来说是通过数学手段证明你的程序的行为符合预期。这是对程序正确性的强而有力的证明，但通常非常困难、局限性很大、scalability 较差，因此更多用于对于安全/可靠性要求非常严苛的场景，如自动驾驶，火星车等。问题求解一中提到的“通过 loop invariant 证明循环正确性”可以认为是 verification 的一种非常简单的形式。由于 verificaton 需要大量的程序语言(PL)/形式化方法(FM)的背景知识，且对于简单算法问题来说颇有大材小用之嫌，故在这里不作赘述。 Testing: 测试是更加常用的检查程序是否有漏洞的方法，其核心思想是构造大量的输入并检查目标程序在这些输入上的输出是否符合预期。测试有着天然的局限性：它只能证明你的程序有 bug，但无法证明你的程序没有 bug (OJ 的本质也是测试，因此在 OJ 上通过的程序并不一定是对的 而且由于助教太懒数据太水很可能确实是错的)。不过我们总可以认为，如果我们构造的输入足够多且足够丰富，那么通过了所有测试的程序的可靠性相对会很高。 这里我们介绍一种简单易行的测试技术：differential testing (如果你曾经参加过算法竞赛，“对拍”的本质就是 DiffTest)。DiffTest 的核心思想是针对同一个问题完成两份不同的实现，然后构造大量的输入喂给两份实现观察它们的输出是否相同 (就像你每天早晨和同桌对作业答案，虽然你们都不能保证自己做的是对的，但做错且错得一样的概率毕竟很小，如果你们的解题思路不一样就更小了)。为了避免过于空洞，我们以“计算Fibonacci第n项”这个问题为例说明如何在 OJ 算法题上进行 DiffTest。\n假设你已经写好了一个使用矩阵快速幂优化 Fibonacci 计算的程序 fib.","tags":null,"title":"Differential Testing","type":"docs"},{"authors":null,"categories":null,"content":"不少同学被OJ的取模问题折磨得心力憔悴——不论多么仔细地检查每一处四则运算，总会有一处漏网之鱼让程序输出错误的结果。这里我们展示一种比较优雅的代码书写方式：\nconst int MOD = 998244353; int add(int x, int y) { x += y; if (x \u0026gt;= MOD) x -= MOD; return x;} int sub(int x, int y) { x -= y; if (x \u0026lt; 0) x += MOD; return x; } int mul(int x, int y) { return 1ll * x * y % MOD; } void Add(int \u0026amp;x, int y) { x = add(x, y); } void Sub(int \u0026amp;x, int y) { x = sub(x, y); } void Mul(int \u0026amp;x, int y) { x = mul(x, y); } 这里我们定义了 MOD 这个变量以及 6 个函数统一完成加法、减法和乘法的取模操作。这样后续程序中的任何运算都可以调用这几个函数来实现：\nc = sub(a, b); // instead of c = (a - b) % MOD; Add(c, d); // instead of c += d %= MOD; Mul(a_very_very_long_variable_name, c); // instead of a_very_very_long_variable_name = 1ll * a_very_very_long_variable_name * c % MOD; 使用统一的取模函数和 MOD 变量有包括但不限于以下好处：\n正确性: 你只需要仔细地书写这几个取模函数，后面的程序中你只要保证不出现 + - *，就不会发生“漏了取模”的悲剧。 简洁性: 在上述的的第三个例子中可以看出使用取模函数可以避免重复书写长变量名，使代码更加简洁。 可维护性: 假设某一天我们通知需要将模数紧急换成 1000000007，相比较将程序中散落在各处的 998244353 修改掉，如果你定义了 MOD 变量，你只需要修改一处。 性能: 你也许注意到了我们在加法和减法中使用了 “if 判断 + 加减”的方式代替了取模，你可以证明只要传入的参数在 [0, MOD) 范围内，该写法的正确性的可以保证的。在计算机底层实现中，进行一次取模操作的代价显著高于简单判断和加减，这样的写法有助于提升效率 (有时候这种提升是惊人的！)。 我们承认取模这件事情在工程开发中可能并不常见，但这样的程序设计却体现了软件工程的通用思想：\n将需要频繁使用的常量定义成宏/constexpr。 将容易出错的功能单独封装成函数，之后调用接口解决问题。 程序设计优化是一件“绝知此事要躬行”的事情。阅读一遍这篇文章大抵不会对你的思想产生重大的影响：你也许会认为这些是多此一举，或者你对自己写代码时的仔细程度非常自信。你只有经历了现实的捶打，经历了熬夜通宵的折磨，才会深刻地意识到人类永远无法克服基因决定的共同弱点，才会理解这些文字背后是前人的智慧和血的教训。\n笔者在高中时曾参加一项极其重要的编程比赛。他针对一道难题推导出了一个极其复杂的数学公式并编码实现了它，但在比赛结束前的 5 分钟他发现自己的程序处处漏了取模——他永远不会忘记在手指被汗水浸湿以至于键盘打滑的情况下狂按 ctrl+F, ctrl+C, ctrl+V 是怎样的紧张和绝望，也不会忘记最终也没有把取模问题解决完，因为这样一个小细节与自己想要的结果失之交臂的痛苦。从那之后，他再也没有犯过低级的漏取模错误。\n我不期望你看完这段话就真的能听进去 (因为这也是人类刻在基因里的弱点之一)，但我衷心希望你为之付出的代价能比我小一些。\n","date":1679443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679443200,"objectID":"8a5544446b554a3a6f7ed6ff4bac3409","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/coding/modulation/","publishdate":"2023-03-22T00:00:00Z","relpermalink":"/courses/problemsolving22/coding/modulation/","section":"courses","summary":"不少同学被OJ的取模问题折磨得心力憔悴——不论多么仔细地检查每一处四则运算，总会有一处漏网之鱼让程序输出错误的结果。这里我们展示一种比较优雅的代码书写方式：\nconst int MOD = 998244353; int add(int x, int y) { x += y; if (x \u0026gt;= MOD) x -= MOD; return x;} int sub(int x, int y) { x -= y; if (x \u0026lt; 0) x += MOD; return x; } int mul(int x, int y) { return 1ll * x * y % MOD; } void Add(int \u0026amp;x, int y) { x = add(x, y); } void Sub(int \u0026amp;x, int y) { x = sub(x, y); } void Mul(int \u0026amp;x, int y) { x = mul(x, y); } 这里我们定义了 MOD 这个变量以及 6 个函数统一完成加法、减法和乘法的取模操作。这样后续程序中的任何运算都可以调用这几个函数来实现：","tags":null,"title":"优雅地取模","type":"docs"},{"authors":null,"categories":null,"content":"按照线性代数中的矩阵乘法规则，常见的矩阵乘法写法如下：\nfor (int i = 1; i \u0026lt;= n; i++) for (int j = 1; j \u0026lt;= n; j++) for (int k = 1; k \u0026lt;= n; k++) c[i][j] += a[i][k] * b[k][j] 但是我们强烈建议你调整循环的顺序，按照如下方式书写矩阵乘法：\nfor (int i = 1; i \u0026lt;= n; i++) for (int k = 1; k \u0026lt;= n; k++) for (int j = 1; j \u0026lt;= n; j++) c[i][j] += a[i][k] * b[k][j] 虽然这样有点“反直觉”，但在稍大规模的数据下运行时，你会发现这种写法的效率比前者高很多。理解效率提高的原因需要对计算机体系结构和 C/C++ 语言中数组在内存中的存储有一定的了解，这里不作赘述。你可以暂且将其背下来 😂\n为了更优雅地实现矩阵快速幂，我们还强烈建议你学习 C++ Class 相关的内容并了解操作符重载。这样你可以自己定义矩阵类并为矩阵类书写乘法规则，从而直接复用“快速幂”一讲中的代码计算矩阵快速幂。下面给出一个参考实现：\nclass Matrix { int b[10][10]; Matrix () { memset(b, 0, sizeof(b)); } void init_I() { for (int i = 1; i \u0026lt;= n; i++) b[i][i] = 1; } Matrix operator * (Matrix other) { Matrix res; for (int i = 1; i \u0026lt;= n; i++) for (int k = 1; k \u0026lt;= n; k++) for (int j = 1; j \u0026lt;= n; j++) res.b[i][j] += b[i][k] * other.b[k][j]; return res; } }; Matrix quick_pow(Matrix x, int y) { T res; res.init_I(); while (y) { if (y \u0026amp; 1) res = res * x; x = x * x; y \u0026gt;\u0026gt;= 1; } return res; } ","date":1679443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679443200,"objectID":"add2b1461c94bca5cb2465fa9692ba01","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/coding/matmul/","publishdate":"2023-03-22T00:00:00Z","relpermalink":"/courses/problemsolving22/coding/matmul/","section":"courses","summary":"按照线性代数中的矩阵乘法规则，常见的矩阵乘法写法如下：\nfor (int i = 1; i \u0026lt;= n; i++) for (int j = 1; j \u0026lt;= n; j++) for (int k = 1; k \u0026lt;= n; k++) c[i][j] += a[i][k] * b[k][j] 但是我们强烈建议你调整循环的顺序，按照如下方式书写矩阵乘法：","tags":null,"title":"矩阵快速幂","type":"docs"},{"authors":null,"categories":["Theoretical Computer Science"],"content":" Getting Started: Fibonacci A Variation of Fibonacci When It Comes to Higher Orders… An “Eigendecomposition” Approach Fibonacci: Review I Cayley-Hamilton Theorem The Characteristic Polynomial For Homogeneous Linear Recurrence Matrices Magical Decomposition Summary \u0026amp; Complexity Analysis A “Generatingfunctionology” Approach Fibonacci: Review II Generating Function Equation for General Linear Recurrences An Even-Odd Separation Idea Summary \u0026amp; Complexity Analysis Conclusion \u0026amp; Misc References The post focuses on solving homogeneous linear recurrences quickly with the aid of computers. Specifically, we are interested in figuring out the $n$-th term of sequences with the following recurrence formula:\n$$ f_n=\\sum_{k=1}^m c_kf_{n-k} $$\nSince the answer may be too large, we usually focus on $f\u0026rsquo;_n=f_n\\mod M$. We are more interested in cases where $M$ is suitable for FFT, such as $998,244,353$, because polynomial-related techniques can be leveraged to accelerate the computation. In the whole passage, we will use $f_n$ (instead of $f\u0026rsquo;_n$) to represent the answer under modulation for simplicity.\nGetting Started: Fibonacci Let’s start with one of the simplest (and most famous) sequences: Fibonacci.\n$$ F_n=\\begin{cases}0\u0026amp;, n=1\\\\1\u0026amp;, n=2\\\\F_{n-1}+F_{n-2}\u0026amp;, n\\geq 2\\end{cases} $$\nComputing $F_n$ in $O(n)$ time complexity is trivial. But when $n$ is extremely large, say, $\\geq 10^9$, it’s hard for general computers to get the answer within seconds. One of the most common approaches to solving such problems is using matrices.\nMatrices are good at describing linear relationships, and the recurrence formula of Fibonacci happens to be linear. Therefore we can rewrite it in matrix language:\n$$ \\begin{pmatrix}0 \u0026amp; 1\\\\1 \u0026amp; 1\\end{pmatrix}\\begin{pmatrix}F_{n-1}\\\\F_n\\end{pmatrix}=\\begin{pmatrix}0\\cdot F_{n-1}+1\\cdot F_n\\\\1\\cdot F_{n-1}+1\\cdot F_n\\end{pmatrix}=\\begin{pmatrix}F_n\\\\F_{n+1}\\end{pmatrix} $$\n$\\begin{pmatrix}0 \u0026amp; 1\\\\1 \u0026amp; 1\\end{pmatrix}$is a good matrix for “pushing” the computation of $F_n$ by 1. Although this seems trivial, when we repeatedly use the matrix to push forward our computation, things become interesting:\n$$ \\begin{pmatrix}F_n\\\\F_{n+1}\\end{pmatrix}=\\begin{pmatrix}0 \u0026amp; 1\\\\1 \u0026amp; 1\\end{pmatrix}\\cdots\\left(\\begin{pmatrix}0 \u0026amp; 1\\\\1 \u0026amp; 1\\end{pmatrix}\\left(\\begin{pmatrix}0 \u0026amp; 1\\\\1 \u0026amp; 1\\end{pmatrix}\\begin{pmatrix}F_0\\\\F_1\\end{pmatrix}\\right)\\right) $$\nThanks to the associativity of matrix multiplication, we can neatly rewrite the expression as\n$$ \\begin{pmatrix}F_n\\\\F_{n+1}\\end{pmatrix}=\\begin{pmatrix}0 \u0026amp; 1\\\\1 \u0026amp; 1\\end{pmatrix}^n\\begin{pmatrix}F_0\\\\F_1\\end{pmatrix} $$\nSo far, we have not simplified the computation of $F_n$, and matrix multiplications even place more burden on the computer. However, we have powerful techniques to deal with exponents: repeated squaring, i.e., denote the transformation matrix as $M$, we first compute $M^2$, then compute $M^4$ by taking the square of $M^2$, and so on. In this way, we can compute $\\begin{pmatrix}0 \u0026amp; 1\\\\1 \u0026amp; 1\\end{pmatrix}^n$in $O(\\log n)$ complexity, and finally by applying it to the initial vector $\\begin{pmatrix}F_0\\\\F_1\\end{pmatrix}$we’ll get $F_n$.\nIf you’re an experienced math learner, you must have known several ways to directly compute the general term formula of the Fibonacci sequence and may complain about this “stupid” matrix approach. However, the general term formula containing irrational coefficients is unfriendly for numerical computations. I’m not saying that those approaches are useless - instead, in the following sections we’ll come back to the basic Fibonacci example again and again and see how advanced math gives insights into efficient algorithm design.\nA Variation of Fibonacci Before delving deeper into the problem, let\u0026rsquo;s consider a slightly varied version of the Fibonacci sequence:\n$$ F_n=\\begin{cases}0\u0026amp;, n=1\\\\1\u0026amp;, n=2\\\\F_{n-1}+F_{n-2}+n\u0026amp;, n\\geq 2\\end{cases} $$\nRigorously, this is not a homogeneous linear recurrence, but we list it here because it’s a nice example of designing transformation matrices. The only difference is the additional $+n$ when $n\\geq 2$, but it seems much more challenging because we cannot represent $n$ as the linear combination of $F_{n-1}$ and $F_{n-2}$.\nA general insight is that we can include more terms in the “state vector” ( in the standard Fibonacci sequence it’s $\\begin{pmatrix}F_{n} \u0026amp; F_{n+1}\\end{pmatrix}$). Apart from necessary terms in the sequence, we can add “helper terms” to help us find the linear combinations of wanted expressions. Let’s try adding $n$ into the state vector:\n$$ \\begin{pmatrix}F_{n-2}\\\\F_{n-1}\\\\n\\end{pmatrix}\\overset{which\\ matrix?}{\\Longrightarrow}\\begin{pmatrix}F_{n-1}\\\\F_{n}\\\\n+1\\end{pmatrix} $$\nUnfortunately, getting $n+1$ from $n$ is impossible because we have nobody to borrow the “1” from - but why don’t we add constant 1 into our state vector as well?\n$$ \\begin{pmatrix}0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0\\\\1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 1\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1\\end{pmatrix}\\begin{pmatrix}F_{n-2}\\\\F_{n-1}\\\\n\\\\1\\end{pmatrix}=\\begin{pmatrix}F_{n-1}\\\\F_n\\\\n+1\\\\1\\end{pmatrix} $$\nOnce we have the transformation matrix of a sequence, the rest is simple: do matrix multiplications by repeated squaring. To solve this Fibonacci variation, we need a matrix with rank 4, even if it\u0026rsquo;s a second-order recurrence. There\u0026rsquo;s no fixed procedure for devising such a matrix - in some subtle cases, a little human wisdom is necessary.\nWhen It Comes to Higher Orders… The examples shown above are all constant-order recurrences. In the Fibonacci example, we claim that the time complexity is $O(\\log n)$ because the influence from the rank is negligible. However, if we’re confronted with recurrences with higher orders, say $k$, the time complexity of the matrix approach should be $O(k^3\\log n)$ (we don’t take into account algorithms like Strassen’s multiplication because they often come with huge constants), which is prohibitively high even if $k$ is only a few thousand.\nThe journey has just begun! The following sections introduce 2 directions for optimization: one is related to the characteristic polynomial of matrices, and the other leverages generating functions to tackle the issue.\nAn “Eigendecomposition” Approach Fibonacci: Review I A common approach to optimizing matrix powering is eigendecomposition, i.e., for a matrix $M$ with rank $n$, if $M$ has $n$ independent eigenvectors, then $M$ is diagonalizable: $M=S\\Lambda S^{-1}$, where $\\Lambda$ is a diagonal matrix consisting of eigenvalues and $S$ is a matrix consisting of (column) eigenvectors. With this diagonalized form, powering becomes super easy: $M^n=(S\\Lambda S^{-1})^n=S\\Lambda^nS^{-1}$.\nCome back to the Fibonacci example, the only thing left is to compute the eigenvalues of the transformation matrix. For $2\\times 2$ matrices, solving the following quadratic characteristic equation is simple:\n$$ M=\\begin{pmatrix}0\u0026amp;1\\\\1\u0026amp;1\\end{pmatrix}\\qquad\\qquad \\begin{align*}f(\\lambda)\u0026amp;=\\det(M-\\lambda I)=0\\\\\u0026amp;\\Longrightarrow\\lambda_{1,2}=\\frac{1\\pm\\sqrt 5}{2},\\mathbf{x}=\\begin{pmatrix} \\lambda\\\\1\\end{pmatrix}\\end{align*} $$\nTherefore,\n$$ \\begin{align*}\\begin{pmatrix}F_n\\\\F_{n+1}\\end{pmatrix}\u0026amp;=\\begin{pmatrix}0\u0026amp;1\\\\1\u0026amp;1\\end{pmatrix}^n\\begin{pmatrix}F_0\\\\F_1\\end{pmatrix}\\\\\u0026amp;=\\left[\\begin{pmatrix}\\mathbf{x}_1\u0026amp;\\mathbf{x}_2\\end{pmatrix}\\begin{pmatrix}\\lambda_1 \u0026amp; \\\\\u0026amp;\\lambda_2\\end{pmatrix}\\begin{pmatrix}\\mathbf{x}_1\u0026amp;\\mathbf{x}_2\\end{pmatrix}^{-1}\\right]^n\\begin{pmatrix}F_0\\\\F_1\\end{pmatrix}\\\\\u0026amp;=\\begin{pmatrix}\\mathbf{x}_1\u0026amp;\\mathbf{x}_2\\end{pmatrix}\\begin{pmatrix}\\lambda_1^n\u0026amp;\\\\\u0026amp;\\lambda_2^n\\end{pmatrix}\\begin{pmatrix}\\mathbf{x}_1\u0026amp;\\mathbf{x}_2\\end{pmatrix}^{-1}\\begin{pmatrix}F_0\\\\F_1\\end{pmatrix}\\end{align*} $$\nCayley-Hamilton Theorem Unfortunately, when it comes to transformation matrices with arbitrary rank, it’s difficult to solve high-order characteristic equations and irrational eigenvalues are hard for numerical computations. However, the general idea still works: we should find nice properties related to characteristic polynomials and try to do decomposition.\nWe introduce the Cayley-Hamilton theorem, which describes an interesting property of square matrices.\n$\\fbox{Theorem}$ (Cayley-Hamilton)\nIn linear algebra, the Cayley-Hamilton theorem states that every square matrix over a commutative ring satisfies its own characteristic equation, i.e., denote $f(\\lambda)=\\det(\\lambda I-A)$ as the characteristic polynomial of $A$, then $f(A)=O$.\nBeginners may regard this theorem as trivial by the observation that $\\det(AI-A)=0$. However, this “bogus proof” is totally ungrounded because $f(A)$ is a matrix, not a scalar. Since it’s not a rigorous math post, we’ll not prove this theorem in a detailed manner from scratch. Instead, we give the following lemma without proof:\n$\\fbox{Lemma}$ Diagonalizable matrices are dense in the space of all matrices.\nProof of Cayley-Hamilton theorem\nWe start with diagonalizable matrices. For an arbitrary diagonalizable matrix $A$ with rank $n$, it has $n$ independent eigenvectors satisfying $A\\mathbf{x_i}=\\lambda_i\\mathbf{x_i}$. Consider $f(A)\\mathbf{x_i}$, suppose $f(\\lambda)$ is a polynomial with coefficient $c_i$ for term $\\lambda^i$, then\n$$ \\begin{align*}f(A)\\mathbf{x_i}\u0026amp;=\\left(\\sum_{k=0}^nc_kA^k\\right)\\mathbf{x_i}=\\sum_{k=0}^nc_k(A^k\\mathbf{x_i})\\\\\u0026amp;=\\sum_{k=0}^nc_k(\\lambda_i^k\\mathbf{x_i})\\\\\u0026amp;=\\left(\\sum_{k=0}^nc_k\\lambda_i^k\\right)\\mathbf{x_i}\\\\\u0026amp;=f(\\lambda_i)\\mathbf{x_i}=\\mathbf{0}\\end{align*} $$\nTherefore, for each eigenvector $\\mathbf{x_i}$, $f(A)\\mathbf{x_i}=\\mathbf{0}$. By combining eigenvectors to a matrix $S=\\begin{pmatrix}\\mathbf{x_1}\u0026amp;\\cdots\u0026amp;\\mathbf{x_n}\\end{pmatrix}$, we have $f(A)S=O$. Since $S$ is a full-rank matrix, the only possibility is that $f(A)=O$.\nNow let’s move to non-diagonalizable matrices, denoted as $D$. According to the density of diagonalizable matrices in the whole matrix space, there exists a matrix $H$ such that a cluster of matrices $D_t=D+tH$, $t\\in (-1, 0)\\cup (0, 1)$, are diagonalizable. Since $D_t$ is continuous on $t$, $f_{D_t}(D_t)$ is also continuous on $t$, therefore\n$$ f(D)=\\lim_{t\\to 0}f_{D_t}(D_t)=O $$\nThe Characteristic Polynomial For Homogeneous Linear Recurrence Matrices For homogeneous linear recurrence transformation matrices, characteristic polynomial $f$ is easy to compute: according to the recurrence formula, we have\n$$ A=\\begin{pmatrix}0\u0026amp; 1\\\\\u0026amp; \u0026amp; 1\\\\\u0026amp; \u0026amp; \u0026amp; \\ddots\\\\\u0026amp; \u0026amp; \u0026amp; \u0026amp; 1\\\\c_1 \u0026amp; c_2 \u0026amp; c_3 \u0026amp; \\cdots \u0026amp; c_k\\end{pmatrix} $$\nThen\n$$ f(\\lambda)=\\det(\\lambda I-A)=\\begin{vmatrix}\\lambda \u0026amp; -1\\\\\u0026amp; \\lambda \u0026amp; -1\\\\\u0026amp; \u0026amp; \\ddots\u0026amp; \\ddots\\\\\u0026amp; \u0026amp; \u0026amp; \\lambda \u0026amp; -1\\\\-c_1 \u0026amp; -c_2 \u0026amp; -c_3\u0026amp;\\cdots\u0026amp;\\lambda-c_k\\end{vmatrix} $$\nExpanding the determinant by the last row, we’ll observe that every minor is easy to compute: $A_{k,i}=(-1)^{k-i}\\lambda^{i-1}$. Therefore\n$$ \\begin{align*}f(\\lambda)\u0026amp;=(-1)^{2k}(\\lambda-c_k)\\lambda^{k-1}+\\sum_{i=1}^{k-1}(-1)^{k+i}\\cdot ((-1)^{k-i}\\lambda^{i-1})\\cdot (-c_i)\\\\\u0026amp;=\\lambda^k-\\sum_{i=1}^kc_i\\lambda^{i-1}\\end{align*} $$\nMagical Decomposition It’s still unclear how Cayley-Hamilton theorem can help in optimization. The following approach was proposed by Fiduccia in 1985 [2]. For an arbitrary transformation matrix $A$ with rank $k$, consider the following decomposition:\n$$ x^n=f(x)g(x)+r(x) $$\nwhere $f$ is the characteristic polynomial of $A$ and $g(x)/r(x)$ can be computed through polynomial division/modulation. In fact, we are more interested in $r(x)$ because when we let $x=A$:\n$$ A^n=f(A)g(A)+r(A)\\overset{\\text{Cayley-Hamilton}}{=}r(A) $$\nIt seems that we haven’t made solid progress because $r$ is a $k$-order polynomial and computing $r(A)$ by brute force requires $O(k^4)$ effort. However, suppose $\\displaystyle r(x)=\\sum_{i=0}^{k-1}c_ix^i$, actually we’re able to compute $F_n$ in $O(k)$ thanks to the following deduction:\n$$ \\begin{align*}\\begin{pmatrix}F_n\\\\F_{n+1}\\\\\\vdots\\\\F_{n+k-1}\\end{pmatrix}\u0026amp;=A^n\\begin{pmatrix}F_0\\\\F_1\\\\\\vdots\\\\F_{k-1}\\end{pmatrix}=R(A)\\begin{pmatrix}F_0\\\\F_1\\\\\\vdots\\\\F_{k-1}\\end{pmatrix}\\\\\u0026amp;=\\left(\\sum_{i=0}^{k-1}c_iA^i\\right)\\begin{pmatrix}F_0\\\\F_1\\\\\\vdots\\\\F_{k-1}\\end{pmatrix}\\\\\u0026amp;=\\sum_{i=0}^{k-1}c_i\\left(A^i\\begin{pmatrix}F_0\\\\F_1\\\\\\vdots\\\\F_{k-1}\\end{pmatrix}\\right)\\\\\u0026amp;=\\sum_{i=0}^{k-1}c_i\\begin{pmatrix}F_i\\\\F_{i+1}\\\\\\vdots\\\\F_{i+k-1}\\end{pmatrix}\\end{align*} $$\nTherefore\n$$ F_n=\\sum_{i=0}^{k-1}c_iF_i $$\nSummary \u0026amp; Complexity Analysis Let’s have a quick summary of the whole procedure and analyze the complexity:\nConstruct a transformation matrix $A$ according to the recurrence formula. Compute the characteristic polynomial $f_A$. Compute $r_A(x)=x^n\\text{ mod }f_A$. Compute $F_n$ according to the coefficients in $r_A$. The main complexity lies in the third step. Since $n$ is extremely large, it’s impossible to directly do polynomial modulation. Instead, we can leverage repeated squaring:\n$$ x\\Rightarrow [x^2]=(x)^2 \\text{ mod }f_A\\Rightarrow [x^4]=[x^2]^2\\text{ mod }f_A\\Rightarrow \\cdots \\Rightarrow x^n\\text{ mod }f_A $$\nIn this way, we need to conduct $O(\\log n)$ times polynomial multiplication and modulation, which gives a $O(k^2\\log n)$ complexity. If the problem is considered in a ring that supports Fast Fourier Transformation (typically an NTT ring), we can further optimize it to $O(k\\log k\\log n)$.\nA “Generatingfunctionology” Approach Fibonacci: Review II Generating function is always a powerful weapon for tackling sequence problems. Consider\n$$ G(x)=\\sum_{n=0}^\\infty F_nx^n $$\nSince $F_n=F_{n-1}+F_{n-2}$ when $n\\geq 2$, we can get\n$$ G(x)=F_0+F_1x+xG(x)+x^2G(x)=x+(x+x^2)G(x) $$\nTherefore $\\displaystyle G(x)=\\frac{x}{1-x-x^2}=\\frac{1}{\\sqrt 5}\\left(\\frac{1}{1-\\phi x}-\\frac{1}{1-\\hat\\phi x}\\right)$, where $\\phi=\\displaystyle \\frac{1+\\sqrt 5}{2}$ and $\\displaystyle \\hat\\phi=\\frac{1-\\sqrt 5}{2}$. Expand it to Taylor series, we have\n$$ \\begin{align*}G(x)\u0026amp;=\\frac{1}{\\sqrt 5}\\left(\\sum_{n\\geq 0}(\\phi x)^n-\\sum_{n\\geq 0}(\\hat\\phi x)^n\\right)\\\\\u0026amp;=\\sum_{n\\geq 0}\\left(\\frac{1}{\\sqrt 5}(\\phi^n-\\hat\\phi^n)\\right)x^n\\end{align*} $$\nThus $\\displaystyle F_n=\\frac{1}{\\sqrt 5}(\\phi^n-\\hat\\phi^n)$.\nGenerating Function Equation for General Linear Recurrences However, when it comes to recurrences with arbitrary order, techniques like Taylor expansion will lose its power for computers. Anyway, let’s figure out the equation first. Put the coefficients of linear recurrence into a generation function, denoted as $G(x)$, i.e.,\n$$ G(x)=\\sum_{i=1}^kc_ix^i $$\nwe have\n$$ F(x)=F(x)G(x)+R(x) $$\nWhere $R(x)$ is a polynomial for correcting the first few terms in the sequence and can be obtained by computing $F\u0026rsquo;(x)-F\u0026rsquo;(x)G(x)$, where $F\u0026rsquo;(x)$ is the first $k$ terms of $F(x)$.\nTherefore\n$$ F(x)=\\frac{R(x)}{1-G(x)} $$\nAn Even-Odd Separation Idea Since $n$ is extremely huge, computing the polynomial inverse of $1-G(x)$ and then computing $[x^n]F(x)$ through polynomial multiplication is unreasonable. We need a quick way to compute\n$$ [x^n]F(x)=[x^n]\\frac{P(x)}{Q(x)} $$\nwhere $P(x)$ and $Q(x)$ stands for $R(x)$ and $1-G(x)$ in this case.\nConsider the following transformation:\n$$ F(x)=\\frac{P(x)}{Q(x)}=\\frac{P(x)Q(-x)}{Q(x)Q(-x)} $$\n$Q(x)Q(-x)$ is an even function. Let $U(x^2)=Q(x)Q(-x)$, and divide $P(x)Q(-x)$ into two parts according to the parity of $x^k$, we have\n$$ F(x)=\\frac{xOdd(x^2)}{U(x^2)}+\\frac{Even(x^2)}{U(x^2)} $$\nThanks to the fact that $U(x^2)$ only contains even powers, $F(x)$ is successfully separated as an odd part and an even part, and we can choose the part containing $x^n$ (according to the parity of $n$) to continue our computation.\nSummary \u0026amp; Complexity Analysis Let’s have a quick summary of the whole procedure and analyze the complexity:\nCompute $R(x)$ and $G(x)$. Compute $P(x)Q(-x)$ and $Q(x)Q(-x)$ respectively. Choose the part with the same parity as $n$. Repeatedly conduct step 2 until the polynomial becomes a constant one. Step 2 contains polynomial multiplications, which requires $O(k^2)$/$O(k\\log k)$ depending on whether FFT is supported. Every time we conduct step 2, the formal variable of the generating functions grow from $x$ to $x^2$. Therefore the power grows exponentially and we can terminate within $O(\\log n)$ iterations. So the overall complexity is $O(k^2\\log n)$/$O(k\\log k\\log n)$.\nIt’s worth noting that although the “generatingfunctionology” approach has the same time complexity as the previous one, it requires simpler polynomial techniques (only multiplication). The paper [3] argues that this approach improves the result of Fiduccia on constant factors.\nConclusion \u0026amp; Misc The post introduces several kinds of techniques for tackling homogeneous linear recurrence problems. Matrix multiplication with repeated squaring optimizes the complexity from the most trivial $O(kn)$ to $O(k^3\\log n)$, and the following 2 approaches leverage linear algebra/generating function to further improve it to $O(k^2\\log n)$/$O(k\\log k\\log n)$. Readers can refer to the papers for deeper understanding.\nI learned most of the techniques mentioned above when I was taking part in competitive programming contests during high school. There was no detailed tutorial on the Internet at that time and the knowledge are spread through word of mouth. I would be most happy if the post can bring the wisdom of TCS researchers to more people in the world.\nReferences [1] Cayley-Hamilton Theorem. Wikipedia. [2] C. M. Fiduccia. An efficient formula for linear recurrences. SIAM Journal on Computing, 14(1):106–112, 1985. [3] Bostan, A., \u0026amp; Mori, R. (2020). A Simple and Fast Algorithm for Computing the N-th Term of a Linearly Recurrent Sequence. ArXiv. ","date":1679097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679097600,"objectID":"a68890da38a7b1b2fbc3c1d7f95155f7","permalink":"https://kristoff-starling.github.io/posts/recurrences/","publishdate":"2023-03-18T00:00:00Z","relpermalink":"/posts/recurrences/","section":"posts","summary":"How to quickly solve homogeneous linear recurrences with the aid of computers :rocket:","tags":null,"title":"Homogeneous Linear Recurrences: An Algorithmic Perspective","type":"posts"},{"authors":null,"categories":null,"content":"给定 $a,n$，考虑如何计算 $a^n$ 。如果使用如下循环计算结果\nint res = 1; for (int i = 1; i \u0026lt;= n; i++) res = res * a; 时间复杂度为 $O(n)$，当 $n$ 很大时效率太低。快速幂是用于计算该类问题的常见算法，其本质思想是递归/倍增:\n$$ a^n=\\begin{cases}1\u0026amp;,n=0\\\\(a^{n/2})^2\u0026amp;,n是偶数, n\\geq 1\\\\(a^{\\lfloor n/2\\rfloor})^2\\cdot a\u0026amp;,n是奇数, n\\geq 1\\end{cases} $$\n因此我们可以通过不断折半幂次的方式来求解 $a^n$。写出该算法的复杂度递归表达式：\n$$ T(n)=T(n/2)+O(1) $$\n容易得出 $T(n)=O(\\log n)$。\n直接根据递归式，我们容易写出如下递归代码:\nint quick_pow(int a, int n) { if (n == 0) return 1; res = quick_pow(a, n / 2); if (n % 2 == 0) return res * res; else return res * res * a; } 但我们通常使用一种更加优美的写法来使用循环替代递归：\nint quick_pow(int a, int n) { int res = 1; while (n) { if (n \u0026amp; 1) res = res * a; a = a * a; n \u0026gt;\u0026gt;= 1; } return res; } 该实现的核心思想是利用 $n$ 的二进制表示中 1 的位置来判断 $a^n$ 是由哪些 $a^{2^k}$ 组合而成的。即如果 $n$ 的二进制表示中在 $k_1,k_2,\\cdots, k_m$ 这些位置上是 1，那么\n$$ a^n=a^{\\sum_{i=1}^m2^{k_i}}=\\prod_{i=1}^ma^{2^{k_i}} $$\n","date":1679097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679097600,"objectID":"5461e8eca254e2e4a7f00318098c9948","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/algorithms/repeatedsquare/","publishdate":"2023-03-18T00:00:00Z","relpermalink":"/courses/problemsolving22/algorithms/repeatedsquare/","section":"courses","summary":"给定 $a,n$，考虑如何计算 $a^n$ 。如果使用如下循环计算结果\nint res = 1; for (int i = 1; i \u0026lt;= n; i++) res = res * a; 时间复杂度为 $O(n)$，当 $n$ 很大时效率太低。快速幂是用于计算该类问题的常见算法，其本质思想是递归/倍增:\n$$ a^n=\\begin{cases}1\u0026amp;,n=0\\\\(a^{n/2})^2\u0026amp;,n是偶数, n\\geq 1\\\\(a^{\\lfloor n/2\\rfloor})^2\\cdot a\u0026amp;,n是奇数, n\\geq 1\\end{cases} $$","tags":null,"title":"快速幂","type":"docs"},{"authors":null,"categories":null,"content":"关于基础理论，参见 这篇博文。如果你之前从未了解过线性递推相关的知识/目前以完成OJ为主要目标，只需看懂该文章的 Getting Started 章节。本文主要对矩阵乘法和矩阵快速幂的实现给出一点建议。\nDon\u0026rsquo;t Panic!\n只有 Problem Solving 目录下的内容才是大家需要且应当掌握的内容。链接中博文的大部分内容与问题求解课程并不相关，且我不认为掌握这些数学强相关的知识对计算机思维有太多提升。因此如果你不愿意读 Getting Started 之后的内容/读不懂后面的内容，这非常正常也无关紧要！\n你可以参考 这篇博文 来学习矩阵快速幂实现的代码细节。\n","date":1679097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679097600,"objectID":"10083c3eb72e99a1167e565504dc9e49","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/algorithms/matmul/","publishdate":"2023-03-18T00:00:00Z","relpermalink":"/courses/problemsolving22/algorithms/matmul/","section":"courses","summary":"关于基础理论，参见 这篇博文。如果你之前从未了解过线性递推相关的知识/目前以完成OJ为主要目标，只需看懂该文章的 Getting Started 章节。本文主要对矩阵乘法和矩阵快速幂的实现给出一点建议。\nDon\u0026rsquo;t Panic!\n只有 Problem Solving 目录下的内容才是大家需要且应当掌握的内容。链接中博文的大部分内容与问题求解课程并不相关，且我不认为掌握这些数学强相关的知识对计算机思维有太多提升。因此如果你不愿意读 Getting Started 之后的内容/读不懂后面的内容，这非常正常也无关紧要！\n你可以参考 这篇博文 来学习矩阵快速幂实现的代码细节。","tags":null,"title":"矩阵快速幂","type":"docs"},{"authors":null,"categories":null,"content":" Problem A: BrainF**k Syntax Checker\n题意概括：给定一个 BF 程序，判断它是否符合语法要求。\nBF 程序中的 + - , . \u0026gt; \u0026lt; 显然不会对程序的合法性造成影响，因此本题的主要任务是判断 BF 程序中的 [ ] 是否形成了合法的括号序列，即两两匹配。\n值得注意的是，BF 程序中 [ 和 ] 的个数相同并不是括号序列合法的充要条件，比如 ][ 这个序列就是不合法的。在此基础上，我们还要保证 BF 程序的任意前缀中，[ 的个数要大于等于 ] 的个数。\nCode [Click to expand] #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; char program[1000]; string ValidChar = \u0026quot;+-,.\u0026lt;\u0026gt;[]\u0026quot;; int main() { scanf(\u0026quot;%s\u0026quot;, program); int len = strlen(program), LeftRightDelta = 0; bool flag = true; for (int i = 0; i \u0026lt; len; i++) { if (ValidChar.find(program[i]) == string::npos) flag = false; if (program[i] == '[') LeftRightDelta++; if (program[i] == ']') LeftRightDelta--; if (LeftRightDelta \u0026lt; 0) flag = false; } puts((flag \u0026amp;\u0026amp; LeftRightDelta == 0) ? \u0026quot;Yes\u0026quot; : \u0026quot;No\u0026quot;); return 0; } Problem B: BrainF**k Interpreter\n题意概括： 给定一个 BF 程序，模拟其运行过程并输出最后的内存状态。\n这是一道相当有意思的题目，解法也很多。该问题的核心难点是如何处理嵌套的中括号。考场上有很多同学利用递归处理中括号的嵌套，这是一个很好且可行的思路。我们在这里介绍另外一种不需要递归的思路，它书写起来更加简洁，且在一定程度上揭示了计算机运行的本质——大家在本学期的 数字逻辑与计算机组成 和下学期的 计算机系统基础 中会不断与这种逻辑打交道。\n在题面的提示中我们已经给出了计算机执行指令的四步骤，我们在这里再重复一遍：\n取指：取出下一条执行的指令。 译码：根据指令的格式确定该指令的类型。 执行：根据指令类型，执行该指令定义的动作。 跳转：根据指令类型和执行过程，确定下一条应当执行的指令的位置。 真正的计算机处理的是“汇编语言”，我们的 BF 解释器处理的是 BF 语言，这两者在本质上没有区别。计算机内部通常有一个程序计数器 (program counter, 简称 pc)，它的功能和计数没什么关系，反而像一个指针，用来指向下一条要执行的指令。我们来具体地看看四个步骤对应到 BF 语言应当如何操作。\n取指：这是最简单的一步，对应到 C++ 代码大概就是 char instruction = program[pc]。\n译码\u0026amp;执行：这两步在 BF 中可以放在一起做 (因为 BF 的所有指令都没有“操作数”)，你大抵会用一个 if/switch 语句来判断 instruction 是 8 个符号中的哪一种并执行相应的操作。前 6 种指令的操作都非常简单，这里不再赘述。[ 和 ] 本质上是分支控制指令，所以在“执行”这个步骤中它们什么也不用做。\n跳转：前 6 种指令的跳转都非常简单：做完了就做紧接着的下一条指令，即 pc++。我们着重讲解 [ 和 ] 的跳转如何处理：\n[：左中括号指令的逻辑是 if (memory[pointer] != 0) pc++ // go into the loop else pc = (the position of the corresponding \u0026quot;]\u0026quot;) + 1 // skip the loop pc 直接加一意味着进入循环，pc 跳转到对应的 ] 的下一条指令意味着跳过循环。 ]：右中括号指令的逻辑是 pc = (the position of the corresponding \u0026quot;[\u0026quot;) 遇到右中括号，无条件跳转到对应的左中括号，开始新一轮循环条件判断。 注意到 [ 和 ] 的处理都依赖与之匹配的“另一半”，因此在正式开始执行程序之前，我们要预处理一遍程序以知道与每个 [/] 配对的 ]/[ 在什么位置。\n按照这四个步骤书写本题的代码，可以完成得轻松且高效，从中你也可以领悟到计算机系统设计的伟大智慧。\nCode [Click to expand] 注：下面参考程序仅仅实现了一个 BF 解释器，输入格式和输出格式与原题并不相同。\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; int memory[1000], pointer; char program[1000]; int n; int input_count, input[1000]; int jumpto[1000], stk[1000], stot; int main () { scanf(\u0026quot;%s\u0026quot;, program); n = strlen(program); scanf(\u0026quot;%d\u0026quot;, \u0026amp;input_count); for (int i = 1; i \u0026lt;= input_count; i++) scanf(\u0026quot;%d\u0026quot;, input + i); // 预处理每个 [ 和 ] 对应的 ]/[ stot = 0; for (int i = 0; i \u0026lt; n; i++) { if (program[i] == '[') stk[++stot] = i; if (program[i] == ']') { jumpto[i] = stk[stot]; jumpto[stk[stot]] = i + 1; stot--; } } pointer = 0; int pc = 0, input_pt = 0; bool printed = false; while (pc \u0026lt; n) { int next_pc = pc + 1; switch (program[pc]) { case '+': memory[pointer]++; break; case '-': memory[pointer]--; break; case '\u0026lt;': pointer--; break; case '\u0026gt;': pointer++; break; case ',': memory[pointer] = input[++input_pt]; break; case '.': printf(\u0026quot;%d \u0026quot;, memory[pointer]); printed = true; break; case '[': if (memory[pointer] == 0) next_pc = jumpto[pc]; break; case ']': next_pc = jumpto[pc]; break; } pc = next_pc; } if (printed) puts(\u0026quot;\u0026quot;); for (int i = 0; i \u0026lt; 10; i++) printf(\u0026quot;%d \u0026quot;, memory[i]); puts(\u0026quot;\u0026quot;); return 0; } Problem C: DXY\u0026rsquo;s Graph Problem\n题意概括：给定一张图 $G=(V, E)$，其中 $V$, $E$ 分别是点和边的集合。对于图中任意顶点 $v\\in V$，令 $\\text{cover}(v)\\triangleq \\{(x, y)\\in E: x=v\\vee y=v\\}$ (即与该点相邻的所有边的集合)。问是否存在原图顶点的划分 $S_1, S_2$，满足 $S_1\\uplus S_2=V$ (即 $S_1\\cup S_2=V$ 且 $S_1\\cap S_2=\\emptyset$)，且\n$$ \\bigcup_{v\\in S_1}\\text{cover}(v)=\\bigcup_{v\\in S_2}\\text{cover}(v)=E $$\n(注：本题完整题意里中文描述中有关“DXY可以通过自己的点集将原图恢复”的部分给大家带来了较大困扰，对此我们深表歉意。)\n每条边都有两个端点，要想这条边被双方都覆盖到，那么这两个端点必须分属于不同的集合。因此可以成功划分的充要条件是：存在将整张图上的顶点黑白染色，且每条边的两个端点一黑一白的方案。\n我们容易发现这样的方案如果存在一定是唯一的，因为我们已经规定了 1 号点属于 DXY，我们不妨将白色分配给 DXY，那么整个过程相当于从一个白色的 1 号点开始向外搜索，每搜索到一个新的节点就给它涂上和邻居节点不同的颜色。由于整个图是连通的 (即任意两个节点都存在路径互相可达)，所以这样的搜索一定能给每个节点一个唯一的颜色 (如果你想要严谨地证明，可以考虑数学归纳法)。在搜索的过程中，如果发现无法解决的矛盾 (例如某个节点同时和一个黑点和白点相邻)，则问题无解。\n如果你愿意继续深究这个问题 (这部分知识对于解决这道题并无必要)，你会发现可以成功黑白染色充要条件是图中不存在奇数长度的环，这也是判断二分图 (Bipartite Graph) 的方法，大家在后续的问题求解课程中会学习到这个概念和相关的证明。\nCode [Click to expand] #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int MAXN = 1e5 + 10; int n, m; vector\u0026lt;int\u0026gt; v[MAXN]; int color[MAXN]; bool flag; void dfs(int cur) { for (auto neighbor : v[cur]) if (color[neighbor] == 0) { color[neighbor] = 3 - color[cur]; // 两种颜色用 1, 2 表示 // 3 - color[cur] 则表示“另一种颜色” dfs(neighbor); } else if (color[neighbor] != 3 - color[cur]) flag = false; } int main () { scanf(\u0026quot;%d%d\u0026quot;, \u0026amp;n, \u0026amp;m); int x, y; for (int i = 1; i \u0026lt;= m; i++) { scanf(\u0026quot;%d%d\u0026quot;, \u0026amp;x, \u0026amp;y); v[x].push_back(y); v[y].push_back(x); } color[1] = 1; flag = true; dfs(1); if (flag) { puts(\u0026quot;Yes\u0026quot;); int cnt1 = 0, cnt2 = 0; for (int i = 1; i \u0026lt;= n; i++) if (color[i] == 1) cnt1++; else cnt2++; printf(\u0026quot;%d %d\\n\u0026quot;, cnt1, cnt2); for (int i = 1; i \u0026lt;= n; i++) if (color[i] == 1) printf(\u0026quot;%d \u0026quot;, i); puts(\u0026quot;\u0026quot;); for (int i = 1; i \u0026lt;= n; i++) if (color[i] == 2) printf(\u0026quot;%d \u0026quot;, i); puts(\u0026quot;\u0026quot;); } else puts(\u0026quot;No\u0026quot;); return 0; } ","date":1677974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677974400,"objectID":"fd4205e61411699e0ae5cf688465ea65","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/1-final/","publishdate":"2023-03-05T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/1-final/","section":"courses","summary":"Problem A: BrainF**k Syntax Checker\n题意概括：给定一个 BF 程序，判断它是否符合语法要求。\nBF 程序中的 + - , . \u0026gt; \u0026lt; 显然不会对程序的合法性造成影响，因此本题的主要任务是判断 BF 程序中的 [ ] 是否形成了合法的括号序列，即两两匹配。\n值得注意的是，BF 程序中 [ 和 ] 的个数相同并不是括号序列合法的充要条件，比如 ][ 这个序列就是不合法的。在此基础上，我们还要保证 BF 程序的任意前缀中，[ 的个数要大于等于 ] 的个数。","tags":null,"title":"问题求解 I-Final 题解","type":"docs"},{"authors":["Jiawei Liu","Jinjun Peng","Yuyao Wang","Lingming Zhang"],"categories":null,"content":"","date":1675468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675468800,"objectID":"af327a3ccdf5b36cb07bb07881155085","permalink":"https://kristoff-starling.github.io/publication/neuri/","publishdate":"2023-02-04T00:00:00Z","relpermalink":"/publication/neuri/","section":"publication","summary":"","tags":null,"title":"NeuRI: Diversifying DNN Generation via Inductive Rule Synthesis","type":"publication"},{"authors":null,"categories":null,"content":" 题意概述\n给定 $n$ 个数对，保证 $1\\cdots n$ 中的每个数恰好出现两次。每次操作可以任意交换两个数的位置。问至少多少次交换可以使得每对数都相同。\n约束条件：$n\\leq 10^6$。\n这道题颇有思维难度，需要仔细观察并发现问题的性质。发现问题的性质不能靠双眼瞪着屏幕——动起手来，画几个样例手算出解法，很多时候解决问题的灵感就是从手算得出的。\n我们首先可以确定一件事：答案的上限是 $n-1$，因为每轮操作你总可以让某一个数对匹配起来。如果你手算尝试了一些样例，你一定会发现想要让交换次数最少，我们会格外喜欢这样的数对：\n1 2 2 1 因为我们只要让上面的 2 和下面的 1 交换，我们就可以一下子得到两个匹配的数对，这看起来非常赚。但不是什么时候都能有“动一次成两对”这么赚的事情，你很快会发现有的时候格局可能是这样的：\n1 2 2 3 3 5 5 8 8 1 通过观察你可以发现：这样的 5 个数对你只要将前 4 个搞定，最后一个也会随之搞定，且你无法给出比 4 次交换更好的方案。\n你是否觉得上面的 5 个数对像是 1, 2, 3, 5, 8 五个数构成的环？事实上，稍加思索你便能发现 $n$ 个数对其实就是由这样的若干个互不影响的“环”组成的。每个环形如\na1 a2 a2 a3 ... an-1 an an a1 这样一个长度为 $n$ 的环，我们需要 $n-1$ 次操作将其全部搞定，每有一个“环”，我们就可以“节省”一次操作。因此，设 $n$ 个数对共由 $m$ 个环构成，那么最小的操作次数就是 $n-m$。\n判断环的个数相对简单，你并不一定需要使用“并查集”这样高级的数据结构——事实上搜索已经足够完成任务了，这部分的细节留给大家自行思考。\n","date":1670976000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670976000,"objectID":"2dae7db6a3d6f936cf02badc20b06f8b","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/1-6-c/","publishdate":"2022-12-14T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/1-6-c/","section":"courses","summary":"题意概述\n给定 $n$ 个数对，保证 $1\\cdots n$ 中的每个数恰好出现两次。每次操作可以任意交换两个数的位置。问至少多少次交换可以使得每对数都相同。\n约束条件：$n\\leq 10^6$。\n这道题颇有思维难度，需要仔细观察并发现问题的性质。发现问题的性质不能靠双眼瞪着屏幕——动起手来，画几个样例手算出解法，很多时候解决问题的灵感就是从手算得出的。\n我们首先可以确定一件事：答案的上限是 $n-1$，因为每轮操作你总可以让某一个数对匹配起来。如果你手算尝试了一些样例，你一定会发现想要让交换次数最少，我们会格外喜欢这样的数对：\n1 2 2 1 因为我们只要让上面的 2 和下面的 1 交换，我们就可以一下子得到两个匹配的数对，这看起来非常赚。但不是什么时候都能有“动一次成两对”这么赚的事情，你很快会发现有的时候格局可能是这样的：\n1 2 2 3 3 5 5 8 8 1 通过观察你可以发现：这样的 5 个数对你只要将前 4 个搞定，最后一个也会随之搞定，且你无法给出比 4 次交换更好的方案。","tags":null,"title":"【问题求解I-HW6.C】万圣节的新娘","type":"docs"},{"authors":[],"categories":[],"content":"TF/Pytorch with Sanitizers PyTorch Summary 1085 APIs are tested. ASan+UBSan / Compute Sanitizer Two kinds of false positives are filtered: Invalid argument error Out-of-memory allocations Results #APIs #Bugs ASan 7 5 UBSan 19 8 CSan 2+ 2+ ASan: heap-buffer-overflow heap use-after-free SEGV on unknown address UBSan: signed integer overflow non-zero offset to null pointer negative shift exponent CSan: Warp assertion CudaInvalidConfiguration TensorFlow Results #APIs #Bugs CSan 2+ 2+ Out-of-bound reads ","date":1667433600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667433600,"objectID":"5179f8af69f584c405c5a138d255acb1","permalink":"https://kristoff-starling.github.io/slides/20221104/","publishdate":"2022-11-03T00:00:00Z","relpermalink":"/slides/20221104/","section":"slides","summary":"TF/Pytorch with Sanitizers PyTorch Summary 1085 APIs are tested. ASan+UBSan / Compute Sanitizer Two kinds of false positives are filtered: Invalid argument error Out-of-memory allocations Results #APIs #Bugs ASan 7 5 UBSan 19 8 CSan 2+ 2+ ASan: heap-buffer-overflow heap use-after-free SEGV on unknown address UBSan: signed integer overflow non-zero offset to null pointer negative shift exponent CSan: Warp assertion CudaInvalidConfiguration TensorFlow Results #APIs #Bugs CSan 2+ 2+ Out-of-bound reads ","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"之前章节介绍的分支、循环、函数、递归……等概念都是命令式编程语言通用的思想方法。时常有同学问：我们到底学的是 C 还是 C++？可以说之前大家写的程序基本都是 C 风格的 (除了 cin cout string 等少数内容）。这一章介绍的标准模板库 (Standard Template Library, STL)，是 C++ 区别于 C 的重要内容之一。STL 提供的内容将程序员从复杂的底层算法和数据结构中解放出来，使得程序员写程序更加得心应手。\n标准模板库由四个部分构成：\n算法 (Algorithm) 容器 (Container) 函数 (Function) 迭代器 (Iterator) 这一章主要讲解容器。\n大家最近学习了“抽象数据结构“，STL的容器可以理解为C++库为大家实现好了一批数据结构，你只要读懂这些容器对外暴露的接口的功能说明，合理地使用这些接口，就可以在不知道底层实现的情况下享受这些数据结构的福利。我们在这里介绍几个最常用的STL容器和相关操作。\n注：STL容器的用法极其丰富，这里只是浮光掠影简单介绍，大家可以在 cppreference 上查询详细的方法列表。\nvector vector 的中文名是向量，但这个容器和数学中的向量几乎毫无关系，vector 其实更像一个可以自由变换长度，完成一系列操作的“动态数组”。当你不能确定数组长度，或者需要在任意位置插入/删除元素时，vector 将会成为你的一大助力。下面我们通过例子展示 vector 的常见使用方法：\n初始化\n// 通用格式： vector\u0026lt;类型\u0026gt; 名字(最大容量，初始值) #include \u0026lt;vector\u0026gt; // 大家常用的 \u0026lt;bits/stdc++.h\u0026gt; 已经包括了该头文件 int main () { vector\u0026lt;double\u0026gt; v_double(0); // 一个空的，存储的变量为 double 类型的 vector vector\u0026lt;int\u0026gt; v_int(10, 0); // 一个长度为 10 的 vector，初始所有元素为 0 } 元素访问\n// vector 和数组一样支持用下标访问，下标从 0 开始 vector\u0026lt;int\u0026gt; v_int(10, 1); cout \u0026lt;\u0026lt; v_int[2]; // 输出： 0 cout \u0026lt;\u0026lt; v_int[10]; // 下标越界，未定义行为！ 迭代器\n虽然迭代器的概念有点复杂，但为了更好地使用容器，我们还是简单地介绍一下。迭代器可以理解为指向容器中某个元素的“指针”，如果你不知道什么是指针，你可以把它想象成一个“小箭头”。\nvector 中最常用的几个和迭代器相关的函数有：\nbegin()：返回一个指向第一个元素的迭代器。 end()：返回一个指向最后一个元素的“下一个位置”的迭代器。 rbegin()：返回指向最后一个元素的迭代器。 迭代器可以通过简单的 “+1/-1” 操作向右/左移动。我们通过迭代器可以顺序访问数组中的所有元素：\n// 假设当前 vector\u0026lt;int\u0026gt; v 中有 5 个元素，分别是 1, 2，3, 4, 5 for (vector\u0026lt;int\u0026gt;::iterator iter = v.begin(); iter != v.end(); iter++) cout \u0026lt;\u0026lt; *iter \u0026lt;\u0026lt; ' '; // 通过 *iterator 的方式来获取”小箭头“指向的元素的值 // 输出结果： 1 2 3 4 5 for (vector\u0026lt;int\u0026gt;::iterator iter = v.rbegin(); iter != v.begin(); iter--) cout \u0026lt;\u0026lt; *iter ** ' '; // 输出结果： 5 4 3 2，请体会 end() 与 begin() 的不同之处！ 元素的添加和删除\nvector\u0026lt;int\u0026gt; v_int(3, 1); // vector 内容：[1, 1, 1] // push_back(x) 方法用于在末尾添加元素 x v_int.push_back(2) // vector 内容：[1, 1, 1, 2] v_int.push_back(3) // vector 内容：[1, 1, 1, 2, 3] // insert(iter, x) 方法用于在迭代器 iter 指向的位置前插入元素 x v_int.insert(v_int.begin(), 3) // vector 内容：[3, 1, 1, 1, 2, 3] // pop_back() 方法用于删除最后一个元素 v_int.pop_back() // vector 内容：[3, 1, 1, 1, 2] // erase(iter) 方法用于删除迭代器 iter 指向的元素 v_int.erase(v_int.begin() + 1) // vector 内容：[3, 1, 1, 2] // 注：删除了第二个元素 // clear() 函数用于清空 vector v_int.clear() // vector 内容：[] 相关参数\n// 假设当前 vector\u0026lt;int\u0026gt; v 中有 5 个元素，分别是 1, 2，3, 4, 5 cout \u0026lt;\u0026lt; int(v.size()); // 输出：5 bool isEmpty = v.empty() // isEmpty = false stack stack (栈) 是一个先进后出的容器，你可以把它想象成一个电梯：第一个进入电梯的人总是最后一个出来。下面是一些简单的用法：\nstack\u0026lt;int\u0026gt; s; // 初始为空 // push(x) 方法向栈顶放入元素 x s.push(1); s.push(2); s.push(3); // s的内容: (底) [1, 2, 3] (顶) // top() 方法用于获取栈顶元素 int currentTop = s.top(); // currentTop = 3, s: [1, 2, 3] // pop() 方法用于弹出栈顶元素 s.pop(); // s: [1, 2] currentTop = s.top(); // currentTop = 2 // size() 方法用于获取 s 中元素个数 cout \u0026lt;\u0026lt; int(s.size()); // 输出：2 // empty() 方法用于判断 s 是否为空 bool isEmpty = s.empty(); // isEmpty = false queue queue (队列) 是一个先进先出的容器，你可以把它想象成一个双开门电梯：第一个进入电梯的人第一个出来。下面是一些简单的用法：\nqueue\u0026lt;int\u0026gt; q; // 初始为空 // push(x) 方法向队列的尾部加入元素 x q.push(1); q.push(2); q.push(3); // q的内容: (队首) [1, 2, 3] (队尾) // front() 方法用于获取队首元素 int currentFront = q.front(); // currentFront = 1 // q.pop() 方法用于弹出队首元素 q.pop(); // q: [2, 3] currentFront = q.front(); // currentFront = 2 // size() 方法用于获取 q 中元素个数 int currentSize = int(q.size()); // currentSize = 2 // empty() 方法用于判断 q 是否为空 bool isEmpty = q.empty(); // isEmpty = false set set (集合) 顾名思义实现了一个集合应有的功能：插入、去重、判断一个元素是否存在。特别的是 set 中的元素还是按照顺序排列的 (这其实和集合定义中的无序性稍有不符)。下面是一些简单的用法：\nset\u0026lt;int\u0026gt; s; // s: {} // insert(x) 方法向集合插入元素 x s.insert(2); // s: {2} s.insert(1); // s: {1, 2} s.insert(1); // s: {1, 2}，重复元素不会被反复插入 s.insert(3); // s: {1, 2, 3} // find(x) 方法查询 x 是否在集合中，如果在则返回指向该元素的迭代器，否则返回 s.end() set\u0026lt;int\u0026gt;::iterator iter_1 = s.find(1); cout \u0026lt;\u0026lt; *iter; // 输出：1 set\u0026lt;int\u0026gt;::iterator iter_0 = s.find(0); bool isEnd = (iter_0 == s.end()); // isEnd = true // erase(x) 方法用于删除元素 x s.erase(2); // s: {1, 3} // 使用迭代器按顺序访问 s,会发现元素是按顺序排列的 for (set\u0026lt;int\u0026gt;::iterator iter = s.begin(); iter != s.end(); iter++) cout \u0026lt;\u0026lt; *iter \u0026lt;\u0026lt; ' '; // 输出：1 3 // clear() 方法用于清空集合 s.clear(); // s: {} 映射 在标题中使用 map 这个单词会被自动渲染成地图。。。因此使用了“映射”作为标题\nmap (映射) 和数学中的映射一样，维护了一个 key-value pair 的集合。下面是一些简单的用法：\nmap\u0026lt;string, int\u0026gt; m; // 这是一个从 string 到 int 的映射 // 映射的插入非常简单：直接使用数组赋值的语法格式即可 m[\u0026quot;apple\u0026quot;] = 1; m[\u0026quot;banana\u0026quot;] = 2; // 访问一个 key 对应的 value：直接使用数组访问的语法格式 cout \u0026lt;\u0026lt; m[\u0026quot;apple\u0026quot;]; // 输出：1 cout \u0026lt;\u0026lt; m[\u0026quot;orange\u0026quot;]; // 对于不存在的 key，通常会输出默认值 0 m[\u0026quot;apple\u0026quot;] = 3; cout \u0026lt;\u0026lt; m[\u0026quot;apple\u0026quot;]; // 输出：3 // find(x) 方法用于查询映射中是否有 x 这个 key，如果有则返回指向该 pair 的迭代器，否则返回 m.end() map\u0026lt;string, int\u0026gt;::iterator iter_pear = m.find(\u0026quot;pear\u0026quot;); bool isEnd = (iter_pear == m.end()) // isEnd = true map\u0026lt;string, int\u0026gt;::iterator iter_banana = m.find(\u0026quot;banana\u0026quot;); // 使用 .first 获取 key，.second 获取 value cout \u0026lt;\u0026lt; *iter_banana.first \u0026lt;\u0026lt; ' ' \u0026lt;\u0026lt; *iter_banana.second; // 输出： banana 2 ","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667260800,"objectID":"b184338ae303fed1508b67ac0336ca05","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/stl-container/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/stl-container/","section":"courses","summary":"之前章节介绍的分支、循环、函数、递归……等概念都是命令式编程语言通用的思想方法。时常有同学问：我们到底学的是 C 还是 C++？可以说之前大家写的程序基本都是 C 风格的 (除了 cin cout string 等少数内容）。这一章介绍的标准模板库 (Standard Template Library, STL)，是 C++ 区别于 C 的重要内容之一。STL 提供的内容将程序员从复杂的底层算法和数据结构中解放出来，使得程序员写程序更加得心应手。\n标准模板库由四个部分构成：\n算法 (Algorithm) 容器 (Container) 函数 (Function) 迭代器 (Iterator) 这一章主要讲解容器。","tags":null,"title":"C++标准模板库——容器","type":"docs"},{"authors":["Xingyu Du"],"categories":null,"content":"一.有限状态机的介绍 首先说说自动机是干什么的。用简单的话来说，有限状态机是一个黑箱，输入是一个合法的字符串(随着你们逐渐深入的学习，这里的“字符串”的概念将会被\u0026quot;Language\u0026quot;替换)，输出\u0026quot;Accept\u0026quot;或者\u0026quot;Reject\u0026quot;，是不是很像你们的OJ（OJ也是状态机！甚至放开了说，一切程序都是状态机！）而要知道哪些字符串会被\u0026quot;Accept\u0026quot;，哪些字符串会被\u0026quot;Reject\u0026quot;，我们就需要继续了解状态机的概念。\n自动机的工作原理和地图很类似。假设你在你仙林校区，然后你从仙林校区到鼓楼校区，按顺序经过了很多地铁站。每个地铁站都可能有多条换乘路线，而你在所有这些地铁站的选择就构成了一个序列。\n例如，你的选择序列是“ 南大仙林校区-\u0026gt; 羊山公园-\u0026gt;仙林中心 -\u0026gt;学则路 -\u0026gt; 仙鹤门 -\u0026gt; 金马路 -\u0026gt;马群 -\u0026gt; 钟灵街 -\u0026gt; 孝陵卫 -\u0026gt; 下马坊 -\u0026gt; 苜蓿园 -\u0026gt; 明故宫 -\u0026gt; 西安门 -\u0026gt;大行宫 -\u0026gt; 新街口 -\u0026gt; （转1号线）-\u0026gt; 珠江路 -\u0026gt; 鼓楼”，那你按顺序经过的地铁线路可能是“2号线-\u0026gt;1号线\u0026quot;。可以发现，通勤的选择序列不止这一个。同样要去鼓楼校区，你还可以从金马路换乘到4号线，再从4号线到鼓楼站。\n而我们如果找到一个选择序列，就可以在地图上比划出这个选择序列能不能去鼓楼校区。比如，如果一个选择序列是“南大仙林校区-\u0026gt; 羊山公园-\u0026gt;仙林中心 -\u0026gt;学则路 -\u0026gt; 仙鹤门 -\u0026gt; 金马路 -\u0026gt;马群 -\u0026gt; 钟灵街 -\u0026gt; 孝陵卫 -\u0026gt; 下马坊 -\u0026gt; 苜蓿园 -\u0026gt; 明故宫 -\u0026gt; 西安门 -\u0026gt;大行宫 -\u0026gt; 新街口 -\u0026gt; 上海路-\u0026gt;汉中门 -\u0026gt; 莫愁湖 -\u0026gt; 云锦路”，那么它就不会带你去学校，但是仍旧可能是一个可被接受的序列（这里的可接受是任意两个相邻的地点都有地铁能只经过一站而到达），因为目标地点可能不止一个。\n也就是说，我们通过这个地图和一组目的地，将信号序列分成了三类，一类是无法识别的信号序列（例如“南大仙林校区-\u0026gt; ???”），一类是能去学校的信号序列，另一类是不能的信号序列。我们将所有合法的信号序列分成了两类，完成了一个判定问题。\n既然自动机是一个数学模型，那么显然不可能是一张地图。对地图进行抽象之后，可以简化为一个有向图。因此，自动机的结构就是一张有向图。\n而自动机的工作方式和流程图类似，不同的是：自动机的每一个结点都是一个判定结点；自动机的结点只是一个单纯的状态而非任务；自动机的边可以接受多种字符（不局限于 T 或 F）。\n例如，完成“判断一个二进制数是不是偶数”的自动机如下：\n从起始结点开始，从高到低接受这个数的二进制序列，然后看最终停在哪里。如果最终停在红圈结点，则是偶数，否则不是。\n如果需要判定一个有限的信号序列和另外一个信号序列的关系（例如另一个信号序列是不是某个信号序列的子序列），那么常用的方法是针对那个有限的信号序列构建一个自动机。这个在学习 KMP 的时候会讲到。（早着呢）\n需要注意的是，自动机只是一个 数学模型，而 不是算法，也 不是数据结构。实现同一个自动机的方法有很多种，可能会有不一样的时空复杂度。\n二.有限状态机的形式化定义 一个 确定有限状态自动机（DFA） 由以下五部分构成：\n字符集（$\\Sigma$），该自动机只能输入这些字符。 状态集合（$Q$）。如果把一个 DFA 看成一张有向图，那么 DFA 中的状态就相当于图上的顶点。（这里大家没学过图论，但这些基本概念需要大家主动了解，这些概念算是图论里的“常识”了) 起始状态（$start$），$start \\in Q$，是一个特殊的状态。起始状态一般用 $s$表示，为了避免混淆，本文中使用$start$ 。 接受状态集合（$F$），$F \\subseteq Q$，是一组特殊的状态。 转移函数（$\\delta$），$\\delta$ 是一个接受两个参数返回一个值的函数，其中第一个参数和返回值都是一个状态，第二个参数是字符集中的一个字符。如果把一个 DFA 看成一张有向图，那么 DFA 中的转移函数就相当于顶点间的边，而每条边上都有一个字符。 DFA 的作用就是识别字符串，一个自动机$A$ ，若它能识别（接受）字符串$S$ ，那么 $A(S)=True$，否则$A(S)=False$ 。\n当一个 DFA 读入一个字符串时，从初始状态起按照转移函数一个一个字符地转移。如果读入完一个字符串的所有字符后位于一个接受状态，那么我们称这个 DFA 接受 这个字符串，反之我们称这个 DFA 不接受 这个字符串。\n如果一个状态 $v$没有字符$c$ 的转移，那么我们令$\\delta(v,c)=null$ ，而$null$只能转移到$null$ ，且$null$不属于接受状态集合。无法转移到任何一个接受状态的状态都可以视作 $null$，或者说， $null$代指所有无法转移到任何一个接受状态的状态。\n（注:上一段表示一旦不存在当前状态的某个转移，那么状态机一定会不接受这个字符串)\n我们扩展定义转移函数 $\\delta$，令其第二个参数可以接收一个字符串：$\\delta(v,s)=\\delta(\\delta(v,s[1]),s[2..|s|])$，扩展后的转移函数就可以表示从一个状态起接收一个字符串后转移到的状态。那么，$A(s)=[\\delta(start,s)\\in F]$。这里难以理解抽象函数的话，可以当成在字符串中一个个读取字符，然后一步步转移当前状态，最后在最终状态判断是否为接受状态\n如，一个接受且仅接受字符串 \u0026ldquo;a\u0026rdquo;, \u0026ldquo;ab\u0026rdquo;, \u0026ldquo;aac\u0026rdquo; 的 DFA：\nNFA是在DFA的基础上存在某些状态$v$，满足$\\delta(v,\\epsilon)\\neq null$，这里的$\\epsilon$表示空字符串，这就导致NFA可能处于多种状态的叠加态中（这是后面将NFA转化成DFA的关键，将当前的多种状态当成一个新状态！这样记原状态数为k种，此时总状态数就会有$2^k$种，但每一次状态转移都是唯一的！)，一个NFA的例子如下，我们判断一个字符串是否以\u0026quot;01\u0026quot;结尾，正则表达式表示为\u0026quot;$.*01$\u0026ldquo;的NFA如下 (S3为接收节点)：\ngraph TD state1((s1)) --\u0026gt;|0| state2((s2)) state2 --\u0026gt;|e/任意字母|state1 state2 --\u0026gt; |1| state3((s3)) state3 --\u0026gt; |e/任意字母|state1 以上内容节选自OI-Wiki\n三.有限状态机的代码实现 1.DFA代码实现 I.非图论建模 非图论建模DFA，主要要确定状态机的各个状态，和状态之间的转移，以上文的只接受\u0026quot;a\u0026rdquo;,\u0026ldquo;ab\u0026rdquo;,\u0026ldquo;aac\u0026quot;的DFA为例，可以实现一个函数“get_nxt_state()\u0026ldquo;实现状态的转移。缺点很明显，没有建图的过程，用一个个if判断，代码会冗长不好看\n//函数返回值为true表示转移到一个合法状态，函数返回值为false表示转移到一个非法状态 bool get_nxt_state(char ch,int\u0026amp; state){ switch(state){ case 0:{ if(ch=='a')state=1;//合法输入 else return false;//非法输入 return true; } case 1:{ ... } case 2:{ } } } bool dfa(string str){ int status; for(int i=0;i\u0026lt;str.size();i++){ if(get_nxt_status(str[i],state)==false) return false; } return status在接受状态中; } II.图论建模 图论建模DFA，同上，只是在每个状态内部预先处理碰到不同字符后的下一个状态，一种可能的实现方案为\nstruct Node{ int nxt[128];//不太好的编程习惯 }Nodes[100000];//不太好的编程习惯2，当然这样会超空间 void add(int from,int to,char ch){ Nodes[from].nxt[ch]=to; } bool dfa(string str){ int tNode=0;//0是初始节点 //预先设置好每个节点是否是available; for(int i=0;i\u0026lt;str.size();i++){ tNode=Nodes[tNode].nxt[str[i]]; if(tNode==0x3f3f3f3f)return false; } return tNode是一个接受状态; } 2.NFA代码实现 I.以矩阵和向量的形式建模（NFA 转换成 DFA) NFA可能在一次状态转移后，可能同时满足多个状态，记NFA的总状态数为k,则可以用一个长度为k的列向量表示当前所处状态，该列向量的第i位表示当前是否可能处于第i种状态，同时可以使用矩阵表示状态之间的转移，转移矩阵需要提前构造。\n这个思路中的列向量相当于把所有的状态压缩进一个列向量中，比如共有4个状态，状态1和状态2均有可能，则列向量为{0,1,1,0}，列向量共有2^k种不同的可能代表\ntypedef vector\u0026lt;int\u0026gt;arr; typedef vector\u0026lt;arr\u0026gt;matrix; arr operator*(matrix mat,arr vec){ int n=mat.size(); arr ret(n,0); for(int i=0;i\u0026lt;n;i++) for(int j=0;j\u0026lt;n;j++) ret[i]|=mat[i][j]\u0026amp;vec[j]; return ret; }//矩阵乘列向量 matrix transition_matrix[256];//转移矩阵，其中第i个转移矩阵表示当前遇到的字符为 i时的转移矩阵，其第j行第k列表示可以从第k个状态转移到第j个状态 int state_count;//总的状态数，初始状态为状态0 void dfa_init(string patton){ //TBD 确认状态数 //TBD 构造转移矩阵 } bool nfa(string str){ arr vec(state_count,0); vec[0]=1; for(int i=0;i\u0026lt;str.size();i++){ vec=vec*transition_matrix[str[i]]; } //最后结果遍历所有vec中为true的位，判断它是否是接受状态 return vec[state_count-1]; } II.以图论建模，用DFS搜索 用DFS去尝试所有的匹配可能，如果在DFS过程中完成字符串匹配后处于接受状态，则接受这个字符串，否则不接受\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;graph[10000];//不好的编程风格 //graph[i][j][k]表示当前状态为i，读入的字符为j，能到达的第k个状态的状态号 void add(int from,int to, char ch){ graph[from][ch].push_back(to); } bool nfa_dfs(int status,string str,int pl){ if(pl==patton.size())return status为接受状态; if(graph[status][str[pl]].size()==0)return false; bool flag=false; for(int i=0;i\u0026lt;graph[status][str[pl]].size();i++){ flag|=nfa_dfs(graph[status][str[pl]][i],str,pl+1); if(flag)return true;//剪枝 } return false; } bool nfa(string str){ return nfa_dfs(0,str,0); } 四.以实际应用为例，进行模型构建和代码实现 1.以匹配合法邮件地址为例 为了方便表示，我们不考虑判断合法域名，以及合法邮件地址，我们给出邮件地址的BNF范式\nemail address::=\\\u0026lt;string '@' domain\u0026gt; string::=\\\u0026lt;word|digit\u0026gt;{word|digit} domain::=\\\u0026lt;string '.' string\u0026gt; word和digit分别表示单词和数字，定义不给出\n例子分析: 我们首先确定状态的个数\n初始状态 位于第一个string的状态 位于\u0026rsquo;@\u0026lsquo;的状态 位于第二个string的状态 位于\u0026rsquo;.\u0026lsquo;的状态 位于第三个string的状态 我们注意到，对于本题，合法的邮件地址要求下，只有状态6才是接受状态\n接下来分析状态转移\n对于状态1,当接收到数字或字母时,会转移到状态2,其他情况均不合法\n对于状态2,当接收到数字或字母时,保持当前状态,接收到\u0026rsquo;@\u0026lsquo;时,转移到状态3,其他情况均不合法\n对于状态3,当接收到数字或字母时,会转移到状态4,其他情况均不合法\n对于状态4,当接收到数字或字母时,保持当前状态,接收到\u0026rsquo;.\u0026lsquo;时,转移到状态5,其他情况均不合法\n对于状态5,当接收到数字或字母时,会转移到状态6,其他情况均不合法\n对于状态6,当接收到数字或字母时,保持当前状态,其他情况均不合法\n代码实现： 接下来有两种代码实现方式，头文件在此均忽略不计\n//方案1，状态转移 bool isdigit(char ch){ return '0'\u0026lt;=ch\u0026amp;\u0026amp;ch\u0026lt;='9'; } bool isletter(char ch){ return ('a'\u0026lt;=ch\u0026amp;\u0026amp;ch\u0026lt;='z')||('A'\u0026lt;=ch\u0026amp;\u0026amp;ch\u0026lt;='Z'); //注意不要写成 'a'\u0026lt;=ch\u0026lt;='z'这样的情况，否则相当于('a'\u0026lt;=ch)\u0026lt;='z' } //此函数是表示给出当前状态和当前读入的字符，判断是否存在合法转移，以及如果合法，跳转到下一个状态 //对于函数的参数的\u0026quot;\u0026amp;\u0026quot;符号，可以了解一下实参和形参，以及函数的副作用 //注意这种写法较为冗长，可以建立一个accept的列表 bool get_next_state(char ch,int\u0026amp; state){ switch(state){ case '1':{ if(isdigit(ch)||isletter(ch)){ state=2; return true; } return false; break;//这里的break不需要，仅仅是为了提醒大家switch里记得不要漏掉break语句 } case '2':{ if(isdigit(ch)||isletter(ch)){ state=2; return true; } else if(ch=='@'){ state=3; return true; } return false; break; } case '3':{ if(isdigit(ch)||isletter(ch)){ state=4; return true; } return false; break; } case '4':{ if(isdigit(ch)||isletter(ch)){ state=4; return true; } else if(ch=='.'){ state=5; return true; } return false; break; } case '5':{ if(isdigit(ch)||isletter(ch)){ state=6; return true; } return false; break; } case '6':{ if(isdigit(ch)||isletter(ch)){ state=6; return true; } return false; break; } } } //另一种get_next_state的实现如下 bool get_next_state(char ch,int\u0026amp; state){ static bool init=false; struct table{ string str; int next_state; }; static vector\u0026lt;table\u0026gt;nextstate[7]; if(!init){ //将合法状态加入表格中，这个合法状态字符串常量可以用一个const string 表示，下文用String表示字符串常量\u0026quot;abcdefghijklmnopqrstuvwxyz0123456789\u0026quot; table[1].push_back((table){String,2}); table[2].push_back((table){String,2}); table[3].push_back((table){String,4}); table[4].push_back((table){String,4}); table[5].push_back((table){String,6}); table[6].push_back((table){String,6}); table[2].push_back((table){\u0026quot;@\u0026quot;,3}); table[4].push_back((table){\u0026quot;.\u0026quot;,5}); init=true; //当然这个步骤可以在函数外部完成 } for(int i=0;i\u0026lt;nextstate[state].size();i++){ //遍历合法状态 string availstr=nextstate[state][i].str; for(int j=0;j\u0026lt;availstr.size();j++){ if(ch==availstr[j]){ state=nextstate[state][i].next_state; return true; } } } return false; } bool solve(){ string str;//推荐使用string存放字符串数据 cin\u0026gt;\u0026gt;str; int state=1; for(int i=0;i\u0026lt;str.size();i++){ if(!get_next_state(str[i],state)){ return false;//如果转移不合法，则返回false } } return state==6;//只有状态6是接受状态 } int main(){ int t=1; while(t--)solve(); } 如果大家注意到的话，第二种方式可以当做”图“来理解，”图“在计算机中只是一种模型，并不一定只有了解”图“的知识，才能写出来含有”图“思想的题目，我这里避免了使用传统建图的方式，不过这里的状态转移表的思想和”图\u0026quot;类似\n其他例题： https://leetcode.cn/problems/valid-number/ (这玩意居然还标了困难\u0026hellip;是我大意了，以为是个比较简单的题目\u0026hellip;不过LeetCode上的困难题大家大二以后都是随便手撕的（误） 但总的来说，LeetCode是一个适合新手练习的网站，LeetCode中，所有错误都会把错误样例给你，便于调试和debug)\n2.更简易正则表达式 为了给大家一个NFA建模的例子，同时保证不直接提供OJ代码，我这里将以一个更简易版的正则表达式的判别\n这里的正则表达式只包含26个小写字母和\u0026rdquo;*\u0026ldquo;符号，其含义和OJ中正则表达式的含义相同\n例子分析 首先要对正则表达式进行语法分析，得到该正则表达式对应的所有状态\n对于正则表达式”a*a*“来说，用它去匹配\u0026quot;aa\u0026rdquo;，可能有多重匹配的结果，比如第一个\u0026rsquo;a\u0026rsquo;匹配了两次，第二个\u0026rsquo;a\u0026rsquo;匹配了零次，和第一个\u0026rsquo;a\u0026rsquo;匹配一次，第二个\u0026rsquo;a\u0026rsquo;匹配一次，和第一个\u0026rsquo;a\u0026rsquo;匹配零次，第二个\u0026rsquo;a\u0026rsquo;匹配两次。因此同一个字符串，可能在正则表达式中有多种对应的匹配**（思考一下如何计算到底有多少种可能的匹配方式呢）**。因此我们可以将正则表达式建模成NFA\n以\u0026quot;a*aba*\u0026ldquo;为正则表达式举例，连同初始状态，它一共有以下四个状态\n初始状态 正在匹配第一个\u0026quot;a*\u0026rdquo; 正在匹配\u0026quot;b\u0026rdquo; 正在匹配第二个\u0026quot;a*\u0026quot; 注意:由于正则表达式的NFA特性，导致初始状态时，既可以处在状态1，也可以处在状态2(当前匹配了0次\u0026rsquo;a\u0026rsquo;，为合法的匹配)\n代码实现： 我这里将给出上文提到的两种实现方式去解决该问题，当然，对于本题，动态规划也是一个可行的算法，这里不多赘述\n//NFA转化成DFA去做 typedef vector\u0026lt;int\u0026gt; arr; typedef vector\u0026lt;arr\u0026gt; matrix; arr operator*(matrix mat,arr vec){ assert(mat.size()\u0026gt;0\u0026amp;\u0026amp;vec.size()\u0026gt;0\u0026amp;\u0026amp;mat[0].size()==vec.size());//矩阵运算的前提 int n=mat.size(),m=vec.size(); arr ret(n,0); for(int i=0;i\u0026lt;n;i++){ for(int j=0;j\u0026lt;m;j++){ ret[i]|=mat[i][j]\u0026amp;vec[j];//0-1矩阵计算 } } return ret; } struct _state{ char ch=0;//这里因为没有出现一个state里允许多字符的'[]'和'.'出现，于是用char表示当前状态允许的字符 int type=0;//当前state的修饰符状态，0表示无修饰符，1表示用'*'修饰,这里建议了解一些enum，在完成较大工程时适合使用 }; //正则表达式的parse过程，将正则表达式标记成多个状态 vector\u0026lt;_state\u0026gt; parse(string regex){ vector\u0026lt;_state\u0026gt;states; for(int i=0;i\u0026lt;regex.size();i++){ _state state; state.ch=regex[i]; state.type=0; if(i+1\u0026lt;regex.size()\u0026amp;\u0026amp;regex[i+1]=='*'){ i++; state.type=1; } states.push_back(state); } return states; } bool solve(){ string regex;//正则表达式 string str;//被匹配的字符串 cin\u0026gt;\u0026gt;regex\u0026gt;\u0026gt;str; vector\u0026lt;_state\u0026gt;states=parse(regex); int state_count=states.size()+1;//总共的状态数 //初始化合法状态 arr state(state_count,0);//表示当前状态 state[0]=1; for(int i=0;i\u0026lt;states.size();i++){ if(states[i].type==1){ state[i+1]=1; } else break; } //接下来构建转移矩阵的部分，每一个字母有一个独特的转移矩阵，转移矩阵含义照上文解读 vector\u0026lt;matrix\u0026gt;trans_matrix(26,matrix(state_count,arr(state_count,0))); int lastavail=0;//这里表示连续的'*'的开始位 for(int i=0;i\u0026lt;states.size();i++){ int index=states[i].ch-'a'; int type=states[i].type; if(type==1){ //如果当前是\u0026quot;*\u0026quot;的话，那么对于之前的状态，只要他们能到达上一个状态，都能实现转移到当前状态(epsilon边) for(int j=0;j\u0026lt;=i;j++){ for(int k=0;k\u0026lt;26;k++)trans_matrix[k][i+1][j]=trans_matrix[k][i][j]; } trans_matrix[index][i+1][i+1]=1; trans_matrix[index][i+1][i]=1;//这个是多余的(因为能到达i的话，一定能到达状态i+1，但是是可行的) } else{ trans_matrix[index][i+1][i]=1; //否则只能实现从i到i+1的转移 } } //不断转移计算 for(int i=0;i\u0026lt;str.size();i++){ state=trans_matrix[str[i]-'a']*state; } return state[state_count-1];//正则表达式的支持状态只有末状态. } int main(){ int t=1; while(t--){ solve(); } } //DFS去做 struct _state{ char ch=0;//这里因为没有出现一个state里允许多字符的'[]'和'.'出现，于是用char表示当前状态允许的字符 int type=0;//当前state的修饰符状态，0表示无修饰符，1表示用'*'修饰,这里建议了解一些enum，在完成较大工程时适合使用 }; //正则表达式的parse过程，将正则表达式标记成多个状态 vector\u0026lt;_state\u0026gt; parse(string regex){ vector\u0026lt;_state\u0026gt;states; for(int i=0;i\u0026lt;regex.size();i++){ _state state; state.ch=regex[i]; state.type=0; if(i+1\u0026lt;regex.size()\u0026amp;\u0026amp;regex[i+1]=='*'){ i++; state.type=1; } states.push_back(state); } return state; } vector\u0026lt;_state\u0026gt;states; int lastavail;//详情见dfs bool dfs(string str,int index, int state){ if(index==str.size())return state==states.size(); //首先判断当前state可以转移的state vector\u0026lt;int\u0026gt;availstate; //注意当前的state下标在states数组里应该是states[state-1] if(state\u0026gt;0\u0026amp;\u0026amp;states[state-1].type==1\u0026amp;\u0026amp;str[index]==states[state-1].ch)availstate.push_back(state); //可以贪心，对于所有的可到达的\u0026quot;*\u0026quot;标志，只要进入最小下标的可到达的\u0026quot;*\u0026quot;标记位置即可,这是一种剪枝策略，这里不使用该剪枝策略，不用剪枝策略的话，复杂度最高可以达到2^n //(为什么可以这样贪心，请自己理解，不懂可以问助教) for(int i=state;i\u0026lt;states.size();i++){ if(states[i].type!=1){ if(states[i].ch==str[index])availstate.push_back(i+1); break; //这里碰到一次type==0的情况后，仍然可以转移到它后面的type==1的情况，但是那样是无意义的，于是这里我写了一个lastavail的标志，表示可以通过epsilon转移到最后一个状态的最小state } else{ if(states[i].ch==str[index])availstate.push_back(i+1); } } for(int i=0;i\u0026lt;availstate.size();i++){ if(dfs(str,index+1,availstate[i]))return true;//这里也是简单的剪枝,不剪枝的写法如下 } /* 不剪枝的写法 bool flag=false; for(int i=0;i\u0026lt;availstate.size();i++){ flag|=dfs(str,index+1,availstate[i]); } return flag; */ return false; } bool solve(){ string regex; string str; cin\u0026gt;\u0026gt;regex\u0026gt;\u0026gt;str; states=parse(regex); vector\u0026lt;int\u0026gt;initialstate; initialstate.push_back(0); lastavail = states.size(); for (int i = states.size()-1; i \u0026gt;= 0; i--) { if (states[i].type == 1)lastavail = i; else break; } return dfs(str,0,0); } 动态规划解法： 自行了解一下 ( https://leetcode.cn/problems/regular-expression-matching/)\n","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667260800,"objectID":"40b45547b6550c1bdd40cdeb11f7a5f3","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/dfa/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/courses/problemsolving22/dfa/","section":"courses","summary":"鸣谢dxy助教的贡献！","tags":null,"title":"有限状态机简介","type":"courses"},{"authors":null,"categories":null,"content":" 声明\nPython语言的学习不是这门课的硬性要求，因此我们不会在OJ作业/期末测试中强制大家使用Python完成习题。但我们仍然强烈建议你在初学阶段至少涉猎一下这样一门与 C/C++ 风格迥异的语言。\n接触 Python 可以给你带来不限于以下好处：\n感受 Python 精简灵活的语法：在这里你不用书写头文件，不需要书写 main() 函数，不需要在每行后面写分号，不需要定义变量……Python 提供的丰富的内置数据类型让你可以轻松自由地操纵数据。 感受函数式编程范式：Python 是一门兼有命令式和函数式风格的语言。在 Python 中你可以轻而易举地玩转高阶函数、lambda表达式等，感受函数式编程的独特思想和魅力。 强大的第三方库：Python 丰富的第三方库的支持可以让你轻松地完成一些“惊为天人”的东西，比如处理电脑文件的自动化脚本，带有图形界面的小游戏等等。 接触 Python 可能带来的坏处：总是在 C/C++ 程序中写出 Python 风格的会导致编译错误的代码。\n我们不会介绍 Python 的安装，如果你感兴趣可以上网自行搜索教程安装 Python 的运行环境，并亲自上手感受这样一门现代语言。你目前只需要能看懂这份教程即可。\n想必大家听过一句著名的广告词“人生苦短，我用Python”。Python是世界上程序员最喜爱的编程语言之一 (主要原因已经在上方的蓝框中涉及了一部分)。我们仍然用输出 \u0026ldquo;Hello, world!\u0026rdquo; 的例子来入门：\nprint('Hello, world!') 是的，只需要一行。不需要头文件、main() 函数，也不需要理解复杂的 scanf()/printf() 语法和输入输出流，一个直观的 print() 函数解决一切！\n下一个例子是喜闻乐见的 a+b problem：\na = int(input()) b = int(input()) print(a + b) 在 Python 中你不需要提前定义变量，可以“拿来就用”，这是因为 Python 是一门动态语言，可以在执行的过程中进行 type inference。这里需要注意的是 input() 读入进来的内容默认是字符串类型，我们需要用 int() 将其转换为整数类型。如果你想要查看一个变量存储的数据的类型，你可以使用 type() 函数：\na = input() print(type(a)) # 在 Python 中，你可以用\u0026quot;#\u0026quot;进行行末注释！ \u0026quot;\u0026quot;\u0026quot; 在 Python 中，你可以用三引号框住 一段注释！ \u0026quot;\u0026quot;\u0026quot; 在 Python 中定义函数可以使用 \u0026ldquo;def\u0026rdquo; 关键字：\ndef add(a, b): # 注意这里必须有冒号！ return a + b print(add(1, 2)) # 输出：3 值得注意的是，Python没有C/C++语言中一层层的大括号，所以Python程序需要依靠严格的缩进来保证清晰的程序结构。因此函数体的语句前方必须有缩进！类似地，if语句的分支，循环语句的循环体也必须保证正确的缩进。\nPython中的判断语句：\ndef judge_even_odd(x): if x % 2 == 0: # 注意这里要有冒号！ return 'even' else: # 注意这里要有冒号！ return 'odd' print(judge_even_odd(1)) # 输出：odd Python中的循环语句：\ndef cumulative_sum(n): res = 0 while n \u0026gt;= 0: # 注意这里要有冒号！ res += n n -= 1 return res print(cumulative_sum(10)) # 输出：55 注意：在 Python 中 if/while 的判断条件左右是不需要加括号的。\n一个简单的递归程序：\ndef fibonacci(n): if n == 0: return 0 elif n == 1: return 1 else: return fibonacci(n-1) + fibonacci(n-2) print(fibonacci(9)) # 输出：34 ","date":1667174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667174400,"objectID":"a5e0fe7a78a60762adfe8e30afe04623","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/python-intro/","publishdate":"2022-10-31T00:00:00Z","relpermalink":"/courses/problemsolving22/python-intro/","section":"courses","summary":"一份简短的 Python 教程，帮助你快速掌握 Python 中最基础的语法(正在更新中）","tags":null,"title":"Python 快速入门教程","type":"courses"},{"authors":null,"categories":null,"content":" 题意概述\n给定字符串 $s$，求 $|\\{(i,j,k)|s_i=j,s_j=y,s_k=y\\}|$。\n约束条件：$|s|\\leq 10^6$。\n大家容易想到的一个非常简明的做法是使用三重循环计数：\nans = 0; for (int i = 0; i \u0026lt; int(s.size()); i++) for (int j = i + 1; j \u0026lt; int(s.size()); j++) for (int k = j + 1; k \u0026lt; int(s.size()); k++) if (s[i] == 'j' \u0026amp;\u0026amp; s[j] == 'y' \u0026amp;\u0026amp; s[k] == 'y') ans++; 但由于此题中 $|s|$ 达到了 $10^6$，使用三重循环意味着循环最内层的核心语句被执行了将近 $|s|^3$ 次。计算机一秒钟可以执行的 C/C++ 基本语句数目大约在 $10^8$ 量级，这样的程序显然会超时。\n本题的出题助教 (aka. dxy) 希望大家构造自动机解题。这里我们给出一个另外的比较简单的思路：\n我们将上面的程序改写为如下伪代码：\nans = 0; for (int i = 0; i \u0026lt; int(s.size()); i++) if (s[i] == 'j') ans += \u0026quot;s[i]的后面(可以不连续)的yy的数目\u0026quot;; 之前的代码中我们使用双重循环来数 \u0026ldquo;yy\u0026rdquo; 的个数，但事实上我们有更快速的方法：假设 s[i] 的后面一共有 n 个字母y，那么任意挑选两个都可以组成一个yy，所以yy的总数目是 $\\binom{n}{2}=\\frac{1}{2}n(n-1)$。基于这个想法，我们可以用一个二重循环解决该问题：\nans = 0; for (int i = 0; i \u0026lt; int(s.size()); i++) if (s[i] == 'j') { int y_count = 0; for (int j = i + 1; j \u0026lt; int(s.size()); j++) if (s[j] == 'y') y_count++; ans += C(y_count, 2); // 组合数需要另外实现 } 我们的算法已经得到了改进，但 $|s|^2$ 次运行仍然无法在规定时间内获得结果，算法还需要进一步的优化。上述方法的瓶颈在于我们每遇到一个j都会把它后面的y数一遍，这样有很多的字母y被反复数了很多遍，这无疑拖慢了速度。\n事实上，一个巧妙的顺序的改变就可以“柳暗花明”：我们将外层循环的顺序倒过来，一边寻找j一边把j“身后”的y的个数数出来，这样就不需要内层循环了：\nans = y_count = 0; for (int i = int(s.size()) - 1; i \u0026gt;= 0; i--) { if (s[i] == 'y') y_count++; if (s[i] == 'j') ans += C(y_count, 2); } 循环的使用方法博大精深，大家可以仔细体会这段代码。\n此外，本题由于结果过大，最终需要输出答案对 $998244353$ 取模的结果。大家在本题中可能会使用乘法，此时必须格外小心两个 int 类型变量相乘 (还没来得及取模时) 结果溢出的情况，一个好的解决方案是使用更大的数据类型存储中间结果。\n","date":1666828800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666828800,"objectID":"18ce0a6d4d94910fde56fd2b3af6d845","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/solutions/1-4-c/","publishdate":"2022-10-27T00:00:00Z","relpermalink":"/courses/problemsolving22/solutions/1-4-c/","section":"courses","summary":"题意概述\n给定字符串 $s$，求 $|\\{(i,j,k)|s_i=j,s_j=y,s_k=y\\}|$。\n约束条件：$|s|\\leq 10^6$。\n大家容易想到的一个非常简明的做法是使用三重循环计数：\nans = 0; for (int i = 0; i \u0026lt; int(s.size()); i++) for (int j = i + 1; j \u0026lt; int(s.size()); j++) for (int k = j + 1; k \u0026lt; int(s.","tags":null,"title":"【问题求解I-HW4.C】jyy为什么是神","type":"docs"},{"authors":null,"categories":null,"content":" 2.1 Principles of Network Applications 2.1.1 Network Application Architectures 2.1.2 Processes Communicating Client and Server Processes The Interface Between the Process and the Computer Network Addressing Processes 2.1.3 Transport Services Available to Applications Reliable Data Transfer Throughput Timing Security 2.1.4 Transport Services Provided by the Internet TCP Services UDP Services Services Not Provided by Internet Transport Protocols 2.1.5 Application-Layer Protocols 2.1.6 Network Applications Covered in This Book 2.2 The Web and HTTP 2.2.1 Overview of HTTP 2.2.2 Non-Persistent and Persistent Connections HTTP with Non-Persistent Connections HTTP with Persistent Connections 2.2.3 HTTP Message Format HTTP Request Message HTTP Response Message 2.2.4 User-Server Interaction: Cookies 2.2.5 Web Caching The Conditional GET 2.2.6 HTTP/2 HTTP/2 Framing Response Message Prioritization and Server Pushing 2.3 Electronic Mail in the Internet 2.3.1 SMTP 2.3.2 Mail Message Formats 2.3.3 Mail Access Protocols 2.4 DNS - The Internet\u0026rsquo;s Directory Service 2.4.1 Services Provided by DNS 2.4.2 Overview of How DNS Works A Distributed, Hierarchical Database DNS Caching 2.4.3 DNS Records and Messages DNS Message Inserting Records into the DNS Database 2.5 Peer-to-Peer File Distribution Scalability of P2P Architecture BitTorrent 2.6 Video Streaming and Content Distribution Networks 2.6.1 Internet Video 2.6.2 HTTP Streaming and DASH 2.6.3 Content Distribution Networks CDN Operation Cluster Selection Strategies 2.6.4 Case Studies: Netflix and YouTube Netflix YouTube 2.7 Socket Programming: Creating Network Applications 2.1 Principles of Network Applications 开发网络应用的核心是书写可以在不同的终端设备上运行的代码——值得注意的是我们不需要使我们的程序可以在 network core 中运行，因为 network core 中的 router/switch 根本没有应用层。\n2.1.1 Network Application Architectures 需要注意的是 application architecture 和之前的 network architecture (即应用/传输/网络/链路/物理五层架构) 是不同的。应用架构 (application architecture) 由软件开发者提出，用来描述一个网络应用应当以什么样的结构分布在各个终端设备上。现在最流行的两种应用架构是所谓的 client-server 架构和 P2P 架构。\n在客户机-服务器架构 (client-server architecture) 中，有一台一直运作的主机称为服务器 (server)，它的功能是为许许多多的其他主机，称为客户机 (client)，提供服务。在 client-server 架构中，不同的客户机之间不会直接建立通讯，他们都只和服务器交互，服务器有一个固定且为大家所知的 IP 地址，客户机可以通过向该 IP 地址发送 packet 的方式与服务器建立通讯。\n通常在 client-server 应用中，一个服务器主机很难支撑繁重的业务，所以开发者一般会建立数据中心 (data center)。数据中心里有大量的主机，它们合起来对外形成一个虚拟服务器。\n在点对点架构 (peer=to=peer/P2P architecture) 中，我们不再有服务器和数据中心的概念。用户的主机之间直接建立联系，这种 pair 被称为同伴 (peer)。P2P 的一大优势在于其 self-scalability，例如在一个 P2P 文件分享应用中，虽然每个用户索取文件会为网络带来 workload，但每个用户也会将自己的文件贡献给同伴，为网络增添服务能力。此外，P2P 节省了建设服务器等服务基础设施的钱财和精力。不过 P2P 高度去中心化的结构使其在安全性、可靠性等方面存在一定的挑战。\n2.1.2 Processes Communicating 这个 section 主要讨论位于不同终端设备的程序之间是如何交互的。根据操作系统的术语，事实上并不是程序在交互，而是进程在交互。两个进程处于两个不同终端设备的应用层，它们通过向网络发送报文的方式交换信息。\nClient and Server Processes 对于每一对通信的进程，我们通常将其中提供服务的进程称为 server，使用服务的进程称为 client。例如在 Web 应用中，网页浏览器是 client 进程，Web server 是 server 进程；在 P2P 文件共享中，下载文件的进程是 client 进程，上传文件的进程是 server 进程。事实上，在 P2P 中，很多情况下一个进程可能同时在上传和下载，但具体到一个固定的 pair 中时它要么是 server 要么是 client。\n关于 client side 和 server side 有一个更正式的定义：对于一对正在通信的进程来说，初始化通信会话的那个进程是 client，那个等待它人与自己连接并开启会话的进程是 server。\nThe Interface Between the Process and the Computer Network 应用层的 application 通过套接字 (socket) 发送和接收消息。socket 是传输层向应用层提供的 API，它为应用层提供的保证是 application 只要向 socket 传输内容，下层的基础设施就会将内容传输到连接另外一端的 socket。应用开发者不能也不应该直接触碰底层的传输细节，他们只能通过选择传输协议和给定一些参数的方式来定制自己所需的服务。\nAddressing Processes 发送消息时发送方需要知道接收主机的 IP 地址 (IP address)。此外，由于一个主机可以同时运行多个网络应用/进程，我们还需要一个方法来辨别接收消息的进程，这就是端口号 (port number) 的功能。端口号有一些convention，比如 Web server 的端口号通常是 80，mail server 通常是 25 等等。\n2.1.3 Transport Services Available to Applications application 将消息发送到 socket 之后，下面的传输层协议就要负责将消息传到对面的 socket。大部分的网络提供多种传输协议，不同的协议在各项性能指标上存在差异，我们一般从 reliable data transfer, throughput, timing 和 security 四个维度来衡量一个传输协议。\nReliable Data Transfer packet 在网络传输的过程中可能因为各种原因丢失，对于许多应用 (例如电子邮件、网络银行等)，丢失数据会造成严重的后果。如果一个协议可以保证一端发出的数据可以完整地被另一端接收，那么我们称该协议提供可靠数据传输 (reliable data transfer)。\n对于一些 loss-tolerable 的应用，比如各种流媒体，它们就不必要选择提供可靠数据传输的协议。丢失一点数据可能只是造成一点画面失真而已，它们更在乎传输的流畅度。\nThroughput 网络的拥塞程度会对传输的实际吞吐率产生很大的影响。有的传输协议可以向应用层提供 throughput 的保证，例如无论网络多么拥塞我都保证吞吐率不小于 $r$ bits/sec。这样的保证对于一些 bandwidth-sensitive application 及其重要。对于像电子邮件、文件传输这样的 elastic application，即时吞吐率的保证就无关紧要。\nTiming 类似于 throughput，传输协议也可以提供 timing 保证，例如保证一个 bit 在写入 socket 后可以在 $t$ sec 内传输到另一端的 socket。这种保证对即时应用十分重要。\nSecurity 传输协议可以提供一些安全性的保证，例如在发送端对信息加密，接收端再对信息解密，这样中途即使被窃听也不会泄露用户隐私。\n2.1.4 Transport Services Provided by the Internet 因特网 (或者更一般地，TCP/IP 网络) 提供两种传输协议：TCP 和 UDP。当我们编写网络应用时，我们需要在这两个传输协议中做出选择。\nTCP Services TCP 协议为发送和接收双方提供如下服务：\nConnection-oriented service: TCP 会让传输双方在开始正式传输信息之前先交换一些控制信息，这个过程被称为握手 (handshaking)。完成握手后，两个进程的 socket 之间会建立起 TCP 连接 (TCP connection)。这个 TCP connection 是双向的，即两个进程可以同时互发消息。消息传输完成后，进程必须销毁这个连接。 Reliable data transfer service: TCP 保证一方发送的数据会不重复不以漏地传输到另一方，且接收消息的顺序和发送消息的顺序相同。 TCP 中还有一些拥塞控制机制，当发送方和接收方之间的网络过于拥塞时，TCP 会暂时挂起发送进程以缓解网络的拥塞程度。该机制并不是直接为通信进程服务的，而是为整个互联网提供的福利。\nUDP Services UDP 是一个轻量级的传输协议，它只提供最少的能保证正常运转的服务。UDP 在开始通信之前不会握手；传输不具有可靠性，即不能保证发送的数据一定会被收到；此外，在 UDP 中发送的消息可能会乱序地到达接收方。UDP 中也没有拥塞控制机制，发送方可以以任何 (物理限制以内的) 速率把数据送出去。\nSecuring TCP\n无论是 TCP 还是 UDP 都不会对数据进行任何加密，这使得用户数据在传输途中随时可能被窃取。因此互联网社区推出了 TCP 的一个增强服务：Transport Layer Security (TLS)。有 TLS 增强的 TCP 除了可以提供 TCP 原有的所有服务，还可以提供一些安全服务，例如 encryption, data integrity, end-point authentication 等。\n值得注意的是 TLS 不是和 TCP, UDP 同一级别的传输协议，它只是一个“增强扩展包”。想要使用 TLS 需要在客户端和服务器端都安装 TLS 代码。TLS 提供一套和 TCP 几乎相同的 API 接口，用户把信息传输给 TLS socket 后，TLS 对数据做加密，然后传给 TCP socket，TCP 将数据传到另一端的 TCP socket 后，TCP 把加密数据传给 TLS，TLS 完成解密后将数据通过 TLS socket 提供给上层应用。\nServices Not Provided by Internet Transport Protocols 值得注意的是无论是 TCP 还是 UDP 都没有提供 throughput 或 timing 的保证，但这并不意味着即时通讯软件无法在互联网中使用，因为应用的开发者尽可能保证了它们的产品在糟糕的网络环境下也能正常运转。\n大部分的网络应用 (例如电子邮件、文件传输、远程控制) 都采用 TCP 协议，因为 reliable data transfer 对它们来说非常重要。一些网络电话应用对数据丢失容忍度较高，可能会采取 UDP 协议来绕过 TCP 的拥塞控制和 packet overhead；但由于很多防火墙会拦截大部分的 UDP traffic，所以网络电话应用通常会把 TCP 当作 UDP 失效时的后备选项。\n2.1.5 Application-Layer Protocols 之前我们讨论的都是下层如何传输 message，但 message 本身的结构和内容也十分重要。应用层协议 (application-layer protocol) 负责这一部分。通常来说应用层协议会定义：\nmessage 的类型 (request/response etc.)； 各种类型的 message 的语法、各个字段的语义； 一系列规则，定义一个进程应该什么时候以什么方式发送 message。 我们需要注意区分网络应用和应用层协议：后者只是前者的一个组成部分 (不过是很重要的一部分)。以网页为例，网页这个应用包含了文档的格式标准 (HTML)、网页浏览器、网页服务器，以及应用层协议。网页所采用的 HTTP 协议规定了浏览器和服务器交换数据的方式，只是网页这一应用的一个组成部分。\n2.1.6 Network Applications Covered in This Book 本书讨论 5 个重要的应用：网页、电子邮件、目录服务、视频流和 P2P。\n2.2 The Web and HTTP 在 20 世纪 90 年代初，因特网仍然只是一个研究员、学者、高校学生远程连接、传输数据的小圈子。但 World Wide Web 这一应用的出现让因特网火爆全球。网页最大的特点就是提供 on demand 的服务，用户可以在任意时刻获取信息，而不是像看电视，听收音机那样要在指定的时间守候。\n2.2.1 Overview of HTTP 超文本传输协议 (HyperText Transfer Protocol, HTTP) 是网页使用的应用层协议，处在整个应用的核心位置。HTTP 分为客户端程序和服务端程序，这两个程序通过交换 HTTP message 通信，HTTP 定义了 message 的结构和消息交换的方式。\n首先介绍一些概念：一个 Web page (aka. document) 包含一系列的对象，一个对象就是一个可以通过 URL 索引的文件 (HTML, JPG, Javascript, CSS 等等)。Web page 包含的对象中有一个是 base HTML 文件，该文件通过 URL 去索引别的对象。每个 URL 都有 host name 和 path name 两个部分。例如\nhttp://www.someSchool.edu/someDepartment/picture.gif 中 www.someSchool.edu 是 host name，/someDepartment/picture.gif 是 path name。\nHTTP 规定的 client-server 交互方式简单来说就是 client 向 server 发送 HTTP request，server 收到后向 client 发送 HTTP response。HTTP 使用 TCP 作为下层的传输协议，因此 TCP connection 建立后，在 client 眼中它只要把 HTTP request 发送到 socket，然后等一会儿这个“神奇的小门”就会把 HTTP response 呈现出来；在 server 眼中它只要从 socket 中取出 HTTP request，分析后把相关的数据用 socket 传回去即可。计算机网络的层状结构使得 HTTP 这样的顶层协议完全不需要担心数据丢失、重新发送等问题，这些细节都由 TCP 以及更下次层的协议栈搞定。\n服务器端不会存储任何的额外信息。例如如果 client 连续两次请求同一个文件，server 就会连续发两次，而不会智能地在第二次回复“你已经请求过这个文件了”。因此 HTTP 是一种无状态协议 (stateless protocol)。\n2.2.2 Non-Persistent and Persistent Connections 在许多网络应用中 client 和 server 之间会进行多次通信，于是一个需要思考的问题是应该为每一次通信建立一个 TCP connection 还是用一个 TCP connection 完成多次通信。前者被称为 non-persistent connection，后者被称为 persistent connection。这两者各有利弊，虽然 HTTP 默认 persistent，但 client/server 可以选择将其配置为 non-persistent。\nHTTP with Non-Persistent Connections 在 non-persistent 的连接中，client 向 server 索取一个页面 (base HTML + 10 JPG) 会经历如下的过程：\nclient 与 server 建立 TCP connection，并向 server 发送 HTTP request。 server 接收到请求后，将相关的文件传输回去，并告诉 TCP 关闭连接 (连接不会直接关闭，会等 client 接收到文件再关闭)。 client 接收到文件后 (此时 connection 正式关闭)，发现 HTML 文件中索引了 10 张图片，于是用 step1\u0026amp;2 的方式将 10 张图片拿到手。 可以看到在 non-persistent connection 中，每个 TCP connection 只能传输一个对象。不过上述过程也有一些优化的空间，比如获取图片时 client-server 之间可以并行地开多个 connection 一起传输，这样可以节省时间。\n之前的描述中我们简化了建立连接的过程，事实上建立 TCP connection 有一定的 overhead。我们定义 round-trip time (RTT) 为一个 packet 从 client 到 server 再回到 client 所需的时间，client 和 server 之间完成一个对象的传输需要经历“三步握手”—— client 向 server 发送一个 segment、server 回复一个 segment (此时连接建立)、client 向 server 发送 request，然后 server 将对象文件以流水线的方式通过 connection 发送回来。获取一个对象总共需要的时间为 $$ 2\\times RTT+\\frac{Size(object)}{\\text{server\u0026rsquo;s transmission rate}} $$\nHTTP with Persistent Connections 建立 persistent connection 可以免去创建连接的 overhead，而且多次 request 可以用流水线的方式发送，不需要等前一个 request 得到 response 后再发送下一个，因此效率很高。\n2.2.3 HTTP Message Format HTTP Request Message 一个 HTTP request message 的通用格式如下：\nmethod URL Version \\r\\n // Request line HeaderFieldName: value \\r\\n /* */ ... /* Header lines */ HeaderFieldName: value \\r\\n /* */ \\r\\n ... /* */ ... /* Entity body */ ... /* */ request message 的第一行被称为 request line，后续的若干行称为 header line。下面是一个具体的例子：\nGET /somedir/page.html HTTP/1.1 Host: www.someschool.edu Connection: close User-agent: Mozilla/5.0 Request line 中，GET 是一个 method (最常用)，通常用于从服务器获取内容；URL 指定了服务器中文件的路径；Version 指定了 HTTP 版本。Header line 中，Host 指定了主机地址；Connection: close 表示建立一个 non-persistent 的连接，本次传输完成后就关闭；User-agent 指定了客户端 (浏览器) 的版本，服务器可以根据版本返回更加适配的 message (比如同一个文件的不同版本)。除此之外还有很多的 header line 可以选择。\nGET 方法后面没有 entity body，但其他方法后面是可以有 entity body 的，例如 POST 方法通常用于填写网页中的表格，用户填写的内容就放在 entity body 中传给服务器。(注：值得一提的是事实上现在大部分的应用还是使用 GET 方法来传输填表结果，它们会把填写的内容放到 URL 里，比如填写了 apple 和 banana，那么 URL 就会形如 www.somesite.com/fruitsearch?apple\u0026amp;banana。)\n除了 GET 和 POST，HEAD 方法和 GET 类似，但服务器不会返回请求的对象，通常用于 debugging；PUT 方法用于向服务器上传文件；DELETE 方法用于在服务器中删除文件。\nHTTP Response Message 一个 HTTP request message 的通用格式如下：\nversion StatusCode Phrase \\r\\n // Status line HeaderFieldName: value \\r\\n /* */ ... /* Header lines */ HeaderFieldName: value \\r\\n /* */ \\r\\n ... /* */ ... /* Entity body */ ... /* */ Response message 的第一行被称为 status line，后续的若干行被称为 header line。下面是一个具体的例子：\nHTTP/1.1 200 OK Connection: close Date: Tue, 18 Aug 2015 15:44:04 GMT Server: Apache/2.2.3 (CentOS) Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT Content-Length: 6821 Content-Type: text/html (data data data data data ...) 括号中的 (data data ...) 表示 entity body 的内容 (即 client 要的数据)。\nstatus line 中，HTTP/1.1 表示了 protocol version，200 OK 是 status code 和对应的状态描述。常见的 status code 如下：\n200 OK：请求成功。 301 Moved Permanently：请求的资源已经被永久移除。该资源的新地址会在 header line 区域中以 Location: ... 的形式给出。 400 Bad Request：请求无法解析。 404 Not Found：请求的东西不存在。 505 HTTP Version Not Supported：HTTP 协议版本不支持。 header line 中，比较有意思的一些 line 包括：Connection: close 告诉 client 该消息传输完成后 TCP connection 就会被关闭；Date: 中的日期指的是服务器接收到请求，将资源提取出来的时间 (而不是文件的创建时间)；Content-Type 指明了返回文件的类型，文件的类型由该字段决定而不由其扩展名决定。\n浏览器的版本、类型，用户配置，以及当前本地是否有 cached 的对象旧版本……这些因素都会影响 client 发送 request 时包含哪些 header line，在服务器端影响因素是类似的。\n2.2.4 User-Server Interaction: Cookies 我们之前提到 HTTP 是一个 stateless 的协议，但很多时候服务器希望能识别用户以及记录用户的状态，从而提供更好的服务/将一些用户写入黑名单。HTTP 使用 cookie 完成该功能。\nCookie 技术包含 4 个组成部分：(1) HTTP response message 中的 cookie header line (2) HTTP request message 中的 cookie header line (3) 浏览器负责管理的本地 cookie file (4) 服务器端存储 cookie 相关信息的数据库。 Cookie 的工作流程如下：\n假设一个新用户第一次访问某网站 (发送 request message)，该网站识别到这是一个新用户后，会在数据库中为该用户创建一个 cookie id、在数据库中存储一些用户相关的信息，并在 response message 中加入一条 cookie header line，格式为 Set-cookie: cookie-id。 浏览器处理 response message 发现形如 Set-cookie 的 header line 后，会把该服务器分配的 cookie id 存入本地的一个 cookie file 中。 之后这个用户如果再访问该网站，浏览器会检索 cookie file，发现有对应的 cookie id 则会以 Cookie: cookie-id 的形式在 request message 中添加一个 cookie header line。服务器处理 request message 时则可以根据 cookie-id 在数据库中调取该用户相关的信息。 尽管 Cookie 可以优化用户的上网体验，但其在隐私泄漏上的问题也使其倍受争议。\n2.2.5 Web Caching Web cache (也称 proxy server) 通常由 ISP 购买和安装，其作用和计算机系统中的 cache 类似：当用户希望从真正的服务器获取文件时，它会和 proxy server 建立 TCP connection，proxy server 会首先检查自己本地有没有该文件，如果有就直接传回给用户，如果没有则会与真正的服务器建立一个 TCP connection，获取文件后一方面传回给用户，一方面在自己本地留一个副本以便后续用户直接取用。\nWeb cache 有两点好处：一方面它与用户机器建立连接、传输数据的速度更快，可以优化用户的 delay；另一方面在一个小局域网中安装 web cache 可以防止大量的请求外溢到因特网中，从而减少因特网的流量压力，减少整个网络的 queuing delay 等等。\nThe Conditional GET 所有的类 cache 策略都要考虑数据一致性的问题。HTTP 协议提供了 conditional GET 这一机制来使 cache 完成和服务器的同步。具体来说，当 cache 希望确认自己手上的副本是否是最新版时，它会向真正的服务器发送一个 GET request，其中增加一个 header line：If-modified-since: xxx。服务器检查本地文件的最后修改时间，如果正好匹配则会返回空消息告诉 cache 副本已是最新 (status code 为 304 Not Modified)，否则会将新版本传回。\n2.2.6 HTTP/2 2015 年标准化的 HTTP/2 相较于 HTTP/1.1 的主要优势是它能够只使用一个 TCP connection 完成 response multiplexing。\nHTTP/1.1 默认使用 persistent TCP connection，即只使用一个 TCP connection 从一个服务器获取多个文件。这样的做法存在一个 Head of Line (HOL) blocking 的问题：假设当前网页的第一个 object 是一个特别大的视频，后面跟着的是一堆小的 object，那么 HTTP/1.1 按顺序传输会导致在第一个 object 上花费很多时间，从而整个网页很久都完全显现不出来。为了绕过这个问题，HTTP/1.1 会开很多个 TCP connection 来并行传输。不过多个 TCP connection 会共享带宽，这使得网络应用会尽可能“多开一点” TCP connection 以占取更大份额的带宽 (比如两个应用各开一个，那么一人一半带宽，但如果有人恶意开了 10 个连接，他就能占据 10/11 的带宽)。\nHTTP/2 Framing HTTP/2 解决这个问题的方法类似于操作系统的分时多任务：在 HTTP/1.1 中一个 response message 没法拆开，但 HTTP/2 允许将一个大的 message 拆成若干个 frame，然后多个 message 轮流一人一个 frame 地传输，这样小 message 就可以很快地传完。\n该策略的技术难点是如何将大的 message 拆分。HTTP/2 里专门设计了一个 framing sub-layer，负责 message 的拆分和重组。\nResponse Message Prioritization and Server Pushing HTTP/2 在“分时多任务”的基础上支持一定程度的“用户自定义”，例如用户可以为各个 request 设置优先级、依赖关系等等。\nHTTP/2 的另一个特性是允许 server 对一个 request 返回多个 response。例如用户请求一个网页，服务器自动分析发现这个网页附带一些 object，就可以 response 时 push 一些额外的 object 给客户端，这样在用户发出 object 请求之前就返回文件，省去了一些延迟。\n2.3 Electronic Mail in the Internet 电子邮件系统主要由三个部分组成：user agent, mail server 和简单邮件传输协议 (Simple Mail Transfer Protocol, SMTP)。每个电子邮件用户都在自己的 mail server 上有自己的邮箱 (mailbox)。user agent 可以理解为在用户主机上和自己的 mail server 交互，操控邮箱的软件。假设 Alice 给 Bob 发送邮件，首先 Alice 的 user agent 将邮件上传到 Alice 的邮箱中，然后 mail server 负责将邮件发送到 Bob 的 mail server (更准确地说，是将该邮件 append 到 message queue 中，等待发送)，Bob 的 mail server 接收到邮件后将其存放在 Bob 的邮箱中。当 Bob 打开自己的 user agent 查看邮件时，user agent 将邮件内容从 mail server 上抓取下来。如果 Alice 的 mail server 迟迟无法发送成功，它在尝试多次后会删除这个 message 并向 Alice 返回发送失败。\nSMTP 协议负责的是不同 mail server 之间传输的部分。它使用 TCP 提供的 reliable data transfer service 传输邮件。SMTP 有 client 和 server 两个端，每个 mail server 既要运行 client 也要安装 server，它发送邮件时是 client，接收邮件时是 server。\n2.3.1 SMTP SMTP 是比 HTTP 古老得多的应用层协议。因此它有一些“过时的特征”，例如它要求整个 mail message 都要使用 7-bit 的 ASCII 码传输，这使得使用 SMTP 前后需要有 encoding/decoding 的额外步骤。\nSMTP 工作的基本流程为：\nmail server 将待发送的邮件放入 message queue 后，安装在 mail server 上的 SMTP 客户端发现有新邮件，于是根据其内容与目标地址建立 TCP connection，连接目标机器的 25 号端口。 TCP connection 建立后双方会经过一个握手过程，该过程中双方会交换邮件的发送人、接收人等信息。 握手完成后，正式开始邮件内容的传输。 下面是一个具体的例子：\nS: 220 hamburger.edu C: HELO crepes.fr S: 250 Hello crepes.fr, pleased to meet you C: MAIL FROM: \u0026lt;alice@crepes.fr\u0026gt; S: 250 alice@crepes.fr ... Sender ok C: RCPT TO: \u0026lt;bob@hamburger.edu\u0026gt; S: 250 bob@hamburger.edu ... Recipient ok C: DATA S: 354 Enter mail, end with \u0026quot;.\u0026quot; on a line by itself C: (data) C: (data) C: . S: 250 Mesage accepted for delivery C: QUIT S: 221 hmburger.edu closing connection 这里所有的行都是 client/server 直接通过 TCP 传输的内容。client 在这里使用了 HELO MAIL FROM RCPT TO DATA QUIT 等命令，server 对于每条命令都会返回 reply code 以及 (optional) 一些英文解释。\n值得注意的是 SMTP 使用 persistent TCP connection，即两个 mail server 之间可以通过一个 TCP connection 传输多封邮件。每封邮件的传输都从 MAIL FROM 开始，到传输完数据后的 . 结束。传输完所有邮件后 client 再使用 QUIT 退出。\n2.3.2 Mail Message Formats SMTP 对邮件内容的格式也有一定的要求。一封邮件除了其主体内容外还有若干 header line，其中 From 和 To 这两个 header line 必须有，Subject 等 header line 是可选的。一封典型的邮件内容如下：\nFrom: alice@crepes.fr To: bob@hamburger.edu Subject: Searching for the meaning of life. (body) (body) (body) ... 需要注意的是之前提到的 MAIL FROM RCPT TO 和这里的 From 和 To 不一样：前者是两个 mail server 握手阶段使用的命令，后者是邮件本身内容的一部分。\n2.3.3 Mail Access Protocols 有人认为 Bob (接收者) 没有必要拥有一个额外的 mail server，他自己的终端设备就可以是 server，这样发送者直接把邮件发送到它的终端设备上就好。但一个问题是用户的终端设备并不一定一直处于联网状态 (比如没信号，或者没电关机了)，这样发送者就会发送失败。因此我们总是需要一台 24 小时待命的服务器负责接收邮件，Bob 在自己 available 的时候再去查看邮件。\nmail server 向 mail server 发送邮件使用 SMTP 协议，Alice (发送者) 向自己的 mail server 上传邮件也可以使用 SMTP 协议 (或者 HTTP) 协议，但在 Bob (接收者) 这一端，他不能使用 SMTP 协议，因为他需要的是一个 pull 操作，而 SMTP 是一个 push 协议。一般情况下，如果接收者使用网页版的 e-mail 或者手机应用，user agent 会使用 HTTP 协议来获取邮件；另外一种方式 (例如 Microsoft Outlook)，则是使用 Internet Mail Access Protocol (IMAP) 协议来获取邮件。这两个协议都可以让 Bob 对位于 mail server 中的自己的邮箱里的内容进行访问、修改、标记等等。\n2.4 DNS - The Internet\u0026rsquo;s Directory Service 一台主机在网络中有多种”称呼方法“，最常见的 identifier 是 hostname，例如 www.facebook.com。hostname 对人类非常友好，但提供的信息有限，其不固定的长度也不便于路由器处理。因此网络实现中更普遍使用的 identifier 是 IP 地址 (IP address)。IP 地址 (IPv4) 共占 4 个字节，用 4 个 [0,256) 的整数表示。IP 地址有着严格的等级结构，就像 postal address 一样，越往后得到的信息越详细越细节。\n2.4.1 Services Provided by DNS 域名系统 (domain name system, DNS) 的主要任务是将 hostname 翻译成对应的 IP 地址。DNS 是一个应用层协议，在服务器端它有一群分布式的 DNS server 存储域名信息。DNS 协议基于 UDP 运行，默认端口号是 53。\nDNS 通常被 HTTP, SMTP 等其他应用层协议使用，例如 HTTP 协议想要发送 request message 时，会启动 DNS 应用的客户端，将域名发送给 DNS server，DNS server 返回对应的 IP 地址，然后 HTTP 通过 IP 地址建立 TCP connection。DNS 解析的步骤是通信过程的一个额外的 delay。\n除了域名解析，DNS 还提供以下的服务：\nHost aliasing：一台有着比较复杂的 hostname 的机器还可以有一些更好记的别名。原本的 hostname 称为 canonical hostname，别名则称为 alias hostname。DNS 提供将 alias hostname 翻译成 canonical hostname (以及 IP 地址) 的服务。 Mail server aliasing：和 host aliasing 类似，mail server 也可以有更好记的别名，DNS 提供翻译服务。 Load distribution：有很多网页背后会使用一群服务器来提供支持，每台服务器有各自的 IP 地址，但它们共享一个 hostname。当 DNS 解析这样的 hostname 时，它会返回一个 IP 地址的 list，不过每次请求它返回的结果都会 shift 一下，这是因为大部分的协议通常选择 list 的第一个 IP 地址发送请求，每次 shift 一下可以使得各个服务器均匀地承受流量。 2.4.2 Overview of How DNS Works 最简单的想法是使用一台 DNS server 处理所有的请求，可惜这样简单的设计至少有如下的一些问题：\nA single point of failure：只要这台 DNS server 挂了，全球的 DNS 服务就都挂了。 Traffic volume：这台服务器承受全球的 DNS request 的流量，会导致严重的 delay。 Distant centralized database：地球上总有一些地区离这台服务器很远，这些地区使用 DNS 服务会有很高的 delay。 Maintenance：这一台服务器需要大得惊人的容量来存储所有的 IP 地址，还需要不断更新。 因此，分布式成为了 DNS server 必须的选择。\nA Distributed, Hierarchical Database 为了解决上面的问题，DNS 使用了大量的服务器，以 hierarchical 的方式组织起来分布在全世界。DNS 等级体系中共有三类服务器：\nRoot DNS server：全球共有 1000 多个，它们是 13 个不同的 root server 的复制，它们的主要任务是根据顶级域名提供对应的 TLD server 的 IP 地址。 Top-level domain (TLD) server：每一个顶级域名——如 com org net edu，以及国家顶级域名——如 us cn jp fr 都各自有对应的 TLD server (或 server cluster)。它们的主要任务是根据下一级域名提供 authoritative server 的 IP 地址。 Authoritative DNS server：每一个接入公网的组织都必须提供外界可访问的 DNS 记录，这些记录保存在组织的 authoritative DNS server 上。 除了这三类服务器，还有一类服务器称为 local DNS server (aka. default name server)，它不属于等级体系中但也非常重要，可以理解为主机使用 DNS 服务的 proxy server。\n一台主机通过 DNS 服务查询另一台主机的 IP 地址的过程大致如下图所示。该查询过程是 iterative + recursive 形式的。Local DNS server 作为 requesting server 的代表，顺序地向各个层级的 DNS server 发送请求，最终将结果返回给 requesting server。\n该查询过程也可以是 fully recursive 的，每一个服务器都把整个任务交给下一级服务器，并将最终结果返回给上一层服务器。\n可以看到不论是哪种顺序，在该例子中 requesting server 总是需要 8 次消息传输才能获得 IP 地址，效率不高。\nDNS Caching DNS caching 是减少 DNS 查询过程 delay 的一项关键技术。各个层级的 DNS server 内部都有 cache 维护hostname 到 IP 地址的映射表。这样如果有多次对同一个 hostname 的查询，DNS server 就不用把查询下放到底层的 authoritative server 而可以直接返回。不过由于 hostname 的 IP 地址是可以变的，通常 DNS server 两天就会 flush 一次 cache。\nCache 中除了存储 hostname 的 IP 地址，还可以存储一些 DNS server 的 IP 地址，这样的好处是可以绕过上级 server 直接发送查询给下层 server。\n2.4.3 DNS Records and Messages 各级 DNS server 完成了对分布式 DNS 数据库的抽象。DNS 数据库中存储的数据称为 resource record (RR)。一条 RR 是一个四元组 (Name, Value, Type, TTL)。其中 TTL 表示该数据的生存周期，即服务器应该过多久将其从 cache 中 flush 掉。剩下的三个属性：\n若 Type=A，则 Name 是一个 hostname，Value 是一个 IP 地址，A record 是 hostname-IP mapping。 若 Type=NS，则 Name 是一个 domain，Value 是保存了该 domain 下所有 host 地址的 authoritative server 的 hostname。NS record 用于指引 DNS server 继续深入 query chain。 若 Type=CNAME，则 Name 是一个 alias hostname，Value 保存了对应的 canonical hostname。CNAME record 用于 host aliasing 的翻译。 若 Type=MX，则 Name 是一个 mail server 的别名，Value 保存了对应的 canonical hostname。MX record 用于 mail server aliasing 的翻译。 如果一个 DNS server 是某个 hostname 的 authoritative server，那么它里面会存储该 hostname 的 A record。如果一个 DNS server 不是某个 hostname 的 authoritative server，那么它会存储包括了该 hostname 的 domain 的 NS record，以及一条记录 NS record 中主机的 IP 地址的 A record。\nDNS Message DNS message 的格式如下：\nIdentification Flags // Number of questions Number of answer RRs // 12 bytes Number of authority RRs Number of additional RRs // ---------------------------------------------------------------------- Questions (variable number of questions) // Name, type field for a query ---------------------------------------------------------------------- Answers (variable number of RRs) // RRs in response to query ---------------------------------------------------------------------- Authority (variable number of RRs) // Records for authoritative servers ---------------------------------------------------------------------- Additional information (variable number of RRs) // Additional info that may be used query 和 reply message 有着相同的格式：\nheader section 共 12 个字节，由一系列的字段组成。第一个字段是 16 bit 的 identifier，reply message 的 identifier 是对应 query 的 identifier，这样 client 就可以把请求和回复对应上；Flag 字段包括指明这是 query 还是 reply 的 flag，DNS server 是否是 authoritative server 的 flag，要求是否使用 recursion 的 flag 等。此外还有 4 个计数的字段。 question section 包含询问信息，主要有询问的 name 和 type。 answer section 由 reply message 使用，包含一条或多条 resource record。 authority section 包含其他 authoritative server 的 record。 additional section 包含其他的有用信息，比如某些 canonical hostname 的 IP 地址。 Inserting Records into the DNS Database 想要新建网站的人需要通过 registrar 获得域名且需要提供自己的 hostname 和 IP 地址，数据库管理员负责将数据录入数据库。\nDNS Vulnerabilities\n对 DNS 的攻击主要有以下几类：\nDDoS 攻击：历史上发生过两次重大的针对 DNS 的 DDoS 攻击：一次攻击针对所有的 root DNS server，由于 root server 有较好的保护机制，且大多数的 local DNS server 的 cache 可以绕过 root server 直接走下层，所以该攻击没有取得好的效果。另一次攻击针对 top-level domain DNS server，这次攻击就比较有效。 man-in-the-middle attack：截获 DNS query，并返回一个虚假的 reply 给用户。 DNS poisoning attack：和中间人攻击类似，不过这种攻击的目的是将 DNS server 将错误的信息写入 cache，直接污染数据库。 2.5 Peer-to-Peer File Distribution 前面章节介绍的所有应用都是 client-server 模式的，应用的正常运转需要一直处于运行状态的服务器。在 P2P 模式中，互相连接的 host 可以直接交互，节省了一些 overhead。\nScalability of P2P Architecture 考虑如下的一个简化的场景：有 $N$ 个节点需要服务器上的一个文件，该文件的大小为 $F$ bits。服务器上传的速度是 $u_s$，第 $i$ 台客户机下载的速度是 $d_i$，上传的速度是 $u_i$。\n在 client-server 架构中，没有人帮助服务器分发文件，所以 $N$ 个节点共 $NF$ bits 的数据都要由服务器自己上传。此外每个节点下载自己的文件需要时间。假设上传和下载可以并行地完成，令 $d_{min}=\\min\\{d_1,\\cdots, d_n\\}$，则 $$ D_{cs}\\geq \\max\\left\\{\\frac{NF}{u_s},\\frac{F}{d_{min}}\\right\\} $$ 在 P2P 架构中，一方面第一份文件需要服务器自己上传，一方面每个节点下载自己的文件需要时间，一方面每个节点在下载的同时也参与到上传中，后续的上传工作可以合力完成。所以 $$ D_{P2P}\\geq \\max\\left\\{\\frac{F}{u_s},\\frac{F}{d_{min}},\\frac{NF}{u_s+\\sum_{i=1}^nu_i}\\right\\} $$ 可以证明在精巧的设计下两个时间都可以达到下界。可以看到 client-server 模式下时间是关于 $N$ 的线性函数， P2P 模式下时间关于 $N$ 的函数上升速度缓慢且有极限，所以 P2P 模式的 scalability 更好。\nBitTorrent BitTorrent 是当下最流行的 P2P 文件分发协议之一。这里简单介绍一些 BitTorrent 的机理。在 BitTorrent 中参与一个文件 distribution 的 peer 的集合称为一个 torrent。每个 torrent 中都有一个节点称为 tracker，一个节点新加入 torrent 时会到 tracker 那里注册，tracker 会每隔一段时间检查每个节点是否还在 torrent 中并更新 active list。\n对于一个新加入的节点，tracker 会随机选择一些 peer 并将其 IP 地址发送给新节点，新节点会尝试和这些 peer 建立 TCP connection，成功建立 connection 的 peer 被称为 neighboring peer。由于 torrent 中随时会有节点退出也随时会有新节点加入，一个节点的 neighboring peer 集合是动态变化的。\n文件的共享以 chunk (256KB) 为单位。在任意时刻，一个节点手里会有该文件的某些 chunk，它的目标是收集自己还没有的其他 chunk，所以每隔一段时间节点会向自己的 neighbor 询问他们手里拥有哪些 chunk，并根据信息向一些 neighbor 发送索求 chunk 的申请。于是对于每个节点来说，它有两件事情需要考虑：一是应当先去索要哪些 chunk，二是如何应付别的节点发送过来的 request。\n对于第一个问题，BitTorrent 采取 rarest first 的策略，即优先申请那些自己没有的，且在 neighbor 中出现次数最少的 chunk。这样的好处是可以让那些比较稀有的 chunk 迅速在网络中传播开来，提高文件分享的速率。\n对于第二个问题，BitTorrent 采取了一个非常聪明的 trading algorithm，称为 tit-for-tat。每个节点会实时维护自己的所有 neighbor 向自己传输文件的速率 (每过 10s 刷新，更准确地说是在一个 time interval 内传输的数据量)，并选择排名前 4 高的节点向它们发送数据。排名前 4 的 neighbor 被称为 unchoked。此外每过 30s 节点会随机选择一个自己的 neighbor 并向其发送数据 (不论其排名如何)，这个节点被称为 optimistically unchoked。除了这 4+1 个 neighbor，剩下的 neighbor 都被称为 choked，它们无法获得该节点的数据。\nunchoked 和 optimistically unchoked 各自有道理。unchoked 的选择使得节点之间倾向于互相帮助互惠共利，同时一定程度上避免了一些只索取不付出的“吸血节点”来捣乱。optimistically unchoked 的选择可以理解为向一个“陌生”节点示好，尝试与其建立“外交关系”，如果陌生节点积极的予以反馈，那么这对节点就可能逐渐地将对方升级为自己的 top 4。此外，一个刚进入网络的节点手里没有任何 chunk，无法向外界提供数据，所以刚开始不可能成为任何节点的 top 4。optimistically unchoked 可以让这些萌新节点免费获得一些初始成本，帮助其快速融入网络。\n2.6 Video Streaming and Content Distribution Networks 2.6.1 Internet Video Video 的本质是 sequence of images，其最显著的特点就是 high bit rate，因此视频会消耗大量存储，视频的传输会消耗大量的流量。当然，我们可以通过压缩技术来获得同一个视频的不同码率的版本，码率越高，视频质量越高，消耗资源也越大。\n2.6.2 HTTP Streaming and DASH 在 HTTP streaming 中，视频文件和普通的文件无异，有一个可以索引的 URL。client 可以通过 HTTP GET 指令来获取视频。由于视频较长获取较慢，通常客户端会准备一个 client application buffer，GET 指令不断获取数据存入 buffer，当 buffer 中的数据量超过一个阈值时，客户端程序就会开始播放——从 buffer 中抓取 video frame、解压、呈现在用户屏幕上。这样客户端就实现了边下载边观看。\nHTTP streaming 的一个问题是：无论当前用户的网络状况如何，它都只能获取固定码率的视频，因此网速不好时视频播放容易卡顿。动态自适应流媒体 (Dynamic Adaptive Streaming over HTTP, DASH) 技术致力于缓解该问题。在 DASH 中一个视频会有多个不同码率的版本，以不同的 URL 存放在 server 中。此外 server 里有一个 manifest file 提供了可选择的码率版本和对应的 URL。一个完整的视频被划分成了若干小的 chunk，client 首先会获取 manifest file，了解不同的码率版本，然后根据当前的网络状况选择一个合适的码率版本用 HTTP GET 获取一个 chunk，获取的过程中客户端同时收集本次获取的网速等信息，从而决定下一个 chunk 选哪个版本。这样，DASH 允许了 client 在多个不同版本的视频中自由切换。\n2.6.3 Content Distribution Networks Content provider 需要建立 data center 来存储提供给用户的视频资源。正如 DNS server 只建一个有诸多弊端，如果服务商只建一个超大的 data center，就会有部分地区延时高、单点崩溃意味着全盘崩溃等问题。因此几乎所有的 video-streaming 公司都采用了 Content Distribution Network (CDN)，建立一个分布式的服务器群，服务器的选址通常有如下两种策略：\nEnter Deep：将服务器打入到 access network 内部，海量部署小服务器，尽可能靠近用户以减小用户的 delay 并提高 throughput。这种方式成本和后续维护的代价都比较高。 Bring Home：建立数量较少规模较大的服务器，部署在 IXP 中。这种方式代价较低但用户体验也相对较差。 通常来说 CDN 不会让每台服务器都存储所有资源的副本，而是让服务器扮演 cache 的角色。如果用户索求的资源在当前服务器中没有，服务器会向上层做 pull request，得到后发送给用户的同时在自己本地留一个副本。\nCDN Operation 这里以一个例子讲述 CDN 的运行过程。假设 content provider 公司 NetCinema 使用了第三方 CDN 公司 KingCDN 的服务。NetCinema 的一个视频的 URL 是 video.netcinema.com/abc，那么用户获取视频的流程如下：\n用户访问该视频链接时，用户主机发出了一条关于 vidio.netcinema.com 的 DNS request。 用户的 Local DNS server (LDNS) 一层层访问到 NetCinema 公司的 authoritative server 并将其发送请求。authoritative server 注意到该域名的前缀是 video，知道视频其实是交给 KingCDN 托管的，所以它返回了 KingCDN 的域名给用户的 LDNS，从而将用户 redirect 到 KingCDN。 LDNS 收到了一个新域名，于是它再次发送 DNS query，一层层访问到了 KingCDN 的 authoritative server，authoritative server 会选择一个 CDN server 并将其 IP 地址返回给 LDNS。 LDNS 将 IP 地址给用户后，用户主机与指定的 CDN server 建立 TCP connection 并获取视频。 Cluster Selection Strategies 上述过程中有一步“选择一个 CDN server”，这其中很有讲究。CDN deployment 的核心便是 cluster selection strategy。CDN 的 authoritative server 接收到 LDNS 的 DNS query 时可以获知用户的 IP 地址，从而获得一些用户相关的信息。authoritative server 可以根据这些信息选择一个“最好“的 CDN server。\n最简单常用的一个策略是 geographically closest。地理距离近通常意味着传输时间短，但这个策略有时不灵光——第一，地理距离短并不一定意味着 link 少；第二，有些用户的 LDNS 和终端设备之间可能隔了很远；第三，该策略完全没有考虑网络的动态状况。因此，除了该策略外 CDN 还可以通过一些 real-time measurement 来影响 CDN server 分配的决策。\n2.6.4 Case Studies: Netflix and YouTube Netflix Netflix 的特色在于它有一个巨大的 Amazon cloud 处于核心位置，Amazon cloud 负责视频的处理，不同版本的生成，并将内容推送到 CDN server 中。由于 Netflix 建立了自己的 private CDN network，CDN operation 的步骤不像上一节那样有一个 redirect 的过程，Amazon cloud 可以直接指定 CDN server。此外，Netflix 使用的是 push cache，即 Amazon cloud 会在非高峰时间将内容主动推送到 CDN server 上，而不是让 CDN server 动态地在 cache miss 时索取。\nYouTube 类似于 Amazon cloud，Google data center 会完成视频的处理，版本生成等工作。YouTube 也有自己的 private CDN network。和 Netflix 不同的地方在于：YouTube 使用 pull cache，以及 YouTube 不支持 DASH，只能让用户手动选择码率后使用 HTTP streaming。\n2.7 Socket Programming: Creating Network Applications 略\n","date":1666310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666310400,"objectID":"64927882c3ac1613eaede8e85ab65306","permalink":"https://kristoff-starling.github.io/notes/booknotes/network-topdown/ch02/","publishdate":"2022-10-21T00:00:00Z","relpermalink":"/notes/booknotes/network-topdown/ch02/","section":"notes","summary":"2.1 Principles of Network Applications 2.1.1 Network Application Architectures 2.1.2 Processes Communicating Client and Server Processes The Interface Between the Process and the Computer Network Addressing Processes 2.1.3 Transport Services Available to Applications Reliable Data Transfer Throughput Timing Security 2.","tags":null,"title":"Chapter 2: Application Layer","type":"docs"},{"authors":[],"categories":[],"content":"TF with Sanitizers Address/Memory/UB Sanitizer asan/msan: build fail (GCC/Clang) ubsan: stuck during linking GitHub issue (#50892): \"Currently we don't officially support an OSS ASAN build, although one is in the long term roadmap.\"\nAug 2, 2021\nCompute Sanitizer Don\u0026rsquo;t need additional flags for compilation, even a binary version works (?)\nCommand: compute-sanitizer --tool memcheck python3 test.py\nimport tensorflow as tf _ = tf.config.list_physical_device('GPU') =\u0026gt; terminate w/o error\nimport tensorflow as tf _ = tf.abs(1) =\u0026gt; deadlock\n","date":1665014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665014400,"objectID":"e76b6dbbe2109a79aa27398f7cbc9e3c","permalink":"https://kristoff-starling.github.io/slides/20221007/","publishdate":"2022-10-06T00:00:00Z","relpermalink":"/slides/20221007/","section":"slides","summary":"TF with Sanitizers Address/Memory/UB Sanitizer asan/msan: build fail (GCC/Clang) ubsan: stuck during linking GitHub issue (#50892): \"Currently we don't officially support an OSS ASAN build, although one is in the long term roadmap.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":" 1.1 Extenional vs. Intensional View of Functions 1.2 The Lambda Calculu 1.3 Untyped v. Typed Lambda-Calculi 1.4 Lambda Calculu and Computability 1.5 Connection to Computer cience 1.6 Connection to Logic 1.1 Extenional vs. Intensional View of Functions 根据现代数学的观点，函数是一个关系的集合。一个函数 $f:X\\to Y$ 有定义域 $X$ 和值域 $Y$，$f\\subseteq X\\times Y$ 且对于任意 $x\\in X$，$(x,y_1)\\in f\\wedge (x,y_2)\\in f\\implies y_1=y_2$。我们将这种观念称作 function as graph。\n但 20 世纪以前很少有人用这样的方法看待函数。更早的关于函数的概念更多是 function a rule，即我们应当通过给出解析式的方式来定义一个函数。两个函数 extensionally equal 当且仅当它们的 input-output behavior 完全相同；两个函数 intensionally equal 当且仅当它们的解析式一样。\n在数学界人们普遍认为 function a graph 的观念更加简洁，因为它更触及函数的本质——有一些函数是无法写出解析式的。但在计算机科学中人们更喜欢使用 function as rule，因为计算机是一项具体的工程，我们不仅在意函数的外在行为，还必须关注一个函数应当如何计算，计算它有多少开销等等。\n1.2 The Lambda Calculu Lambda calculu 是一门关于 functions as formulas 的理论，其核心在于将函数表示成简单的表达式。它的简洁之处在于，我们可以将 \u0026ldquo;Let $f$ be the function that maps $x$ to $x^2$, then consider $A=f(5)$\u0026rdquo; 这句话写成： $$ A = (\\lambda x.x^2)(5). $$ 值得注意的是，上式中的 $x$ 是一个“局部变量”，它只用于描述函数的行为，把它换成 $\\lambda y.y^2$ 没有任何区别的。这样的变量称为 bound variable。\nLambda notation 的一大优势在于它可以非常轻松地表达高阶函数。比如将 $f$ 映射到 $f\\circ f$ 可以这样写： $$ \\lambda f.\\lambda x.f(f(x)). $$\n1.3 Untyped v. Typed Lambda-Calculi 当我们用 function a rules 的观点来看待函数时，我们不那么在意函数的定义域和值域。比如函数 $f=\\lambda x.x$。只要定义域和值域一样这个函数总是有意义的。我们可以说 $\\text{type}(f)=X\\to X$。一个稍复杂的例子是 $g=\\lambda f.\\lambda x.f(f(x))$，我们可以认为给 $g$ 传递一个 $X\\to X$ 类型的函数作为参数，它会返回 $X\\to X$ 类型的函数，所以 $\\text{type}(g)=(X\\to X)\\to(X\\to X)$。\nLambda Calculu 自由的定义域值域可以让我们做到一些更神奇的事情，比如若 $f=\\lambda x.x$，那么 $f(f)=f$。这件事在普通的数学中是做不到的，因为罗素悖论的原因，一个函数自己不可能在该函数的定义域中。\n一个有趣的问题\n令 $\\omega=\\lambda x.x(x)$，那么 $\\omega(\\omega)$ 是什么？ $$ \\begin{align} \\omega(\\omega)\u0026amp;=(\\lambda x.x(x))(\\omega)\\\\ \u0026amp;=(x(x))[x/\\omega]\\\\ \u0026amp;=\\omega(\\omega) \\end{align} $$ 该表达式不存在 normal form。\n在 type 方面 lambda calculu 分成以下几类：\nUntyped lambda calculu：从不对任何参数的类型进行指定，在非常自由的同时引入了一些不安全的因素 (比如函数可能会无法识别输入参数)。 imply-typed lambda calculus：为每个参数都完整地指定具体的类型，这样我们的函数就和集合论中的函数基本没有区别，$f(f)$ 这样的东西不会出现。 Polymorphically typed lambda calculu：介于前两者之间，在指定类型的时候允许多态，比如 $X\\to X$ 这样的类型。 1.4 Lambda Calculu and Computability Computability 是一个古老的问题：给定一个函数 $f:X\\to X$，我们如何判定它是否是可计算的？不同的研究者给出了不同的定义方法：\nTurning： 定义图灵机，并定义一个函数可计算当且仅当它在图灵机上可以得到结果。 Godel：定义了一个集合 general recurive function，并定义一个函数可计算当且仅当它在这个集合中。 Church：定义了 lambda calculu，并定义一个函数可计算当且仅当它可以被写为一个 lambda term。 后来人们证明：这三种定义是等价的，这就是著名的 Church-Turning theis。\n1.5 Connection to Computer cience lambda calculu 是一种非常理想化的编程语言，也是最简单的满足 Turning-complete 的编程语言。它常常用来定义和证明程序相关的性质。几乎所有的函数式编程语言 (Lisp, Haskell, Scheme etc.) 都是在 lambda calculus 的基础上，增添了一些自己的功能。\n1.6 Connection to Logic 在 19 世纪到 20 世纪初期，数学家对证明的本质有过一场争论。一个流派是所谓的 contructivist，他们认为证明一个东西存在就必须显式地将其构造出来；另一个流派是 classical logicians，他们认为只要能从一个东西不存在这个命题出发导出矛盾即可，不一定要给出构造。\n对于 contructivist 来说，一段证明必须是一个构造，或者说一个程序。lambda calculus 就是表达这种构造的一个符号系统。constructivist 并没有成为主流，但构造性的证明有其独特的价值。相较于反证法，构造性证明中提出的构造方法可以对多个领域提供帮助。\n","date":1664928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664928000,"objectID":"10de94d5dc2d00512909a528250fbf4d","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-formal-semantics/material/lambda-calculus/ch01/","publishdate":"2022-10-05T00:00:00Z","relpermalink":"/notes/coursenotes/nju-formal-semantics/material/lambda-calculus/ch01/","section":"notes","summary":"1.1 Extenional vs. Intensional View of Functions 1.2 The Lambda Calculu 1.3 Untyped v. Typed Lambda-Calculi 1.4 Lambda Calculu and Computability 1.5 Connection to Computer cience 1.6 Connection to Logic 1.","tags":null,"title":"Chapter 01: Introduction","type":"docs"},{"authors":null,"categories":null,"content":" 2.1 Syntax 2.2 Free and Bound Variable, $\\alpha$-Equivalence 2.3 Substitution 2.4 Introduction to $\\beta$-Reduction 2.5 Formal Definitions of $\\beta$-reduction and $\\beta$-equivalence 2.1 Syntax $\\fbox{Definition}$ (lambda term) 在一个无限的变量集合 $V$ 下 (将其中的变量命名为 $x,y,z\u0026hellip;$)，lambda term 可以由如下的 BNF 范式定义： $$ \\text{Lambda terms:}\\quad M,N::=x|(M\\space N)|(\\lambda x.M) $$ 上面的三种形式分别被称为 variable, application 和 lambda abstraction。\n书写 lambda 表达式的一些 convention：\n最外层的括号可以省略。 application 是左结合的，即 $M\\space N\\space P$ 指的是 $(M\\space N)\\space P$。 lambda abstraction 的函数体向右极大延伸，即 $\\lambda x.M\\space N$ 指的是 $\\lambda x.(M\\space N)$ 而不是 $(\\lambda x. M)\\space N$。 多个 lambda abstraction 可以合并了写，例如 $\\lambda xyz.M$ 和 $\\lambda x.\\lambda y.\\lambda z. M$ 等价。 2.2 Free and Bound Variable, $\\alpha$-Equivalence 自由变量的归纳定义：令 $FV(M)$ 表示 $M$ 这个 lambda term 中的自由变量的集合，则 $$ \\begin{align} \u0026amp;FV(x)=\\{x\\}\\\\ \u0026amp;FV(M\\space N)=FV(M)\\cup FV(N)\\\\ \u0026amp;FV(\\lambda x.M)=FV(M)-\\{x\\} \\end{align} $$ 例如 $\\lambda x.N$ 中的 $x$ 就是 bound variable，$\\lambda x$ 被称为 binder，$N$ 被称为该函数的 scope。\n在定义 $\\alpha$-equivalence 之前，我们要先给出变量换名的归纳定义： $$ \\begin{align} x\\{y/x\\}\u0026amp;\\triangleq y\\\\ z\\{y/x\\}\u0026amp;\\triangleq z,\\qquad\\qquad\\qquad\\qquad\\qquad\\text{ if }z\\neq x\\\\ (M\\space N)\\{y/x\\}\u0026amp;\\triangleq (M\\{y/x\\})(N\\{y/x\\})\\\\ (\\lambda x.M)\\{y/x\\}\u0026amp;\\triangleq (\\lambda y.M\\{y/x\\})\\\\ (\\lambda z.M)\\{y/x\\}\u0026amp;\\triangleq (\\lambda z.M\\{y/x\\})\\qquad\\qquad\\quad \\text{ if }z\\neq x \\end{align} $$ $\\fbox{Definition}$ ($\\alpha$-equivalence) 对于任意 lambda term $M$ 和变量 $y$，$\\alpha$-equivalence 指 $$ \\frac{y\\notin M}{\\lambda x.M=_{\\alpha}\\lambda y.M\\{y/x\\}} $$\n2.3 Substitution 上一节中我们给出的是变量换名的规则，即将一个变量转化成另一个变量，这一节我们给出变量替换的规则。变量替换可以将一个变量换成任意一个 lambda term。变量替换和变量换名类似，但要注意两点：\n我们只对 free variable 进行替换，scope 中的 bound variable 不能换。 要小心 unintended capture，即如果当前的新 term 里出现了某个 bound variable，我们需要先对 bound variable 进行一次变量换名。 具体的规则如下： $$ \\begin{align} x[N/x]\u0026amp;\\triangleq N\\\\ y[N/x]\u0026amp;\\triangleq y\\\\ (M\\space P)[N/x]\u0026amp;\\triangleq (M[N/x])(P[N/x])\\\\ (\\lambda x.M)[N/x]\u0026amp;\\triangleq \\lambda x.M\\\\ (\\lambda y.M)[N/x]\u0026amp;\\triangleq \\lambda y.(M[N/x])\\qquad\\qquad \\text{if }x\\neq y\\text{ and }y\\neq FV(N)\\\\ (\\lambda y.M)[N/x]\u0026amp;\\triangleq \\lambda y\u0026rsquo;.(M\\{y\u0026rsquo;/y\\}[N/x])\\quad \\text{if }x\\neq y,y\\in FV(N) \\text{ and }y\u0026rsquo; \\text{ fresh} \\end{align} $$\n2.4 Introduction to $\\beta$-Reduction Convention：从现在起我们不再关注 bound variable 是否相同，当我们说 $M=N$ 时，我们指的是它们在 $\\alpha$-equivalence 这个关系下属于同一个等价类。\n将函数的参数取值代入函数的过程称为 $\\beta$-reduction。一个形如 $(\\lambda x.M)N$ 的东西，即把一个 lambda abstraction 作用到另一个 lambda term 上，称为 $\\beta$-redex，它可以被化简成 $M[N/x]$，化简后的式子称为 reduct。化简的过程就是不断寻找 $\\beta$-redex 并用相应的 reduct 代替它，一个没有任何 $\\beta$-redex 的 lambda term 被称为 $\\beta$-normal form。\n下面是一个简单的利用 $\\beta$-reduction 化简的例子： $$ \\begin{align} (\\lambda x.y)((\\lambda z.zz)(\\lambda w.w))\u0026amp;\\to_\\beta(\\lambda x.y)((\\lambda w.w)(\\lambda w.w))\\\\ \u0026amp;\\to_\\beta(\\lambda x.y)(\\lambda w.w)\\\\ \u0026amp;\\to_\\beta y \\end{align} $$ 当然，如果我们选择了最外层的 redex 化简，可以只花一步得到 $y$。不同的 reduction 顺序繁琐程度可能不同，有的顺序可能得不到结果，但所有能得到结果的 reduction order 得到的结果是唯一的。\n$\\beta$-reduction 不一定会使式子变短，甚至可能让式子更长。有些 lambda term 运用 $\\beta$-reduction 是无法化简为 $\\beta$-normal form 的，例如 $$ \\begin{align} (\\lambda x.xx)(\\lambda y.yyy)\u0026amp;\\to_\\beta(\\lambda y.yyy)(\\lambda y.yyy)\\\\ \u0026amp;\\to_\\beta(\\lambda y.yyy)(\\lambda y.yyy)(\\lambda y.yyy)\\\\ \u0026amp;\\to_\\beta \\ldots \\end{align} $$\n2.5 Formal Definitions of $\\beta$-reduction and $\\beta$-equivalence $\\beta$-reduction 的规则和可以运用 $\\beta$-reduction 的情形规定如下： $$ \\frac{}{(\\lambda x.M)N\\to_\\beta M[N/x]} $$\n$$ \\begin{align} \\frac{M\\to_\\beta M\u0026rsquo;}{M\\space N\\to_\\beta M\u0026rsquo;\\space N}\\\\ \\frac{N\\to_\\beta N\u0026rsquo;}{M\\space N\\to_\\beta M\\space N\u0026rsquo;}\\\\ \\frac{M\\to_\\beta M\u0026rsquo;}{\\lambda x.M\\to_\\beta \\lambda x.M\u0026rsquo;} \\end{align} $$\n$\\fbox{Definition}$ $M\\twoheadrightarrow_\\beta M\u0026rsquo;$ 当且仅当 $M$ 可以通过任意多步 (包括 0 步) $\\beta$-reduction 得到 $M\u0026rsquo;$。形式化地，$\\twoheadrightarrow_\\beta$ 定义了 $\\to_\\beta$ 的传递闭包。\n$\\fbox{Definition}$ 我们称 $M$ 和 $M\u0026rsquo;$ 满足 $\\beta$-equivalence，记作 $M=\\beta M\u0026rsquo;$，当且仅当 $M$ 可以通过任意多步 (包括 0 步) $\\beta$-reduction 及其逆操作得到 $M\u0026rsquo;$。形式化地，$=\\beta$ 定义了 $\\to_\\beta$ 的对称闭包。\n","date":1664928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664928000,"objectID":"0619a13b7de4444c319450559fde6435","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-formal-semantics/material/lambda-calculus/ch02/","publishdate":"2022-10-05T00:00:00Z","relpermalink":"/notes/coursenotes/nju-formal-semantics/material/lambda-calculus/ch02/","section":"notes","summary":"2.1 Syntax 2.2 Free and Bound Variable, $\\alpha$-Equivalence 2.3 Substitution 2.4 Introduction to $\\beta$-Reduction 2.5 Formal Definitions of $\\beta$-reduction and $\\beta$-equivalence 2.1 Syntax $\\fbox{Definition}$ (lambda term) 在一个无限的变量集合 $V$ 下 (将其中的变量命名为 $x,y,z\u0026hellip;$)，lambda term 可以由如下的 BNF 范式定义： $$ \\text{Lambda terms:}\\quad M,N::=x|(M\\space N)|(\\lambda x.","tags":null,"title":"Chapter 02: The Untyped Lambda Calculus","type":"docs"},{"authors":null,"categories":null,"content":"Untyped lambda calculus 的强大之处在于它可以被用来表示各种各样的数据，比如 boolean, 自然数，复杂数据结构，函数等。这一切都只需要纯粹的 lambda 语法，不需要额外的 syntax 和 axiom。\n3.1 Boolean True 和 False 的定义： $$ \\begin{align} \\mathbf{True}\u0026amp;\\triangleq \\lambda x.\\lambda y.x\\\\ \\mathbf{False}\u0026amp;\\triangleq \\lambda x.\\lambda y.y\\\\ \\end{align} $$ 布尔代数的基本操作： $$ \\begin{align} \\mathbf{not}\u0026amp;\\triangleq \\lambda b.b\\space \\mathbf{False}\\space \\mathbf{True}\\\\ \\mathbf{and}\u0026amp;\\triangleq \\lambda b.\\lambda b\u0026rsquo;.b\\space b\u0026rsquo;\\space \\mathbf{False}\\\\ \\mathbf{or}\u0026amp;\\triangleq \\lambda b.\\lambda b\u0026rsquo;.b\\space \\mathbf{True}\\space b' \\end{align} $$ if-then-else： $$ \\text{if-then-else}\\triangleq \\lambda x.x $$\n$$ \\begin{align} \\text{if-then-else }\\mathbf{True}\\space M\\space N\u0026amp;\\twoheadrightarrow_\\beta M\\\\ \\text{if-then-else }\\mathbf{False}\\space M\\space N\u0026amp;\\twoheadrightarrow_\\beta M\\\\ \\end{align} $$\n3.2 Natural Numbers 这里主要介绍 Church numeral 体系。我们定义： $$ \\overline{n}\\triangleq \\lambda f.\\lambda x.f^nx $$ 接下来可以定义一些作用在 church numeral 上的函数。最基本的是 $\\mathbf{succ}\\triangleq \\lambda n.\\lambda f.\\lambda x.f\\space (n\\space f\\space x)$。我们可以验证其功能的正确性：对于任意 $\\overline n$， $$ \\begin{align} \\mathbf{succ}\\space \\overline{n}\u0026amp;=(\\lambda nfx.f\\space (n\\space f\\space x))(\\lambda f.\\lambda x.f^nx)\\\\ \u0026amp;\\to_\\beta\\lambda fx.f\\space ((\\lambda f.\\lambda x.f^nx)\\space f\\space x)\\\\ \u0026amp;\\to_\\beta\\lambda fx.f(f^n\\space x)\\\\ \u0026amp;=\\lambda fx.f^{n+1}x\\\\ \u0026amp;=\\overline{n+1} \\end{align} $$ 下面是加法、乘法、乘方的定义： $$ \\begin{align} \\mathbf{add}\u0026amp;\\triangleq \\lambda nmfx.n\\space f\\space (m\\space f\\space x).\\\\ \\mathbf{mult}\u0026amp;\\triangleq \\lambda nmfx.n\\space (m\\space f)\\space x.\\\\ \\mathbf{exp}\u0026amp;\\triangleq \\lambda nmfx.n\\space m\\space f\\space x. \\end{align} $$ 注意 lambda application 是左结合的，这导致了 $\\mathbf{exp}$ 和 $\\mathbf{mult}$ 的微小差别。具体的理解细节参考 Software Foundation 和 UCB CS61A HW02。\n$\\fbox{Definition}$ 设 $f:\\mathbb{N}^k\\to\\mathbb N$ 为函数，$M$ 是一个 lambda term，我们称 $M$ 表示了 $f$ 当且仅当对于任意 $n_1,\\cdots, n_k\\in \\mathbb N$，均有 $$ M\\space \\overline{n_1}\\space \\ldots\\space \\overline{n_k}\\twoheadrightarrow_\\beta \\overline{f(n_1,\\ldots, n_k)}. $$ 另一个简单有用的函数是 $\\mathbf{iszero}$，接收一个 church numeral，用上一节定义的 boolean 来返回 True/False： $$ \\mathbf{iszero}\\triangleq \\lambda nxy.n\\space (\\lambda z.y)\\space x $$ 该函数的核心要义在与如果 $n$ 是 0，那么 $\\lambda z.y$ 这个函数不会使用，最后的结果就是 $\\lambda xy.x=\\mathbf{True}$。只要 $\\lambda z.y$ 被使用了一次，最后剩下的就是 $\\lambda xy.y=\\mathbf{False}$。\n3.3 Fixpoints and Recursive Functions 对于函数 $f$，我们称 $x$ 是函数 $f$ 的不动点 (fixpoint) 当且仅当 $f(x)=x$。在 lambda calculus 中，不动点的定义是类似的：对于任意 lambda term $F,N$，若 $N=F\\space N$，则称 $N$ 是 $F$ 的 fixpoint。\n$\\fbox{Theorem}$ 在 untyped lambda calculus 中，所有的 lambda term 都有 fixpoint。\n证明：令 $A=\\lambda xy.y(xxy)$，再定义 $\\Theta=A\\space A$。我们发现对于任意 $F$，$N=\\Theta\\space F$ 就是 $F$ 的不动点： $$ \\begin{align} N\u0026amp;=\\Theta F\\\\ \u0026amp;=A A F\\\\ \u0026amp;=(\\lambda xy.y(xxy))AF\\\\ \u0026amp;=F(AAF)\\\\ \u0026amp;=F(\\Theta F)\\\\ \u0026amp;=F\\space N\\qquad\\qquad\\qquad\\qquad \\square \\end{align} $$ $\\Theta$ 被称为 Turning\u0026rsquo;s fixpoint combinator。\n有了 fixpoint 这一工具，我们可以通过求解方程的方法来计算一些递归函数，这里以 Fibonacci 数列为例： $$ \\mathbf{Fib}\\space \\overline{n}=\\text{if-then-else}(n=?0)(\\overline{0})(\\text{if-then-else}(n=?1)(\\overline{1})(\\mathbf{Fib}(\\overline{n}-\\overline{1})+\\mathbf{Fib}(\\overline{n}-\\overline{2}))) $$ 注: $=?$ 和减法这些操作可以通过 $\\mathbf{iszero}$,$\\mathbf{pred}$ 等形式化地定义。\n我们反过来做一步 $\\beta$-reduction，得到 $$ \\mathbf{Fib}=(\\lambda f.\\lambda n.\\text{if-then-else}(n=?0)(\\overline{0})(\\text{if-then-else}(n=?1)(\\overline{1})(f(\\overline{n}-\\overline{1})+f(\\overline{n}-\\overline{2}))))(\\mathbf{Fib}) $$ 令 $$ F=\\lambda f.\\lambda n.\\text{if-then-else}(n=?0)(\\overline{0})(\\text{if-then-else}(n=?1)(\\overline{1})(f(\\overline{n}-\\overline{1})+f(\\overline{n}-\\overline{2}))) $$ 则 $$ \\mathbf{Fib}=F\\space \\mathbf{Fib} $$ 利用 Turning fixpoint combinator 可以直接解出 $$ \\begin{align} \\mathbf{Fib}\u0026amp;=\\Theta F\\\\ \u0026amp;=\\Theta(\\lambda f.\\lambda n.\\text{if-then-else}(n=?0)(\\overline{0})(\\text{if-then-else}(n=?1)(\\overline{1})(f(\\overline{n}-\\overline{1})+f(\\overline{n}-\\overline{2})))) \\end{align} $$\n3.4 Other Data Type: Pairs, Tuples, Lists, Trees, etc. 使用 untyped lambda calculus 可以轻松地定义编程语言中常见的数据结构。\nPairs 对于 lambda term $M$ 和 $N$，我们定义 $$ \\begin{align} \\langle M,N\\rangle\u0026amp;\\triangleq \\lambda z.zMN\\\\ \\mathbf{left}\u0026amp;\\triangleq\\lambda p.p(\\lambda xy.x)\\\\ \\mathbf{right}\u0026amp;\\triangleq\\lambda p.p(\\lambda xy.y) \\end{align} $$ 容易验证 $\\mathbf{left}\\langle M,N\\rangle\\twoheadrightarrow_\\beta M,\\mathbf{right}\\langle M,N\\rangle\\twoheadrightarrow_\\beta N$。这里的 $\\mathbf{left},\\mathbf{right}$ 被称为左/右投影。\nTuples 在 pairs 的基础上扩展我们很容易定义 tuple： $$ \\begin{align} \\langle M_1,M_2\\cdots, M_n\\rangle\u0026amp;\\triangleq \\lambda z.zM_1M_2\\cdots M_n\\\\ \\pi_i^n\u0026amp;\\triangleq \\lambda p.p(\\lambda x_1\\cdots x_n.x_i) \\end{align} $$ 容易验证 $\\pi_i^n\\langle M_1,\\cdots, M_n\\rangle\\twoheadrightarrow_\\beta M_i$。\nLists list 和 tuple 的区别在于 list 是变长的，可以增加元素。一个 list 需要以 $\\mathbf{nil}$ 作为结尾，我们以 $H::T$ 来表示 list 的头部元素是 $H$，剩下的元素组成的尾巴是另一个元素 $T$。我们定义 $$ \\begin{align} \\mathbf{nil}\u0026amp;\\triangleq\\lambda xy.y\\\\ H::T\u0026amp;\\triangleq \\lambda xy.xHT \\end{align} $$\n在该定义的基础上，我们可以定义一些有用的函数，例如 $\\mathbf{addlist}$ 可以将 list 中所有的数求和： $$ \\mathbf{addlist}\\space l= l(\\lambda ht.\\mathbf{add}\\space h\\space (\\mathbf{addlist}\\space t))(\\overline{0}) $$ 其中第二个参数 $\\overline{0}$ 是专门为 $\\mathbf{nil}$ 准备的。这是一个递归的定义，我们可以用 3.3 节的方法将其转化成一个正式的函数。\n我们尝试从方法论的角度对 pair, list 的定义方式做出一点解释。比如 pair 中之所以要在定义中引入 $z$ 这个东西，是方便将来传入一个函数代入 $z$ 对 $M\\space N$ 做一些操作。list 中预留的 $xHT$ 中的 $x$ 也是方便将来传入一些操作函数。之所以 list 中我们需要预留 $x,y$ 两个操作函数“占位符”，是因为我们对普通节点和 $\\mathbf{nil}$ 的处理方式不同。\nTrees 二叉树要么是一个叶子 (保存了一个自然数)，要么是一个节点。一个节点有自己的左右孩子，每个孩子也是一个二叉树。我们定义 $$ \\begin{align} \\mathbf{leaf}\\space n\u0026amp;\\triangleq \\lambda xn.xn\\\\ \\mathbf{node}\\space L\\space R\u0026amp;\\triangleq \\lambda xy.yLR \\end{align} $$ 和上面类似地，我们定义一个函数 $\\mathbf{addtreesq}$，将树中所有叶子节点上的数的平方求和： $$ \\mathbf{addtreesq}\\space t=t(\\lambda n.\\mathbf{mult}\\space n\\space n)(\\lambda lr.\\mathbf{add}(\\mathbf{addtreesq}\\space l)(\\mathbf{addtreesq}\\space r)) $$\n","date":1664928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664928000,"objectID":"bd1c81b7c62e2fdcaacb2dfe71159878","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-formal-semantics/material/lambda-calculus/ch03/","publishdate":"2022-10-05T00:00:00Z","relpermalink":"/notes/coursenotes/nju-formal-semantics/material/lambda-calculus/ch03/","section":"notes","summary":"Untyped lambda calculus 的强大之处在于它可以被用来表示各种各样的数据，比如 boolean, 自然数，复杂数据结构，函数等。这一切都只需要纯粹的 lambda 语法，不需要额外的 syntax 和 axiom。\n3.1 Boolean True 和 False 的定义： $$ \\begin{align} \\mathbf{True}\u0026amp;\\triangleq \\lambda x.\\lambda y.x\\\\ \\mathbf{False}\u0026amp;\\triangleq \\lambda x.\\lambda y.y\\\\ \\end{align} $$ 布尔代数的基本操作： $$ \\begin{align} \\mathbf{not}\u0026amp;\\triangleq \\lambda b.","tags":null,"title":"Chapter 03: Programming in the Untyped Lambda Calculus","type":"docs"},{"authors":null,"categories":null,"content":" Overview Execution Graph Concepts Consistency Predicate Sequential Consistency Coherent Consistency Release/Acquire Consistency Happen-before and C/C++11 Memory Model Overview The basic procedure of declarative/axiomatic concurrency semantics:\nDefine the notion of a program execution (generalization of an execution trace) Map a program to a set of executions Define a consistency predicate on executions Semantics = the set of consistent executions of a program Exception: \u0026ldquo;catch-fire\u0026rdquo; semantics\n\u0026ldquo;catch-fire\u0026rdquo; semantics are those existing at least one \u0026ldquo;bad\u0026rdquo; consistent execution, which implies undefined behavior. (mainly appear in C/C++)\nExecution Graph The vertices stands for the events in the program. There are 4 event types: read, write, update, fence. The edges represents relations between events. There are two relation types: program order po (also called sequenced-before, sb), and reads-from, rf.\nConcepts $\\fbox{Definition}$ (label) A label has one of the following forms: $$ R\\space x\\space v_r\\qquad W\\space x\\space v_w\\qquad U(x\\space v_r\\space v_w)\\qquad F $$ where $x\\in \\text{Loc}$ and $v_r,v_w\\in \\text{Val}$.\n$\\fbox{Definition}$ (event) An event is a triple $\\langle id, i, l\\rangle$ where\n$id\\in \\mathbb N$ is an event identifier. $i\\in \\text{Tid}\\cup {0}$ is a thread identifier. $l$ is a label. Note: the thread identifier \u0026ldquo;0\u0026rdquo; is used for some initial statements that don\u0026rsquo;t belong to any specific thread.\n$\\fbox{Definition}$ (execution graph) An execution graph is a tuple $\\langle E, po,rf\\rangle$, where\n$E$ is a finite set of events. $po$ (program order) is a partial order on $E$. $rf$ (reads-from) is a binary relation on $E$ such that For every $\\langle w,r\\rangle\\in rf$: $\\text{type}(w)\\in {W,U},\\text{type}(r)\\in {R, U}$ $\\text{loc}(w)=\\text{loc}(r)$ $val_w=val_r$. $rf^{-1}$ is a function, i.e., every read operation can read from only one write. $\\fbox{Definition}$ (sequential) An execution graph $G$ is called sequential if\n$\\text{tid}(a)=0$ for every $a\\in G.E$. $G.po$ is a total order on $G.E$. $G.rf=\\emptyset$. A sequential graph can be constructed from commands by the following rules:\nSilent: $$ \\frac{c,s\\overset{\\epsilon}{\\to}c\u0026rsquo;,s\u0026rsquo;}{c,s,G\\Rightarrow c\u0026rsquo;,s\u0026rsquo;,G} $$ Non-silent: $$ \\frac{c,s\\overset{l}{\\to}c\u0026rsquo;,s\u0026rsquo;\\qquad a=\\langle n,0,l\\rangle\\qquad n\\notin {\\text{id}(b)|b\\in G.E}}{c,s,G\\Rightarrow c\u0026rsquo;,s\u0026rsquo;,Add(a,G)} $$ where $Add(a,G)$ yields an execution graph $G\u0026rsquo;$ givens by\n$G\u0026rsquo;.E=G.E\\cup {a}$ $G\u0026rsquo;.po=G.po\\cup (G.E\\times {a})$ $G\u0026rsquo;.rf=G.rf$ $G$ is an execution graph of a command c with a final store s if $c,s_0,G_\\emptyset\\Rightarrow^*\\mathbf{skip},s,G$.\nConsistency Predicate The restriction of execution graph is quite loose. Given a program, we can draw a huge number of execution graphs satisfying the requirements above, but not all of them are reasonable. Therefore our goal is to define some consistency rules to specify \u0026ldquo;valid\u0026rdquo; execution graphs.\nLet $X$ be some consistency predicate. We say an outcome $O$ is allowed for a program $P$ under $X$ if there exists an execution graph $G$ such that $G$ is X-consistent and $G$ belongs to $P$ with outcome $O$.\nException: \u0026ldquo;catch-fire\u0026rdquo; semantics\nor if there exists an execution graph $G$ such that $G$ is X-consistent, $G$ is an execution graph of $P$ and $G$ is \u0026ldquo;bad\u0026rdquo;.\n$\\fbox{Definition}$ (completeness) An execution graph $G$ is called complete if $codom(G.rf)=G.R$, i.e., every read reads from some write.\nSequential Consistency $\\fbox{Definition}$ (SC-consistent, Lamport) Let $sc$ be a total order of $G.E$, $G$ is called SC-consistent wrt (with respect to) $sc$ if\nIf $\\langle a,b\\rangle\\in G.po$, $\\langle a, b\\rangle \\in sc$. If $\\langle a, b\\rangle\\in G.rf$, then $\\langle a,b\\rangle\\in sc$ and there does not exist $c\\in G.W_{loc(b)}$ such that $\\langle a,c\\rangle\\in sc$ and $\\langle c,b\\rangle\\in sc$. Notes: the first condition requires that program order should be consistent with the $sc$ total order. The second condition requires that a read should read from a write prior to it and there shouldn\u0026rsquo;t be another write (on the same location) between them, i.e., read from the latest write.\nThere\u0026rsquo;s an alternative version of SC-consistency:\n$\\fbox{Definition}$ (modification order) $mo$ is called a modification order for an execution graph $G$ if $mo=\\bigcup_{x\\in \\text{Loc}}mo_x$, where each $mo_x$ is a total order on $G.W_x$.\n$\\fbox{Definition}$ (SC-consistent, alternative) An execution graph $G$ is called SC-consistent if the following hold:\n$G$ is complete.\nThere exists a modification order $mo$ for $G$ such that $G.po\\cup G.rf\\cup mo\\cup rb$ is acyclic.\nHere $rb\\triangleq (G.rf^{-1};mo) -{id}$. The \u0026ldquo;;\u0026rdquo; operator means that if there exists $\\langle a,c\\rangle\\in G.rf^{-1}$ and $\\langle c,b\\rangle\\in mo$, then $\\langle a,b\\rangle\\in rb$. The ${id}$ is used to filter out some dummy relations generated by $U$ (an operation $U$ reads from another write $W$ and $W\\to U$ is also in $mo$.)\n$\\fbox{Theorem}$ The two SC definitions are equivalent.\nProof:\nLamport SC $\\Rightarrow$ alternative SC: We\u0026rsquo;ve got an total order $sc$ which includes $po$ and $rf$, so we only need to construct $mo$. We let $mo\\triangleq [W_x]; sc; [W_x]$. (Here $[W_x]$ is a tricky way of representing the starting node should belong to $G.W_x$.). Since $mo\\subseteq sc$, we only need to proof that $rb$ won\u0026rsquo;t generate circle with $sc$. Suppose the opposite, then the execution graph should be like\ngraph TD W1 --\u0026gt;|rf| R W1 --\u0026gt;|mo| W2 W2 --\u0026gt;|sc| R R --\u0026gt;|rb| W2 which contradicts the property of $sc$ in Lamport SC\u0026rsquo;s definition.\nalternative SC $\\Rightarrow$ Lamport SC: We\u0026rsquo;ve got $po,rf,mo$. Let $sc$ be a total order satisfying $po\\cup rf\\cup mo\\cup rb\\subseteq sc$. ($po\\cup rf\\cup mo\\cup rb$ is acyclic, so it\u0026rsquo;s reasonable.) We need to prove that the total order $sc$ satisfies the second property in the definition. Suppose the opposite, i.e., there exists $\\langle a,b\\rangle, \\langle a,c\\rangle, \\langle c,b\\rangle\\in sc$ and $\\langle a,b\\rangle\\in rf,c\\in G.W_{loc(b)}$, it\u0026rsquo;s easy to discover that $b\\overset{rb}{\\to}c$ (the graph is the same as above), so $\\langle b,c\\rangle\\in sc$, which contradicts the fact that $sc$ is an total order.\nCoherent Consistency SC with interleaving semantics is (relatively) human-friendly, but it\u0026rsquo;s expensive to implement SC on hardware. What\u0026rsquo;s more, SC prohibits various optimization that are sound for sequential code. What most hardware guarantee and compilers preserve is \u0026ldquo;SC-per-location\u0026rdquo; (aka. coherence)\n$\\fbox{Definition}$ (coherent) an execution graph $G$ is coherent if the following hold:\n$G$ is complete. For every location $x$, there exists a total order $sc_x$ satisfying the Lamport SC\u0026rsquo;s properties. A few alternative definitions of coherence are shown below:\n$\\fbox{Definition}$ an execution graph $G$ is called coherent if the following hold:\n$G$ is complete. There exists a modification order $mo$ such that $G.po|_{loc}\\cup G.rf\\cup mo\\cup rb$ is acyclic. Note: $rf, mo,rb$ are naturally \u0026ldquo;per-location\u0026rdquo;, here the notation $G.po|_{loc}$ means that we only consider program order edges on the same location.\nLet\u0026rsquo;s have a loot at some prohibited patterns:\nNo future read:\ngraph TD S1(Rx) --\u0026gt; |po| S2(Wx) S2 -.-\u0026gt; |rf|S1 RMW-1 (can be triggered by an CAS(x, 1, 1) instruction):\ngraph TD S1(Ux) -.-\u0026gt;|rf| S1 coherence-ww/rw/wr/rr:\ngraph TD S1(Wx) --\u0026gt; |po| S2(Wx) -.-\u0026gt;|mo| S1 S3(Wx) -.-\u0026gt; |rf| S4(Rx) --\u0026gt; |po| S5(Wx) -.-\u0026gt; |mo| S3 S6(Wx) -.-\u0026gt; |mo| S7(Wx) --\u0026gt; |po| S8(Rx) S6 -.-\u0026gt; |rf| S8 S9(Wx) -.-\u0026gt;|rf| S10(Rx) --\u0026gt; |po| S11(Rx) S12(Wx) -.-\u0026gt;|rf| S11 S12(Wx) -.-\u0026gt;|mo| S9 Note: with $rb$ edges, these graphs will have cycles.\nRMW-2:\ngraph LR S1(Wx) -.-\u0026gt; |rf| S2(Ux) -.-\u0026gt; |mo| S1 Atomicity:\ngraph LR S1(Wx) -.-\u0026gt;|mo| S2(Wx) -.-\u0026gt;|mo| S3(Ux) S1 -.-\u0026gt;|rf| S3 This pattern illustrates that RMW event may only read from the immediate $mo$-predecessor - it has synchronization.\nIt can be proved that the bad patterns above cover all the cases of invalid execution graphs, so\n$\\fbox{Definition}$ an execution graph $G$ is coherent if $G$ is complete and there exists a modification order $mo$ satisfying:\n$rf;po$ is irreflexive (no-future-read) $mo;po$ is irreflexive (coherence-ww) $mo;rf;po$ is irreflexive (coherence-rw) $rf^{-1};mo;po$ is irreflexive (coherence-wr) $rf^{-1};mo;rf;po$ is irreflexive (coherence-rr) $rf$ is irreflexive (RMW-1) $mo;rf$ is irreflexive (RMW-2) $rf^{-1};mo;mo$ is irreflexive (RMW-atomicity) Release/Acquire Consistency COH is often too weak. For example, the common implementation of spinlock fails to work in COH since the variables used in the lock have no relation with the variables used in the critical section:\nlock(l): unlock(l): r := 0 l := 0 while not r do r := CAS(l, 0, 1) Initially: x = y = 0; lock(l); || lock(l); x = 1; || y = 1; a = y; /* 0 */ || b = x; /* 0 */ // store buffering is allowed even with spinlock! unlock(l); || unlock(l); In addition, COH also doesn\u0026rsquo;t support message passing:\nInitially: x = y = 0; x = 42; || a = y; y = 1; || while (!a) a = y; // Message passing: y = 1 ==\u0026gt; x = 42 is expected. || b = x; // 0 // b = 0 is allowable in COH! The lesson we can learn from these examples is that the $rb$ relation in one variable should influence the global program order, i.e., $rb$ should serve as a synchronization. This leads to the RA memory model:\n$\\fbox{Definition}$ (RA-consistent) an execution graph $G$ is RA-consistent if it\u0026rsquo;s complete and there exists a modification order $mo$ such that $(po\\cup rf)^+|_{loc}\\cup mo\\cup rb$ is acyclic.\nThe subtle difference between $po|{loc}\\cup rf$ and $(po\\cup rf)^+|{loc}$ is that the latter allow $rf$ relation on one location to connect events on other locations. Let\u0026rsquo;s check it on message passing example:\nCOH on x : allowed\ngraph TD S1(x=0) --\u0026gt;|po| S2(x=42) S1 -.-\u0026gt; |mo| S2 S1 --\u0026gt; |po| S3(b=x // 0?) S1 -.-\u0026gt; |rf| S3 RA on x : not allowed\ngraph TD S1(x=0) --\u0026gt; |po| S2(x=42) --\u0026gt; |\u0026quot;(po,rf)+\u0026quot;| S3(y=1) S1 --\u0026gt; |po| S4(a=y // 1) S3 --\u0026gt;|\u0026quot;(po,rf)+\u0026quot;| S4 S4 --\u0026gt; |\u0026quot;(po,rf)+\u0026quot;| S5(b=x // 0?) S1 -.-\u0026gt; |rf| S5 S5 -.-\u0026gt; |rb| S2 In RA, the $rf$ relation between y=1 and a=y serves as a bridge that connects x=42 and b=x. In this situation If b=x reads from x=0, the $rb$ edge generated will cause a cycle.\nHappen-before and C/C++11 Memory Model We\u0026rsquo;ve already known that according to the strength, COH\u0026lt;RA\u0026lt;SC, but there\u0026rsquo;s still some room between COH and RA: in the message passing example, we only need the $rf$ relation on y to have the synchronization effect and we don\u0026rsquo;t care about x. The idea is that we can introduce access modes on variables:\nx =(rlx) 42; || a = y(rlx) y =(rel) 1; || while (!a) a = y; || a = y(acq) || b = x(rlx) Each memory access has a mode:\nReads: $\\text{rlx}$ or $\\text{acq}$. Writes: $\\text{rlx}$ or $\\text{rel}$. RMWs: $\\text{rlx}$ or $\\text{acq}$ or $\\text{rel}$ or $\\text{acq-rel}$. The strength order can be represented as the following graph:\ngraph LR S1(rlx) --\u0026gt; S2(acq) S1 --\u0026gt; S3(rel) S2 --\u0026gt; S4(acq-rel) S3 --\u0026gt; S4 S1 --\u0026gt; S4 And we do synchronization only on $\\text{rel/acq}$: $$ \\begin{align} G.sw\u0026amp;\\triangleq [W^{\\supseteq\\text{rel}}];G.rf;[R^{\\supseteq \\text{acq}}]\\\\ G.hb\u0026amp;\\triangleq (G.po\\cup G.sw)^+ \\end{align} $$ Here $W^{\\supseteq \\text{rel}}$ means the set of write events that have access mode not weaker than $\\text{rel}$.\n$\\fbox{Definition}$ (C11 Consistency) an execution graph $G$ is C11-consistent if $G$ is complete and there exists a modification order $mo$ such that $hb_{loc}\\cup rf\\cup mo\\cup rb$ is acyclic.\nNote: the definition of RA-consistency doesn\u0026rsquo;t need to additionally include $rf$ because the transitive closure $(po\\cup rf)^+$ has include all the information in $rf$. However, in C11-consistency $hb_{loc}$ only consider $rf$ edges between \u0026ldquo;strong\u0026rdquo; r/w/rmw events so we still need to include $rf$.\nThe full C/C++11 memory model is more general in that it includes more access modes and fences.\n","date":1664841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664841600,"objectID":"7ca388c34fb448496fed5d134084d086","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-concurrency/lectures/lec04/","publishdate":"2022-10-04T00:00:00Z","relpermalink":"/notes/coursenotes/nju-concurrency/lectures/lec04/","section":"notes","summary":"Overview Execution Graph Concepts Consistency Predicate Sequential Consistency Coherent Consistency Release/Acquire Consistency Happen-before and C/C++11 Memory Model Overview The basic procedure of declarative/axiomatic concurrency semantics:\nDefine the notion of a program execution (generalization of an execution trace) Map a program to a set of executions Define a consistency predicate on executions Semantics = the set of consistent executions of a program Exception: \u0026ldquo;catch-fire\u0026rdquo; semantics","tags":null,"title":"Lecture 04: Declarative Semantics for Concurrency","type":"docs"},{"authors":null,"categories":null,"content":" 1.1 What Is the Internet 1.1.1 A Nuts-and-Bolts Description 1.1.2 A Services Description 1.1.3 What Is a Protocol 1.2 The Network Edge 1.2.1 Access Networks Home Access Enterprise Access Wide-Area Wireless Access 1.2.2 Physical Media 1.3 The Network Core 1.3.1 Packet Switching Store-and-Forward Transmission Queuing Delays and Packet Loss Forwarding Tables and Routing Protocols 1.3.2 Circuit Switching Multiplexing in Circuit-Switched Networks Packet Switching Versus Circuit Switching 1.3.3 A Network of Networks 1.4 Delay, Loss, and Throughput in Packet-Switched Networks 1.4.1 Overview of Delay in Packet-Switched Networks Processing Delay Queuing Delay Transmission Delay Propagation Delay Comparing Transmission and Propagation Delay 1.4.2 Queuing Delay and Packet Loss Packet Loss 1.4.3 End-to-End Delay Traceroute End System, Application, and Other Delays 1.4.4 Throughput in Computer Networks 1.5 Protocol Layers and Their Service Models 1.5.1 Layered Architecture Protocol Layering Application Layer Transport Layer Network Layer Link Layer Physical Layer 1.5.2 Encapsulation 1.6 Networks Under Attack Put Malware into Your Host Via the Internet Attack Servers and Network Infrastructure Sniff Packets Masquerade as Someone You Trust 1.7 History of Computer Networking and the Internet 1.1 What Is the Internet 1.1.1 A Nuts-and-Bolts Description 这里的 \u0026ldquo;nuts-and-bolts\u0026rdquo; 指介绍网络中一些基本的元素和组件。网络中用户使用的电脑、手机、手柄……等物品称为主机 (host) 或终端设备 (end system)。终端设备通过由通信线路 (communication links) 和包交换机 (packet switches) 组成的网络相互连接，不同的链路具有不同的 transmission rate，在链路上传送的数据是一份一份的，称为一个个包 (packet)。\nPacket switch 负责接收 packet 并将其转发到其他的链路上。最主要的两种 packet switch 就是路由器 (router) 和链路层交换机 (link-layer switch)，前者通常用于 network core，后者通常用于 access network。Packet-switched network 和日常生活中的交通运输网络很像：packet 就好比卡车上的货物，communication links 就好比高速公路，packet switch 就好比十字路口，end system 就好比仓库和大楼。\n终端设备需要通过因特网服务提供商 (Internet Service Provider, ISP) 来接入网络。ISP 分为若干层级，彼此互联，形成网络。\n终端设备、包交换机等在网络中收发数据都要遵循相关的协议 (protocol)。传输控制协议 (Transmission Control Protocol, TCP) 和网络互联协议 (Internet Protocol, IP) 是最重要的两个协议。IP 协议描述了 packet 的格式。\n1.1.2 A Services Description 这个角度旨在说明计算机网络是由若干服务组成的：对于每个服务项目，你需要遵守它提出的 specification，这样你就可以享受它的若干服务。\n我们开发的网络游戏、社交软件等称为 distributed application，因为它们需要运行在多个终端设备上，这些终端设备需要彼此交换信息。终端设备通过套接字接口 (socket interface) 来连入互联网，socket interface 主要规定了程序应当如何发送数据 (比如格式)，就像邮局规定寄信需要装信封贴邮票一样。\n1.1.3 What Is a Protocol 一个协议定义了两个通讯实体之间发送信息的格式和顺序，以及收到某些信息后应当采取的行动。\n1.2 The Network Edge Hosts 有时可以细分成两类：客户端 (client) 和服务器 (server)。客户端就是电脑、手机等，服务器通常指更加强大的，存储和分发网页、视频等的机器。先在大多数的网页内容都存储在数据中心 (data center)。\n1.2.1 Access Networks 接入网络 (access network) 指将终端设备和第一个路由器物理地连接起来的网络。\nHome Access 对于家庭来说，常见的 access network 有以下几种：\n电话线接入 (digital subscriber line, DSL)：电脑通过一个 DSL modem 连接到电话线上，DSL modem 负责将数字信号转换成可以在电话线上传输的高频模拟信号。电话线上不同的频率可以传输不同的信号。来自一个地区各家各户的信号会汇总到一个 digital subscriber line access multiplexer (DSLAM) 处，它负责将模拟信号转换回数字信号，并将信号转发到 Internet / telephone network 中。\nDSL 的上传速率和下载速率是不一样的，因此 DSL 被称为是一项非对称技术。\n电缆接入 (cable)：基本原理和 DSL 相同，电脑通过 cable modem 连接到电缆上，一个 cable modem termination system (CMTS) 负责和 DSLAM 相同的工作。\ncable network access 的一个显著特征是这是一个共享的传输介质，因此同一个时刻使用网络的人越多，实际的网速就会越低。\n光纤到户 (fiber to the home, FTTH)：从 central office 直接拉光纤到家里。\n5G：信号从服务商的 5G 基站通过无线的方式传输到家庭的 modem。\nEnterprise Access 企业/高校会部署一个 local area network (LAN) 作为接入网络，最常用的是以太网 (Ethernet)：多台终端设备通过 twisted-pair copper wire 连接到以太网交换机上，以太网交换机再连接到更大的因特网中。wireless LAN 应用的也很广泛。\nWide-Area Wireless Access 电信公司花费了大量财力部署无线网络的基站。这种技术和 WiFi 不太一样，只要终端设备和基站距离在几千米之内就可以收到信号。\n1.2.2 Physical Media 略。\n1.3 The Network Core Network Core 是由链路和包交换机组成的网络，用于将各地的终端设备连接起来。\n1.3.1 Packet Switching 在网络中不同的终端设备之间需要传递信息。长的信息会被切割成一块一块小的数据，这些块被称为包 (packet)。包在 communication link 上的传输速度等于该 link 的 full transmission rate，即如果一个 $L$ bits 的包在一个 $R$ bits/s 的链路上传输，则需要 $L/R$ 秒。\nStore-and-Forward Transmission 绝大多数的 packet switches 采取存储转发传输 (store-and-forward transmission)，这意味着交换机一定会在接收到整个 packet 之后才会开始将 packet 转发到下一条链路，不存在并行的一边接收一边转发的情况。\n假设每个包的大小都是 $L$ bits，每条链路的 transmission rate 都是 $R$ bits，那么\n$N$ 个包转发 1 次 (即 src 和 dst 之间只有一个 packet switch)，需要的时间是 $(N+1)\\cdot L/R$，注意发送第二个包的时候，packet switch 可以并行地接收第二个包和转发第一个包。 1 个包经过 $N$ 个 link (即 $N-1$ 个 packet switch)，需要的时间是 $N\\cdot L/R$。 $P$ 个包经过 $N$ 个 link，需要的时间是 $(P+N-1)\\cdot L/R$。 Queuing Delays and Packet Loss 每个 packet switch 上都连接了多个 link，对于每条 link，packet switch 都有一个输出缓冲区 (output buffer, also called output queue)，存放那些即将被发出去的包。如果一个新到来的包需要从某条 link 转发出去，但这条 link 正在转发别的包，那么这个新的包就要到该 link 的 output buffer 中等待。因此除了 store-and-forward delay，包在传输过程中还有排队延迟 (queuing delay)，其长短取决于网络的拥塞程度。\n由于 buffer 的大小是有限的，有时候新来的包会发现 output buffer 已经满了，这时就会发生包丢失 (packet loss)——要么新来的包被丢弃，要么 buffer 里的某一个其他正在等待的包被丢弃。\nForwarding Tables and Routing Protocols 对于 packet switch 来说，收到一个包以后该选择哪一条 link 去转发是它主要关心的问题。在 Internet 中，每个终端设备都有一个 IP 地址。当 src 想要给 dst 发送消息时，它会将 dst 的 IP 地址写在 packet header 中。路途中的每个 router 会解析 IP 地址的一部分，根据本地的转发表 (forwarding table) 决定沿着哪条链路继续传输。\nInternet 有一系列的路由协议 (routing protocol)，这些协议用来自动生成各个路由器的转发表。一个路由协议可以根据全局的情况来统筹规划，比如设计一条大城市之间的最短转发路径。\n1.3.2 Circuit Switching 在网络中主要有两种传输数据的方式：packet switching 和 circuit switching。这一节主要介绍后者。在 circuit-switched 网络中，两个终端设备之间联络需要提前预定资源，一旦建立了 end-to-end connection 后，在两个设备通话期间，这条路径上预定的资源会被这两个设备独占，从而可以保证一个稳定的 transmission rate (注意：在 circuit switching 中传输速率和 link 的个数无关，即不再有所谓的 store-and-forward delay)。\nMultiplexing in Circuit-Switched Networks switches 之间由 link 连接，一个 link 中包含多个 circuit。circuit 上一般会采用频分复用 (frequency-division multiplexing, FDM) 或时分复用 (time-division multiplexing, TDM) 技术。前者指的是将频谱分成多个 band 给不同的人用，后者指的是将时间轴切分成多个时间片给不同的人用。\nPacket Switching Versus Circuit Switching Packet Switching 的劣势主要在于，由于存在不可预测的延迟，它不能保证即时服务的稳定性。但 packet switching 总体来说比 circuit switching 更高效，因为 packet switching 可以更动态、更灵活地分配资源。下面是两个例子：\n假设 link 的传输速率是 1Mbps，有一些用户需要 100kbps 的传输速率。在 circuit switching 中，我们可以使用 TDM 技术，把 1s 分成 10 份，每个用户在 1s 中获取一个时间片，这样可以有 10 个用户同时使用网络。但在 packet switching 中，我们可以证明在每个客户每个时刻有 0.1 的概率 active 的情况下，即使有 35 个用户同时 active 也有 0.9996 的概率只有不超过 10 人 active，这样 packet switching 在几乎保证了用户需求的情况下支持了更多用户。 假设 10 个用户有 9 个在休息，有一个在大量产生数据，那么在 circuit switching 中，有需求的用户仍然只能得到 1/10 的时间片，而在 packet switching 中，所有的传输资源都可以为唯一的活跃用户所用。 现在的主流是向 packet switching 靠拢。\n1.3.3 A Network of Networks 我们之前讨论了 home network, enterprise network 等等，无数的终端设备连接到由电话公司、电缆公司、高校……搭建的 access ISP 上。这些 access ISP 之间也需要连接起来，形成一个 network of networks。\n现代的互联网格局大致如下图所示：\n整个互联网大致是一个三级格局：access ISP 连向 regional ISP，regional ISP 连向 Tier 1 ISP，底层的 ISP 可以连接多个上层 ISP，还可以跨级连接。处于下层的 ISP 连向上层是为了和别的 ISP 连通，因此下层的 ISP 是 customer，上层的 ISP 是 provider，customer 给 provider 付费，provider 提供服务。顶层的 Tier 1 ISP 全球只有几十个，通常是国家级的，它们彼此之间连接，保证网络的连通。\n在基本的 hierarchical 架构下还有如下的一些特性：\nPoints of presence (PoP)：PoP 是 provider network 里的一组路由器，负责和 customer 联络。 customer 为了减少给 provider 付费，同级的 ISP 之间也可以自己建立通讯，这种方式称为 peer。有一些第三方公司建立了互联网交换中心 (Internet Exchange Point, IXP)，为 peer 提供服务。这种机制也可以减轻上层 ISP 的通讯压力。 有一些本应处于底层的 content provider (比如 Google)，由于自身实力过于雄厚，拥有无数的数据中心和服务器，所以建立了自己的私有网络。Google 和 Tier 1 ISP 建立联络以保证自己的内容可以发送给世界各地，它在各地也有一些 IXP 可以直接和底层的 ISP 建立联系 (从而不用付钱走别的 Tier 1 ISP)。 1.4 Delay, Loss, and Throughput in Packet-Switched Networks 1.4.1 Overview of Delay in Packet-Switched Networks 在 packet 传输的过程中，它在每个节点都会受到一些 delay，最重要的四种 delay 是处理时延 (processing delay)，排队时延 (queuing delay)，发送时延 (transmission delay) 和传播时延 (propagation delay)，这些 delay 综合起来形成一个节点的 total nodal delay。\nProcessing Delay processing delay 指的是处理 packet header 以及确定这个 packet 该如何转发所花费的时间。在高速路由器中 processing delay 通常以微秒计。\nQueuing Delay queuing delay 指的是在路由器的 output buffer 上排队等待的时间，该 delay 和整个网络的拥塞程度有关。量级从微秒到毫秒不等。\nTransmission Delay transmission delay 指的是把要传输的数据 push 到 link 上所花费的时间，量级从微秒到毫秒不等。\nPropagation Delay propagation delay 指的是数据在 link 上传输所花费的时间，该 delay 和 link 的物理材质以及距离的远近有关，量级以毫秒计。\nComparing Transmission and Propagation Delay transmission delay 指的是把数据 push out 到 link 上的时间，它和 packet 的大小以及 link 的 transmission rate 有关。propagation delay 指的是数据在 link 上传播的时间，它主要和路途的距离有关。一个节点的总时延可以写为 $$ d_{nodal}=d_{proc}+d_{queue}+d_{trans}+d_{prop} $$ 通常来说 $d_{proc}$ 这一项总是可以忽略不计的，而其他几项在不同的场景下可能很小也可能很大。\n1.4.2 Queuing Delay and Packet Loss queuing delay 是最复杂和有趣的一种时延，每个包的 queuing delay 可能都不一样 (比如两个包来到一个 router，先来的包可能没有 queuing delay，后来的包就可能要等一个包的时间)，因此我们在刻画 queuing delay 的时候通常采取一些统计量，比如 queuing delay 的平均值、方差、超过某个阈值的概率等等。\nqueuing delay 的大小和当前的流量，link 的 transmission rate (transmission rate 大，push out 一个包就要更长的时间，排队的包就要等更久) 以及流量的特征 (arrive periodically/in burst) 等有关。我们这里考虑一个简单情形：对于一个 router，buffer 没有容量限制，包的到来速率是 $a$ 个/秒，每个包的大小都是 $L$ bits，即流量是 $La$ bits/s；link 的 transmission rate 是 $R$ bits/s，那么 $La/R$ 这个值从量纲上看是没有单位的，通常称为流量强度 (traffic intensity)。(更一般的定义是 $\\frac{\\text{arrival rate of bits}}{\\text{service rate of bits}}$。) 流量强度是衡量 queuing delay 的重要指标，如果 $La/R\u0026gt;1$，那么可想而知发送的速度比到来的速度满，久而久之 queuing delay 将趋向于无限，因此网络系统建设的一个黄金原则就是：保证 system 的 traffic intensity 不大于 1。\n当 $La/R\\leq 1$ 时，研究表明如果将平均 queuing delay 看作关于流量强度的函数，则该函数呈指数型，因此稍稍减小流量强度就可能对 queuing delay 有很明显的改善。\nPacket Loss 在实际生活中 router 的 buffer 大小是有限的，因此当流量强度趋向于 1 的时候 queuing delay 并不会趋向于无穷。当 buffer 满了的时候，router 会选择丢弃 (drop) 新来的包，或者说新来的包丢失 (lost) 了。衡量网络性能时，我们不仅会关注每个节点的 delay，还会关注发生包丢失的概率。通常情况下，为了保证数据的完整性，发生包丢失时，丢失的包会再次从 source 发出。\n1.4.3 End-to-End Delay 我们之前讨论的都是一个 router/节点上的延迟，在这个 section 中我们讨论 end-to-end 的延迟。假设从起点到终点一共有 $N-1$ 个 router，当前流量很少节点上不会发生 queuing delay，那么 end-to-end 的 delay 为 $$ d_{end-end}=N(d_{proc}+d_{trans}+d_{prop}) $$ 这里前面的系数之所以是 $N$ 而不是 $N-1$ 是因为起点节点把 packet 发送到第一个 router 上也有一个一组处理+发送+传播。\nTraceroute traceroute 是一个命令行工具，命令格式为：\ntraceroute hostname 它的功能是从运行命令的主机向目标主机发送一系列的 special packet。包在传输过程中会经过一系列的 router，假设沿路一共有 $N$ 个 router，编号 1~N，那么我们的主机就会发送 $N+1$ 个包。当 router 接收到一个 special packet 时，它会返回一条包含自己的名字、地址等信息的简短消息，且不会把 special packet 继续转发下去。这样沿路的所有 router 以及目标主机都会收到一个 special packet 并把自己的信息传输回去，我们的主机就可以根据这些信息分析到每个节点的传输时长，delay 等。traceroute 会把这个过程做 3 次并取平均值。\n由于 queuing delay 的影响，路径上处在前面的节点的平均传输时长是有可能比后面的节点长的。\nEnd System, Application, and Other Delays 除了之前提到的 4 种 delay，网络系统中还有许多其他类型的 delay，比如多个设备接入 WiFi 时，需要遵守协议保证资源共享，从而形成 delay；再例如在因特网语音 (Voice over IP, VoIP) 中，消息的发送方必须要在包里填写上加密的语音信息，这一步时延被称为 media packetization delay。\n1.4.4 Throughput in Computer Networks 除了 delay 和 packet loss，衡量网络系统的另一个重要指标就是 end-to-end 的吞吐率。在一场 end-to-end 的传输中，任意时刻的即时吞吐率 (instantaneous throughput) 指的是该时刻接收端在 1s 内接受的 bit 量 (单位：bit/s)，类似的平均吞吐率则应用一段时间内接受的 bit 数除以时间长度。一个网络的吞吐率取决于整个网络的瓶颈链路 (bottleneck link)，即 transmission rate 最小的链路。通常来说 access network 中的链路很有可能称为瓶颈 (因为 network core 中的一般都是高速链路)；如果有多条传输路径共享某一条链路，那么这个“独木桥”也很有可能成为瓶颈。\n1.5 Protocol Layers and Their Service Models 1.5.1 Layered Architecture 我们以人类坐飞机为例，整个流程大致如下：\nTicket(purchase) Ticket(complain) | | Baggage(check) Baggage(claim) | | Gates(load) Gates(unload) | | Runaway takeoff Airplane routing Runaway landing -------------------------\u0026gt; 可以看到整个系统的功能被分成了若干层。每个层都可以提供一些服务，这些服务包含两个方面：一是对来的旅客做一些操作，二是使用更下一层提供的服务 (不会跨层调用)。\n对于复杂系统来说，这种模块化的设计很有好处：每层只对上层提供一些 specification，这样某一层的 implementation 如果变了，只要保证 specification 不变，系统的其他部分就不需要改变。\nProtocol Layering 在网络系统中，网络的设计者设计了一些协议，每个协议属于一个 layer。对于一个 layer，我们关心它可以对上面的层提供的服务，即所谓的服务模型 (service model)。一个 protocol layer 即可以用硬件实现，也可以用软件实现，也可以硬软结合，例如应用层的协议 (如 HTTP, SMTP) 通常是由终端设备中的软件实现的，而网络层的协议则通常是硬软结合实现的。一个值得注意的点是，正如全世界各地的每个机场都有值机点一样，一个协议是分布式地存在于网络系统中的各个设备上的。\n尽管 protocol layer 的思想有很多好处，但仍有一些观点反对 layering。layering 的一个潜在的缺点是有时候多个层不得不实现相同的功能模块；另一个潜在的缺点是有时候一些层不得不获取下一个层的信息，这打破了 layer separation。\n各个层的 protocol 合起来总称协议栈 (protocol stack)。因特网的协议栈共有五个层：应用层 (application layer)，传输层 (transport layer)，网络层 (network layer)，链路层 (link layer) 和物理层 (physical layer)。\nApplication Layer 网络应用和应用层协议处于应用层。常见的应用层协议有 HTTP, SMTP, FTP 等。我们日常可见的一些服务，比如在地址栏里输入 human-readable 的网址就可以访问网站，也是由应用层的 DNS 支持的。\n应用层的 packet 通常称为报文 (message)。\nTransport Layer 在因特网中，传输层协议有两个：TCP 和 UDP，它们都可以传输应用层的报文。TCP 和 UDP 的不同点在于前者可以对 reliability, flow control, congestion control 提供一些保证。\n传输层的 packet 通常称为段 (segment)。\nNetwork Layer 网络层的 packet 通常称为数据报 (datagram)。source host 的传输层协议 (TCP/UDP) 会将要发送的 segment 和目标主机的地址传给网络层，网络层负责发送这些内容。\n网络层最重要的协议是 IP，它定义了 datagram 的每一个字段的内容以及终端设备和路由器应当如何处理这些字段。网络中的每个设备都要遵守 IP。除此之外，网络层中还有很多小的路由协议。\nLink Layer 网络层会为 datagram 的传输规划出一条经过若干路由器的路线，但网络层需要依靠链路层完成具体的传输。具体地，在某一个节点中，网络层会把 datagram 传给链路层，链路层把 datagram 传给另一个节点的链路层，另一个节点再把 datagram 上传给自己的网络层。常见的链路层协议有 Ethernet, WiFi 等。\n链路层的 packet 通常称为帧 (frame)。\nPhysical Layer 物理层的任务就是将 frame 里一个一个的 bit 从一个节点传输到另一个。根据不同的线材 (twisted-pair copper, single-mode fiber etc.)，物理层也有不同的协议。\n1.5.2 Encapsulation 网络中不是所有的设备都 implement 了5层协议。所有的 host 都 implement 了5层，像交换机、路由器等可能只做了低下的两三层。\n数据传输过程中的一个重要的概念就是封装 (encapsulation)。每一层都会从上面一层接收 packet，在 packet 前加上自己这一层相关信息的 header，然后打包发给下一层。在每一层 packet 都分为 header field 和 payload field 两部分，payload field 本质上就是上一层传下来的包。\nLayer Packet Application $M$ Transport $H_t\\space M$ Network $H_n\\space H_t\\space M$ Link $H_l\\space H_n\\space H_t\\space M$ Physical 解析的过程正好相反：每一层把自己这层的 header 拔下来，根据 header 中的信息做一些操作，然后把剩下的 payload field 往上传。\n1.6 Networks Under Attack 互联网最初建立时的目标用户是 ”a group of mutually trusting users\u0026quot;，但现在互联网变得非常庞大，其中的人不可能做到互相信赖。互联网最初的一套底层的设计不能推倒重来，所以就有了各种攻击手段和防御手段。\nPut Malware into Your Host Via the Internet 网络上除了好的程序，还有一些恶意软件 (malware)，它们会侵入设备并做一切可能的坏事。此外，成千上万的主机可能会被利用并构建成一个僵尸网络 (botnet)，坏人利用 botnet 来免费为他们自己做事。大部分的恶意软件都具有自我复制的功能：一旦感染了一台设备，它就会顺着这台设备在互联网中的连接去感染别的设备，从而形成一个指数级的感染规模。\nAttack Servers and Network Infrastructure 另一类常见的攻击手段是拒绝服务攻击 (denial-of-service, DoS attack)。DoS 攻击顾名思义就是让某些 server 停止工作，通常分为三大类：\nVulnerability attack：利用应用或操作系统的弱点代码攻击，使系统崩溃。 Bandwidth flooding：向目标主机传输大量的数据，使其应接不暇，无法接收其他的正常数据。 Connection flooding：攻击者和目标主机建立大量的 TCP 连接，使其应接不暇，无法建立其他的正常连接。 这里着重讨论一下 bandwidth flooding。有的时候一个 link 的 transmission rate 很高，用一台机器很难发送足够海量的数据，而且如果所有的垃圾数据都来自同一台机器，上游的 router 很容易监测到这种攻击并作出相应的防御。因此现在攻击者更倾向于使用分布式拒绝服务攻击 (distributed Dos, DDoS)。攻击者控制一个有成千上万台僵尸机的 botnet 来向目标主机倾泄垃圾数据。\nSniff Packets 坏人可能会在一个网络中放置一个被动的接受器，这个接受器可以将网络中传输的每个 packet 都复制一份，这样的被动接受器被称为包嗅探器 (packet sniffer)。\nsniffer 可以被用来窃取用户的隐私信息，其由于它是完全被动的，不会向网络主动发送 packet，所以它很难被发现。预防 packet sniffer 的有效手段是对包的内容进行加密。\nMasquerade as Someone You Trust 在网络中，我们可以很容易地制作一个包含任意源地址，目标地址和内容的 packet。网络中的节点只会负责地帮助我们转发这个包，但不一定能检验这个包的真实性。这种向网络中发送包含虚假源地址的包的攻击手段被称为 IP 欺骗 (IP spoofing)。通过 IP spoofing，我们可以在网络中伪装成另一个人与他人通信。\n为了防御 IP spoofing，我们需要在网络中添加 end-point authentication，即检验消息的源地址的真实性。\n1.7 History of Computer Networking and the Internet 略。\n","date":1663891200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663891200,"objectID":"a0bae3c162ead46f0d0f5607f3c6fd01","permalink":"https://kristoff-starling.github.io/notes/booknotes/network-topdown/ch01/","publishdate":"2022-09-23T00:00:00Z","relpermalink":"/notes/booknotes/network-topdown/ch01/","section":"notes","summary":"1.1 What Is the Internet 1.1.1 A Nuts-and-Bolts Description 1.1.2 A Services Description 1.1.3 What Is a Protocol 1.2 The Network Edge 1.2.1 Access Networks Home Access Enterprise Access Wide-Area Wireless Access 1.","tags":null,"title":"Chapter 1: Computer Networks and the Internet","type":"docs"},{"authors":null,"categories":null,"content":" A Simple Concurrent Programming Language Basic Setup Thread Subsystem Storage Subsystem Linking the Two The Thread Subsystem Thread Local Steps Lifting to Concurrent Programs SC Storage subsystem Linking the Thread and Storage Subsystems x86\u0026rsquo;s TSO Storage Subsystem: Linking The Thread and Storage Subsystem Exercise: PSO Storage System A Simple Concurrent Programming Language Basic domains:\nRegisters: $r\\in \\text{Reg}$. Memory locations: $x\\in \\text{Loc}$. Values (including 0): $v\\in \\text{Val}$. Thread identifiers: $i\\in \\text{Tid}=\\{1,\\cdots,N\\}$. Expressions and commands (here all commands are atomic):\ne ::= r | v | e +(-*/) e | ... c ::= skip | if e then c else c | while e do c | c ; c (sequential) | r := e | r := x (read) | x := e (write) r := FAA(x, e) | r := CAS(x, e, e) | fence FAA means \u0026ldquo;fetch-and-add\u0026rdquo;, r = FAA(x, e) will do\nr = x; x += e; atomically.\nCAS means \u0026ldquo;compare-and-set/swap\u0026rdquo;, r = CAS(x, er, ew) will do\nr = x; if (r == er) { x = ew; r = 1; } else r = 0; atomically.\nfence only takes effect under WMM. It forces previous writes to be propagated into memory.\nPrograms: $P:Tid\\to Cmd$, written as $P=c_1||c_2||\\cdots ||c_N$.\nBasic Setup Different memory models usually share the same thread behaviors while have different implementation on the read/write side. Therefore we decompose the system into thread subsystem and storage subsystem and set an \u0026ldquo;virtual\u0026rdquo; interface between them.\nThread Subsystem thread local step: $(c,s)\\overset{l}{\\to}(c\u0026rsquo;,s\u0026rsquo;)$, Lift them to program steps: $(P,S)\\overset{i,l}{\\to}(P\u0026rsquo;,S\u0026rsquo;)$. Storage Subsystem It\u0026rsquo;s memory-model-dependent.\nDescribe the effect of memory accesses and fences.\n$M\\overset{i:l}{\\to}M\u0026rsquo;$.\nLinking the Two Either the thread or the storage subsystem make an internel step, i.e., $\\epsilon$, or they make matching $i:l$ steps. The transformation is denoted as $P,S,M\\Rightarrow P\u0026rsquo;,S\u0026rsquo;,M\u0026rsquo;$.\nThe Thread Subsystem Thread Local Steps Store: $s:\\text{Reg}\\to \\text{Val}$ (initially $s_0\\triangleq \\lambda r.0$).\nState: $(c,s)\\in \\text{Command}\\times \\text{Store}$\nTransitions:\n$\\mathbf{skip}$: $$ \\frac{}{\\mathbf{skip};c,s\\overset{\\epsilon}{\\to}c,s} $$\nSequential:\n$$ \\frac{c_1,s\\overset{l}{\\to}c_1\u0026rsquo;,s\u0026rsquo;}{c_1;c_2,s\\overset{l}{\\to}c_1\u0026rsquo;,c_2,s\u0026rsquo;} $$\nRegister operations: $$ \\frac{s\u0026rsquo;=s[r\\mapsto s(e)]}{\\text{r:=e},s\\overset{\\epsilon}{\\to}\\mathbf{skip},s\u0026rsquo;} $$ Memory read: $$ \\frac{l=R(x, v)}{\\text{r:=x},s\\overset{l}{\\to}\\mathbf{skip},s[r\\to v]} $$ Here $l=R(x, v)$ means that we read from the memory and $M[x] = v$.\nMemory write: $$ \\frac{l=W(x, s(e))}{\\text{x:=e,s}\\overset{l}{\\to}\\mathbf{skip},s} $$ $\\mathbf{if}$-$\\mathbf{then}$-$\\mathbf{else}$ branch: $$ \\frac{s(e)\\neq 0}{\\mathbf{if}\\space e\\space \\mathbf{then}\\space c_1\\space \\mathbf{else}\\space c_2,s\\overset{\\epsilon}{\\to}c_1,s} $$\n$$ \\frac{s(e)= 0}{\\mathbf{if}\\space e\\space \\mathbf{then}\\space c_1\\space \\mathbf{else}\\space c_2,s\\overset{\\epsilon}{\\to}c_2,s} $$\n$\\mathbf{while}$ loop: $$ \\frac{}{\\mathbf{while}\\space e\\space \\mathbf{do}\\space c,s\\overset{\\epsilon}{\\to}\\mathbf{if}\\space e\\space\\mathbf{then}\\space (c;\\mathbf{while}\\space e\\space \\mathbf{do}\\space c)\\space \\mathbf{else}\\space \\mathbf{skip},s} $$ Fetch-and-add: $$ \\frac{l=U(x, v, v + s(e))}{\\text{r:=}\\mathbf{FAA}(x,e),s\\overset{l}{\\to}\\mathbf{skip},s[r\\to v]} $$ Here we define a new way to interact with memory: U (update). U(x, vr, vw) means that we fetch $v_r$ from $M[x]$ and write $v_w$ to $M[x]$.\nCompare-and-swap: $$ \\frac{l=R(x, v)\\quad v\\neq s(e_r)}{\\text{r:=}\\mathbf{CAS}(x, e_r,e_w),s\\overset{l}{\\to}\\mathbf{skip},s[r\\to 0]} $$\n$$ \\frac{l=U(x, s(e_r), s(e_w))}{\\text{r:=}\\mathbf{CAS}(x, e_r,e_w),s\\overset{l}{\\to}\\mathbf{skip},s[r\\to 1]} $$\nIt\u0026rsquo;s worth noticing that when compare-and-swap fails, it acts as a normal read operation (\u0026ldquo;R\u0026rdquo; instead of \u0026ldquo;U\u0026rdquo;)\nFence: $$ \\frac{}{\\mathbf{fence},s\\overset{F}{\\to}\\mathbf{skip},s} $$ For WMM, when the memory receives \u0026ldquo;F\u0026rdquo;, it will do particular operations.\nLifting to Concurrent Programs State: $(P,S)\\in\\text{Program}\\times (\\text{Tid}\\to \\text{Store})$. (initially $(P,S_0)$, where $S_0\\triangleq \\lambda i.s_0$)\nTransitions: $$ \\frac{P(i),S(i)\\overset{l}{\\to}c,s}{P,S\\overset{i:l}{\\mapsto}P[i\\to c],S[i\\mapsto s]} $$\nSC Storage subsystem Machine state: $M:\\text{Loc}\\to\\text{Val}$ (initially $M_0\\triangleq \\lambda x.0$).\nTransitions: $$ \\frac{l=W(x, v)}{M\\overset{i:l}{\\to}M[x\\mapsto v]} $$\n$$ \\frac{l=R(x, v)\\quad M[x]=v}{M\\overset{i:l}{\\to}M} $$\n$$ \\frac{l=U(x,v_r,v_w)\\quad M[x]=v_r}{M\\overset{i:l}{\\to}M[x\\mapsto v_w]} $$\n$$ \\frac{l=F}{M\\overset{i:l}{\\to}M} $$\n(fence doesn\u0026rsquo;t take effect in SC memory model.)\nLinking the Thread and Storage Subsystems Silent: $$ \\frac{P,S\\overset{i:\\epsilon}{\\to}P\u0026rsquo;, S\u0026rsquo;}{P,S,M\\Rightarrow P\u0026rsquo;,S\u0026rsquo;,M} $$ Non-silent: $$ \\frac{P,S\\overset{i:l}{\\to}P\u0026rsquo;,S\u0026rsquo;\\quad M\\overset{i:l}{\\to}M\u0026rsquo;}{P,S,M\\Rightarrow P\u0026rsquo;,S\u0026rsquo;,M\u0026rsquo;} $$ An outcome $O:\\text{Tid}\\to\\text{Store}$ is allowed for a program $P$ under SC if there exists $M$ such that $$ P,S_0,M_0\\Rightarrow^* \\mathbf{skip}||\u0026hellip;||\\mathbf{skip},O,M. $$\nx86\u0026rsquo;s TSO Storage Subsystem: Machine states:\nA memory $M:\\text{Loc}\\to\\text{Val}$ A function $B:\\text{Tid}\\to (\\text{Loc},\\text{Val})^*$ assigning a store buffer to every thread. Here a pair $(x, v)$ stands for a write. The most recent write appears at the left most position of the write sequence. (Initially, $M_0\\triangleq \\lambda x.0$,$B_0=\\lambda i.\\epsilon$).\nTransitions:\nWrite (only to the thread-local buffer): $$ \\frac{l=W(x, v)}{M,B\\overset{i:l}{\\to}M,B[i\\mapsto (x,v)\\cdot B(i)]} $$ Propagate (flush the least recent operation in the buffer to the memory): $$ \\frac{B(i)=b\\cdot (x,v)}{M,B\\overset{i:\\epsilon}{\\to}M[x\\mapsto v],B[i\\mapsto b]} $$ Read $$ \\frac{l=R(x,v)\\quad B(i)=(x_n,v_n)\\cdot\\ldots\\cdot(x_1,v_1)\\quad M[x_1\\mapsto v_1]\\cdots[x_n\\mapsto v_n] (x)=v}{M,B\\overset{i:l}{\\to}M,B} $$ Notice that during a read, the buffer won\u0026rsquo;t be flushed into the memory.\nRMW (read-modify-write): $$ \\frac{l=U(x,v_r,v_w)\\quad B(i)=\\epsilon \\quad M(x)=v_r}{M,B\\overset{i:l}{\\to}M[x\\mapsto v_w],B} $$ The condition $B(i)=\\epsilon$ indicates that RMW will automatically synchronize the state. Notice that in $\\mathbf{CAS}$, if the comparison failed, $\\mathbf{CAS}$ would act as a normal \u0026ldquo;read\u0026rdquo; operation and in TSO no synchronization would be conducted.\nFence: $$ \\frac{l=F\\quad B(i)=\\epsilon}{M,B\\overset{i:l}{\\to}M,B} $$ Fence is used as forced synchronization.\nLinking The Thread and Storage Subsystem Silent thread: $$ \\frac{P,S\\overset{i:\\epsilon}{\\to}P\u0026rsquo;,S\u0026rsquo;}{P,S,M,B\\Rightarrow P,S\u0026rsquo;,M,B} $$ Silent storage: $$ \\frac{M,B\\overset{i:\\epsilon}{\\to}M\u0026rsquo;,B\u0026rsquo;}{P,S,M,B\\Rightarrow P,S,M\u0026rsquo;,B\u0026rsquo;} $$ Non silent: $$ \\frac{P,S\\overset{i:l}{\\to}P\u0026rsquo;,S\u0026rsquo;\\qquad M,B\\overset{i:l}{\\to}M\u0026rsquo;,B\u0026rsquo;}{P,S,M,B\\Rightarrow P\u0026rsquo;,S\u0026rsquo;,M\u0026rsquo;,B\u0026rsquo;} $$ The definition of allowed outcome is similar to that of SC.\nExercise: PSO Storage System Partial Store Ordering (PSO) is a WMM similar to TSO, but it does not guarantee that stores to different locations propagate to the main memory in the order they were issued. In particular, it allows the following weak behavior:\nInitially, x = y = 0; x = 1; || a = y; // 1 y = 1; || b = x; // 0; (1) Operational semantics for PSO:\nWe only need to redefine the propagate rule in TSO: $$ \\frac{B(i)=b\u0026rsquo;\\cdot(x,v)\\cdot b\\qquad b=(x_t,v_t)\\cdot\\ldots\\cdot(x_1,v_1),\\forall 1\\leq i\\leq t,x_i\\neq x}{M,B\\overset{i:\\epsilon}{\\to}M[x\\mapsto v],B[i\\mapsto b\u0026rsquo;\\cdot b]} $$ (2) store-store fence:\nIn the thread subsystem: $$ \\frac{}{\\mathbf{ssfence};c,s\\overset{SSF}{\\to}\\mathbf{skip};c,s} $$ In the storage subsystem:\nSSF rule: add a special mark into the buffer array: $$ \\frac{}{M,B\\overset{SSF}{\\to}M,B[i\\mapsto F\\cdot B(i)]} $$ Propagation rule needn\u0026rsquo;t be changed because our conditions implicitly require that there\u0026rsquo;s no store-store fence before the target operation. But we need an additional rule to move away \u0026ldquo;F\u0026rdquo; marks: $$ \\frac{B(i)=b\\cdot F}{M,B\\overset{i:\\epsilon}{\\to}M\u0026rsquo;,B[i\\mapsto b]} $$ (3) Show that programs containing store-store fences between every two writes have the same outcomes under TSO and PSO:\nTSO and PSO differ only in their propagation rules. If there is a store-store fence between every two writes, it\u0026rsquo;s easy to prove that at any point, the buffer of arbitrary thread should be in the form of $(x_n,v_n)\\cdot F\\cdot \\ldots \\cdot F\\cdot (x_2,v_2)\\cdot F\\cdot (x_1,v_1)$. Therefore at any point the propagation rule in PSO can only choose the least recent operation in the buffer to propagate, which makes it completely the same as TSO\u0026rsquo;s propagation rule.\n","date":1663632000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663632000,"objectID":"0fd5c9e5a384c343cc49e9aa239ed5f3","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-concurrency/lectures/lec03/","publishdate":"2022-09-20T00:00:00Z","relpermalink":"/notes/coursenotes/nju-concurrency/lectures/lec03/","section":"notes","summary":"A Simple Concurrent Programming Language Basic Setup Thread Subsystem Storage Subsystem Linking the Two The Thread Subsystem Thread Local Steps Lifting to Concurrent Programs SC Storage subsystem Linking the Thread and Storage Subsystems x86\u0026rsquo;s TSO Storage Subsystem: Linking The Thread and Storage Subsystem Exercise: PSO Storage System A Simple Concurrent Programming Language Basic domains:","tags":null,"title":"Lecture 03: Operational Semantics for Concurrency","type":"docs"},{"authors":null,"categories":null,"content":" PL and Static Analysis Why We Learn Static Analysis What is Static Analysis Static Analysis Features and Examples Static Analysis: Bird\u0026rsquo;s Eye View Static Analysis: An Example Abstraction Over-approximation PL and Static Analysis Programming Languages:\nTheory: language design, type system, semantics and logics. etc. Environment: compilers, runtime system etc. Application: ensure the soundness, performance, security of projects =\u0026gt; program analysis/verification/synthesis. Background: in recent decades, the language cores had few changes, but the programs became significantly larger and more complicated.\nPL Categories\nImperative languages (e.g. Java, C++): fine control on program states (hardware) Functional languages (e.g. Haskell, OCaml, scheme): reduce side effects (states of programs), but less control on states Declarative languages (e.g. SQL, prolog) abstraction on computing process, describe targets of programs. Challenge: How to ensure the reliability, security and other promises of large-scale and complex programs?\nWhy We Learn Static Analysis Static Analysis (static means at compile time, before execution) are helpful in\nProgram Reliability: null pointer dereferences, memory leak etc. Program Security: private information leak, injection attack etc. Compiler Optimization: dead code elimination, code motion etc. Program Understanding: IDE call hierarchy, type indication etc. What is Static Analysis Static analysis analyzes a program $P$ to reason about its behaviors and determines whether it satisfies some properties before running $P$.\nCan two pointers point to the same memory location? Does $P$ dereference any null pointers? Will certain assert() statements in $P$ fail? …… Unfortunately, by Rice\u0026rsquo;s Theorem, there is no such approach to determine whether $P$ satisfies such non-trivial properties, i.e., giving exact answer: Yes or No.\nRice Theorem\nAny non-trivial property of the behavior of programs in a r.e.(recursively enumerable, recognizable by a Turning-machine) language is undecidable.\nA property is trivial if either it\u0026rsquo;s not satisfied by any language or it\u0026rsquo;s satisfied by all languages. (Non-trivial properties $\\approx$ properties related with run-time behaviors of programs)\n“Perfect\u0026quot;, i.e., sound and complete, static analysis does not exist.\nSoundness and Completeness\nSoundness: over-approximation, the result is a superset of the truth.\nCompleteness: under-approximation, the result is a subset of the truth.\nUseful static analysis should compromise. If we compromise soundness, we introduce false negatives; if we compromise completeness, we introduce false positives. Mostly static analysis techniques compromise completeness, i.e. sound but not fully precise static analysis.\nSoundness is critical to a collection of important applications. For example:\nB b = new B(); | C c = new C(); a.fld = b; | a.fld = c; fld = (B) a.fld; // \u0026lt;- is the casting safe? (This is a control flow graph, not concurrent threads.) If the analysis is unsound, e.g. only contains the behavior of the first snippet, we may come to the false conclusion that the casting is safe.\nStatic Analysis Features and Examples Static Analysis: Bird\u0026rsquo;s Eye View if (input) x = 1; else x = 0; // x = ? Two analysis results:\nWhen input is true, x = 1; when input is false, x = 0. - Sound, precise, expensive. x = 1 or x = 0. - Sound imprecise, cheap. The goal of static analysis is to ensure soundness while making good trade-offs between analysis precision and analysis speed.\nTwo words to conclude: abstraction \u0026amp; over-approximation.\nStatic Analysis: An Example Target: determine the sign (+/-/0) of all the variables of a given program (useful in divided-by-0 detection, negative indices detection\u0026hellip;).\nAbstraction Under this specific goal we don\u0026rsquo;t care about the exact value (e.g. 10 or 20), we only care about the sign. The abstraction construct a mapping from concrete domain to abstract domain: ($+,-,0,T,\\top,\\bot$) ($\\top$ stands for unknown, $\\bot$ stands for undefined).\nOver-approximation Transfer functions define how to evaluate different program statements on abstract values.\ne.g. + ++ =+, + +- =T.\nx = 10; + y = -1; - z = 0; 0 a = x + y; unknown b = z / y; 0 c = a / b; undefined -\u0026gt; divided by zero p = arr[y]; undefined -\u0026gt; negative index q = arr[a]; undefined -\u0026gt; negative index c and p shows the usefulness of static analysis. q shows that static analysis may lead to false positives.\nControl flow\nx = 1; if (input) y = 10; else y = -1; z = x + y; graph TD S1(x=1) --\u0026gt; |y=+|S2(y=10) S1 --\u0026gt; |y=-|S3(y=-1) S2 --\u0026gt; S4(\u0026quot;z=x+y\u0026lt;br\u0026gt;(merge: y=unknown)\u0026quot;) S3 --\u0026gt; S4 As it\u0026rsquo;s impossible to enumerate all paths in practice, flow merging is taken for granted in most static analysis.\n","date":1663200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663200000,"objectID":"84d6c299b611d8382515418c9e207221","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-software-analysis/lectures/lec01/","publishdate":"2022-09-15T00:00:00Z","relpermalink":"/notes/coursenotes/nju-software-analysis/lectures/lec01/","section":"notes","summary":"PL and Static Analysis Why We Learn Static Analysis What is Static Analysis Static Analysis Features and Examples Static Analysis: Bird\u0026rsquo;s Eye View Static Analysis: An Example Abstraction Over-approximation PL and Static Analysis Programming Languages:","tags":null,"title":"Lecture 01: Introduction","type":"docs"},{"authors":null,"categories":null,"content":" Sets Generalized Unions of Sets Generalized Intersections of Sets Relations Basic notations Equivalence Relations Functions Variation Function Types Currying Products Tuples as Functions Generalized Products Exponentiation Sums Sets Generalized Unions of Sets $$ \\begin{align} \\bigcup S \u0026amp;\\triangleq \\{x\\space |\\space \\exists \\space T\\in S. x\\in T\\}\\\\ \\bigcup_{i\\in I} S(i) \u0026amp;\\triangleq \\bigcup\\{S(i) \\space|\\space i\\in I\\}\\\\ \\bigcup_{i=m}^n S(i) \u0026amp;\\triangleq \\bigcup_{i\\in [m,n]} S(i) \\end{align} $$\nNote: in the first definition, $S$ is a a set of sets.\nGeneralized Intersections of Sets $$ \\begin{align} \\bigcap S \u0026amp;\\triangleq \\{x\\space|\\space \\forall\\space T\\in S. x\\in T\\}\\\\ \\bigcap_{i\\in I} S(i) \u0026amp;\\triangleq \\bigcup\\{S(i)\\space |\\space i\\in I\\}\\\\ \\bigcap_{i=m}^n S(i) \u0026amp;\\triangleq \\bigcup_{i\\in [m,n]} S(i) \\end{align} $$\nLet\u0026rsquo;s consider $\\emptyset$. For union: $$ \\begin{align} \\bigcup \\emptyset \u0026amp;= \\{x\\space|\\space \\exists\\space T\\in \\emptyset. x\\in T\\}\\\\ \u0026amp;= \\{x\\space|\\space \\exists\\space T. T\\in \\emptyset\\space \\wedge x\\in T\\}\\\\ \u0026amp;=\\emptyset \\end{align} $$ For intersection: $$ \\begin{align} \\bigcap \\emptyset \u0026amp;= \\{x\\space|\\space \\forall\\space T\\in \\emptyset.x\\in T\\}\\\\ \u0026amp;=\\{x\\space|\\space \\forall\\space T.T\\in \\emptyset\\to x\\in T\\}\\\\ \u0026amp;=\\{x\\space|\\space \\forall\\space T.\\text{false}\\to x\\in T\\}\\\\ \\end{align} $$ This results in \u0026ldquo;a set of everything\u0026rdquo;, which contradicts the Russel paradox. Therefore $\\bigcap \\emptyset$ is meaningless.\nRussel Paradox\nIf there exists \u0026ldquo;a set of everything\u0026rdquo;, denoted as $A$. Consider $$ B=\\{x\\in A\\space |\\space x\\notin x\\} $$ Since $A$ is a set of everything, $B\\in A$. The question is whether $B\\in B$.\nIf $B\\in B$, then according to the definition of $B$, $B\\notin B$ holds. If $B\\notin B$, then according to the definition of $B$, $B\\in B$ holds. Relations $$ A\\times B\\triangleq \\{(x, y)\\space|\\space x\\in A \\text{ and }y\\in B\\} $$\nHere $(x, y)$ is called a pair. We denote $\\pi_0(x, y)=x,\\pi_1(x, y)=y$.\n$\\rho$ is a relation from $A$ to $B$ if $\\rho \\subseteq A\\times B$, or equivalently, $\\rho \\in \\mathcal P(A\\times B)$\nBasic notations Identity: $\\text{Id}_s\\triangleq \\{(x, y)\\space |\\space x\\in S\\}$. Domain: $dom(\\rho)\\triangleq \\{x\\space |\\space \\exists\\space y. (x,y)\\in \\rho\\}$. Range: $ran(\\rho)\\triangleq \\{y\\space |\\space \\exists\\space x. (x, y)\\in\\rho\\}$. Composition: $\\rho\u0026rsquo;\\circ\\rho\\triangleq \\{(x,z)\\space |\\space \\exists\\space y.(x,y)\\in \\rho \\space\\wedge\\space (y,z)\\in\\rho\u0026rsquo;\\}$. Inverse: $\\rho^{-1}\\triangleq \\{(x, y)\\space |\\space (y,x)\\in \\rho\\}$ Equivalence Relations $\\rho$ is an equivalence relation on $S$ if it\u0026rsquo;s reflexive, symmetric and transitive.\nReflexivity: $\\text{Id}_s\\subseteq \\rho$. Symmetry: $\\rho^{-1}\\subseteq \\rho$. Transitivity: $\\rho \\circ\\rho \\subseteq \\rho$. Functions A relation $\\rho$ is a function if for all $x,y,y\u0026rsquo;$, $(x,y)\\in \\rho$ and $(x,y\u0026rsquo;)\\in\\rho$ imply $y=y\u0026rsquo;$.\nEmpty set is a special function (check the definition).\nFunctions can be denoted by Typed Lambda Expressions: $\\lambda x\\in S. E$ denotes the function $f$ with domain $S$ such that $f(x)=E$ for all $x\\in S$.\nVariation Variation of a function at a single argument: $$ f\\{x\\rightsquigarrow n\\}\\triangleq \\lambda z. \\begin{cases} f\\space z\u0026amp;, z\\neq x\\\\ n\u0026amp;,z=x \\end{cases} $$ Note that $x$ does not have to be in $dom(f)$.\nFunction Types We use $A\\to B$ to represent the set of all functions from $A$ to $B$.\n$\\to$ is right associative, i.e., $A\\to B\\to C=A\\to(B\\to C)$.\nExample: if $f\\in A\\to B\\to C$, then for any $a\\in A$ and $b\\in B$ $f\\space a\\space b=(f(a))b\\in C$ (here $f(a)$ is another function).\nCurrying $f\\in A_1\\times A_2\\times \\cdots \\times A_n\\to B$, $f(a_1, a_2, \\cdots, a_n)=b$\nCurrying: $g\\in A_1\\to A_2\\to \\cdots A_n$. $g\\space a_1\\space a_2\\cdots a_n=b$.\nProducts Product: $$ S_0\\times S_1\\times S_{n-1}\\triangleq \\{(x_0,\\cdots, x_{n-1}\\space|\\space \\forall\\space i=1,\\cdots ,n.x_i\\in S_i\\} $$ $\\pi_i(x_0,\\cdots, x_{n-1})=x_i$.\nTuples as Functions $(x_0,x_1,\\cdots, x_{n-1})$ can be viewed as a function: $$ \\lambda i\\in \\mathbf{n}.\\begin{cases}x_0\u0026amp;,i=0\\\\x_1\u0026amp;,i=1\\\\\u0026amp;\\cdots\\\\x_{n-1}\u0026amp;,i={n-1}\\end{cases} $$ where $\\mathbf{n}=\\{0,1,\\cdots n-1\\}$.\nThen $$ S_0\\times \\cdots \\times S_{n-1}\\triangleq \\{f\\space|\\space dom(f)=\\mathbf{n}, \\forall\\space i\\in \\mathbf{n}, f\\space i\\in S_i\\} $$\nGeneralized Products $$ \\prod_{i\\in I}S(i)\\triangleq \\{f\\space |\\space dom(f)=I, \\forall \\space i\\in I,f\\space i\\in S(i)\\} $$\nLet $\\theta$ be a function from a set of indices to a set of sets, i.e., $\\theta$ is an indexed family of sets. Then $$ \\Pi\\theta\\triangleq \\{f\\space |\\space dom(f)=dom(\\theta), \\forall\\space i\\in dom(\\theta).f\\space i\\in \\theta\\space i\\} $$ Some interesting corner cases:\n$\\Pi \\emptyset=\\{\\emptyset\\}$. If there exists $i\\in dom(\\theta)$, $\\theta\\space i=\\emptyset$, then $\\Pi\\theta=\\emptyset$. Exponentiation We denote $S^T$ for $\\displaystyle{\\prod_{x\\in T} S}$ if $S$ is independent of $x$. An interesting fact is that $$ \\begin{align} S^T\u0026amp;=\\prod_{x\\in T}S=\\Pi\\lambda x\\in T. S\\\\ \u0026amp;=\\{f\\space|\\space dom(f)=T,\\forall\\space x\\in T,f\\space x\\in S\\}\\\\ \u0026amp;=(T\\to S) \\end{align} $$ We always use $\\mathbf{2}^S$ for power set $\\mathcal P(S)$. That\u0026rsquo;s because $\\mathbf{2}^S=(S\\to 2)$. For any subset $T$ of $S$, we can define $$ f = \\lambda x\\in S. \\begin{cases}1\u0026amp;, x\\in T\\\\0\u0026amp;,x\\notin T\\end{cases} $$ Then $f\\in (S\\to 2)$. For any $f\\in (S\\to \\mathbf{2})$, we can also construct a subset of $S$.\nSums $$ S_0+S_1+\\cdots+S_n\\triangleq \\{(i,x)\\space|\\space i\\in \\mathbf{n}, x\\in S_i\\} $$\nGeneralized form: $$ \\sum_{i\\in I}S(i)\\triangleq\\{(i,x)\\space |\\space i\\in I, x\\in S(i)\\} $$\n$$ \\Sigma\\theta\\triangleq \\{(i,x)\\space |\\space i\\in dom(\\theta),x\\in \\theta\\space i\\} $$\nWe can prove that $\\displaystyle{\\sum_{x\\in T}S}=T\\times S$: $$ \\begin{align} \\sum_{x\\in T}S=\\{(x,y)\\space|\\space x\\in T,y\\in S\\}=T\\times S \\end{align} $$\n","date":1663113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663113600,"objectID":"d034510a12dc95c82064711411c6b67a","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-formal-semantics/lectures/lec02/","publishdate":"2022-09-14T00:00:00Z","relpermalink":"/notes/coursenotes/nju-formal-semantics/lectures/lec02/","section":"notes","summary":"Sets Generalized Unions of Sets Generalized Intersections of Sets Relations Basic notations Equivalence Relations Functions Variation Function Types Currying Products Tuples as Functions Generalized Products Exponentiation Sums Sets Generalized Unions of Sets $$ \\begin{align} \\bigcup S \u0026amp;\\triangleq \\{x\\space |\\space \\exists \\space T\\in S.","tags":null,"title":"Lecture 02: Mathematical Background","type":"docs"},{"authors":null,"categories":null,"content":" The Need of Weak Memory Model Design Criteria Happened-before Memory Model (HMM) Example: Store Buffering Example: Out-of-thin-Air Read Example: Independent Reads of Independent Writes (IRIW) Example: HMM - No DRF guarantee. Memory models define which reads see which writes. Sequential Consistency (SC) model is the simplest memory model: several threads\u0026rsquo; executions are interleaved (interleaving semantics), every read fetches the most recent write (full visibility).\nThe Need of Weak Memory Model SC mode prohibits many optimizations, e.g. store buffering\nInitially: x = y = 0; x = 1; || y = 1; r1 = y; || r2 = x; r1 = r2 = 0 is impossible in SC model. However, compilers are unaware of concurrency and may adjust the order of statements, which violates SC model:\nr1 = y; #1 || y = 1; #2 x = 1 #4 || r2 = x; #3 SC model is inconsistent with the current compiler \u0026amp; architecture implementations. That\u0026rsquo;s why we need weak memory models, which allow more behaviors.\nDesign Criteria Usability: DRF guarantee. DRF programs should have the same behaviors as in SC model. DRF stands for Data-Race-Freedom. A data race occurs when we have two concurrent conflicting operations.\nConflicting: two operations both access the same memory location and at least one is a write.\nConcurrent: two operations are not ordered by \u0026ldquo;happens-before\u0026rdquo;. Here \u0026ldquo;happens-before\u0026rdquo; varies under different memory models. In SC, \u0026ldquo;happens-before\u0026rdquo; means:\nProgram order: statement $S_1$ appears before $S_2$. Synchronization-with: lock - unlock Implementability: WMM cannot be too strong. It should be compatible with the mainstream compilers/architecture design:\nAllow common optimization techniques. Allow standard compilation schemes to major modern architectures. That is, for an arbitrary code $C$, let $WMM(C)$ be the set of possible behaviors of $C$ under WMM, $Compiler(C)$ be the set of possible behaviors after compilation, $Compiler(C)\\subseteq WMM(C)$ should hold.\nHowever, WMM cannot be too week either. e.g., type-safety and security guarantee shall be preserved.\nCompiler Optimization Can Be Smart\nIt\u0026rsquo;s difficult to put forward a good WMM because optimizations are complex. For example,\nr1 = x; || y = 2; r2 = x; || x = r3; if (r1 == r2) y = 2; || The code can be optimized like this:\ny = 2; // reorder r1 = x; r2 = r1; // reduce memory access if (true); // \u0026quot;r2 = r1\u0026quot; guarantees (r1 == r2) Happened-before Memory Model (HMM) Program execution: a set of events, and some orders between them.\nHappened-before order is the transitive closure of po (program order) and sw (synchronize-with). In HMM, a read can see\nThe most recent write that happens before it. A write that has no happens-before relation. In WMM, we consider declarative semantics, i.e., instead of constructing the execution, we firstly do assumptions on the result of reads, then we draw execution graph and check whether the result is reasonable.\nExample: Store Buffering graph LR S1(x=y=0) --\u0026gt; S2(x=1) --\u0026gt; S3(r1=y // 0?) S1 --\u0026gt; S4(y=1) --\u0026gt; S5(r2=x // 0?) S5 -.-\u0026gt; S1 S3 -.-\u0026gt; S1 Assumption: r1 = r2 = 0, we find that x = y = 0 is the most recent write that happens before r1 = y and r2 = x. Therefore the assumption is reasonable.\nExample: Out-of-thin-Air Read Out-of-thin-air (OOTA) read means that the result is completely unreasonable.\nInitially: x = y = 0; r1 = x; | r2 = y; y = r1; | x = r2; assumption: r1 = r2 = 42; graph LR S1(x=y=0) --\u0026gt; S2(r1=x // 42?) --\u0026gt; S3(y=42) S1 --\u0026gt; S4(r2=y // 42?) --\u0026gt; S5(x=42) S2 -.-\u0026gt; S5 S4 -.-\u0026gt; S3 Another understanding:\nSpeculation: r2 should be 42, which means that y needs to be 42. If r2 equals 42, then in thread #2 x will be 42. If x equals 42, then in thread #1 r1 will be 42. If r1 equals 42, then in thread #1 y will be 42. -\u0026gt; cycle formed, justified! OOTA reads should be prohibited, otherwise malicious inputs may challenge the safety of programming languages. Java\u0026rsquo;s JMM spare great efforts to eliminate OOTA from HMM, resulting in JMM\u0026rsquo;s complexity, and JMM may generate some surprising behaviors.\nJMM\u0026rsquo;s Suprising Behaviors - Example\nC1; || lock I || lock I; || C3; ===\u0026gt; C1; || C3; C2; || C2; || unlock I; || unlock I; || Adding more synchronization may increase behaviors!\nC1; || C2 || C3; ===\u0026gt; C1; || C3; C2; || Inlining threads may increase behaviors!\nExample: Independent Reads of Independent Writes (IRIW) Initially: x = y = 0; x = 1; || r1 = x; || r3 = y; || y = 1; || r2 = y; || r4 = x; || Assumption: r1 = 1, r2 = 0, r3 = 1, r4 = 0; The assumption means that thread #2 shows x=1 happens before y=1 while thread #3 shows y=1 happens before x=1, which is impossible in SC.\ngraph LR S1(x=y=0) --\u0026gt; S2(x=1) S1 --\u0026gt; S3(r1=x // 1?) --\u0026gt; S6(r2=y // 0?) S1 --\u0026gt; S4(r3=y // 1?) --\u0026gt; S7(r4=x // 0?) S1 --\u0026gt; S5(y=1) S3 -.-\u0026gt; S2 S4 -.-\u0026gt; S5 S6 -.-\u0026gt; S1 S7 -.-\u0026gt; S1 However, In HMM, it\u0026rsquo;s allowed.\nExample: HMM - No DRF guarantee. Initially: x = y = 0; r1 = x; || r2 = y; if (r1 != 0) || if (r2 != 0) y = 42; || x = 42; In SC, since both if statements yield false, the two threads have no data race and the program satisfies DRF property. However, in HMM, r1 = r2 = 42 is possible, demonstrating that HMM doesn\u0026rsquo;t have DRF guarantee:\ngraph LR S1(x=y=0) --\u0026gt; S2(r1=x // 42?) --\u0026gt; |if pass|S3(y=42) S1 --\u0026gt; S4(r2=y // 42?) --\u0026gt; |if pass|S5(x=42) S4 -.-\u0026gt; S3 S2 -.-\u0026gt; S5 ","date":1663027200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663027200,"objectID":"0e698f9c856517156b4061455a34c981","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-concurrency/lectures/lec02/","publishdate":"2022-09-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-concurrency/lectures/lec02/","section":"notes","summary":"The Need of Weak Memory Model Design Criteria Happened-before Memory Model (HMM) Example: Store Buffering Example: Out-of-thin-Air Read Example: Independent Reads of Independent Writes (IRIW) Example: HMM - No DRF guarantee.","tags":null,"title":"Lecture 02: Happens-before Memory Model","type":"docs"},{"authors":null,"categories":null,"content":"Limitations of Testing Tests can show the precense, not the absense of bugs.\nTesting is not useful in concurrent/network situations. Even if we find a bug, it\u0026rsquo;s difficult to reproduce it.\nCoq A formal proof management system. Refer to Software Foundations for Coq learning.\n","date":1662508800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662508800,"objectID":"f70306b941c084dffeb8b64c1aad7e79","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-formal-semantics/lectures/lec01/","publishdate":"2022-09-07T00:00:00Z","relpermalink":"/notes/coursenotes/nju-formal-semantics/lectures/lec01/","section":"notes","summary":"Limitations of Testing Tests can show the precense, not the absense of bugs.\nTesting is not useful in concurrent/network situations. Even if we find a bug, it\u0026rsquo;s difficult to reproduce it.","tags":null,"title":"Lecture 01: Introduction","type":"docs"},{"authors":null,"categories":null,"content":" Implementations of Concurrent Programs Problem with Concurrency Model Summary Programmers View Memory Model Store Buffering Load Buffering WMM for High-Level Languages Implementations of Concurrent Programs Python:\nimport threading def func(): ... if __name__ == '__main__': t = threading.Thread(target=func,args=...) t.start() t.join() Java: use \u0026ldquo;Runnable\u0026rdquo; module\nC++: use \u0026lt;thread\u0026gt; header file.\nSome programming languages use message-passing mechanism instead of sharing memory, such as Go. But we can use the same abstraction.\nProblem with Concurrency Interleaving semantics means that the execution is non-deterministic, which is difficult for bug detection and reproduction.\nvoid thread_function() { for (int i = 0; i \u0026lt; 100; i++) std::cout \u0026lt;\u0026lt; \u0026quot;new thread\u0026quot; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; '\\n'; } int main () { std::thread t(thread_function); for (int i = 0; i \u0026lt; 100; i++) std::cout \u0026lt;\u0026lt; \u0026quot;main thread\u0026quot; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; '\\n'; } If we use \u0026lt;\u0026lt; to concatenate multiple outputs, the printing is not thread-safe and the example code results in interleaving outputs.\nThe simplest solution to this is to use locks (synchronization operations):\nstd::mutex mu; void shared_output(std::string msg, int i) { std::lock_guard\u0026lt;std::mutex\u0026gt; guard(mu); std::cout \u0026lt;\u0026lt; msg \u0026lt;\u0026lt; i \u0026lt;\u0026lt; '\\n'; } Model Summary Multiple threads Single shared memory Objects live in memory Unpredictable asynchronous delays. Programmers View Parallel composition, shared memory \u0026amp; interleaving semantics Lock \u0026amp; synchronization operations Concurrent objects (e.g. implementation of locks) and their clients Memory Model In computing, a memory model describes the interactions of threads through memory and their shared use of data.\nWhen we write codes, we use sequential consistency (SC) model to understand it. However:\nNo multiprocessor implements SC. Modern compilers may invalidate the order. Each hardware has its own memory model. Theses models are called weak/relaxed memory model. (Here the \u0026ldquo;weak\u0026rdquo; means that practical memory model may have more \u0026ldquo;unexpected\u0026rdquo; behavior.)\nStore Buffering Initially: x = y = 0; x = 1; | y = 1; r1 = y; | r2 = x; It\u0026rsquo;s possible that r1 = r2 = 0 ! (e.g. in X86.)\nX86\u0026rsquo;s TSO memory model:\nWhen we write data to the memory, the processor puts the data to the buffer and updates the buffer to the memory later. Each processor\u0026rsquo;s buffer is invisible to other processors.\nA possible execution leading to r1 = r2 = 0 is shown as follows:\nx = 1 in T1 (write to buffer) y = 1 in T2 (write to buffer) r1 = y in T1 (no y in T1\u0026rsquo;s buffer, read from memory, get 0) r2 = x in T2 (no x in T2\u0026rsquo;s buffer, read from memory, get 0) Update buffers to memory. Load Buffering Initially: x = y = 0; r1 = x; || r2 = y; y = 1; || x = 1; It\u0026rsquo;s possible that r1 = r2 = 1 ! (e.g. in ARM)\nWMM for High-Level Languages For programmers, if they write code that satisfies DRF property, the compilers and processors guarantee SC behavior.\nWe should embrace WMM since it\u0026rsquo;s part of the reality. Furthermore, many programs don\u0026rsquo;t rely on the strict SC model to ensure correctness.\n","date":1662422400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662422400,"objectID":"ca23a34ca6964790afa6ab50b6eb4ab1","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-concurrency/lectures/lec01/","publishdate":"2022-09-06T00:00:00Z","relpermalink":"/notes/coursenotes/nju-concurrency/lectures/lec01/","section":"notes","summary":"Implementations of Concurrent Programs Problem with Concurrency Model Summary Programmers View Memory Model Store Buffering Load Buffering WMM for High-Level Languages Implementations of Concurrent Programs Python:\nimport threading def func(): .","tags":null,"title":"Lecture 01: Introduction","type":"docs"},{"authors":null,"categories":null,"content":"Error Handling Purpose of the compiler:\nto detect non-valid programs to translate the valid ones. The error handler should\nReport errors accurately and clearly Recover from an error quickly Not slow down compilation too much. Panic Mode When an error is detected, the parser discards tokens until one with a clear role is found and continues from there. The tokens \u0026ldquo;with a clear role\u0026rdquo; are referred to as syncrhonizing tokens and typically are the statement or expression terminators.\nFor example, the expression (1++2)+3 is invalid. When the parser sees the second +, it knows that it\u0026rsquo;s invalid to have 2 consecutive + and enters panic mode. In panic mode, a possible recovery strategy is to skip ahead to next integer and then continue, i.e., continue at 2.\nIn Bison, we can use the special terminal error to describe how much input to skip. For example, if we write $$ E\\to \\text{int}\\space |\\space E+E\\space |\\space (E)\\space |\\space \\text{error int}\\space |\\space (\\text{error}) $$ when the parser enters panic mode, error will match any number of characters and the rule error int will let the parser continue at the next integer.\nError Productions Another way to handle errors is to specify known common mistakes into the grammar. For example, it\u0026rsquo;s common for programmers to forget * (i.e. 5x instead of 5 * x), so we can write $$ E\\to\\space \u0026hellip;\\space |\\space E\\space E $$ The E E is responsible for matching errors.\nThe disadvantages of error productions is that it significantly slows down the compilation.\nError Correction Some compilers support error correction. When it encounters an error, it will find a correct \u0026ldquo;nearby\u0026rdquo; program through exhaustive search or token insertions/deletions.\nThe disadvantages of error correction:\nhard to implement. slows down parsing of correct programs. \u0026ldquo;nearby\u0026rdquo; is not necessarily \u0026ldquo;the intended\u0026rdquo; program. Abstract Syntax Trees For an expression 5+(12+3), we have a parse tree:\ngraph TD s1((E)) --\u0026gt; s2((E)) s1 --\u0026gt; s8((+)) s1 --\u0026gt; s3((E)) s2 --\u0026gt; s4((5)) s3 --\u0026gt; s5((\u0026quot;(\u0026quot;)) s3 --\u0026gt; s6((E)) s3 --\u0026gt; s7((\u0026quot;)\u0026quot;)) s6 --\u0026gt; s9((E)) s6 --\u0026gt; s10((+)) s6 --\u0026gt; s11((E)) s9 --\u0026gt; s12((12)) s11 --\u0026gt; s14((3)) However, the parse tree contains too much unnecessary information: parentheses, single-successor nodes etc. Therefore in compilers we use the abstract syntax tree (abbr: AST) instead.\ngraph TD s1(a) --\u0026gt; s2((5)) s1 --\u0026gt; s3(a) s3 --\u0026gt; s4((12)) s3 --\u0026gt; s5((3)) Recursive Descent Parsing In this algorithm, the parse tree is constructed from the top and from left to right. The general procedure is: we continuously check the left-most unchecked node:\nIf it\u0026rsquo;s an unterminal, we try the productions in order and recursively do the parsing. If it\u0026rsquo;s an terminal, we compare the node with the current character in the input string (backtracking is needed if they fail to match). Recursive Descent Algorithm Let TOKEN be the type of tokens. Let the global next pointer to the next input token.\nSome needed boolean functions:\nbool term(TOKEN tok) // whether a given token terminal matches the input bool Sn(); // whether the n-th production of S works bool S(); // whether there exists any production of S that works An example: productions for arithmetic expressions with + * and parentheses: $$ \\begin{align} E\u0026amp;\\to T\\space |\\space T+E\\\\ T\u0026amp;\\to \\text{int}\\space |\\space \\text{int}\\space *\\space T\\space |\\space (E) \\end{align} $$ Our code should be\nbool term(TOKEN tok) { return *next++ = tok; } bool E1() { return T(); } bool E2() { return T() \u0026amp;\u0026amp; term(PLUS) \u0026amp;\u0026amp; E(); } bool T1() { return term(INT); } bool T2() { return term(INT) \u0026amp;\u0026amp; term(TIMES) \u0026amp;\u0026amp; T(); } bool T3() { return term(OPEN) \u0026amp;\u0026amp; E() \u0026amp;\u0026amp; term(CLOSE); } bool E() { TOKEN *save = next; return (next = save, E1()) || (next = save, E2()); } bool T() { TOKEN *save = next; return (next = sava, T1()) || (next = save, T2()) || (next = save, T3()); } To start the parser, set next to the first character of the input string and call E().\nLeft Recursion Consider the following grammar: $S\\to S\\alpha\\space |\\space \\beta$, which accepts strings with $\\beta$ at the beginning and arbitrary $\\alpha$ after. If we write the code:\nbool S1() { return S() \u0026amp;\u0026amp; term(ALPHA); } bool S2() { return term(BETA); } bool S() { TOKEN *save = next; return (next = save, S1()) || (next = save, S2()); } The program will result in infinite loop (S() calls S1(), S1() calls S() and so on). The problem is that the grammar is left recursive - the derivation generate strings from right to left, but our parser scans from left to right. We need to rewrite the grammars as right recursive: $$ \\begin{align} S\u0026amp;\\to \\beta S\u0026rsquo;\\\\ S\u0026rsquo;\u0026amp;\\to \\alpha S\u0026rsquo;\\space |\\space \\epsilon \\end{align} $$ In principle, grammars can be transformed to right recursive ones automatically. But in practice people manually do the transformation.\n","date":1661212800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661212800,"objectID":"44408969ca3660ac1a4a39cad428f574","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec06/","publishdate":"2022-08-23T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/lectures/lec06/","section":"notes","summary":"Error Handling Purpose of the compiler:\nto detect non-valid programs to translate the valid ones. The error handler should\nReport errors accurately and clearly Recover from an error quickly Not slow down compilation too much.","tags":null,"title":"Stanford-CS143 Lecture 06: Syntax-Directed Translation","type":"docs"},{"authors":null,"categories":null,"content":"Regular expression is the weakest formal language. There are lots of languages that cannot be represented by regular expression. e.g. $\\{(^i)^i:i\\geq 1\\}=\\{(),(()), ((())),\u0026hellip;\\}$ (the set of balanced parentheses).\nThe parser takes the output of lexer, i.e. sequence of tokens as input, and outputs the parse tree of the program.\nCool code: if x = y then 1 else 2 fi\nParser input/lexer output: IF ID = ID THEN INT ELSE INT FI\nParser output:\nIF-THEN-ELSE---+----=---+---ID | | +---INT +---ID | +---INT Context-Free Grammars The parser must distinguish between valid and invalid strings of tokens. Therefore we need a language, and a method, for describing valid strings of tokens.\nProgramming languages have recursive structure, which makes parsing difficult, and context-free grammars are a natural notation for this recursive structure.\nA CFG consists of\nA set of terminals, denoted as $T$. A set of non-terminals, denoted as $N$. A start symbol $s\\in N$. A set of productions. Each production is of format $X\\to Y_1,\\cdots, Y_n$, where $X\\in N$, $Y_i\\in T\\cup N\\cup {\\epsilon}$. Productions can be read as rules, meaning that LHS can be replaced by RHS. Example: all balanced parentheses sequence: $T={(,)},N={s}$, two rules: $$ \\begin{align} s \u0026amp;\\to (s)\\\\ s \u0026amp;\\to \\epsilon \\end{align} $$ The way to understand a CFG:\nBegin with a string with only the start symbol $S$. Replace any non-terminal $X$ in the string by the right-hand side of some production $X\\to Y_1,\\cdots Y_n$. Repeat (2) until there are no non-terminals. Formally, we use $\\alpha_1\\overset{*}{\\to}\\alpha_2$ to represent that string $\\alpha_1$ can be transformed to string $\\alpha_2$ in 0 or more steps (applying productions). Let $G$ be a context-free grammar with start symbol $S$, then the language $L(G)$ of $G$ is $$ L(G)=\\{a_1a_2\\cdots a_n|\\forall i.a_i\\in T \\wedge S\\overset{*}{\\to}a_1\\cdots a_n\\} $$ Terminals have no productions. In parsing terminals are usually tokens.\nSome parsing examples: $$ \\begin{align} \\text{EXPR} \u0026amp;\\to id\\\\ \u0026amp;\\quad |\\space if\\space \\text{EXPR}\\space then\\space \\text{EXPR}\\space else\\space \\text{EXPR}\\space fi\\\\ \u0026amp;\\quad |\\space while\\space \\text{EXPR}\\space loop\\space \\text{EXPR}\\space pool\\\\ \u0026amp;\\quad |\\space \\cdots \\end{align} $$\nDerivations A derivation is a sequence of productions: $s\\to \\alpha_1\\to \\alpha_2\\to \\cdots$. Derivations can be represented as parse trees. For example, the arithmetic expression $id*id+id$ has a derivation $$ E\\to E+E\\to E*E+E\\to id*E+E\\to id*id+E\\to id*id +id $$ and the parse tree is\ngraph TD s1((E)) --\u0026gt; s2((E)) s1((E)) --\u0026gt; s3(+) s1 --\u0026gt; s4((E)) s2 --\u0026gt; s5((E)) s2 --\u0026gt; s6(*) s2 --\u0026gt; s7((E)) s4 --\u0026gt; s8((id)) s5 --\u0026gt; s9((id)) s7 --\u0026gt; s10((id)) Terminals are on the leaves of the parse tree and the in-order traversal of leaves results in the original string.\nFor one string, there are various derivations. The most commonly used ones are left-most and right-most derivations. But one string has only one parse tree.\nAmbiguity A grammar is ambiguous if it has more than one parse tree for some string.\nFor example, id * id + id has two different computing orders (*-first v.s. +-first). There are mainly two ways to handle with ambiguity:\nRewrite grammar unambiguously. Write $$ \\begin{align} E\u0026amp;\\to E\u0026rsquo;+E\\space |\\space E\u0026rsquo;\\\\ E\u0026rsquo;\u0026amp;\\to id*E\u0026rsquo;\\space |\\space id\\space |\\space (E)*E\u0026rsquo;\\space |\\space (E) \\end{align} $$ instead of one production ( $E$ can represent arbitrary $E\u0026rsquo;$s summing together, $E\u0026rsquo;$ is responsible for * )\nEnforces precedence of operators (* over +).\nThe next example illustrates that it\u0026rsquo;s difficult to write unambiguous grammars. It\u0026rsquo;s common for us to write the grammar for \u0026ldquo;if-then-else\u0026rdquo; like this: $$ \\begin{align} E\u0026amp;\\to if\\space E\\space then\\space E\\\\ \u0026amp;\\quad |\\space if\\space E\\space then\\space E\\space else\\space E\\\\ \u0026amp;\\quad |\\space \\text{OTHERS} \\end{align} $$\nHowever, the statement IF E1 THEN IF E2 THEN E3 ELSE E4 is ambiguous following the above grammar because we don\u0026rsquo;t know whether ELSE E4 belongs to the inner IF or the outer IF. Usually, we want the ELSE statement to match the nearest unmatched IF, i.e. the statement should be understood as IF E1 THEN(IF E2 THEN E3 ELSE E4). To solve this, we need to define \u0026ldquo;MIF\u0026rdquo; (matched IF) and \u0026ldquo;UIF\u0026rdquo; (unmatched IF) in the grammar:\n$$ \\begin{align} E\u0026amp;\\to \\text{MIF}\\space |\\space \\text{UIF}\\space\\\\ \\text{MIF} \u0026amp;\\to if\\space E\\space then\\space \\text{MIF}\\space else\\space \\text{MIF}\\\\ \u0026amp;\\quad |\\space \\text{OTHERS}\\\\ \\text{UIF} \u0026amp;\\to if\\space E\\space then\\space E\\\\ \u0026amp;\\quad |\\space if\\space E\\space then\\space \\text{MIF}\\space else\\space \\text{UIF}\\\\ \u0026amp;\\quad |\\space \\text{OTHERS} \\end{align} $$\nIt\u0026rsquo;s impossible to automatically convert an ambiguous grammar to an unambiguous one, and it\u0026rsquo;s also hard to manually write those complicated grammars. Besides, ambiguous grammar are more natural and concise, so the common practice is to choose more natural grammar along with disambiguating declarations.\nMost tools allow precedence and associativity declarations to disambiguate grammars. Take id * id + id as an example, the natural grammar $$ \\begin{align} E\u0026amp;\\to E + E\\\\ \u0026amp;\\quad |\\space E * E\\\\ \u0026amp;\\quad |\\space (E) \\end{align} $$ along with declarations\n%left + %left * can erase ambiguity. The declarations say that both + and * are left associative, and because *\u0026rsquo;s declaration comes later, * has higher priority than +.\n","date":1661126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661126400,"objectID":"2b6bdbf76649e58241f7efcfeef88326","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec05/","publishdate":"2022-08-22T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/lectures/lec05/","section":"notes","summary":"Regular expression is the weakest formal language. There are lots of languages that cannot be represented by regular expression. e.g. $\\{(^i)^i:i\\geq 1\\}=\\{(),(()), ((())),\u0026hellip;\\}$ (the set of balanced parentheses).\nThe parser takes the output of lexer, i.","tags":null,"title":"Stanford-CS143 Lecture 05: Introduction to Parsing","type":"docs"},{"authors":null,"categories":null,"content":"3. Introduction flex 是一个生成 scanner 的工具。flex 接受一个 .flex 文件，.flex 文件用于描述如何生成一个 scanner，由若干 rules 组成，每条规则都是一个正则表达式和一段 C 代码的二元组。flex 工具会输出一个 C 代码 lex.yy.cc，该代码与 flex 的 runtime library 链接之后可以生成可执行文件。可执行文件执行时会分析输入的内容，如果某条规则的正则表达式与输入内容匹配则执行 rule 中定义的 C 代码。\n4. Some Simple Examples 一个最简单的例子如下：\nint num_lines = 0, num_chars = 0; %% \\n ++num_lines; ++num_chars; . ++num_chars %% . 表示匹配除了换行符以外的任何字符。上述规则可以统计输入内容中的字符数量和代码行数。\n5. Format 一个 .flex 文件的结构如下，不同 section 由 %% 分开：\ndefinitions %% rules %% user code 5.1 Definitions Section Definition 区域中的条目服从如下形式：\nname definition 其中 name 要求以下划线或字母开头，后面接任意个数的字母，下划线和 -。后续的定义中可以用 {name} 的方式使用前面的定义，例如\nDIGIT [0-9] ID [a-z][a-z0-9]* FLOAT {DIGIT}+\u0026quot;.\u0026quot;{DIGIT}* 由无缩进的 /* */ 或 %{ %} 包裹住的内容将被原样拷贝到生成的 C 代码中。由 %top{} 包裹住的内容将被拷贝到 C 代码的最前面。\n5.2 Rules Section Rules 区域中的条目服从如下形式：\npattern action 其中 pattern 是用于识别的模式，action 是识别到 pattern 后执行的指令，pattern 前不可以有缩进，action 必须和 pattern 在同一行 (如果 action 有多行则第一行需要和 pattern 同行)。\n在 rules section 的第一条 rule 之前可以用 %{ %} 包裹的方式定义一些变量，这些变量可以在 scanning 的过程中使用。\n5.3 User Code Section User code section 会被原样拷贝到 C 代码中。这个区域是 optional 的，如果省略的话分割 rules 和 user code 的 %% 也可以省略。\n5.4 Comments in the Input flex 支持 C 风格的注释，即 /* */ 之间的内容都会被视为注释，这些注释会被原样拷贝到 C 代码中。注释几乎可以添加在任何地方，除了以下两条限制：\n注释不能出现在 rules section 中本应该是 pattern 的地方，即 /* */ 不能无缩进地出现在一行的开头或者出现在 scanner states 之后。 注释不能出现在 definitions section 中的 %option 行中。 6. Patterns 本章节给出了可以用于 rules section 中 pattern 的语法。主要语法和扩展正则表达式相似。\n7. How the Input Is Matched 如果当前有多条规则 pattern 可以匹配，则 flex 会选择匹配长度最长的规则；如果有多条规则匹配长度相同，则 flex 会选择最先出现的规则 (这两条规则与编译器 lexical analysis 的要求相符)。\n如果没有规则可以匹配，那么 flex 会使用默认规则：将第一个字符原样输出。\n当 match 决定之后，全局变量 yytext (char 指针) 会指向匹配的内容 (token)，yyleng (int 变量) 会存储匹配的长度，这些变量可以在 action 的代码中使用。\nyytext 有两种可以选取的定义方式：一个是 char *，一个是 char []，在 definitions section 可以通过 %pointer/%array 来指定 (默认采取指针)。\n采取指针的好处是更快的速度以及不用担心 token 过长导致的 overflow 问题。 采取数组的好处是可以自由地修改 yytext 的内容。数组的大小默认是 YYLMAX，在 definitions section 可以通过宏定义的方式自定义这个长度。 8. Actions 每条 rule 中的 pattern 都有一个对应的 action，action 可以是一段任意的 C 代码。如果一个 pattern 后的 action 为空，那么这个 pattern 匹配到的输入内容将被忽略。\n下面是一个简单的 action 的例子，它可以将连续的多个 whitespace 缩减成一个，并且过滤行末 whitespace：\n%% [ \\t]+ putchar(' '); [ \\t]+$ /* ignore this token */ action 中可以书写任意 C 代码，甚至可以使用 return 向 yylex() 的调用者返回内容。\n如果 action 中有 {，那么这个 action 是可以跨行的，flex 会把直到与其对应的 } 前的所有内容当作本条 rule 的 action。\n如果 action 的内容是 |，那么它的意思是“该 rule 的 action 和下一条 rule 的 action 相同”。\naction 中有一些特殊的命令可以使用：\nECHO：将 yytext 复制到 scanner 的输出中。\nBEGIN：后面跟一个 start condition，后面会详细介绍这一用法。\nREJECT：使用 REJECT 将会使 scanner 转向下一条 second best 的规则进行匹配。例如：\nint word_count = 0; %% frob special(); REJECT; [^ \\t\\n]+ word_count++; 这段代码的意思是遇到单词 \u0026ldquo;frob\u0026rdquo; 就执行一个特殊的函数 special()。在 frob 后使用 REJECT 则会在执行完 special() 后使 scanner 转向第二条规则的 pattern 再匹配一次，从而 frob 也会被计入到单词总数中。如果去掉这个 REJECT，\u0026ldquo;frob\u0026rdquo; 就只会触发第一条规则，从而单词个数统计出错。\nyymore()：告诉 scanner 下一次匹配到某条规则的时候要将 token 追加到本次的 token 后面而不是覆盖，例如：\n%% mega- ECHO; yymore(); kludge ECHO; 如果 scanner 的输入是 \u0026ldquo;mega-kludge\u0026rdquo;，那么输出结果将会是 \u0026ldquo;mega-mega-kludge\u0026rdquo;，因为匹配到 kludge 时由于前一次 \u0026ldquo;mega-\u0026rdquo; 调用了 yymore()，所以 ECHO 的时候将 \u0026ldquo;kludge\u0026rdquo; 追加到之前的 \u0026ldquo;mega-\u0026rdquo; 后面。\n两条注记：\nyymore() 的正确执行要求用户代码不能随意更改 yyleng。 yymore() 会轻微影响 scanner 匹配的效率。 yyless(n)：将当前 token 除了前 n 个字符以外的后续字符退回到输入流中供 scanner 下次再扫描。例如：\n%% foobar ECHO; yyless(3); [a-z]+ ECHO; 如果 scanner 的输入是 \u0026ldquo;foobar\u0026rdquo;，那么输出结果将会是 \u0026ldquo;foobarbar\u0026rdquo;。\n特别地，yyless(0) 会将整个 token 退回到输入流中，所以除非 action 中有 BEGIN，调用 yyless(0) 将会导致死循环。\nunput(c)：将字符 c 放入到输入流中，scanner 下一个扫描到的字符将会是字符 c。例如，下面的代码会将匹配到的 token 左右加上括号退回到输入流中 (注意 unput(c) 的语义要求必须要将字符按照倒序退回到输入流中，这样再次扫描得到的才是正序)：\n{ int i; /* Copy yytext because unput() trashes yytext */ char *yycopy = strdup(yytext); unput(')'); for (i = yyleng - 1; i \u0026gt;= 0; i--) unput(yycopy[i]); unput('('); free(yycopy); } 使用 unput() 需要格外注意的一点是：如果 yytext 使用的是默认的 %pointer，调用 unput() 会损坏 yytext 的内容 (每调用一次都会覆盖最右侧的一个字符)，因此如果想要保留 yytext 原本的内容，要么像示例代码一样提前把内容复制出来 (不能只复制指针！)，要么使用 %array 作为 yytext。\n此外，不可以调用 unput() 将 \u0026lt;EOF\u0026gt; 放入到输入流中。\ninput()：读取输入流中的下一个字符。例如下面的代码可以吃掉输入中的 C 注释：\n%% \u0026quot;/*\u0026quot; { int c; for (;;) { while ((c = input()) != '*' \u0026amp;\u0026amp; c != EOF) ; /* eat up text of comment */ if (c == '*') { while ((c = input()) == '*') ; if (c == '/') break; /* found the end */ } if (c == EOF) { error(\u0026quot;EOF in comment\u0026quot;); break; } } } 注：如果 scanner 是用 C++ 编译的，那么应当使用 yyinput() 以避免函数名与 C++ 自带函数冲突。\n9. The Generated Scanner flex 的输出是一个 C 文件 lex.yy.c，其中有一个 scanning routine yylex()，一些用于匹配 token 的表格和一些其他的辅助 routine 和 macro。默认情况下 yylex() 的声明是这样的：\nint yylex() { ... various definitions and actions in here } 通过定义 YY_DECL 宏的方式我们可以修改 yylex() 的声明，比如\n#define YY_DECL float lexscan(a, b) float a, b; 的方式将 yylex() 改名为 lexscan()，返回值是 float 且接受两个参数 a b。\n当 yylex() 被调用后，它会从文件 yyin (默认为 stdin) 中扫描 token 并执行 action，当 action 主动返回或者遇到 EOF (此时返回值是 0) 时 yylex() 会停止运行，否则会一直执行。\n当 yylex() 遇到 EOF 时，后续的执行过程是未定义的，除非 yyin 指向了新的输入文件或者 yyrestart() 被调用。注意调用 yyrestart() 不会将 start condition 置为 INITIAL；当 yylex() 因 action 返回而终止时，yylex() 会再次被调用且从上一次终止的地方继续扫描。\nscanner 中的 ECHO 命令会输出到 yyout 文件中 (默认为 stdout)，可以通过宏定义的方式来修改。\n10. Start Conditions flex 提供一种机制，可以让 rules 条件性地被激活。如果一条 rule 的前缀是 \u0026lt;sc\u0026gt;，那么只有当 scanner 处于 \u0026ldquo;sc\u0026rdquo; 这个 start condition 的时候该 rule 才处于 active 的状态。\nstart condition 在 definitions section 中定义。有两种定义方法：%s sc 和 %x sc，第一种方法是 inclusive 的 start condition，它的意思是没有任何前缀的规则默认也可以被该 sc 激活；第二种方法是 exclusive 的 start condition，它的意思是只有显式地标注了 \u0026lt;sc\u0026gt; 前缀的规则才能被 sc 激活。举一个例子，下面的两段代码等价：\n%s example %% \u0026lt;example\u0026gt;foo do_something(); bar something_else(); %x example %% \u0026lt;example\u0026gt;foo do_something(); \u0026lt;INITIAL, example\u0026gt;bar something_else(); 一个特殊的前缀是 \u0026lt;*\u0026gt;，它表示所有的 start condition，有这个前缀的规则在任何 start condition 下都处于 active 状态。\n在 action 中使用 BEGIN 语句可以激活一个 start condition。一个特殊的用法是 BEGIN(0) 和 BEGIN(INITIAL)，它们的功能相同，都是指激活那些没有前缀的规则。\n如果有多条规则使用相同的 sc 前缀，我们可以使用如下语法简化代码的书写：\n\u0026lt;SCs\u0026gt; { pattern1 action1; pattern2 action2; ... } /* equivalent to * \u0026lt;SCs\u0026gt;pattern1 action1 * \u0026lt;SCs\u0026gt;pattern2 action2 * ... */ ","date":1660435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660435200,"objectID":"172b98679ef5af42d7887e657255f944","permalink":"https://kristoff-starling.github.io/notes/manualnotes/flex/","publishdate":"2022-08-14T00:00:00Z","relpermalink":"/notes/manualnotes/flex/","section":"notes","summary":"该笔记是对 flex 工具手册精华部分的翻译和解读。flex 是一款基于 C/C++ 的通过正则表达式生成编译器 scanner 代码的工具。","tags":null,"title":"Flex Manual - Notes","type":"notes"},{"authors":null,"categories":null,"content":"Summary of (extended) regular expression rules:\nAt least one: $A^{+}\\triangleq AA^*$ Union: $A | B \\triangleq A + B$ Option: $A?\\triangleq A+\\epsilon$ Range: $[a- z]\\triangleq a+b+\\cdots+z$ Excluded range: $[$^$a- z]\\triangleq$ complement of $[a- z]$ Lexical Specification The procedure of lexical analysis:\nWrite a rexp for the lexemes of each token class, i.e., number, identifier, keywords etc.\nConstruct $R$, matching all lexemes i.e. $R = R_1 + R_2 + \\cdots$.\nLet input be $x_1x_2\\cdots x_n$, for each $1\\leq i\\leq n$, check whether $x_1\\cdots x_i\\in L(R)$.\nWhich prefix to choose?\nSometimes we may have $x_1\\cdots x_i\\in L(R)$, $x_1\\cdots x_j\\in L(R)$ and $i\\neq j$ (e.g. == and =). In this situation we follow the \u0026ldquo;maximal munch\u0026rdquo; principle, i.e., we always choose the longer one.\nWhat if no rule matches?\nCompilers should do error handling instead of crashing when there is an lexical error. A common way to handle this is to define an extra set $\\text{Error}\\triangleq \\text{all strings}$ and give it the lowest priority.\nIf success, then we know that $x_1\\cdots x_i\\in L(R_j)$ for some $j$.\nWhich token to choose?\nSometimes we may have $x_1\\cdots x_i\\in L(R_j)$, $x_1\\cdots x_i\\in L(R_k)$ and $j\\neq k$. (e.g. if is a keyword, but it also satisfies the definition of identifiers). In this situation we choose the one with higher priority.\n(Actually, usually in the definition of identifiers keywords are explicitly excluded.)\nRemove $x_1\\cdots x_i$ from input and go to (3).\nFinite Automata A regular expression $R$ formally defines a set of strings $L(R)$. However, we need an implementation to identify that given a string $s$, whether $s\\in L(R)$. Finite automata is a good implementation model.\nA finite automaton consists of\nAn input alphabet $\\Sigma$ A finite set of states $S$ A start state $n$ A set of accepting states $F\\subseteq S$ A set of transitions $\\text{state1}\\overset{input}{\\to}\\text{state2}$ Given an input string, If we reach the end of input and we\u0026rsquo;re an accepting state, the automaton accept the string. The automaton reject a string if 1) we\u0026rsquo;re not in an accepting state. 2) we get stuck (no transition).\nThe language of a finite automaton is the set of accepted strings.\nExample: a finite automaton accepting strings with any number of 1 and a 0 at the end.\ngraph LR s1((A)) s2(B) s1 --\u0026gt; |0|s2 s1 --\u0026gt; |1|s1 There\u0026rsquo;s a special transition called $\\epsilon$ transition: $A\\overset{\\epsilon}{\\to}B$. This transition doesn\u0026rsquo;t consume any character, i.e., we can choose to go to $B$ from $A$ with no condition.\nThere are 2 kinds of FA:\nDeterministic Finite Automata (DFA):\nOne transition per input label per state No $\\epsilon$-moves Nondeterministic Finite Automata (NFA):\nCan have multiple transitions for one input label in a given state Can have $\\epsilon$-moves Actually, the first condition is not essential because we can use $\\epsilon$-moves to transform it into a normal one. Here\u0026rsquo;s an example:\ngraph LR s1(1) --\u0026gt; |1|s2(2) s1 --\u0026gt; |1|s3(3) s4(1) --\u0026gt; |e|s5(N/A) s4 --\u0026gt; |e|s6(N/A) s5 --\u0026gt; |1|s7(2) s6 --\u0026gt; |1|s8(3) A crucial difference between DFA and NFA is that given an input, after receiving several characters, we\u0026rsquo;re in a certain state in DFA while we may be in a set of possible states in NFA. An NFA accepts a string if there exists a path that reaches an accepting state.\nNFA, DFA and regular expressions have the equivalent power of representing languages. Usually DFA are faster to execute (there\u0026rsquo;s no choice to consider), but NFA is much smaller (exponentially smaller).\nRegular Expressions to NFAs Target: lexical specification $\\to$ regular expressions $\\to$ NFA $\\to$ DFA $\\to$ table-driven implementation of DFA\nThe way we transform regular expressions to NFAs is to design an NFA for each RE rule.\nWe denote the NFA for expression A as\ngraph LR s1((st)) --\u0026gt; s2([A's NFA]) --\u0026gt; s3[ed] $\\epsilon$:\ngraph LR s1((st)) --\u0026gt; |e| s2[ed] A character $a$:\ngraph LR s1((st)) --\u0026gt; |a| s2[ed] Rule $AB$:\ngraph LR s1((A's st)) --\u0026gt; s2([A's NFA]) --\u0026gt; s3(A's ed) --\u0026gt;|e| s4(B's st) --\u0026gt; s5([B's NFA]) --\u0026gt; s6[B's ed] Rule $A + B$:\ngraph LR s1((st)) --\u0026gt; |e| s2(A's st) s1 --\u0026gt; |e| s3(B's st) s2 --\u0026gt; s4([A's NFA]) s3 --\u0026gt; s5([B's NFA]) s4 --\u0026gt; s6(A's ed) s5 --\u0026gt; s7(B's ed) s6 --\u0026gt; |e| s8[ed] s7 --\u0026gt; |e| s8[ed] Rule $A^*$:\ngraph LR s1((st)) --\u0026gt; |e| s2(A's st) --\u0026gt; s3([A's NFA]) --\u0026gt; s4(A's ed) --\u0026gt;|e| s5[ed] s4 --\u0026gt; |e| s1 s1 --\u0026gt; |e| s5 An example: $(1+0)^*1$:\nNFA to DFA An NFA may be in many states at any time. However, for a n-state NFA, there are at most $2^N-1$ different subsets of states, which is finite. That\u0026rsquo;s the core idea of how to transform NFA to DFA.\n$\\fbox{Definition}$ ($\\epsilon$-closure) The $\\epsilon$-closure of a node $q$ in NFA, denoted as $\\epsilon\\text{-closure}(q)$, is the set of nodes that can be reached from $q$ by walking through only $\\epsilon$ edges. For example, in the NFA above, $\\epsilon\\text{-closure}(q_6)={q_0,q_1,q_2,q_4,q_7,q_8}$.\n$\\fbox{Definition}$ For a set of states $X$ and a character $a$ in NFA, $a(X)\\triangleq {y|\\exists x\\in X, x\\overset{a}{\\to}y}$.\nComponents of an NFA:\nstates: a set $S$. start: a state $s\\in S$. final: a set $F\\subseteq S$. Corresponding DFA:\nstates: nonempty subsets of $S$. start: $\\epsilon\\text{-closure}(s)$. final: ${X\\subseteq S|X\\cap F\\neq \\emptyset}$. transitions: $X\\overset{a}{\\to}Y$ exists iff $Y=\\epsilon\\text{-closure}(a(X))$. An example: $(1+0)^*1$:\nImplementing Finite Automata A DFA can be represented as a 2D table. States and input symbols are the two dimensions and the contents of the table are transition. Pseudocode can be written based on this:\ni = 0; state = initial; while (input[i] != '\\0') { state = table[state][input[i]]; i++; } If the table is too huge, we can directly use NFA: the table should add a column representing $\\epsilon$ transitions and all the contents are set of states instead of states.\nAlthough NFA\u0026rsquo;s table is more concise, the simulation is more expensive because we have to maintain a set of current states.\n","date":1660089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660089600,"objectID":"b17e8a092f542e94d353d8953595cd83","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec04/","publishdate":"2022-08-10T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/lectures/lec04/","section":"notes","summary":"Summary of (extended) regular expression rules:\nAt least one: $A^{+}\\triangleq AA^*$ Union: $A | B \\triangleq A + B$ Option: $A?\\triangleq A+\\epsilon$ Range: $[a- z]\\triangleq a+b+\\cdots+z$ Excluded range: $[$^$a- z]\\triangleq$ complement of $[a- z]$ Lexical Specification The procedure of lexical analysis:","tags":null,"title":"Stanford-CS143 Lecture 04: Implementation of Lexical Analysis","type":"docs"},{"authors":null,"categories":null,"content":"Token classes:\nIn English: nouns, verbs, adjactives etc. In programming languages: identifiers, keywords, \u0026ldquo;()\u0026rdquo; etc. Identifier: strings of letters or digits, staring with a letter (variable names). Integer: a non-empty string of digits (leading zeroes are allowed). Keywords: \u0026ldquo;if\u0026rdquo;, \u0026ldquo;else\u0026rdquo;, \u0026ldquo;begin\u0026rdquo; etc. Whitespace: a non-empty sequence of blanks, newlines and tabs Operator: relational operators like == \u0026lt; \u0026gt; etc. ( ) ; = : these are special token classes which consist of only one string. A key-value pair of format \u0026lt;class, string\u0026gt; is called a token. The lexical analyzer takes in a string(program) and outputs tokens to the parser. For example：\nInput: foo=42 Output: \u0026lt;identifier, \u0026quot;foo\u0026quot;\u0026gt; , \u0026lt;operator, \u0026quot;=\u0026quot;\u0026gt; , \u0026lt;integer, \u0026quot;42\u0026quot;\u0026gt; (note: here \u0026ldquo;42\u0026rdquo; is a string, not a number!) An implementation of LA must do two things:\nRecognize substrings corresponding to tokens, which are called lexemes. Idenfity the token class of each lexeme. LA Examples FORTRAN rule: whitespace is insignificant. So VAR1 is the same as VA R 1.\nAn Example:\nDO 5 I = 1, 25 DO 5 I = 1.25 The first line is a do-loop where variable I iterates from 1 to 25. The second line, however, is a variable definition - DO5I = 1.25. When we scan the string from left to right, at tht point we finish \u0026ldquo;DO\u0026rdquo; we\u0026rsquo;re not sure whether it\u0026rsquo;s a keyword, we must look ahead to see whether there\u0026rsquo;s a comma. Therefore, \u0026ldquo;lookahead\u0026rdquo; may be required to decide where one token ends and the next token begins.\n\u0026ldquo;lookahead\u0026rdquo; is a universal need even in modern PLs. For example,\nif (i == j) x = 1; else x = 2; when we encounter =, we need to look ahead to decide whether it\u0026rsquo;s a double-equal; when we encounter e we need to look ahead to decide whether it\u0026rsquo;s a variable name or a keyword.\nPL/1 rule: keywords are not reserved (i.e. keywords can be used as variable names).\nIF ELSE THEN THEN = ELSE; ELSE ELSE = THEN It\u0026rsquo;s challenging to recognize which ELSE\u0026amp;THEN are variables.\nDECLARE(ARG1, ..., ARGN) we\u0026rsquo;re not sure whether DECLARE is a keyword or an array reference. Since it can have arbitrary number of arguments, an unbounded lookahead will be required.\nRegular Languages We must specify what set of strings is in a token class, and the solution is to use regular languages.\n2 base cases:\nSingle character: $c\\triangleq {c}$ Epsilon: $\\epsilon\\triangleq {\u0026rsquo;\u0026rsquo;}$ 3 compound expressions:\nUnion: $A+B\\triangleq \\{a|a\\in A\\}\\cup \\{|b\\in B\\}$ Concatenation: $AB\\triangleq \\{ab|a\\in A,b\\in B\\}$ Iteration: $A^* \\triangleq \\left\\{\\bigcup_{i\\geq 0}A^i \\right\\}$, here $A^0=\\epsilon$. $\\fbox{Definition 3.1}$ The regular expressions over $\\Sigma$ are the smallest set of expressions including: $$ \\begin{align} R::=\u0026amp;\\quad\\space \\epsilon\\\\ \u0026amp;|\\quad c, c\\in \\Sigma\\\\ \u0026amp;|\\quad R + R\\\\ \u0026amp;|\\quad RR\\\\ \u0026amp;|\\quad R^* \\end{align} $$\nFormal Languages $\\fbox{Definition 3.2}$ Let $\\Sigma$ be a set of characters (an alphabet), a language over $\\Sigma$ is a set of strings of characters drawn from $\\Sigma$.\ne.g. Alphabet = English characters, Language = sentences (maybe we need a strict definition of valid sentences)\ne.g. Alphabet = ASCII, Language = C programs (this is rigorous, the language is exactly what C compilers accept)\nA meaning function $L:\\text{expression}\\to \\text{set of strings}$ is a mapping that maps syntax to semantics. For example, the rigorous way of defining regular expression symbols are: $$ \\begin{align} L(\\epsilon)\u0026amp;={\u0026rsquo;\u0026rsquo;}\\\\ L(c)\u0026amp;={c}\\\\ L(A+B)\u0026amp;=L(A)\\cup L(B)\\\\ L(AB)\u0026amp;={ab:a\\in L(A),b\\in L(B)}\\\\ L(A^*)\u0026amp;=\\bigcup_{i\\geq 0}L(A^i) \\end{align} $$ The mappings between expressions and meanings are not 1-to-1. it\u0026rsquo;s many-to-1: e.g. $L(11+10)=L(1(1+0))$. This is the foundation of optimization: we can use simpler expressions to do exactly the same thing. But meaning functions should never be 1-to-many, indicating that the language is ambiguous.\nMeaning function makes clear what is syntax and what is semantics. It allows us to consider notation as a separate issue. It\u0026rsquo;s important to think about syntax/notation separately. For example, Roman numerals and Arabic numerals are two systems having the same semantics, but the latter is popular because of its simplicity in syntax.\nLexical Specifications Lexemes We use regular expressions to specify lexemes.\nKeywords: if/else/then/\u0026hellip;\n$\\text{Keywords}=\\text{if}+\\text{else}+\\text{then}+\\cdots$\nInteger: a non-empty string of digits.\n$\\text{digit}=0+1+2+3+\\ldots+8+9$，$\\text{Integer}=\\text{digit}\\space \\text{digit}^*$.\nRepresenting non-empty strings is a common need, so we denote $A^+\\triangleq AA^*$. Therefore we can also write $\\text{Integer}=\\text{digit}^+$.\nIdentifier: strings of letters of digits, starting with a letter.\n$\\text{letter}=a+b+\\cdots+y+z+A+B+\\cdots+Y+Z$. There is a convenient notation for ranges: $\\text{letter}=[a- z]+[A- Z]=[a- zA- Z]$.\n$\\text{Identifier}=\\text{letter}\\space (\\text{letter}+\\text{digit})^*$.\nWhitespace: a non-empty sequence of blanks, newlines and tabs.\n$\\text{Whitespace}=(\\text{\u0026rsquo; \u0026lsquo;}+\\text{\u0026rsquo;\\n\u0026rsquo;}+\\text{\u0026rsquo;\\t\u0026rsquo;})^+$.\nExample: Pascal Numbers $$ \\begin{align} \\text{num} \u0026amp;= \\text{digits}\\space\\space \\text{opt_fraction}\\space\\space \\text{opt_exponent}\\\\ \\text{opt_fraction}\u0026amp;=(\\text{\u0026rsquo;.\u0026rsquo;}\\space\\space \\text{digits})+\\epsilon\\\\ \\text{opt_exponent}\u0026amp;=(\\text{\u0026lsquo;E\u0026rsquo;}\\space (\\text{\u0026rsquo;+\u0026rsquo;}+\\text{\u0026rsquo;-\u0026rsquo;}+\\epsilon)\\space \\text{digits})+\\epsilon\\\\ \\text{digits}\u0026amp;=\\text{digit}^+\\\\ \\text{digit}\u0026amp;=[0-9] \\end{align} $$\nWe observe that \u0026ldquo;$+\\epsilon$\u0026rdquo; in regular expressions indicates \u0026ldquo;optional\u0026rdquo;, i.e. the elements before can be either present or absent. For convenience, we denote $A?\\triangleq A+\\epsilon$, so the rules above can be rewritten as $$ \\begin{align} \\text{opt_fraction} \u0026amp;= (\\text{\u0026rsquo;.\u0026rsquo;}\\space \\text{digits})?\\\\ \\text{opt_exponent} \u0026amp;= (\\text{\u0026lsquo;E\u0026rsquo;}\\space (\\text{\u0026rsquo;+\u0026rsquo;}+\\text{\u0026rsquo;-\u0026rsquo;})?\\space \\text{digits})? \\end{align} $$ It\u0026rsquo;s worth notice that regular expressions defines the set of strings we want, but we still need an implementation, i.e. given a string $s$ and a regular expression $R$, we want to know whether $s\\in L(R)$.\n","date":1657411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657411200,"objectID":"15f3ff7fe0d2c7ab5e48039d9e47ff8a","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec03/","publishdate":"2022-07-10T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/lectures/lec03/","section":"notes","summary":"Token classes:\nIn English: nouns, verbs, adjactives etc. In programming languages: identifiers, keywords, \u0026ldquo;()\u0026rdquo; etc. Identifier: strings of letters or digits, staring with a letter (variable names). Integer: a non-empty string of digits (leading zeroes are allowed).","tags":null,"title":"Stanford-CS143 Lecture 03: Lexical Analysis","type":"docs"},{"authors":null,"categories":null,"content":"Cool (Classroom Object Oriented Language).\n5 programming assignments (all the 4 layers should be plug compatible)\nwrite a cool program lexical analysis parsing semantic analysis code generation Example: Hello World class Main { i : IO \u0026lt;- new IO; main():Int { { i.out_string(\u0026quot;Hello World!\\n\u0026quot;); 1; } }; }; A cool program (*.cl) should have class Main. A class contains several methods and attributes. Here i is an attribute with type IO. main() is a method with return value type Int. The method contains a block of statements enclosed in parentheses. Each statement should end with a semi-colon. Notice that we write 1; instead of return 1;.\nSome equivalent code snippets:\nclass Main { i : IO \u0026lt;- new IO; main():IO { i.out_string(\u0026quot;Hello World!\\n\u0026quot;) }; } class Main { i : IO \u0026lt;- new IO; main():Object { i.out_string(\u0026quot;Hello World!\\n\u0026quot;) }; } class Main { main():Object { (new IO).out_string(\u0026quot;Hello World\\n\u0026quot;) }; } class Main inherits IO { main():Object { self.out_string(\u0026quot;Hello World\\n\u0026quot;) }; } Here \u0026ldquo;inherit\u0026rdquo; means that class Main inherits all the attributes and methods of class IO. In the fourth code snippet, the \u0026ldquo;self\u0026rdquo; can be omitted.\nExample: Factorial An example program that reads from stdin, adds 1 and writes to stdout:\nclass Main inherits A2I{ main() : Object { (new IO).out_string( i2a(a2i((new IO).in_string()) + 1).concat(\u0026quot;\\n\u0026quot;) ) }; }; New grammar: i2a() and a2i() in atoi.cl implements ascii-integer transformation. concat() can concatenate 2 strings together. If you want to compile a library, just list all the file names to the compiler.\nA recursive version of fact.cl:\nclass Main inherits A2I { main() : Object { (new IO).out_string( i2a(a2i(fact((new IO).in_string()))).concat(\u0026quot;\\n\u0026quot;) ) }; fact(i: Int): Int { if (i = 0) then 1 else i * fact(i-1) fi }; }; New grammar: if-then-else-fi structure.\nAn iterative version of fact.cl:\nclass Main inherits A2I { main() : Object { (new IO).out_string( i2a(a2i(fact((new IO).in_string()))).concat(\u0026quot;\\n\u0026quot;) ) }; fact(i: Int): Int { let fact: Int \u0026lt;- 1 in { while (not (i = 0)) loop { fact \u0026lt;- fact * i; i \u0026lt;- i - 1; } pool; fact; } }; }; New grammar: while-loop-pool structure, let to define a local variable.\nPay attention that = in cool is a comparison operator, assignment operator should be \u0026lt;- !\nExample: list class List { item: String; next: List; init(i: String, n: List): List { { item \u0026lt;- i; next \u0026lt;- n; self; } }; flatten(): String { if (isvoid next) then item else item.concat(next.flatten()) fi }; }; class Main inherits IO { main(): Object { let hello: String \u0026lt;- \u0026quot;Hello \u0026quot;, world: String \u0026lt;- \u0026quot;World!\u0026quot;, newline: String \u0026lt;- \u0026quot;\\n\u0026quot;, nil: List, list: List \u0026lt;- (new List).init(hello, (new List).init(world, (new List).init(newline, nil))) in out_string(list.flatten()) }; }; New grammar: define multiple variables at the same time, the \u0026ldquo;isvoid\u0026rdquo; function.\nA more sophisticated flatten() function:\nclass List { item: String; next: List; init(i: String, n: List): List { { item \u0026lt;- i; next \u0026lt;- n; self; } }; flatten(): String { let string: String \u0026lt;- case item of i: Int =\u0026gt; i2a(i); s: String =\u0026gt; s; o: Object =\u0026gt; { abort(); \u0026quot;\u0026quot;; }; esac in if (isvoid next) then string else string.concat(next.flatten()) fi }; }; New grammar: case of - esac structure, abort() function\nNote: the \u0026quot;\u0026quot; is used to convince the type checker that the return value is of type String.\n","date":1656806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656806400,"objectID":"cf8617baea8bb68b74040953d3a3fdd8","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec02/","publishdate":"2022-07-03T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/lectures/lec02/","section":"notes","summary":"Cool (Classroom Object Oriented Language).\n5 programming assignments (all the 4 layers should be plug compatible)\nwrite a cool program lexical analysis parsing semantic analysis code generation Example: Hello World class Main { i : IO \u0026lt;- new IO; main():Int { { i.","tags":null,"title":"Stanford-CS143 Lecture 02: Cool Overview","type":"docs"},{"authors":null,"categories":null,"content":"Interpreters: it takes in program and data and and immediately generates output (an on-line process).\nCompilers: it takes in program and generates an executable (assembly/bytecode). The executable takes in data and generates output (an off-line process).\nThe Structure of Compilers Lexical Analysis: divide program text into \u0026ldquo;words\u0026rdquo; or \u0026ldquo;tokens\u0026rdquo;.\nif x == y then z = 1; else z = 2; tokens: if x == z then z = 1 ; else z = 2 ;\nParsing: understand the sentence structure.\nif x == y then z = 1; else z = 2; if-then-else-+-predicate---relation-+-'x' | | | +-'==' | | | +-'y' | +-then-stmt---assign-+-'z' | | | +-'1' | +-else-stmt---assign-+-'z' | +-'2' Semantic Analysis: understand the \u0026ldquo;meaning\u0026rdquo; of sentences.\nIt\u0026rsquo;s too hard for compilers and compilers usually only perform limited semantic analysis to catch inconsistencies, they don\u0026rsquo;t know what programs are supposed to do.\nThe Complexity of Semantics\n\u0026ldquo;Jack said that Jack forgot his homework at home\u0026rdquo;. We even don\u0026rsquo;t know how many people are involved in this sentence without contexts.\nProgramming languages define strict rules to avoid such ambiguities. e.g.\n{ int jack = 3; { int jack = 4; cout \u0026lt;\u0026lt; jack; // should print 4 } } Optimization: automatically modify programs so that they run faster and use less memory, power, network resources etc.\nThe complexity of Optimizations\nX = Y * 0 is the same as X = 0 ? It\u0026rsquo;s not necessarily correct! If X Y are floating points and Y is NAN, then NAN * 0 = NAN, instead of zero.\nCode Generation: a translation into another language (assembly usually).\nThe proportions of each phase have changed since FORTRAN:\nFORTRAN: LLLLLL PPPPPP SS OOOOOO GGGGGG Modern: LL PP SSSSSS OOOOOOOOOO GG The Economy of Programming Languages Why so many PLs? Application domains have distinctive/conflicting needs. It\u0026rsquo;s hard to design one system for all.\nscientific computing: good floating points, good array/tensor operations, parallelism etc. (FORTRAN) business applications: persistence, report generation, data analysis etc. (SQL) systems programming: control of low-level resources, real-time constraints (C/C++) Why new PLs? Claim: Programmer training is the dominant cost for a programming language. (Lots of people need to learn this language!)\nCorollaries:\nWidely-used languages are slow to change. Easy to start a new language (zero user at the start). New languages are usually adopted to fill a void (it\u0026rsquo;s easy for new language to adapt to new situations). New languages tend to look like old languages (to reduce the training cost). What\u0026rsquo;s a good PL? Thers is no universally accepted metric for language design.\n","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656633600,"objectID":"87ddeb54ae3fbf77c65e34f3b50c8d03","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/lectures/lec01/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/lectures/lec01/","section":"notes","summary":"A brief introduction to interpreters and compilers + The economy of programming languages","tags":null,"title":"Stanford-CS143 Lecture 01: Introduction","type":"docs"},{"authors":null,"categories":null,"content":" Microsoft FAT Specification 的 local copy 见此处。以下是对该手册的精华部分的翻译和解读。\nSection 1: Definitions and Notations 这里只记录比较重要的定义和记号。\n1.1 Definition sector：可以独立于其他单元直接获取的最小单元。 bad(defective) sector：损坏的 sector，其中的内容无法读写。 cluster：一个 cluster 里包含若干个连续的 sector。cluster 是 allocation 的最小单位，为文件分配空间时必须分配整数个 cluster。 volume：一段物理上连续的块地址空间 (可以理解为“全集”)。 partition：分区，volume 中的一部分 sector。 1.2 Notations $ip(x)\\triangleq [x],ceil(x)\\triangleq\\lceil x\\rceil,rem(x/y)\\triangleq x\\space \\text{mod}\\space y$。\nSection 2: Volume Structure FAT 文件系统的结构如下：\nBPB \u0026hellip; BPB \u0026hellip; File Allocation Table FAT copy Root Directory Data \u0026hellip; Data Reserved Region FAT Region Root Directory Region (FAT12/FAT16) File \u0026amp; Directory (Data) Region FAT 中的数据存储是小端的。\nSection 3: Boot Sector and BPB BPB (BIOS Parameter Block) 位于 reserved region 的第一个 sector。这个 sector 也被称为 boot sector 或者 0 号 sector。所有的 FAT 文件系统的 boot sector 中都必须有 BPB。以下的变量中以 BPB_ 开头的属于 BPB 的内容，以 BS_ 开头的实际上是 boot sector 的内容，不属于 BPB。\n3.1 BPB structure common to FAT12, FAT16, and FAT32 Implementations 这部分的 BPB 结构是 FAT12, FAT16 和 FAT32 共有的。使用 C 代码可以表示如下 (注：定义结构体时使用 __attribute__((__packed__)) 可以不让编译器自动对齐)。\nstruct BPB_common { char BS_jmpBoot[3]; /* 0 */ char BS_OEMName[8]; /* 3 */ uint16_t BPB_BytsPerSec; /* 11 */ uint8_t BPB_SecPerClus; /* 13 */ uint16_t BPB_RsvdSecCnt; /* 14 */ uint8_t BPB_NumFATs; /* 16 */ uint16_t BPB_RootEntCnt; /* 17 */ uint16_t BPB_TotSec16; /* 19 */ uint8_t BPB_Media; /* 21 */ uint16_t BPB_FATSz16; /* 22 */ uint16_t BPB_SecPerTrk; /* 24 */ uint16_t BPB_NumHeads; /* 26 */ uint32_t BPB_HiddSec; /* 28 */ uint32_t BPB_TotSec32; /* 32 */ }__attribute__((__packed__)); 各个字段的解释如下：\nBS_jmpBoot：包含了一个 3 个字节的 Inter x86 格式的无条件跳转指令，用于跳转到操作系统的 bootstrap code。boot code 通常位于 boot sector 的尾部，跟在 BPB 后面。两种常见的 jump instruction 的格式为：\njmpBoot[0] = 0xEB; jmpBoot[1] = 0x??; jmpBoot[2] = 0x90; jmpBoot[0] = 0xE9; jmpBoot[1] = 0x??; jmpBoot[2] = 0x??; BS_OEMName：占 8 个字节，可以在 FAT 的实现中被指定为任何值。其内容通常为格式化该磁盘的系统名称 (比如如果使用 Linux 的 mkfs.fat 命令创建磁盘镜像，该字段就会是 \u0026ldquo;mfks.fat\u0026rdquo;)。\nBPB_BytsPerSec：每个 sector 的字节数。该值只能是 512, 1024, 2048, 4096 中的一个。\nBPB_SecPerClus：每个 cluster 的 sector 数。该值必须大于 0 且是 2 的幂次。因为该字段只占一个字节，因此合法的值只有 1, 2, 4, 8, 16, 32, 64, 128。\nBPB_RsvdSecCnt：reserved region 中的 reserved sector 的个数。该值可以是任何非零整数。通常情况下，这个字段用于使数据区的开头 (即 cluster #2) 地址对齐。\nBPB_NumFATs：file allocation table 的个数。通常来说 2 是一个比较推荐的数值 (为了防止磁盘受损导致的文件系统损坏)，但 1 也是允许的。\nBPB_RootEntCnt：对于 FAT12 和 FAT16，该字段表示根目录下 32-byte 目录项的个数，BPB_RootEntCnt * 32 理应是 BPB_BytsPerSec 的偶数倍。在 FAT16 中，为了达到最大的兼容性，该值应当设置为 512。对于 FAT32，该值必须是 0。\nBPB_TotSec16：对于 FAT12 和 FAT16，该字段表示了文件系统中 sector 的数目。该字段只有 2 个字节，如果 sector 的数目大于等于 0x10000，则高位部分会存储到 BPB_TotSec32 中。对于 FAT32，该字段必须是 0。\nBPB_Media：合法的值有 0xF0, 0xF8, 0xF9, 0xFA, 0xFB, 0xFC, 0xFD, 0xFE 和 0xFF。对于不可移动的固定磁盘，0xF8 是标准值；如果是可移动设备，该字段通常是 0xF0。\nBPB_FATSz16：对于 FAT12 和 FAT16，该字段表示一个 FAT 中 16-bit sector 的个数。对于 FAT32，该字段必须是 0。\nBPB_SecPerTrk：该字段只在一些有着特定几何特征 (一个 volume 被划分成多个轨道，有多个读写头) 的设备上有用，表示了每个 track 上 sector 的数目。该字段是为 0x13 号中断准备的。\nBPB_NumHeads：读写头数量。该字段也是为 0x13 号中断准备的。\nBPB_HiddSec：该字段表示了这个 FAT 分区后面的隐藏 sector 的数目，也是为 0x13 号中断准备的。对于没有分区的设备，该字段必须为 0。此外，利用该字段来对齐数据区是不正确的。\nBPB_TotSec32：对于 FAT32，该字段表示了文件系统中 sector 的数目。对于 FAT12 和 FAT16，如果 BPB_TotSec16 足够存放对应数值，则该字段为 0，否则该字段会存储数据的高位。\n3.2 Extended BPB structure for FAT12 and FAT16 volumes 如果是 FAT12 和 FAT16，boot sector 中还有如下的一些字段 (紧跟在 BPB_common 之后)：\nstruct BPB_16bit { uint8_t BS_DrvNum; /* 36 */ uint8_t BS_Reserved1; /* 37 */ uint8_t BS_BootSig; /* 38 */ uint32_t BS_VolID; /* 39 */ char BS_VolLab[11]; /* 43 */ char BS_FilSysType[8]; /* 54 */ uint8_t __padding[448]; /* 62 */ uint16_t Signature_word; /* 510 */ }__attribute__((__packed__)); 各个字段的解释如下：\nBS_DrvNum：0x13 号中断的驱动号，设置成 0x80 或 0x00。 BS_Reserved1：保留字段，设置为 0x0。 BS_BootSig：如果后面两个字段 (BS_VolID 和 BS_VolLab) 中的任何一个是非零数，将该字段设置为 0x29。 BS_VolID：该字段和 BS_VolLab 共同支持了可移动设备上的 volume tracking。这些字段使得 FAT 文件系统驱动可以识别出插入到可移动驱动上的错误磁盘。BS_VolID 应当通过将当前日期和时间拼接成 32 位数值的方式生成。 BS_VolLab：Volume label。该字段的内容应当和根目录下的 11 字节 volume label 相同。FAT 文件系统应当保证如果根目录下的 volume label 被创建或者修改，该字段也会被更新。如果没有 volume label，该字段会被填充为 \u0026ldquo;NO NAME \u0026ldquo;。 BS_FilSysType：\u0026ldquo;FAT12 \u0026ldquo;，\u0026ldquo;FAT16 \u0026quot; 或 \u0026ldquo;FAT \u0026quot; 中的一个。注意该字段只是起到一个提供信息的作用，并不用于决定 FAT 的类型。 Signature_word：偏移量为 510 的 byte 为 0x55，偏移量为 511 的 byte 为 0xaa。 3.3 Extended BPB structure for FAT32 volumes 如果是 FAT32，boot sector 中还会有如下的一些字段 (紧跟在 BPB_common 之后)：\nstruct BPB_32bit { uint32_t BPB_FATSz32; /* 36 */ uint16_t BPB_ExtFlags; /* 40 */ uint16_t BPB_FSVer; /* 42 */ uint32_t BPB_RootClus; /* 44 */ uint16_t BPB_FSInfo; /* 48 */ uint16_t BPB_BkBootSec; /* 50 */ char BPB_Reserved[12]; /* 52 */ uint8_t BS_DrvNum; /* 64 */ uint8_t BS_Reserved1; /* 65 */ uint8_t BS_BootSig; /* 66 */ uint32_t BS_VolID; /* 67 */ char BS_VolLab[11]; /* 71 */ char BS_FilSysType[8]; /* 82 */ uint8_t __padding[420]; /* 90 */ uint16_t Signature_word; /* 510 */ }__attribute__((__packed__)); 各个字段的解释如下 (和 FAT12/FAT16 相同的部分不再解释)：\nBPB_FATSz32：一个 FAT 中包含的 32-bit sector 数目。 BPB_ExtFlags：各个位的标志信息如下 0-3 位：当前 active 的 FAT 的编号，这个编号是 0-based 的，仅在 mirroring 被关闭时有效。 4-6 位：reserved。 7 位：该位是 0 表示 FAT 会在运行时镜像到所有的 FAT 中；该位是 1 表示只有一个 FAT 是活跃的，这个活跃的 FAT 的编号通过 0-3 位表示。 8-15 位：reserved。 BPB_FSVer：高位的 byte 存储主版本号 (major)，低位的 byte 存储小版本号 (minor)。现阶段该值必须被设置为 0x0。 BPB_RootClus：该字段表示了根目录的第一个 cluster 的编号。该值通常是 2，如果有出现 cluster 损坏的情况，则该值是 2 之后第一个可用的 cluster 的编号。 BPB_FSInfo：该字段表示了 FAT32 的 reserved area 中 FSINFO 结构体所在的 sector 编号，通常为 1。值得注意的是，在 boot sector 的备份中也会有一个 FSINTO 结构体，但主 boot sector 和备份 boot sector 的该字段会指向同一个 FSINFO 结构体，只有那个被指向的结构体才是 up-to-date 的。 BPB_BkBootSec：该字段的值是 0 或 6。如果非零，它表示了 boot record 的备份所在的 sector 号 (6 号)。 BPB_Reserved：reserved。必须被设置为 0x0。 3.4 Initialization of a FAT volume Section 3.5 会介绍如何决定 FAT 的类型 (12/16/32)，本 section 主要介绍在 volume 初始化时如何填写 BPB 中的字段。FAT implementation 要保证可以挂载填写了合法数值的 BPB 的设备。\n软盘会被格式化为 FAT12，一个简单的、事先准备好的表格决定了软盘中 BPB 的各个字段的值。注意：FAT12 要求设备容量 \u0026lt;= 4MB。\n对于每个 sector 大小为 512B 的设备，如果设备大小 \u0026lt; 512MB，该设备会被格式化为 FAT16，否则会被格式化为 FAT32。覆盖默认的 FAT 类型选择是可能的。\n下面的表格来自 Microsoft Corporation FAT format utility。对于 FAT16，填写 BPB_SecPerClus 的表格如下：\nstruct DSKSZTOSECPERCLUS { DWORD DiskSize; // 以512byte sector为单位 BYTE SecPerClusVal; }; DSKSZTOSECPERCLUS DskTableFAT16 [] = { {8400, 0}, /* disks up to 4.1 MB, the 0 value for SecPerClusVal trips an error */ {32680, 2}, /* disks up to 16 MB, 1k cluster */ {262144, 4}, /* disks up to 128 MB, 2k cluster */ {524288, 8}, /* disks up to 256 MB, 4k cluster */ {1048576, 16}, /* disks up to 512 MB, 8k cluster */ /* The entries after this point are not used unless FAT16 is forced */ {2097152, 32},/* disks up to 1 GB, 16k cluster */ {4194304, 64},/* disks up to 2 GB, 32k cluster */ {0xFFFFFFFF, 0} /*any disk greater than 2GB, 0 value for SecPerClusVal trips an error */ }; 虽然 FAT16 一般只在 \u0026lt;= 512 MB 的情况下使用，但表格中仍然给出了一些大于 512MB 但强制要求使用 FAT16 的设备的填写方法。该表格的使用方法是：根据当前设备的 disk size，在表格中找出第一个小于等于 disk size 的表项，并将其第二个参数作为 BPB_SecPerClus，第一个参数会被填入 BPB_TotSec16。为了使该表格中的数值可以正确工作，BPB_RsvdSecCnt 需要被设置为 1，BPB_NumFATs 需要被设置为 2，BPB_RootEntCnt 需要被设置为 512。\n对于 FAT32，填写 BPB_SecPerClus 的表格如下：\nDSKSZTOSECPERCLUS DskTableFAT32 [] = { {66600, 0}, /* disks up to 32.5 MB, the 0 value for SecPerClusVal trips an error */ {532480, 1}, /* disks up to 260 MB, .5k cluster */ {16777216, 8}, /* disks up to 8 GB, 4k cluster */ {33554432, 16}, /* disks up to 16 GB, 8k cluster */ {67108864, 32}, /* disks up to 32 GB, 16k cluster */ {0xFFFFFFFF, 64} /* disks greater than 32GB, 32k cluster */ }; 为了使该表格中的数值可以正确工作，BPB_RsvdSecCnt 需要被设置为 32，BPB_NumFATs 需要被设置为 2。\n下面的代码解释了如何计算 BPB_FATSz16/BPB_FATSz32 字段。该代码假设 BPB_RootEntCnt, BPB_RsvdSecCnt 和 BPB_NumFATs 已经被正确设置好。代码中的 DiskSize 是以 sector 为单位的 (即 BPB_TotSec16/BPT_TotSec32 中的值)。\nRootDirSectors = ((BPB_RootEntCnt * 32) + (BPB_BytsPerSec – 1)) / BPB_BytsPerSec; TmpVal1 = DskSize - (BPB_ResvdSecCnt + RootDirSectors); TmpVal2 = (256 * BPB_SecPerClus) + BPB_NumFATs; if (FATType == FAT32) { TmpVal2 = TmpVal2 / 2; FATSz = (TMPVal1 + (TmpVal2 – 1)) / TmpVal2; } if (FATType == FAT32) { BPB_FATSz16 = 0; BPB_FATSz32 = FATSz; } else { BPB_FATSz16 = LOWORD(FATSz); /* there is no BPB_FATSz32 in a FAT16 BPB */ } 注：该代码中的数学运算不是完美的，在一些情况下它算出的 FAT size 会过大，但它一定不会算小，这保证了它不会出错 (过大只是会浪费一些空间)。该代码的简洁是它的优势。\n3.5 Determination of FAT type when mounting the volume FAT 类型唯一决定于 volume 中 cluster 的数量 (CountofClusters)。下面的步骤描述了计算 cluster 数量的过程：\n计算根目录占据的 sector 的数量：\nRootDirSectors = ((BPB_RootEntCnt * 32) + (BPB_BytsPerSec - 1)) / BPB_BytsPerSec; 计算数据区占据的 sector 的数量 (从总 sector 数量中扣除根目录和 FAT 的 sector 数量)：\nFATSz = (BPP_FATSz16 != 0) ? BPB_FATSz16 : BPB_FATSz32; TotSec = (BPB_TotSec16 != 0) ? BPB_TotSec16 : BPB_TotSec32; DataSec = TotSec - (BPB_RsvdSecCnt + (BPB_NumFATs * FATSz) + RootDirSectors); 计算 CountOfCluster：\nCountofClusters = DataSec / BPB_SecPerClus; 下面的 if 语句决定了 FAT 的类型：\nif (CountofClusters \u0026lt; 4085) {/* Volume is FAT12 */} else if (CountofClusters \u0026lt; 6525) {/* Volume is FAT16 */} else {/* Volume is FAT32 */} 注：一个磁盘的 cluster 数目最好不要卡在边界上 (比如 4085 个 cluster 或 65525 个 cluster)，与边界值的差最好大于 16。\n最大的可使用的 cluster 号是 CountofCluster + 1。\n3.6 Backup BPB Structure sector #0 的损坏会对文件系统产生毁灭性的打击，因此为 BPB 做备份是很重要的。在 FAT32 中，sector #6 必须包含 BPB 的备份。\n无论是 sector #0 中的 BPB 还是 sector #6 中的备份 BPB，BPB_BkBootSec 字段中的值都是 6。\n当 sector #0 无法读取时，volume repair utility 应当从 sector #6 提取信息。\nSection 4: FAT File Allocation Table 中的每一个 entry 都代表了一个 cluster 的状态。FAT12 中每个 FAT entry 占 12 个 bit，FAT16 中每个 FAT entry 占 16 个 bit，FAT32 中每个 FAT entry 占 32 个 bit。FAT 表中的 entry 可能比可以分配的 cluster 的数目更多，那些多出来的 FAT entry 必须被置为 0。\nFAT 定义了表示文件的单向链表。整个磁盘中的第一个 cluster 的编号是 2。\n注：一个 FAT 中的目录文件本身只是一个普通文件，它有一个特殊的属性表明它自己是目录，该文件的内容是一系列的 32 字节的目录项。\nFAT entry 的内容如下表：\nFAT12 FAT16 FAT32 Comments 0x000 0x0000 0x0000000 cluster 当前空闲 0x002~MAX 0x0002~MAX 0x0000002~MAX cluster 在使用中，FAT entry 的内容是链表中下一个 cluster 的编号。MAX 指的是最大的合法 cluster 编号 (MAX+1)~0xFF6 (MAX+1)~0xFFF6 (MAX+1)~0xFFFFFF6 reserved，不可使用 0xFF7 0xFFF7 0xFFFFFF7 cluster 损坏 0xFF8~0xFFE 0xFFF8~0xFFFE 0xFFFFFF8~0xFFFFFFE reserved，不可使用 0xFFF 0xFFFF 0xFFFFFFF cluster 在使用中，是一个文件的最后一个 cluster 注：(1) FAT32 表项中的高 4 位不使用。\n(2) FAT12 中 FAT 的大小不能超过 6K 个 sector，FAT16 中 FAT 的大小不能超过 128K 个 sector，FAT32 没有限制。\n4.1 Determination of FAT entry for a cluster 给定一个合法的 cluster 号 $N$，该 section 主要介绍如何确定哪个 FAT entry 对应了这个 cluster。\nFAT16 and FAT32 下面的代码给出了确定某一个 cluster 的 FAT entry 所在的 sector的方法：\nFATSz = (BBP_FATSz16 != 0) ? BPB_FATSz16 : BPB_FATSz32; FATOffset = (FATType == FAT16) ? (N * 2) : (N * 4); ThisFATSecNum = BPB_RsvdSecCnt + (FATOffset / BPB_BytsPerSec); ThisFATEntOffset = REM(FATOffset / BPB_BytsPerSec); 注：FATX 的 FAT 是由若干个 X bit 的 FAT entry 紧密排列而成的，因此 FATOffset 计算出了 $N$ 号 cluster 的 FAT entry 距离 FAT 表开头的偏移字节数，用这个字节数除以 BPB_BytsPerSec 即可得到 sector 号，取余即可得到 sector 内的偏移量。\n上述代码求得的 ThisFATSecNum 是 cluster 在第一份 FAT 中的 FAT entry 所在 sector 号。如果要求其他 FAT 中的 FAT entry 的 sector 号，可以参考如下公式：\nSectorNumber = (FatNumber * FATSz) + ThisFatSecNum; 将磁盘映射到内存中之后，我们可以用如下方法读取一个 FAT entry 的内容 (下面的代码中 SecBuff 是指向对应 sector 开头的指针，WORD 是 16bit，DWORD 是 32bit)：\nif (FATType == FAT16) FAT16ClusEntryVal = *((WORD *) \u0026amp;SecBuff[ThisFATEntOffset]); else FAT32ClusEntryVal = (*((DWORD *) \u0026amp;SecBuff[ThisFATEntOffset])) \u0026amp; 0x0FFFFFFF; 可以用如下方法修改一个 FAT entry：\nif (FATType == FAT16) *((WORD *) \u0026amp;SecBuff[ThisFATEntOffset]) = FAT16ClusEntryVal; else { FAT32ClusEntryVal \u0026amp;= 0x0FFFFFFF; *((DWORD *) \u0026amp;SecBuff[ThisFATEntOffset]) = (0xF0000000 | FAT32ClusEntryVal); } 注：FAT16/FAT32 的表项不能跨 sector 存储。\nFAT12 FAT12 中的每个 FAT entry 占 12bit (1.5 个字节)。所有的计算方法和 FAT16/FAT32 类似，但由于字节数不是整数，所以涉及一些微妙的运算：\nif (FATType == FAT12) FATOffset = N + (N / 2); // 这里的“/”是下取整 ThisFATSecNum = BPB_RsvdSecNum + (FATOffset / BPB_BytsPerSec); ThisFATEntOffset = REM(FATOffset / BPB_BytsPerSec); 在 FAT12 中，一个 FAT entry 是有可能跨 sector 存储的，下面给出了判断方法：\nif (ThisFATEntOffset == (BPB_BytsPerSec - 1)) { // 该FAT entry跨sector存储 // 最简单的应对方法是每次读取时总是读取连续的两个sector:N和N+1(除非N是最后一个sector) } FAT12 中读取 FAT entry 内容的方法也有一些微妙：因为每个 FAT entry 占 12 个 bit，所以两个 FAT entry 正好占据 3 个字节。我们计算出的 ThisFATEntOffset 对应的是该 FAT entry 所在的第一个 byte 的地址，这意味着对于奇数 cluster 而言 FAT entry 是从 ThisFATEntOffset 的开头开始的，对于偶数 cluster 而言 FAT entry 是从 ThisFATEntOffset 所在字节的后 4 个 bit 开始的，因此代码逻辑如下 (注：\u0026gt;\u0026gt; 是逻辑右移)：\nFAT12ClusEntryVal = *((WORD *) \u0026amp;SecBuff[ThisFATEntOffset]); // 先读出16个bit if (N \u0026amp; 0x0001) FAT12ClusEntryVal \u0026gt;\u0026gt;= 4; // 16个bit中只有前12个bit是表项，低位4个bit应当清空 else FAT12ClusEntryVal \u0026amp;= 0x0FFF; // 16个bit中只有后12个bit是表项，高位4个bit应当清空 修改一个表项的方法为：\nif (N \u0026amp; 0x0001) { FAT12ClusEntryVal \u0026lt;\u0026lt;= 4; *((WORD *) \u0026amp;SecBuff[ThisFATEntOffset]) \u0026amp;= 0x000F; } else { FAT12ClusEntryVal \u0026amp;= 0x0FFF; *((WORD *) \u0026amp;SecBuff[ThisFATEntOffset]) \u0026amp;= 0xF000; } *((WORD *) \u0026amp;SecBuff[ThisFATEntOffset]) |= FAT12ClusEntryVal; 4.2 Reserved FAT entries FAT 的前两个 FAT entry 是 reserved 的。\n第一个 FAT entry (FAT[0]) 的内容为：低 8 位保存了 BPB_Media 的值，剩下的位置为 1。\n第二个 FAT entry (FAT[1]) 的内容位：\n对于 FAT12：该 entry 保存了 EOC mark。 对于 FAT16 和 FAT32：MS Windows 的设备驱动将最高的两个位作为 dirty volume 标志位，剩下的其他位置为 1。这里的高 2 位指的是 FAT16 中的 0x8000 (ClnShutBitMask) 和 0x4000 (HrdErrBitMask)，FAT32 中的 0x08000000 (ClnShutBitMask) 和 0x04000000 (HrdErrBitMask)。 ClnShutBitMask 位：如果这个位是 1，那么这个 volume 当前是干净的，可以被挂载并访问；如果这个位是 0，那么这个 volume 是 dirty 的，FAT 文件系统驱动无法正确地解挂载这个 volume，该 volume 的内容应当被扫描一遍以确定是否有 metadata 的损坏。 HrdErrBitMask 位：该位是 1 说明没有遇到任何 read/write 错误。该位是 0 说明自上一次挂载以来 FAT 文件系统驱动遇到过 read/write 错误，可能有 sector 损坏了。该 volume 的内容应当被扫描一遍以确定是否有损坏的 sector。 4.3 Free space determination 文件系统驱动必须扫描所有的 FAT entry 以构建一系列的文件链表和获得所有的空闲 cluster。空闲的 cluster 对应 的 FAT entry 的值为 0。空闲 cluster 在 FAT 中并没有以一个链表的形式串起来，但在 FAT32 中，BPB_FSInfo sector 可能包含了空闲 cluster 的数目。\n4.4 Other points to note FAT 的实现不应当对 (CountOfCluster + 1) FAT entry 之后的内容有任何的假设 (这个 entry 不一定在一个 sector 的结尾处)。并且在格式化时，FAT 的最后一个 sector 中最后一个 FAT entry 之后的部分应被置为 0。\n每个 FAT 包含的 sector 数可能比它实际需要的 sector 数多，这意味着 FAT 的最后可能会包含若干完全没有使用的 sector。驱动实现应当通过 CountOfCluster 来确定 FAT 中最后一个 valid sector 的编号。最后一个 valid sector 后面的 sector 应当全部被置为 0。\nSection 5: File System Information (FSInfo) Structure FSInfo 结构体只在 FAT32 中有。该结构体应当在文件系统初始化时设置好并放在 sector #1 中 (即紧接着 BPB)，该结构体的备份存放在 sector #7 中。\n注：FSInfo 结构体中的所有信息都是建议性的，文件系统驱动应当在初始化时填好 FSInfo 的信息，但并不一定需要在磁盘读写的过程中动态更新这个结构体 (尽管手册建议这么做)。\nFSInfo 的各个字段如下：\nstruct FSInfo { uint32_t FSI_LeadSig[4]; /* 0 */ uint8_t FSI_rsvc1[480]; /* 4 */ uint32_t FSI_StrucBig; /* 484 */ uint32_t FSI_Free_Count; /* 488 */ uint32_t FSI_Nxt_Free; /* 492 */ uint8_t FSI_rsvd2[12]; /* 496 */ uint32_t FSI_TrailSig; /* 508 */ }; 各个字段的解释如下：\nFSI_LeadSig：值为 0x41615252，用于确认 FSInfo 格式的签名。 FSI_Rsvd1：reserved，必须置为 0。 FSI_StrucSig：值为 0x61417272，一个额外用于确认 FSInfo 格式的签名。 FSI_Free_Count：该字段值为磁盘中空闲 cluster 的数量，如果不清楚则置为 0xFFFFFFFF。该字段必须在 volume 挂载时确定，手册建议该字段在 volume 解挂载时仍然保存正确的 count。 FSI_Next_Free：保存了磁盘上第一个空闲 cluster 的编号，如果不清楚则置为 0xFFFFFFFF。该字段必须在 volume 挂载时确定，手册建议该字段在 volume 解挂载时仍然保存正确的编号。 FSI_Rsvd2：reserved，必须置为 0。 FSI_TrailSig：值为 0xAA550000，用于确认 FSInfo 格式的签名 Section 6: Directory Structure FAT 的目录是一种特殊的文件，它像是一个容器，里面装了子目录和文件的相关信息。目录文件由一系列的 32 字节的目录项 (directory entry) 构成，每个目录项描述了一个子目录或一个文件。\n目录项的内容可以用如下结构体描述：\nstruct Dirent { char DIR_Name[11]; /* 0 */ uint8_t DIR_Attr; /* 11 */ uint8_t DIR_NTRes; /* 12 */ uint8_t DIR_CrtTimeTenth; /* 13 */ uint16_t DIR_CrtTime; /* 14 */ uint16_t DIR_CrtDate; /* 16 */ uint16_t DIR_LstAccDate; /* 18 */ uint16_t DIR_FstClusHI; /* 20 */ uint16_t DIR_WrtTime; /* 22 */ uint16_t DIR_WrtDate; /* 24 */ uint16_t DIR_FstClusLO; /* 26 */ uint32_t DIR_FileSize; /* 28 */ }__attribute__((__packed__)); 各个字段的解释如下：\nDIR_Name：“短”文件名，不超过 11 个字节。\nDIR_Attr：文件的属性，合法的属性值如下所示\nATTR_READ_ONLY ATTR_HIDDEN ATTR_SYSTEM ATTR_VOLUME_ID 0x01 0x02 0x04 0x08 ATTR_DIRECTORY ATTR_ARCHIVE ATTR_LONG_NAME 0x10 0x20 0x0F (前四个的或) DIR_Attr 的高两个 bit 保留，必须被置为 0。\nDIR_NTRes：reserved，必须置为 0。\nDIR_CrtTimeTenth：创建时间 (低位)，以 1/10 秒为单位，合法范围是 0\u0026lt;=DIR_CrtTimeTenth\u0026lt;=199。\nDIR_CrtTime：创建时间 (高位)，颗粒度为 2s。\nDIR_CrtDate：创建日期。\nDIR_LstAccDate：上一次 access 该文件的日期。这里的 access 指的是对该文件/目录的 read/write 操作。该字段必须在文件修改时更新 (即写操作时)，填写的日期必须与 DIR_WrtDate 相同。\nDIR_FstClusHI：该文件/目录的第一个 cluster 的编号的高 16 位。该字段仅对 FAT32 有效，FAT12/FAT16 中该字段必须置为 0。\nDIR_WrtTime：上一次修改该文件的时间。在文件刚刚创建的时候，该字段的值应当与 DIR_CrtTime 一样。\nDIR_WrtDate：上一次修改该文件的日期。在文件刚刚创建的时候，该字段的值应当与 DIR_CrtDate 一样。\nDIR_FstClusLO：该文件/目录的第一个 cluster 的编号的低 16 位。\nDIR_FileSize：文件大小，以字节为单位。\n6.1 File/Directory Name (field DIR_Name) DIR_Name 共有 11 个字节，分为两个部分：8 字节的 main part 和 3 字节的扩展名。如果某一个部分字节数不足，后面会用空格补足长度。\n以下是一些注意点：\nmain part 和扩展名之间默认有一个 \u0026ldquo;.\u0026quot;，这个点不会存储在 DIR_Name 中。 DIR_Name[0] == 0xE5 代表这个目录项是空闲的。不过在 KANJI (日本语) 中 0xE5 这个字符是存在的，因此 KANJI 下 0xE5 会用 0x05 来代替。文件系统解析文件名时如果遇到首字节是 0x05 且字符集是 KANJI 时要将 0x05 替换成 0xE5 再返回。 除了 0xE5，DIR_Name[0] == 0x00 也代表这个目录项是空闲的。它与 0xE5 的不同在于 0x00 意味着后面跟着的所有目录项也都是空闲的。 DIR_Name[0] 不能是 0x20，即文件名不能以空格开头。 一个目录下的所有名字都必须是唯一的。 对于文件中字符的限制如下：\n小写字母不允许出现。 小于 0x20 的字符不允许出现 (除了上面提到的 KANJI 的 0x05)。 0x22, 0x2A, 0x2B, 0x2C, 0x2E, 0x2F, 0x3A, 0x3B, 0x3C, 0x3D, 0x3E, 0x3F, 0x5B, 0x5C, 0x5D 和 0x7C。 6.2 File/Directory Attributes 文件或子目录的属性值会影响文件系统驱动对该文件/子目录的操作方式。各种属性值的意义列举如下：\nATTR_READ_ONLY (0x01)：该文件不可修改，对该文件的修改操作会以返回错误码告终。\nATTR_HIDDEN (0x02)：除非用户显式地要求列举出隐藏文件，否则 hidden files 不应在列举目录下文件时出现 (可以理解为 ls -a 和 ls 的区别)。\nATTR_SYSTEM (0x04)：该文件被标记为和操作系统相关的“系统文件”，除非用户显式地要求列举出系统文件，否则 system files 不应在列举目录下文件时出现。\nATTR_VOLUME_ID (0x08)：该文件包含 volume label，这种情况下，DIR_FstClusHI 和 DIR_FstClusLO 必须都置为 0。\n只有根目录可以有一个 entry 包含该属性 (表示长文件名的 entry 不遵从该规则)。\nATTR_DIRECTORY (0x10)：该目录项表示的是一个子目录。这种情况下，DIR_FileSize 必须为 0。\nATTR_ARCHIVE (0x20)：当文件被创建、重命名或修改时，该属性值必须被设置，标志该文件的相关信息已经被修改。在备份时，各种工具可以利用该属性来判断一个文件是否需要备份。\n6.3 Date/Time DIR_CrtTime, DIR_CrtTimeTenth, DIR_CrtDate, DIR_LstAccDate 这四个字段是选填的。文件系统驱动如果不支持这些字段，则必须将其置为 0。DIR_WrtTime 和 DIR_WrtDate 这两个字段是文件系统驱动必须正确更新的。\nDate format DIR_CrtDate, DIR_WrtDate, DIR_LstAccDate 这三个字段需要遵从日期的格式。\n0-4 bit：日 (1~31) 5-8 bit：月 (1~12) 9-15 bit：从 1980 年起的年份 (0~127，可以表示 1980~2107 年) Time Format DIR_CrtTime, DIR_WrtTime 这两个字段需要遵从时间格式。时间是以 2s 为颗粒度的。\n0-4 bit：秒 (以 2s 为单位，数值范围是 0~29，可以表示 0,2,4,\u0026hellip;,58) 5-10 bit：分钟 (0~59) 11-15 bit：小时 (0~23) 6.4 File/Directory Size 文件的最大大小是 0xFFFFFFFF 个字节。最大的目录大小是 $2^{21}$ 个字节。\n6.5 Directory creation 当一个新的目录被创建时，文件系统实现必须保证以下内容：\nDIR_Attr 的 ATTR_DIRECTORY bit 要置为 1。 DIR_FileSize 必须置为 0。 至少要分配一个 cluster，DIR_FstClusLO 和 DIR_FstClusHI 负责表示第一个 cluster 的编号。 (以上三条说的时该目录在其父目录的 directory entry 中的内容)\n如果该目录只有一个 cluster，那么它对应的 FAT entry 应当被标记为 end-of-file。 初始分配的 cluster 的内容应当置为 0。 除了根目录，其他所有目录都必须在开头有如下的两个目录项： .：该目录项表示当前目录，之前提到的 DIR_Attr, DIR_FileSize 的规则仍然需要保持，DIR_FstClusLO 和 DIR_FstClusHI 以及所有的时间、日期字段必须和当前目录的保持一致。 ..：该目录项表示上一级目录，之前提到的 DIR_Attr, DIR_FileSize 的规则仍然需要保持，DIR_FstClusLO 和 DIR_FstClusHI 以及所有的时间、日期字段必须和上一级目录的保持一致 (如果上一级目录是根目录，则 DIR_FstClusLO 和 DIR_FstClusHI 必须都置为 0)。 6.6 Root Directory 根目录是一个特殊的 container file，在格式化时创建。\n在 FAT12 和 FAT16 中，根目录必须紧跟在最后一个 FAT 后，因此根目录的第一个 sector 的编号可以按照如下方式计算：\nFirstRootDirSecNum = BPB_RsvdSecCnt + (BPB_NumFATs * BPB_FATSz16); 根目录的大小根据 BPB_RootEntCnt 字段的值计算。\n在 FAT32 中，根目录是变长的，根目录的第一个 cluster 的编号存放在 BPB_RootClus 字段中。\n只有根目录的 DIR_Attr 字段的值可以等于 ATTR_VOLUME_ID。\n根目录没有名字 (在绝大多数操作系统中，\\ 这个名字被用作根目录)，也没有任何的时间戳 (日期/时间)，也没有 \u0026ldquo;.\u0026rdquo;, \u0026ldquo;..\u0026rdquo; 这两个目录项。\n6.7 File allocation 每个文件的目录项 (存储在包含这个文件的目录中) 都有该文件第一个 cluster 的编号。如果该文件大小为 0 则编号是 0。第一个 cluster 在 FAT 中对应的 FAT entry 要么存储了下一个 cluster 的编号，要么是一个 end-of-file 标志。\ndata region 的第一个 sector (cluster #2) 的编号计算方法如下：\nFirstDataSector = BPB_RsvdSecCnt + (BPB_NumFATs * FATSz) + RootDirSectors; 给定一个合法的 cluster 编号 $N$，该 cluster 的第一个 sector 的编号的计算方法如下：\nFirstSectorofCluster = ((N - 2) * BPB_SecPerClus) + FirstDataSector; Section 7: Long File Name Implementation (optional) 上一个 section 中提到 DIR_Name 字段的长度只有 11 个 字节，其中前 8 个字节是 main part，后三个字节是扩展名。这种目录项被称为短名目录项。但用户很多时候喜欢给自己的文件或目录起长名字，本 section 主要关注如何存储长名的目录项。\n长文件名的文件的相关信息存储在一些额外的长名目录项中。注意这里的长名目录项不是独立的，而是作为短名目录项的补充。即每个文件有一个短名目录项，如果文件名过长则另有一些长名目录项专门存储名字。长名目录项必须紧靠着存放在对应的短名目录项前面 (即 长*n+短 = 一个文件/目录的描述)。\n长名目录项的内容可以用如下结构体表示：\nstruct LongDirent { uint8_t LDIR_Ord; /* 0 */ char LDIR_Name1[10]; /* 1 */ uint8_t LDIR_Attr; /* 11 */ uint8_t LDIR_Type; /* 12 */ uint8_t LDIR_Chksum; /* 13 */ char LDIR_Name2[12]; /* 14 */ uint16_t LDIR_FstClusLO; /* 26 */ char LDIR_Name3[4]; /* 28 */ }__attribute__((__packed__)); 各个字段的解释如下：\nLDIR_Ord：该字段表示该长名目录项是其对应的短名目录项的第几个 (一个很长的名字可能需要多个长名目录项来存储)。对于最后一个长名目录项，其 LDIR_Ord 必须或上 LAST_LONG_ENTRY (0x40)。\nLDIR_Name1：长名的第 1 ~ 5 个字符。\nLDIR_Attr：长名目录项的 LDIR_Attr 必须被设置为 ATTR_LONG_NAME：\nATTR_LONG_NAME = ATTR_READ_ONLY | ATTR_HIDDEN | ATTR_SYSTEM | ATTR_VOLUME_ID; 用来判断一个目录项是否是长名目录项的 Mask 为\n#define ATTR_LONG_NAME_MASK (ATTR_READ_ONLY | ATTR_HIDDEN | ATTR_SYSTEM | ATTR_VOLUME_ID | ATTR_DIRECTORY | ATTR_ARCHIVE); LDIR_Type：必须被置为 0。\nLDIR_ChkSum：针对其对应的短名目录项算出来的一个校验值。\nLDIR_Name2：长名的第 6 ~ 11 个字符。\nLDIR_FstClusLO：必须被置为 0。\nLDIR_Name3：长名的第 12 ~ 13 个字符。\n7.1 Ordinal Number Generation 一个短名目录项对应的一系列附属的长名目录项在 LDIR_Ord 这个字段上应当满足如下要求：\n第一个长名目录项满足 LDIR_Ord == 1。 后续的长名目录项的 LDIR_Ord 保证严格单调递增。 最后一个长名目录项满足 LDIR_Ord == (N | LAST_LONG_ENTRY)。 如果以上任何一条不满足，我们就认为该长名目录项集合被损坏了。\n7.2 Checksum Generation 当短名目录项和长名目录项被创建的时候，我们需要创建一个 8 bit 的校验和。这个校验和根据短名目录项的 DIR_Name 字段生成：\nunsigned char ChkSum (unsigned char *pFcbName) { short FcbNameLen; unsigned char Sum = 0; for (FcbNameLen = 11; FcbNameLen != 0; FcbNameLen--) Sum = ((Sum \u0026amp; 1) ? 0x80 : 0) + (Sum \u0026gt;\u0026gt; 1) + *pFcbName++; return Sum; } 如果长名目录项中的校验和与其对应的短名目录项算出来不一致，我们就认为该长名目录项集合被损坏了。\n7.3 Example illustrating persistence of a long name 下面的图片以 \u0026ldquo;The quick brown.fox\u0026rdquo; 这个名字为例展示了长名的存储方法：\n长文件名不能超过 255 个字符 (不包括结尾的 NULL)。长文件名中的字符限制和短文件名基本一样 (见 Section 6.1)，一些额外的规则为：\n长文件名中可以使用任意多个 . 字符。\n+ , ; = [ ] 这六个特殊字符不能在短文件名中出现，但长文件名中也可以使用。\n长文件名中间允许有空格。开头和结尾的空格会被忽略。\n长名目录项中使用 unicode 来存储字符，unicode 中每个字符占 16 个 bit (2 个字节)，这是与短名目录项不同的地方。另一个不同是长名目录项可以区分大小写。\n7.4 Rules governing name creation and matching 一个目录下所有短文件名和长文件名构成的集合被称为一个 namespace。一个 namespace 下的文件名应当遵循如下规定：\n不论是短文件名还是长文件名，在一个 namespace 中必须是全局唯一的。这里比较唯一性时忽略大小写，即如果两个名字字符一样但大小写不同也被认为是冲突的。 如果一个 OEM 或 unicode 字符无法被转换成系统中的合适字符，文件系统应当将其翻译成 _。 ","date":1655164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655164800,"objectID":"e2dd02bac4180b06e8712fdf0f2cb073","permalink":"https://kristoff-starling.github.io/notes/manualnotes/fat/","publishdate":"2022-06-14T00:00:00Z","relpermalink":"/notes/manualnotes/fat/","section":"notes","summary":"该笔记是对 Microsoft Fat Specification 的精华部分的翻译和解读。","tags":null,"title":"FAT Specification - Notes","type":"notes"},{"authors":null,"categories":null,"content":" 关于计算机信息\n使用 uname -a 命令可以查看操作系统，时间，硬件架构等。\nWhat is Operating System? Operating system is responsible for makeing it easy to run programs, allowing programs to share memory and interact with devices. - OSTEP\n操作系统：“管理软硬件资源，为程序提供服务”的东西。\nENIAC 逻辑门：真空电子管。\n存储器：延迟线内存，类似于“小丑扔球”的技巧，将数据不断地扔进延迟线，拿出来以后经过放大器再扔进延迟线。\n输入输出：打一针/将纸带挪动一下。\n不需要操作系统。能运行程序就不错了，不需要“管理程序的程序”。\n1950s Computer 更快更小的逻辑门 (晶体管)，更大的内存 (磁芯内存)，更丰富的 I/O 设备。因为 I/O 设备速度严重低于处理器速度，所以中断机制出现。更多的人使用通用计算机，他们希望使用 API，而不是直接使用硬件。因此诞生了 FORTRAN 编程语言。\n1950s 的操作系统：管理多个程序依次排队运行的库函数和调度器。\n计算机非常贵非常少，多个用户排队使用计算机。 很多程序卡片 $\\rightarrow$ OS $\\rightarrow$ 硬件 操作 (operate) 任务 (job) 的系统 (system) 批处理系统：程序自动切换 (换卡) + 提供库函数 API 1960s Computer 更大的内存，更多的高级语言 (COBOL, BASIC etc.) \u0026hellip; 我们可以将多个程序同时放到程序里。但计算机中只有一个 CPU。\n1960s 的操作系统：\n传统的执行流：A on CPU (30s) $\\rightarrow$ A on device (5min) $\\rightarrow$ A on CPU (30s) B on CPU (30s)\n理想的执行流：\nCPU: A on CPU(30s) $\\rightarrow$ OS 调度 $\\rightarrow$ B on CPU (30s) $\\rightarrow$ OS 调度 $\\rightarrow$ A on CPU\nDevice:\t$\\rightarrow$ A on device (5min)\n这就是多道程序 (multiprogramming)。为了防止恶意程序对别的程序和操作系统本身的破坏，我们还需要对每个程序的运行有一个好的隔离机制。\n多道程序在程序使用设备时发生切换。在引入时钟中断后，操作系统成为计算机的霸主：操作系统决定谁来运行。\n1970s+ Computer 计算机空前发展，与今天已无大异。\n分时系统趋于成熟，UNIX 诞生，奠定现代操作系统的形态。\nToday 操作系统：虚拟化硬件资源，为应用程序提供服务。\n面对的问题：\n更复杂的处理器和内存：非对称多处理器， Non-uniform Memory Access etc.。 更多的设备和资源。 …… ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"fa96d4008533636bc180a50d7338d605","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec01/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec01/","section":"notes","summary":"关于计算机信息\n使用 uname -a 命令可以查看操作系统，时间，硬件架构等。\nWhat is Operating System? Operating system is responsible for makeing it easy to run programs, allowing programs to share memory and interact with devices. - OSTEP","tags":null,"title":"Lecture 01: Introduction","type":"docs"},{"authors":null,"categories":null,"content":"Digital Logic 数字电路：\n状态：寄存器中保存的值； 初始状态：RESET； 迁移：组合逻辑电路下计算寄存器下一个周期的值。 Example: Seven-seg // logisim.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #define REGS_FOREACH(_) _(X) _(Y) #define OUTS_FOREACH(_) _(A) _(B) _(C) _(D) _(E) _(F) _(G) #define RUN_LOGIC X1 = !X \u0026amp;\u0026amp; Y; \\ Y1 = !X \u0026amp;\u0026amp; !Y; \\ A = (!X \u0026amp;\u0026amp; !Y) || (X \u0026amp;\u0026amp; !Y); \\ B = 1; \\ C = (!X \u0026amp;\u0026amp; !Y) || (!X \u0026amp;\u0026amp; Y); \\ D = (!X \u0026amp;\u0026amp; !Y) || (X \u0026amp;\u0026amp; !Y); \\ E = (!X \u0026amp;\u0026amp; !Y) || (X \u0026amp;\u0026amp; !Y); \\ F = (!X \u0026amp;\u0026amp; !Y); \\ G = (X \u0026amp;\u0026amp; !Y); #define DEFINE(X) static int X, X##1; #define UPDATE(X) X = X##1; #define PRINT(X) printf(#X \u0026quot; = %d; \u0026quot;, X); int main() { REGS_FOREACH(DEFINE); OUTS_FOREACH(DEFINE); while (1) { // clock RUN_LOGIC; OUTS_FOREACH(PRINT); REGS_FOREACH(UPDATE); putchar('\\n'); fflush(stdout); sleep(1); } } 数字电路永远是根据当前状态机的状态确定次态，循环往复。上述程序用两个寄存器 X,Y 实现了七段数码管 0 $\\rightarrow$ 1 $\\rightarrow$ 2 循环更新的功能 (注：这段代码使用了一些 X-macros 技巧，使得我们无需对每个寄存器写相同的代码，值得学习。)\n搭配上一个简单的 python 程序，我们便可以在终端中打印这个七段数码管：\n# seven-seg.py import fileinput TEMPLATE = ''' \\033[2J\\033[1;1f AAAAAAAAA FF BB FF BB FF BB FF BB GGGGGGGGG EE CC EE CC EE CC EE CC DDDDDDDDD ''' BLOCK = { 0: '\\033[37m░\\033[0m', # STFW: ANSI Escape Code 1: '\\033[31m█\\033[0m', } VARS = 'ABCDEFG' for v in VARS: globals()[v] = 0 stdin = fileinput.input() while True: exec(stdin.readline()) pic = TEMPLATE for v in VARS: pic = pic.replace(v, BLOCK[globals()[v]]) # 'A' -\u0026gt; BLOCK[A], ... print(pic) 关于该 python 程序的一些注解：\nexec(stdin.readline()) 用于将读入的内容直接当作 python 语句执行。由于之前的 C 程序在一行中用 ; 将多个变量赋值分开，符合 python 语法，因此可以直接作为 python 程序中的变量赋值语句。 BLOCK[] 数组中存储了两种颜色：37 号是白色，31 号是红色。这里使用了 ANSI Escape Code，具体格式可以参考 这篇文章。 Programs: Code Perspective C 程序也是状态机：\n状态：堆+栈； 初始状态：main() 的第一条语句； 迁移：执行一条简单语句。 从更 low-level 的角度而言，C 程序的状态机描述如下：\n状态：全局变量+栈帧的列表 (每个栈帧里有一个 PC 表示当前执行到哪里)；\n初始状态：main(argc, argv)；\n迁移：执行 top stack frame 中 PC 处的语句，PC++。\n函数的调用本质上就是新建一个栈帧放在栈帧列表的顶部，然后跳转到该栈帧中的第一条指令；函数的返回本质上就是将顶部的栈帧 pop 掉。\nExample: Hanoi-nr // hanoi-nr.c typedef struct { int pc, n; char from, to, via; } Frame; #define call(...) ({ *(++top) = (Frame) { .pc = 0, __VA_ARGS__ }; }) #define ret() ({ top--; }) #define goto(loc) ({ f-\u0026gt;pc = (loc) - 1; }) void hanoi(int n, char from, char to, char via) { Frame stk[64], *top = stk - 1; call(n, from, to, via); for (Frame *f; (f = top) \u0026gt;= stk; f-\u0026gt;pc++) { switch (f-\u0026gt;pc) { case 0: if (f-\u0026gt;n == 1) { printf(\u0026quot;%c -\u0026gt; %c\\n\u0026quot;, f-\u0026gt;from, f-\u0026gt;to); goto(4); } break; case 1: call(f-\u0026gt;n - 1, f-\u0026gt;from, f-\u0026gt;via, f-\u0026gt;to); break; case 2: call( 1, f-\u0026gt;from, f-\u0026gt;to, f-\u0026gt;via); break; case 3: call(f-\u0026gt;n - 1, f-\u0026gt;via, f-\u0026gt;to, f-\u0026gt;from); break; case 4: ret(); break; default: assert(0); } } } switch-case 结构相当于给递归代码编上了“行号”。每个栈帧中的 PC 表示当前层函数执行到了第几行。\nPrograms: Binary Perspective 从二进制的角度，程序仍然是状态机。\n状态：寄存器，内存…… 迁移：执行一条指令 如果整个程序的行为是确定的，状态机应该长成一条直线：$(M_0,R_0)\\rightarrow (M_1,R_1)\\rightarrow\\cdots$ 。如果引入了一些 non-deterministic 的元素，比如 rdrand 指令 (读取一个硬件随机数到寄存器中)，那么状态机会有分叉。但无论如何，这是一个有限状态机 (内存、寄存器数量是有限的)，如果只有计算指令，有限步之后我们必然会回到一个经历过的状态。我们无法实现输入输出，甚至是停止程序。\n因此，程序中有一条特殊的指令：syscall。程序将自己的状态机 $(M,R)$ 交给操作系统，任其修改，最终操作系统返回一个状态机 $(M\u0026rsquo;,R\u0026rsquo;)$，程序继续执行。因此程序=计算+syscall+计算+syscall+……\nExample: A smallest \u0026ldquo;Hello, world\u0026rdquo; 我们想象中的最小函数：\nvoid _start() { } 直接运行会得到 SIGSEGV。使用 GDB 对汇编代码进行调试：\n0x401000 \u0026lt;_start\u0026gt; endbr64 0x401004 \u0026lt;_start+4\u0026gt; push %rbp 0x401005 \u0026lt;_start+5\u0026gt; mov %rsp,%rbp 0x401008 \u0026lt;_start+8\u0026gt; nop 0x401009 \u0026lt;_start+9\u0026gt; pop %rbp 0x40100a \u0026lt;_start+10\u0026gt; ret 执行 ret 指令时发生错误，因此 ret 的本质是将 %rax 的值赋给 PC，而此时 %rax 的值是一个非法的地址。\n用户程序只能解决“计算”的问题，因此我们甚至无法结束程序。我们必须借助系统调用才能使程序正常运行起来。\n# minimal.S #include \u0026lt;sys/syscall.h\u0026gt; .globl _start _start: movq $SYS_write, %rax # write( movq $1, %rdi # fd=1, movq $st, %rsi # buf=st, movq $(ed - st), %rdx # count=ed-st syscall # ); movq $SYS_exit, %rax # exit( movq $1, %rdi # status=1 syscall # ); st: .ascii \u0026quot;\\033[01;31mHello, OS World\\033[0m\\n\u0026quot; ed: 前半段程序负责打印：将系统调用号 SYS_write 和输出对象，输出内容等参数放到 x86-64 制定的寄存器中，然后使用 syscall 指令；后半段负责退出。\n使用 gcc -c minimal.S \u0026amp;\u0026amp; ld minimal.S \u0026amp;\u0026amp; ./a.out 命令，可以得到红色加粗的 \u0026ldquo;Hello, OS World\u0026rdquo;。\nSwitching between Perspectives 记源代码为 $S$，汇编代码为 $S$，则编译器就是一个函数：$S=compile(S)$。\n从状态机的视角来看，编译 (优化) 的正确性 (soundness) 的含义是：两个状态机的可观测行为完全一致。因此在保证整体语义不变的前提下，编译器可以自由地调整语句顺序，合并语句，删除无用语句等。\nExample: Compile Optimization void foo(int g) { g++; g++; } 开启 -O1 优化后，得到的汇编代码为\n0000000000000000 \u0026lt;foo\u0026gt;: 0:\tf3 0f 1e fa endbr64 4:\tc3 ret 编译器直接将 g++ 删除了，因为没有返回，这两句话没有作用。\nextern int g; void foo(int x) { g++; g++; } 汇编代码为\n0000000000000000 \u0026lt;foo\u0026gt;: 0:\tf3 0f 1e fa endbr64 4:\t83 05 00 00 00 00 02 addl $0x2,0x0(%rip) # b \u0026lt;foo+0xb\u0026gt; b:\tc3 ret 因为 g 是外部变量，所以这里对 g 的操作是有意义的，但连续的两次 +1 可以用一次 +2 来代替。\nextern int g; void foo(int x) { g++; asm volatile(\u0026quot;nop\u0026quot; : : \u0026quot;r\u0026quot;(x)); g++; } 汇编代码为\n0000000000000000 \u0026lt;foo\u0026gt;: 0:\tf3 0f 1e fa endbr64 4:\t90 nop 5:\t83 05 00 00 00 00 02 addl $0x2,0x0(%rip) # c \u0026lt;foo+0xc\u0026gt; c:\tc3 ret 这说明编译器可以调整语句的顺序，然后将两个 +1 合并成一个 +2。\n但我们有手段可以让编译器无法进行这个合并：\nextern int g; void foo(int x) { g++; asm volatile (\u0026quot;nop\u0026quot; : : \u0026quot;r\u0026quot;(x) : \u0026quot;memory\u0026quot;); g++; } 汇编代码为\n0000000000000000 \u0026lt;foo\u0026gt;: 0:\tf3 0f 1e fa endbr64 4:\t83 05 00 00 00 00 01 addl $0x1,0x0(%rip) # b \u0026lt;foo+0xb\u0026gt; b:\t90 nop c:\t83 05 00 00 00 00 01 addl $0x1,0x0(%rip) # 13 \u0026lt;foo+0x13\u0026gt; 13:\tc3 ret 中间插入的内联汇编语句使用了 memory clobber，其意思是告诉编译器这些内联汇编代码可能会任意读取、修改内存内容，因此编译器在调整语句顺序时，不能超过这个 asm block。这句话就像一堵墙一样挡在中间，使得两处 +1 无法被合并。\n该手法在操作系统的锁机制中有重要的应用 (避免编译器将 critical section 中的语句优化到外面，导致 race condition)。\nPrograms: OS Perspective 操作系统眼中的程序：程序=计算+syscall+计算+syscall+…… 程序只能通过操作系统允许的方式来访问操作系统掌控的资源，从而操作系统掌握了计算机的“霸权”。\nExample: Entering a Program 一个 C 程序执行的第一条指令在哪里？\n最合理的方法：用 gdb 打开可执行文件，然后用 starti 指令定位到第一条汇编指令，发现在 /lib64/ld-linux-x86-64.so.2 中。这是一个加载器，加载器负责跳转到 __start() 执行。\n凭什么不能是 rtfm.so?\n使用 readelf 工具，可以看到在可执行文件中说明了\n[Requesting program interpreter: /lib64/ld-linux-x86-64.so.2] 如果我们直接对 a.out 进行修改，将 ld-linux-x86-64.so.2 字段改为 rtfm.so，再创建一个从 rtfm.so 到 ld-linux-x86-64.so.2 的链接，我们就真的可以实现用我们制定的 rtfm.so 来加载程序。\n计算机系统不存在玄学，一切都建立在确定的机制上。\n在执行 main() 函数之前，程序经历了很多的过程，使用了很多的系统调用，用 strace 工具可以查看这些系统调用(注：strace 会输出到标准错误，重定向时要注意)。 C 语言还支持在进入 main() 函数之前和之后做事情：\n// hello-goodbye.c #include \u0026lt;stdio.h\u0026gt; __attribute__((constructor)) void hello() { printf(\u0026quot;Hello, World\\n\u0026quot;); } // See also: atexit(3) __attribute__((destructor)) void goodbye() { printf(\u0026quot;Goodbye, Cruel OS World!\\n\u0026quot;); } int main() { } Tip: 利用 Vim 来整理不易阅读的输入内容\nstrace 输出的内容杂乱难读，利用 vim 对其进行整理可以帮助我们阅读。常用的整理命令可以有：\n:%! grep [-v] word 筛选出包含 word 的行 (-v 参数可以反向筛选)。 :%s/, \\r /g 将所有的 , 替换为换行符。人类倾向于阅读行数多但每行都很短的内容。 …… ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"9bf7ad50b9d965285481cacbe717977d","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec02/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec02/","section":"notes","summary":"Digital Logic 数字电路：\n状态：寄存器中保存的值； 初始状态：RESET； 迁移：组合逻辑电路下计算寄存器下一个周期的值。 Example: Seven-seg // logisim.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #define REGS_FOREACH(_) _(X) _(Y) #define OUTS_FOREACH(_) _(A) _(B) _(C) _(D) _(E) _(F) _(G) #define RUN_LOGIC X1 = !","tags":null,"title":"Lecture 02: Programs on Operating Systems","type":"docs"},{"authors":null,"categories":null,"content":"并发：一个计算机程序被分成了若干个部分，在不改变程序最终运行结果的情况下，这些部分被乱序地执行。并发执行的多个部分会共享资源。\nState Machine 在单线程视角中，C 程序的状态机包括全局变量，堆区，栈帧列表等。全局变量和堆区的内容是全局的，是所有函数共享的，理应作为共享资源；栈帧中的变量都是局部变量，栈帧与栈帧之间独立性较强，可以交给多个线程。\n多线程视角下的状态机：\n全局变量，堆区等全局共享资源； 若干个栈帧链，每条栈帧链属于一个线程。 在并发程序中，每一步的结果都是 non-deterministic 的，它的状态转移图是长成这样的：\nstateDiagram state1: (g, T1, T2) state1 --\u0026gt; state2: 线程T1执行 state1 --\u0026gt; state3: 线程T2执行 state2: (g',T1',T2) state3: (g',T1,T2') state2 --\u0026gt; state4: 线程T1执行 state2 --\u0026gt; state5: 线程T2执行 state3 --\u0026gt; state6: 线程T1执行 state3 --\u0026gt; state7: 线程T2执行 state4: …… state5: …… state6: …… state7: …… Simplified Thread API // thread.h #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdatomic.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #define NTHREAD 6400 enum { T_FREE = 0, T_LIVE, T_DEAD, }; struct thread { int id, status; pthread_t thread; void (*entry)(int); }; struct thread tpool[NTHREAD], *tptr = tpool; void *wrapper(void *arg) { struct thread *thread = (struct thread *)arg; thread-\u0026gt;entry(thread-\u0026gt;id); return NULL; } void create(void *fn) { assert(tptr - tpool \u0026lt; NTHREAD); *tptr = (struct thread) { .id = tptr - tpool + 1, .status = T_LIVE, .entry = fn, }; pthread_create(\u0026amp;(tptr-\u0026gt;thread), NULL, wrapper, tptr); ++tptr; } void join() { for (int i = 0; i \u0026lt; NTHREAD; i++) { struct thread *t = \u0026amp;tpool[i]; if (t-\u0026gt;status == T_LIVE) { pthread_join(t-\u0026gt;thread, NULL); t-\u0026gt;status = T_DEAD; } } } __attribute__((destructor)) void cleanup() { join(); } thread.h 是对 C 库 pthreads 的进一步封装。其中的一些关键函数和代码解读如下：\ncreate(fn) ：创建一个新的线程并立即执行，该线程的入口函数是 fn。\n函数 fn 的定义为 void fn(int tid)，其中 tid 为线程号，从 1 开始编号。\n从状态机的角度来看，create() 的语义是在状态机中新开了一个链表，这个链表只有一个 fn 函数的栈帧。\n原理：pthread_create() 函数的声明为\nint pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg); 其中 start_routine 是新线程第一个执行的函数，arg 是给 start_routine 传入的参数，attr 设置为 NULL 表示按照默认方式创建线程。thread.h 中传入的 start_routine 是 wrapper，wrapper 中的语句 thread-\u0026gt;entry(thread-\u0026gt;id) 以线程号为参数，调用了 fn 函数。\njoin()：join() 是线程中的“等待”，和进程中的 wait() 有一点相似。join() 的语义相当于在调用该函数的线程中加入了一条死循环语句：\nwhile (其他线程未结束); 假设当前有三个线程 T1,T2,T3，T1 中调用了 join()，则之后的状态机如下：\nstateDiagram state1:(T1(join),T2,T3) state1 --\u0026gt; state1: 线程 T1 执行 state1 --\u0026gt; state2: 线程 T2 执行 state1 --\u0026gt; state3: 线程 T3 执行 state2:(T1(join), T2(end), T3) state3:(T1(join), T2, T3(end)) state2 --\u0026gt; state2: 线程 T1 执行 state2 --\u0026gt; state4: 线程 T3 执行 state3 --\u0026gt; state3: 线程 T1 执行 state3 --\u0026gt; state4: 线程 T2 执行 state4: (T1,T2(end),T3(end)) note right of state4 T2,T3 线程均结束，T1 死循环解除 end note state4 --\u0026gt; state5 state5: …… 原理：join() 中主线程会遍历线程数组，调用 pthread_join() 函数等待它们一一结束，将其状态设置为 T_DEAD，然后返回。pthread_join() 函数的声明为：\nint pthread_join(pthread_t thread, void **retval); 当前函数会等待 thread 线程执行结束 (若 thread 已经结束就直接返回)，如果 retval 指针不为空，就将 thread 线程的退出状态指针填写到 retval 中。\n在 include 了 threads.h 的情况下，main() 函数执行结束后，所有新创建的线程会被自动释放。该功能是由 thread.h 中的 clean_up() 函数实现的 (添加了 __attribute__((destructor)) 的函数会在 main() 函数返回之后被执行)。clean_up() 额外调用了一次 join()，\nConcurrent Programming: Introduction 全局的变量会被各个线程共享，我们可以写一个程序来证明这一点：\n// shm-test.c #include \u0026quot;thread.h\u0026quot; int x; void Thello(int tid) { usleep(tid * 100000); printf(\u0026quot;Hello world from thread #%c\\n\u0026quot;, \u0026quot;0123456789ABCDEF\u0026quot;[x++]); } int main () { x = 1; for (int i = 0; i \u0026lt; 10 ; i++) create(Thello); return 0; } 该程序的输出结果为\nHello world from thread #1 Hello world from thread #2 Hello world from thread #3 Hello world from thread #4 Hello world from thread #5 Hello world from thread #6 Hello world from thread #7 Hello world from thread #8 Hello world from thread #9 Hello world from thread #A 可以看到，某一个线程对全局变量 x 的修改在别的线程是可见的。\n我们可以写一个小程序来探测每个线程的栈空间大小：\n// stack-probe.c #include \u0026quot;thread.h\u0026quot; __thread char *base, *cur; // thread-local variables __thread int id; // objdump to see how thread-local variables are implemented __attribute__((noinline)) void set_cur(void *ptr) { cur = ptr; } __attribute__((noinline)) char *get_cur() { return cur; } void stackoverflow(int n) { set_cur(\u0026amp;n); if (n % 1024 == 0) { int sz = base - get_cur(); printf(\u0026quot;Stack size of T%d \u0026gt;= %d KB\\n\u0026quot;, id, sz / 1024); } stackoverflow(n + 1); } void Tprobe(int tid) { id = tid; base = (void *)\u0026amp;tid; stackoverflow(0); } int main() { setbuf(stdout, NULL); for (int i = 0; i \u0026lt; 4; i++) { create(Tprobe); } } 该代码中有一些值得注意的细节：\n程序的主要思想是使用一个死递归，由于函数的参数作为局部变量总是放在栈上，所以可以通过查看参数 n 的地址来获得大致的栈顶位置。触发段错误之后，根据输出信息大致判断栈的大小。\n加入了 __thread 声明的变量是线程局部变量 (thread-local variables)，每个线程都单独拥有线程局部变量，对线程局部变量的修改操作彼此互不影响。\n__attribute__((noinline)) 字段可以使函数不会被內联到函数内部，这有助于我们使用 objdump 工具反汇编可执行文件以观测线程局部变量的实现方式。stack-probe.o 的反汇编结果中 set_cur() 函数的汇编代码如下：\n0000000000000196 \u0026lt;set_cur\u0026gt;: 196: f3 0f 1e fa endbr64 19a: 55 push %rbp\t19b: 48 89 e5 mov %rsp,%rbp # 创建新的栈帧 19e: 48 89 7d f8 mov %rdi,-0x8(%rbp)\t1a2: 48 8b 45 f8 mov -0x8(%rbp),%rax # 将第一个参数的值放入rax 1a6: 64 48 89 04 25 00 00 mov %rax,%fs:0x0 # 将rax的值赋给cur 1ad: 00 00 1af: 90 nop 1b0: 5d pop %rbp 1b1: c3 ret 可以看到 %fs:0x0 代表的就是线程局部变量 cur 的地址。%fs 是 x86-64 的一个段寄存器，使用 %fs 将引用线程的 glibc TLS (thread local storage)。这里的偏移量之所以是 0 是因为还没有重定位，重定位之后每个变量都会有一个不同的 offset。\n根据程序的输出结果，可以看出每个线程栈大小为 8192K=8M。\nTip: Unix Philosophy\n由于有多个线程并发输出，该程序的输出结果非常杂乱，为处理之前大致如下：\n... Stack size of T1 \u0026gt;= 8128 KB Stack size of T3 \u0026gt;= 8064 KB Stack size of T4 \u0026gt;= 6208 KB Stack size of T2 \u0026gt;= 7616 KB Stack size of T3 \u0026gt;= 8128 KB [1] 46916 segmentation fault (core dumped) 我们可以利用命令行的 sort 工具来整理输出结果。\n./stack-probe | sort -nk 6 其中参数 -n 表示比较时将字符串转换成数值进行比较 (如果不加这个参数，那些九百多的三位数会被排在作后)，-k 表示选择第几列进行比较，后面的数字 6 指定了数值的那一列。\n如何修改线程栈的大小？\n在执行程序前，使用命令 ulimit -s SIZE 来修改栈大小。SIZE 的单位是 KB。修改完之后，使用 stack-probe.c 程序进行检测可以看到线程栈大小改变了。\n(注：关闭终端后该改变会失效。)\nConcurrent Programming: Atomicity 考虑以下程序：\n// sum.c #include \u0026quot;thread.h\u0026quot; #define N 100000000 long sum = 0; void Tsum() { for (int i = 0; i \u0026lt; N; i++) { sum++; } } int main() { create(Tsum); create(Tsum); join(); printf(\u0026quot;sum = %ld\\n\u0026quot;, sum); } 两个线程各对全局变量 sum 进行 N 次 +1 操作，理论上应该得到结果 200000000，但运行该程序每次都会得到远小于 200000000 的各不相同的结果。导致这个结果的原因是原子性的丧失：“程序 (甚至是一条指令) 独占处理器运行“的基本假设在现代多处理器系统上不再成立。\nTip: Unix Philosophy\n我们想多观测几次 sum.c 程序的输出，但重复执行 ./sum 太低效了。好的方法是现场写一个 shell 脚本：\nwhile true; do ./sum; done 注：在一行内写 shell 脚本需要注意不同语句之间要用分号隔开。\n考察 Tsum() 函数的汇编结果，其中 sum++ 这条核心语句被编译成了 3 条汇编指令：\n1a7: 48 8b 05 00 00 00 00 mov 0x0(%rip),%rax # 1ae \u0026lt;Tsum+0x18\u0026gt; 1ae: 48 83 c0 01 add $0x1,%rax 1b2: 48 89 05 00 00 00 00 mov %rax,0x0(%rip) # 1b9 \u0026lt;Tsum+0x23\u0026gt; 0x0(%rip) 是变量 sum 的地址，由于还没有重定位，所以偏移量还没有填入。sum 的值会先被放入 %rax，然后 %rax +1，然后 %rax 的值被写回 sum。假设当前两个线程在并发地执行这段代码，轮流执行，则执行情况如下表 (设 sum 的初值为 s) ：\nThread1 Thread2 1 %rax in CPU1 = s %rax in CPU2 = s 2 %rax in CPU1 = s+1 %rax in CPU2 = s+1 3 sum = s+1 sum = s+1 可以看到 +1 操作被吞掉了一次。两个线程在并发地对同一个内存地址进行读写，打破了 invariant，从而导致并发 bug。\n解决这个问题的方法是用锁将这几句代码包裹起来，强制两个线程串行地执行。\nConcurrent Programming: Order 如果对 sum.c 进行 -O1 和 -O2 优化，我们会得到不同的结果：\n在 -O1 优化下，编译器会分析出函数的目的是 sum+=N，并使用 Reg = sum, Reg += N, sum = Reg 三条指令实现。因为 race condition，两次 sum = Reg 重复写入，所以 -O1 优化下输出结果为 100000000。\n-O2 优化更为彻底，直接使用一条指令\n48 81 05 01 2e 00 00 addq $0x5f5e100, 0x0(%rip) 来完成。至少“看上去”获得了正确的结果 200000000。(Visibility 一节会再分析这种情况)\n另外一个例子是：\nextern int done; int main () { while (!done); } 的汇编代码是 (-O2 优化)\n0000000000000000 \u0026lt;main\u0026gt;: 0: f3 0f 1e fa endbr64 4: 8b 05 00 00 00 00 mov 0x0(%rip),%eax # a \u0026lt;main+0xa\u0026gt; a: 85 c0 test %eax,%eax c: 75 02 jne 10 \u0026lt;main+0x10\u0026gt; e: eb fe jmp e \u0026lt;main+0xe\u0026gt; 10: 31 c0 xor %eax,%eax 12: c3 ret 它实际上被翻译成了\nif (!done) while(1); 编译器无法考虑到多线程的可能，它认为在执行 while (!done) 的过程中当前程序是不可能被打断的。从状态及的角度来考虑，编译器只要保证最终结果的一致性 (语义一致性)，是可以随意修改指令的顺序 (甚至是指令本身) 的，这给并发编程带来了困难。\n使上述代码能够被正确地编译，一种方法是在循环中加上 memory barrier：\nwhile (!done) asm volatile(\u0026quot;\u0026quot; ::: \u0026quot;memory\u0026quot;); memory barrier 相当于告诉编译器：这里可能发生任意的对内存的修改，所以编译器不再有对 done 的值保持不变的假设。\n另一种方法是\nextern int volatile done; 它也可以保证 C 语义和汇编语义的一致性。\nConcurrent Programming: Visibility // mem-ordering.c #include \u0026quot;thread.h\u0026quot; int x = 0, y = 0; atomic_int flag; #define FLAG atomic_load(\u0026amp;flag) #define FLAG_XOR(val) atomic_fetch_xor(\u0026amp;flag, val) #define WAIT_FOR(cond) while (!(cond)) ; __attribute__((noinline)) void write_x_read_y() { int y_val; asm volatile( \u0026quot;movl $1, %0;\u0026quot; // x = 1 \u0026quot;movl %2, %1;\u0026quot; // y_val = y : \u0026quot;=m\u0026quot;(x), \u0026quot;=r\u0026quot;(y_val) : \u0026quot;m\u0026quot;(y) ); printf(\u0026quot;%d \u0026quot;, y_val); } __attribute__((noinline)) void write_y_read_x() { int x_val; asm volatile( \u0026quot;movl $1, %0;\u0026quot; // y = 1 \u0026quot;movl %2, %1;\u0026quot; // x_val = x : \u0026quot;=m\u0026quot;(y), \u0026quot;=r\u0026quot;(x_val) : \u0026quot;m\u0026quot;(x) ); printf(\u0026quot;%d \u0026quot;, x_val); } void T1(int id) { while (1) { WAIT_FOR((FLAG \u0026amp; 1)); write_x_read_y(); FLAG_XOR(1); } } void T2() { while (1) { WAIT_FOR((FLAG \u0026amp; 2)); write_y_read_x(); FLAG_XOR(2); } } void Tsync() { while (1) { x = y = 0; __sync_synchronize(); // full barrier usleep(1); // + delay assert(FLAG == 0); FLAG_XOR(3); // T1 and T2 clear 0/1-bit, respectively WAIT_FOR(FLAG == 0); printf(\u0026quot;\\n\u0026quot;); fflush(stdout); } } int main() { create(T1); create(T2); create(Tsync); } 对该程序的一些关键代码解读如下：\nTsync 是一个控制线程。它负责将一个开关变量 flag 的第一位和第二位拉高。flag 的第一位供 T1 线程使用，第二位供 T2 线程使用。等待 T1 和 T2 线程均完成操作后，Tsync 会进行下一次循环，Tsync 的设置保证了 T1 和 T2 总是能”同时“开始运行。 T1 和 T2 线程会写入 x/y 并读取 y/x，完成操作后将 flag 的对应位拉低。我们在內联汇编代码中已经加入了 memory fence 保证编译器会按照顺序编译我们的代码。 按理来说，根据执行顺序的不同，我们可能会获得 x=0 y=1，x=1 y=0，x=1 y=1 三种结果，但不可能获得 x=0 y=0。但事实上输出结果中确实有 (0,0)。我们还可以运行很多次，然后统计每种输出出现的频数。这里再次利用了 Unix Philosophy:\n./mem-ordering | head -n 100000 | sort | uniq -c head 命令用于取开头的若干行，用 sort 排序后，uniq -c 可以去重并统计每种输出出现的次数。可以看到 (0,0) 是最多的，(0,1) 比 (1,0) 稍多一些 (这是由于两个线程的不对称性)，(1,1) 没有。\n现代处理器会将指令分解成更小的“微指令” $\\mu op$，这意味着处理器也是一个“编译器”。处理器会维护一个微指令池，其中记录了微指令之间的依赖关系以及出现顺序关系，并在不影响 eventual memory consistency 的情况下调整微指令的执行顺序，多个处理器之间的即时可见性丧失。\n在本例中，由于对 x 变量地址读取的 cache miss，处理器可能会先取出下一条指令的 $\\mu op$ 来做：\n# \u0026lt;-----------+ movl $1, (x) # | movl (y), %eax # --+ 因此，输出结果中出现了 $x=y=0$ 的情况。\n解决这个问题只能从硬件的角度入手。比如可以使用 full barrier __sync_synchronize() ，(在內联汇编中，可以直接使用 mfence 指令)，或者使用原子指令。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"7a23288844d625945a046b327bd08bbd","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec03/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec03/","section":"notes","summary":"并发：一个计算机程序被分成了若干个部分，在不改变程序最终运行结果的情况下，这些部分被乱序地执行。并发执行的多个部分会共享资源。\nState Machine 在单线程视角中，C 程序的状态机包括全局变量，堆区，栈帧列表等。全局变量和堆区的内容是全局的，是所有函数共享的，理应作为共享资源；栈帧中的变量都是局部变量，栈帧与栈帧之间独立性较强，可以交给多个线程。\n多线程视角下的状态机：\n全局变量，堆区等全局共享资源； 若干个栈帧链，每条栈帧链属于一个线程。 在并发程序中，每一步的结果都是 non-deterministic 的，它的状态转移图是长成这样的：\nstateDiagram state1: (g, T1, T2) state1 --\u0026gt; state2: 线程T1执行 state1 --\u0026gt; state3: 线程T2执行 state2: (g',T1',T2) state3: (g',T1,T2') state2 --\u0026gt; state4: 线程T1执行 state2 --\u0026gt; state5: 线程T2执行 state3 --\u0026gt; state6: 线程T1执行 state3 --\u0026gt; state7: 线程T2执行 state4: …… state5: …… state6: …… state7: …… Simplified Thread API // thread.","tags":null,"title":"Lecture 03: Multiprocessor Programming","type":"docs"},{"authors":null,"categories":null,"content":"互斥 (mutual exclusion)：保证两个线程不能同时 (并发) 执行一段代码。\n对于 sum.c ，我们希望添加两个魔法函数 lock() 和 unlock()，使得魔法函数中间的代码具有互斥性：\nvoid Tsum() { for (int i = 0; i \u0026lt; N; i++) { +\tlock(); sum++; +\tunlock(); } } 一个失败的尝试：\n#define LOCK 1 #define UNLOCK 0 void critical_section() { retry: if (locked != UNLOCK) //* goto entry; locked = LOCK; //** // critical section locked = UNLOCK; } 从状态机的角度：\nstateDiagram state1: T1-L*, T2-L* state1 --\u0026gt; state2: 线程T1执行 state1 --\u0026gt; state3: 线程T2执行 state3: …… state2: T1-L**, T2-L* state2 --\u0026gt; state4: 线程T1执行 state2 --\u0026gt; state5: 线程T2执行 state4: …… state5: T1-L**, T2-L** 可以看到存在一个状态，T1 和 T2 同时获得了锁。该方法失败的根本原因是：我们读锁状态的操作和写锁状态的操作无法原子地执行。\nPeterson Algorithm 理解并发的最好方法就是用物理世界中的东西作类比：\n对共享内存的写：往黑板上贴便签条 对共享内存的读：看黑板 (其实不同于人类，计算机的“读”只能看到一个“历史状态”) 假设 Alice 和 Bob 想上厕所，为了不一起进入厕所，他们制定了如下协议：\nAlice 想上厕所，于是举起了自己的旗子 (step1，相当于 STORE 一个共享的变量)，然后将 Bob (对方) 的名字写在厕所门上 (step2，也相当于 STORE 一个共享变量)；如果 Bob 想上厕所也是同理。注意厕所门上的名字是可以覆盖的。 Alice 检查门上的名字和厕所 (step3)，Alice 可以进入厕所当且仅当 Bob 没有举旗子，或者门上的名字是自己的。 Alice 上完厕所后，把自己的旗子放下来 (step4)。 我们讨论几种情况：\nAlice 检查的时候，如果 Bob 没举旗子，说明 Bob 还不想上厕所，那 Alice 可以上厕所。 如果 Bob 也举旗子了，那结果是：先举旗子的人可以先进入厕所，因为后举旗子的人会把先举旗子的人的名字贴在门上，覆盖了先贴的人的内容。 …… 一个完备的证明方法是画状态机。我们设置状态机 $(PC_1, PC_2, x, y, turn,status)$，六个状态分别表示 T1/T2 执行到第几行，T1/T2 的旗子有没有举起来，当前厕所门上写的是谁的名字，以及当前厕所状态。\n我们还可以写一个小程序验证 Peterson：\n#define BARRIER __sync_synchronize()\tvoid critical_section() { long cnt = atomic_fetch_add(\u0026amp;count, 1); int i = atomic_fetch_add(\u0026amp;nested, 1) + 1; if (i != 1) { printf(\u0026quot;%d threads in the critical section @ count=%ld\\n\u0026quot;, i, cnt); assert(0); } atomic_fetch_add(\u0026amp;nested, -1); } int volatile x = 0, y = 0, turn; void TA() { while (1) { x = 1; BARRIER; turn = B; BARRIER; // \u0026lt;- this is critcal for x86 while (1) { if (!y) break; BARRIER; if (turn != B) break; BARRIER; } critical_section(); x = 0; BARRIER; } } void TB() { while (1) { y = 1; BARRIER; turn = A; BARRIER; while (1) { if (!x) break; BARRIER; if (turn != A) break; BARRIER; } critical_section(); y = 0; BARRIER; } } 在 critical_section() 中，代码主要做的事情是操作一个共享变量，如果某个时刻 nested == 2，说明两个线程同时进入了临界区域，则报错。\n由于现代编译器和多处理器会调整语句顺序/乱序执行……所以我们在每条语句后面添加一条 __sync_synchronize() 来保证编译按照顺序进行，且多处理器之间具有可见性。事实证明，如果去掉 BARRIER 会发生错误。\nModel Checker 我们希望用程序自动画出状态机。 model-checker.py 帮助我们完成了这项工作，其中用到的 python 语言机制较多，暂时留坑。我们可以用 model-checker.py 中编写的装饰器来编写多个线程， peterson-flag.py 是一个示例。使用命令 python3 model-checker.py xxx.py 可以输出状态机的所有节点和转移关系。\nmodel-checker.py 主要利用了 python generator 的机制来快速获得进程的状态机。\ndef numbers(init=0, step=1): n = init while True: n += step yield n g = numbers() h = numbers(100, 200) print(g, h) print(g.__next__()) print(g.__next__()) print(h.__next__()) print(g.__next__()) print(h.__next__()) 该程序输出结果为\n\u0026lt;generator object numbers at 0x7f0a75b4fcf0\u0026gt; \u0026lt;generator object numbers at 0x7f0a759f9ba0\u0026gt; 1 2 300 3 500 虽然 numbers() 里面是一个死循环，但执行 numbers() 还是可以退出，这得益于 yield 语句，yield 的功能类似于操作系统的调度，它会主动让出执行流。g.__next__() 语句可以从被打断处重新进入，继续执行函数直到遇到下一次 yield。如果我们在每一条语句后面都加上一个 yield，让 yield 后面返回所有的线程局部变量，我们就获得了函数每执行一步之后的状态机。\nModel checker 将验证程序正确性的问题转化成了一个图论问题：\nSafety (线程是否互斥)：从初始状态出发，是否存在到红色 (互斥失败) 节点的路径？\n图搜索\nLiveness：是否从任意黑色 (没有人执行临界区域代码) 状态出发，总能在有限步内到达蓝色/绿色 (有一个线程执行临界区域代码) 节点？\n这等价于只考虑图中的黑色节点，是否存在环。只要对黑色节点的导出子图求 SCC 即可。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"e50f771fc8fdd16b707b577f3e419f58","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec04/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec04/","section":"notes","summary":"互斥 (mutual exclusion)：保证两个线程不能同时 (并发) 执行一段代码。\n对于 sum.c ，我们希望添加两个魔法函数 lock() 和 unlock()，使得魔法函数中间的代码具有互斥性：\nvoid Tsum() { for (int i = 0; i \u0026lt; N; i++) { +\tlock(); sum++; +\tunlock(); } } 一个失败的尝试：","tags":null,"title":"Lecture 04: Understanding Concurrent Programs","type":"docs"},{"authors":null,"categories":null,"content":"从 high level 来看，我们希望实现如下的结构体和 API：\ntypdef struct { ... }lock; void lock(lock *lk); void unlock(lock *lk); 若 lock() 函数返回，说明获得了这个锁，别的进程会停在 lock() 里直到获得锁的人调用了 unlock()。\n实现互斥的根本困难：不能同时读写共享内存。\nload 的时候不能 store，且看完之后眼睛立刻闭上，看到的都是过去的东西； store 的时候不能 load，贴字条的时候不知道覆盖了什么。 Spin Lock “解决一个问题有两种方法：一个是分析问题、提出算法、实现解决，一个是解决提出问题的人。“ —— jyy\n我们希望硬件支持一条“瞬间完成读和写”的指令：“请所有人闭眼，然后我睁开眼看一眼，并做一个操作\u0026quot;。\nx86: Lock Prefix 以 lock 为前缀的指令支持原子操作。\n// sum-atomic.c #include \u0026quot;thread.h\u0026quot; #define N 100000000 long sum = 0; void Tsum() { for (int i = 0; i \u0026lt; N; i++) { asm volatile(\u0026quot;lock addq $1, %0\u0026quot;: \u0026quot;+m\u0026quot;(sum)); } } int main() { create(Tsum); create(Tsum); join(); printf(\u0026quot;sum = %ld\\n\u0026quot;, sum); } 由于这里的 +1 操作使用了原子指令，所以程序总能得到 2N 的输出。\n此外，一条非常好用的原子指令是 xchg，它可以原子地将一个数值和一个内存地址上的值交换。用 C 语言封装后的形式可以是：\nint xchg(volatile int *addr, int newval) { int result; asm volatile (\u0026quot;lock xchg %0, %1\u0026quot; : \u0026quot;+m\u0026quot;(*addr), \u0026quot;=a\u0026quot;(result) : \u0026quot;1\u0026quot;(newval)); //xchg默认原子，即使不加前缀lock也可以 return result; } 借助 xchg 指令，我们可以轻松地实现一个自旋锁：\nint lock = 0; void lock() {while (xchg(\u0026amp;lock, 1));} void unlock() {xchg(\u0026amp;lock, 0);} 在硬件层面，硬件可以保证所有的带 lock 的指令可以排出一个全序，且原子指令相关的内存都会被提前做好 (内存的可见性)。但这其中有很多技术细节，比如多核的 Cache 之间的一致性是 x86 的噩梦 (一旦某个 CPU 要获得所，其他所有 CPU 核的 L1 Cache 都要上锁)。\nRISC-V: LR/SC 原子指令内部的本质是三个步骤：load(), exec(), store()。RISC-V 提供了 load-reserved/store-conditional (LR/SC) 机制：\nLR: 在共享内存上打一个标记，如果出现中断、别的线程写入等情况，这个标记会消失。 exec()：在寄存器上做一些自己的事情 SC：如果共享内存上的标记还在，则 store。 这里给出一个用于自旋锁的 compare-and-swap (旧值等于某个值才将新值与其交换) 函数的实现，用这个函数实现自旋锁在轮询时可以比 xchg 少一次写入操作：\n// C语言语义 int cas(int *addr, int cmp_val, int new_val) { int old_val = *addr; if (old_val == cmp_val) {*addr = new_val;return 0;} else return 1; } cas: lr.w t0, (a0)\t# 获得旧值，并对(a0)打标记 bne t0, a1, fail\t# 如果 old_val != cmp_val 则跳转到 fail sc.w t0, a2, (a0)\t# 如果标记还在，将a2写入(a0)，t0存储标记存在情况 bnez t0, cas\t# 如果标记被冲刷了，说明出现race condition，回到cas重做 jr ra fail li a0, 1 jr ra 如果有两个线程同时希望获得锁，第一个线程执行完 sc.w 后，第二个线程的标记被冲刷，从而第二个线程执行 sc.w 后 t0=1，无法获得锁。\nLR/SC 机制不仅可以实现锁，还可以让每个线程知道锁的拥堵情况。\nSleep Lock 自旋锁的性能缺陷：\n如果多个线程同时争抢锁，并行/并发的程序会因为自旋锁变得串行。除了进入临界区域的线程，其他的线程都在空转。 如果持有自旋锁的线程被调度走了，那么所有的线程都进不去了。 自旋锁的理想使用场景：\n临界区几乎不拥堵。 持有自旋锁时禁止执行流切换 - 这件事对于应用程序来说太危险了，因此自旋锁一般用于操作系统内核中的并发数据结构 (临界区很短)。 如果锁被占用，待在原地等待锁被释放是一件不太聪明的事情 (尤其是要等很长时间的时候)，我们希望一个线程在等待锁的时候可以被暂时挂起，让出 CPU，等到锁被释放时再唤醒等锁进程。\nC 语言代码是做不到 ”让出 CPU 的\u0026quot;，因此我们需要两个系统调用：\nsyscall(SYSCALL_lock, \u0026amp;lk);\t// 试图获得lk，如果失败则当前进程被挂起 syscall(SYSCALL_unlock, \u0026amp;lk);\t// 释放lk，并唤醒正在等待lk的进程 操作系统的工作是维护这个锁和等待锁的进程\n如果有线程尝试获得锁，且锁处于空闲状态，就把锁给他。 如果有线程尝试获得锁但锁已经被取走了，则将当前线程加入等待锁的队列，并将其挂起。 如果有线程释放了锁，就检查等待锁的队列中是否有线程，如果有则将锁交给下一位 (唤醒它)，如果没有则锁的状态为空闲。 操作系统使用自旋锁保证自己对队列的操作是原子的。 Tip: GDB Usage\n使用 GDB 调试多线程时，如果直接使用 next 命令，所有的线程都会向后走一步。为了更好地观测程序行为，我们可以使用 set scheduler-lock on 命令来打开线程锁，之后再使用 next 命令就只有当前线程会向前走一步。我们可以通过 info threads 来查看线程信息，通过 thread id 来切换当前调试的线程为 id。\nFutex 自旋锁有更快的 fast path：如果获得锁成功，可以立刻进入临界区；但如果没有获得锁，则要浪费 CPU 时钟周期。 睡眠锁有更快的 slow path: 如果没有获得锁，可以执行线程切换；但在能获得锁的情况下，也需要执行系统调用陷入内核。 我们希望发明一种锁，对于 fast path，只需要一条原子指令就可以获得锁，对于 slow path，可以通过系统调用 yield。这就是 Futex = spin + mutex。\n我们可以利用 model checker 来确认 futex 的正确性：\nclass Futex locked, waits = '', '' def tryacquire(self): if not self.locked: # Test-and-set (cmpxchg) # Same effect, but more efficient than xchg self.locked = '🔒' return '' else: return '🔒' def release(self): if self.waits: self.waits = self.waits[1:]\t# 将队首元素踢出队列 \u0026lt;=\u0026gt; 将编号为队首元素的线程唤醒 else: self.locked = '' @thread def t1(self): while True: if self.tryacquire() == '🔒': # User self.waits = self.waits + '1' # Kernel while '1' in self.waits: # Kernel pass cs = True # User del cs # User self.release() # Kernel @thread def t2(self): while True: if self.tryacquire() == '🔒': self.waits = self.waits + '2' while '2' in self.waits: pass cs = True del cs self.release() Tip: 强大的 model checker\n我们的 model checker 的原理是：对于有装饰器 thread 修饰的函数，在每条语句后添加 yield。因此我们可以轻松地实现一个原子的操作：只要将操作写成一个函数，并在一行内调用这个函数即可。再例如，xchg 原子操作在我们的 model checker 中可以很简单地写为\nx, y = y, x 线程函数中的语句\nwhile '1' in self.waits: pass 并不是内核的真正行为：内核会切换走去执行别的线程。但从这个正在等待的线程的视角，内核在做和自己无关的事等价于内核在自己这里轮询。因此我们精巧地模拟出了内核的正确行为。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"41157f258c887520eab10434fd7565d4","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec05/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec05/","section":"notes","summary":"从 high level 来看，我们希望实现如下的结构体和 API：\ntypdef struct { ... }lock; void lock(lock *lk); void unlock(lock *lk); 若 lock() 函数返回，说明获得了这个锁，别的进程会停在 lock() 里直到获得锁的人调用了 unlock()。\n实现互斥的根本困难：不能同时读写共享内存。\nload 的时候不能 store，且看完之后眼睛立刻闭上，看到的都是过去的东西； store 的时候不能 load，贴字条的时候不知道覆盖了什么。 Spin Lock “解决一个问题有两种方法：一个是分析问题、提出算法、实现解决，一个是解决提出问题的人。“ —— jyy","tags":null,"title":"Lecture 05: Concurrent Programming: Mutex","type":"docs"},{"authors":null,"categories":null,"content":"线程同步：在某个时间点共同达到互相已知的状态。(每个线程都有可能做自己的某个耗时很长的工作)\nnnpy：等我洗完头就吃饭/等我打完游戏就吃饭。 “先到先等”的同步机制。 Producer-Consumer Problem void Tproducer() {while (1) puts(\u0026quot;(\u0026quot;);} void Tconsmuer() {while (1) puts(\u0026quot;)\u0026quot;);} 我们希望生成合法的括号序列，且括号序列嵌套深度不超过给定值 $n$：\nproducer: 序列深度小于 $n$ 才能打印； consumer: 序列深度大于等于 1 才能打印。 我们可以用一个队列来维护任务池，producer 将任务放到队尾，consumer 从队头取任务。取和放的操作都要在锁的保护下进行。\n// pc.c #include \u0026quot;thread.h\u0026quot; #include \u0026quot;thread-sync.h\u0026quot; int n, count = 0; mutex_t lk = MUTEX_INIT(); void Tproduce() { while (1) { retry: mutex_lock(\u0026amp;lk); if (count == n) { mutex_unlock(\u0026amp;lk); goto retry; } count++; printf(\u0026quot;(\u0026quot;); mutex_unlock(\u0026amp;lk); } } void Tconsume() { while (1) { retry: mutex_lock(\u0026amp;lk); if (count == 0) { mutex_unlock(\u0026amp;lk); goto retry; } count--; printf(\u0026quot;)\u0026quot;); mutex_unlock(\u0026amp;lk); } } int main(int argc, char *argv[]) { assert(argc == 2); n = atoi(argv[1]); setbuf(stdout, NULL); for (int i = 0; i \u0026lt; 8; i++) { create(Tproduce); create(Tconsume); } } Tip: 如何证明这个模型是正确的？\n我们可以编写一个压力测试：\nimport sys limit = int(sys.argv[1]) count, n = 0, 100000 while True: for ch in sys.stdin.read(n): if ch == '(': count += 1 if ch == ')': count -= 1 assert 0 \u0026lt;= count \u0026lt;= limit print(f'{n} Ok.') 指定较深层次的括号，每检查 100000 个括号输出一个 OK 信息。\n我们还可以用 model checker 证明该模型的正确性：\n# pc.py class ProducerConsumer: locked, count, log, = '', 0, '' def tryacquire(self): self.locked, seen = '🔒', self.locked return seen == '' def release(self): self.locked = '' @thread def tp(self): while True: while not self.tryacquire(): pass if not self.count == 1: break self.release() self.log, self.count = self.log + '(', self.count + 1 self.release() @thread def tc1(self): while True: while not self.tryacquire(): pass if not self.count == 0: break self.release() self.log, self.count = self.log + ')', self.count - 1 self.release() @thread def tc2(self): while True: while not self.tryacquire(): pass if not self.count == 0: break self.release() self.log, self.count = self.log + ')', self.count - 1 self.release() @marker def mark_negative(self, state): count = 0 for ch in self.log: if ch == '(': count += 1 if ch == ')': count -= 1 if count \u0026lt; 0: return 'red' 使用命令 python model-checker.py pc.py | grep red 可以快速检查是否有红色节点。\nConditional Variable 轮询地等待条件成立太浪费事件了。我们希望在条件不满足的时候进入睡眠状态，然后条件可能满足的时候把我唤醒，于是有了条件变量 (注：这个思想和睡眠锁类似，但等待的对象不一样。睡眠锁等待的是空锁的出现，而条件变量是在获得锁之后，等待关键变量相关的条件可能成立的时机)。\n条件变量最基本的 API 有：\nint pthread_cond_wait(pthread_cond_t *cv, pthread_mutex_t *lk); int pthread_cond_signal(pthread_cond_t \u0026amp;cv); int pthread_cond_broadcast(ptread_cond_t \u0026amp;cv); wait() 函数传入一个条件变量和一个互斥锁，调用时要求线程持有该锁。wait() 会将这个互斥锁释放掉，然后睡眠该线程。等到有别的线程调用 signal() 或 broadcast() 来唤醒这个条件变量有关的线程时，wait() 会重新获得互斥锁，并继续执行下去。 signal() 和 broadcast() 的作用都是唤醒在条件变量 cv 上睡眠的线程。两者的不同是 signal() 只挑一个线程唤醒，broadcast() 会唤醒所有 cv 上的线程。 条件变量的正确使用方式如下：\nmutex_lock(\u0026amp;lk); while (!cond) { cond_wait(\u0026amp;cv, \u0026amp;lk); } assert(cond); // do some job. // if job is unrelated to critical variables, mutex lock can be released. /* if other threads' cv may be satisfied */ cond_broadcast(\u0026amp;cv); /* ------------------------------------- */ mutex_unlock(\u0026amp;lk); 有几点需要说明：\nwhile (!cond) 写成 if (!cond) 是一个常见的错误。比如当前有一个 Tproducer 和两个 Tconsumer，那么可能出现 Tproducer 打印完 ( 后唤醒了第一个 Tconsumer，然后第一个 Tconsumer 打印完 ) (此时已经不能再打印 ) ) 后唤醒了第二个 Tconsumer。如果是 if (!cond) ，第二个 Tconsumer 被唤醒了之后无法再进行条件检查，从而又打出一个 ) 导致错误。\n使用 while (!cond) 保证了跳出 while 循环后 cond 一定是成立的。\n使用 cond_broadcast(\u0026amp;cv) 而不是 cond_signal(\u0026amp;cv) 可以避免一些“死锁”情况，例如在没有多余的任务时，若干个 consumer 互相 signal 导致任务无法进行下去。\nTproducer 完成任务后从唤醒一个睡在 comsumer-cv 上的线程，Tconsumer 完成任务后唤醒一个睡在 producer-cv 上的线程。为什么这个模型不对？\nclass ProducerConsumer: locked, count, log, waitp, waitc = '', 0, '', '', '' def tryacquire(self): self.locked, seen = '🔒', self.locked return seen == '' def release(self): self.locked = '' @thread def tp(self): for _ in range(2): while not self.tryacquire(): pass # mutex_lock() if self.count == 1: # cond_wait _, self.waitp = self.release(), self.waitp + '1' while '1' in self.waitp: pass while not self.tryacquire(): pass self.log, self.count = self.log + '(', self.count + 1 self.waitc = self.waitc[1:] # cond_signal self.release() # mutex_unlock() @thread def tc1(self): while not self.tryacquire(): pass if self.count == 0: _, self.waitc = self.release(), self.waitc + '2' while '2' in self.waitc: pass while not self.tryacquire(): pass self.log, self.count = self.log + ')', self.count - 1 self.waitp = self.waitp[1:] self.release() @thread def tc2(self): while not self.tryacquire(): pass if self.count == 0: _, self.waitc = self.release(), self.waitc + '3' while '3' in self.waitc: pass while not self.tryacquire(): pass self.log, self.count = self.log + ')', self.count - 1 self.waitp = self.waitp[1:] self.release() 使用 model checker 对该算法进行分析。下面的这种情形会导致问题：\nTc2 首先运行，获得锁之后发现 count == 0 ，于是释放锁并睡眠在 consumer-cv 上。 Tp 运行，获得锁之后打印左括号，count += 1 ，唤醒了线程 Tc2，然后释放了锁。 Tc2 被唤醒了以后并没有获得锁，而是 Tc1 抢先获得了锁，打印了右括号，count -= 1，然后释放了锁。 Tc2 获得了锁。但此时 Tp 生产的资源已经被 Tc1 用掉了，Tc2 因为没有使用 while 判断 count，所以直接打印了右括号，count -= 1，错误发生。 只要是可以多线程的工作，都可以使用上面的模板来进行并行加速。通常来说，如果一个任务要分成若干个“层“，每”层“内的任务之间互相独立，我们就可以利用多线程加速每一层的运算 (但层与层之间的依赖关系是无法多线程加速的)。\nExample: fish 使用打印 \u0026lt; \u0026gt; 和 _ 的三个线程连续输出小鱼。鱼的形态有两种：\u0026lt;\u0026gt;\u0026lt;_ 和 \u0026gt;\u0026lt;\u0026gt;_。\n使用万能的条件变量。我们要搞清楚的事情是：这三个线程应该在什么条件下可以输出？我们画出状态机：\nstateDiagram s1: A('') s1 --\u0026gt; s2: '\u0026lt;' s1 --\u0026gt; s3: '\u0026gt;' s2: B('\u0026lt;') s3: C('\u0026gt;') s2 --\u0026gt; s4: '\u0026gt;' s4: D('\u0026lt;\u0026gt;') s3 --\u0026gt; s5: '\u0026lt;' s5: E('\u0026gt;\u0026lt;') s4 --\u0026gt; s6: '\u0026lt;' s5 --\u0026gt; s6: '\u0026gt;' s6: F('\u0026lt;\u0026gt;\u0026lt;' or '\u0026gt;\u0026lt;\u0026gt;') s6 --\u0026gt; s1: '_' 我们只要在程序中维护当前到达的状态机顶点，然后根据状态机的出边决定某个线程是否可以打印即可。还需要注意的一点是：打印 \u0026lt; \u0026gt; _ 的线程可能各有很多个。从状态机当前节点出发，只能有一个可行字符线程打印。因此还需要一个变量控制当前是否已经有线程在打印途中。\n// fish.c #include \u0026quot;thread.h\u0026quot; #include \u0026lt;string.h\u0026gt; #define LENGTH(arr) (sizeof(arr) / sizeof(arr[0])) enum { A = 1, B, C, D, E, F, }; struct rule { int from, ch, to; }; struct rule rules[] = { { A, '\u0026lt;', B }, { B, '\u0026gt;', C }, { C, '\u0026lt;', D }, { A, '\u0026gt;', E }, { E, '\u0026lt;', F }, { F, '\u0026gt;', D }, { D, '_', A }, }; int current = A, quota = 1; pthread_mutex_t lk = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t cond = PTHREAD_COND_INITIALIZER; int next(char ch) { for (int i = 0; i \u0026lt; LENGTH(rules); i++) { struct rule *rule = \u0026amp;rules[i]; if (rule-\u0026gt;from == current \u0026amp;\u0026amp; rule-\u0026gt;ch == ch) { return rule-\u0026gt;to; } } return 0; } void fish_before(char ch) { pthread_mutex_lock(\u0026amp;lk); while (!(next(ch) \u0026amp;\u0026amp; quota)) { // can proceed only if (next(ch) \u0026amp;\u0026amp; quota) pthread_cond_wait(\u0026amp;cond, \u0026amp;lk); } quota--; pthread_mutex_unlock(\u0026amp;lk); } void fish_after(char ch) { pthread_mutex_lock(\u0026amp;lk); quota++; current = next(ch); assert(current); pthread_cond_broadcast(\u0026amp;cond); pthread_mutex_unlock(\u0026amp;lk); } const char roles[] = \u0026quot;.\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;___\u0026quot;; void fish_thread(int id) { char role = roles[id]; while (1) { fish_before(role); putchar(role); // can be long; no lock protection fish_after(role); } } int main() { setbuf(stdout, NULL); for (int i = 0; i \u0026lt; strlen(roles); i++) create(fish_thread); } 这个 fish.c 写的非常漂亮。它完全复刻了状态机的思想，维护了可行的转移条件。变量 quota 保证了只有一个线程“出手”打印。\n还值得注意的一点是，putchar(role) 这个操作和控制状态机转移的关键变量 current 和 quota 无关。且 I/O 操作理论上速度较慢。这样的工作是可以放在锁外面进行的 (事实上，由于 quota 的控制，这个操作并没有起到明显的优化效果)。\n我们可以对其进行压力测试：\n# fish-check.py import sys n, count = 100000, 0 while True: animal = str(sys.stdin.read(4)) assert animal == '\u0026lt;\u0026gt;\u0026lt;_' or animal == '\u0026gt;\u0026lt;\u0026gt;_' count += 1 if count == n: print(f'{n} OK.') count = 0 Semaphore 在上述的括号打印问题中，我们使用互斥锁来保护我们对 count 变量的更新操作。一个想法是：可不可以不止一个锁，而是有 $n$ 个手环。手环数量不能超过上限，producer 可以生产手环，consumer 必须领到手环才能做事情？这种维护了“一堆手环”的锁就是信号量。\n下面的 python 代码描述了信号量的行为建模：\n# sem.py class Semaphore: token, waits = 1, '' def P(self, tid): if self.token \u0026gt; 0: self.token -= 1 return True else: self.waits = self.waits + tid return False def V(self): if self.waits: self.waits = self.waits[1:] else: self.token += 1 @thread def t1(self): self.P('1') while '1' in self.waits: pass cs = True del cs self.V() @thread def t2(self): self.P('2') while '2' in self.waits: pass cs = True del cs self.V() 变量 token 维护了资源 (手环) 的数量。P() 用于获取手环，如果当前有剩余的手环就领走，并进入临界区域；如果当前没有剩余的手环就进入等待序列。V() 用于归还手环。如果当前有正在等待的人，就直接将手环交给它 (wait list 队首元素弹出)，如果没有就归还给 kernel (token++)。\nC 语言的线程库为我们提供了信号量的相关 API:\nint sem_init(sem_t *sem, int pshared, unsigned int value); int sem_wait(sem_t *sem); int sem_post(sem_t *sem); sem_init() 用于初始化一个信号量，pshared == 0 表示该信号量只在当前进程的线程之间共享；pshared == 1 表示该信号量可以跨进程共享。value 表示信号量的初始值 (游泳馆的最大手环个数)。 sem_wait() 和 sem_post() 等价于之前的 P() 和 V()，用于领取手环和归还手环。 利用这些 API 我们可以非常轻巧地实现之前的括号打印任务：\n// pc-sem.c #include \u0026quot;thread.h\u0026quot; #include \u0026quot;thread-sync.h\u0026quot; sem_t fill, empty; void producer() { while (1) { P(\u0026amp;empty); printf(\u0026quot;(\u0026quot;); V(\u0026amp;fill); } } void consumer() { while (1) { P(\u0026amp;fill); printf(\u0026quot;)\u0026quot;); V(\u0026amp;empty); } } int main(int argc, char *argv[]) { assert(argc == 2); SEM_INIT(\u0026amp;fill, 0); SEM_INIT(\u0026amp;empty, atoi(argv[1])); for (int i = 0; i \u0026lt; 8; i++) { create(producer); create(consumer); } } 通常来说，信号量在”一单位资源“明确的情况下比较好用 (比如这里的“一单位资源”就是指一个尚未匹配的左括号)，在有些场景下使用信号量很难写出正确的并发程序。此外，信号量的 V() 函数是可以在“没有领取手环”的时候“凭空”“变出一个手环“上交的，因此使用时必须格外小心。\nDining Philosophers Problem 五个哲学家围成一桌吃饭。每两个人之间有一把叉子 (一共五把)，哲学家只有同时拿到左边和右边的叉子才能吃饭。如何维护这件事情？\n这件事情不是很好明确“一单位资源“：一把叉子既是某位哲学家的“右叉子”，又是某位哲学家的“左叉子”，如果我们对每把叉子维护一个信号量，写入如下程序：\n// philosopher.c #include \u0026quot;thread.h\u0026quot; #include \u0026quot;thread-sync.h\u0026quot; #define N 5 sem_t locks[N]; void Tphilosopher(int id) { int lhs = (N + id - 1) % N; int rhs = id % N; while (1) { P(\u0026amp;locks[lhs]); printf(\u0026quot;T%d Got %d\\n\u0026quot;, id, lhs + 1); P(\u0026amp;locks[rhs]); printf(\u0026quot;T%d Got %d\\n\u0026quot;, id, rhs + 1); V(\u0026amp;locks[lhs]); V(\u0026amp;locks[rhs]); } } int main(int argc, char *argv[]) { for (int i = 0; i \u0026lt; N; i++) { SEM_INIT(\u0026amp;locks[i], 1); } for (int i = 0; i \u0026lt; N; i++) { create(Tphilosopher); } } 运行一小会儿就会卡住。此时每个哲学家都抓着自己左手边的叉子，它们都想得到右叉子，但都得不到。因为都得不到，他们也不会放下自己手中的叉子。这就是死锁。如果把每把叉子想象成图中的节点，哲学家们对叉子的需求序列 (先要左叉子，再要右叉子) 就构成了一个环。如果锁依赖关系中有环，就可能出现死锁。\n当然我们可以用万能的条件变量来正确实现：\nmutex_lock(\u0026amp;mutex); while (!(avail[lhs] \u0026amp;\u0026amp; avail[rhs])) { wait(\u0026amp;cv, \u0026amp;mutex); } avail[lhs] = avail[rhs] = false; mutex_unlock(\u0026amp;mutex); mutex_lock(\u0026amp;mutex); avail[lhs] = avail[rhs] = true; broadcast(\u0026amp;cv); mutex_unlock(\u0026amp;mutex); 该段代码与之前相比的区别在于，哲学家总是看到左右叉子都有再同时拿起，吃完了就会放下。不会出现之前方法中的哲学家拿到一把叉子再等另一把叉子，自己手里的叉子也不给别人用的情况。\n系统中另一种常见的处理生产者-消费者模型的方法是 master-slave：我们安排一个服务员来维护所有的叉子，所有的哲学家都通过与服务员通信的方法来向服务员索要叉子/让服务员把叉子取走。\nvoid Tphilosopher(int id) { send_request(id, EAT); P(allowed[id]); // waiter 会把叉子递给哲学家 philosopher_eat(); send_request(id, DONE); } void Twaiter() { while (1) { (id, status) = receive_request(); if (status == EAT) { ... } if (status == DONE) { ... } } } ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"9ce85d4f930bd215850660c5324d03f2","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec06/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec06/","section":"notes","summary":"线程同步：在某个时间点共同达到互相已知的状态。(每个线程都有可能做自己的某个耗时很长的工作)\nnnpy：等我洗完头就吃饭/等我打完游戏就吃饭。 “先到先等”的同步机制。 Producer-Consumer Problem void Tproducer() {while (1) puts(\u0026quot;(\u0026quot;);} void Tconsmuer() {while (1) puts(\u0026quot;)\u0026quot;);} 我们希望生成合法的括号序列，且括号序列嵌套深度不超过给定值 $n$：\nproducer: 序列深度小于 $n$ 才能打印； consumer: 序列深度大于等于 1 才能打印。 我们可以用一个队列来维护任务池，producer 将任务放到队尾，consumer 从队头取任务。取和放的操作都要在锁的保护下进行。\n// pc.c #include \u0026quot;thread.","tags":null,"title":"Lecture 06: Concurrent Programming: Synchronization","type":"docs"},{"authors":null,"categories":null,"content":"High Performance Computing HPC: 解决需要 massive computation 的任务。\n基本思路：计算图会分成若干层，每层会有很多要计算的节点。将每层的任务先分配到机器，机器里再分配到线程 (两级分解)，并行计算这些节点后，用一个 \u0026ldquo;join()\u0026rdquo; 汇总一下 (涉及线程、机器、共享内存之间的通信)。\nHPC 可以实现的原因：数据的局部性。例如我们想利用 HPC 进行一团气体的运动模拟，那么我们可以将立方体容器内的气体切分成很多块，每个线程管一块。每个线程管理的气体绝大部分的运动都是本地的，我们只需要处理少部分的相邻块的气体分子交换即可。\nExample: Mandelbrot Set // mandelbrot.c #include \u0026quot;thread.h\u0026quot; #include \u0026lt;math.h\u0026gt; int NT; #define W 6400 #define H 6400 #define IMG_FILE \u0026quot;./mandelbrot.ppm\u0026quot; static inline int belongs(int x, int y, int t) { return x / (W / NT) == t; } int x[W][H]; int volatile done = 0; void display(FILE *fp, int step) { static int rnd = 1; int w = W / step, h = H / step; // STFW: Portable Pixel Map fprintf(fp, \u0026quot;P6\\n %d %d 255\\n\u0026quot;, w, h); for (int j = 0; j \u0026lt; H; j += step) { for (int i = 0; i \u0026lt; W; i += step) { int n = x[i][j]; int r = 255 * pow((n - 80) / 800.0, 3); int g = 255 * pow((n - 80) / 800.0, 0.7); int b = 255 * pow((n - 80) / 800.0, 0.5); fputc(r, fp); fputc(g, fp); fputc(b, fp); } } } void Tworker(int tid) { for (int i = 0; i \u0026lt; W; i++) for (int j = 0; j \u0026lt; H; j++) if (belongs(i, j, tid - 1)) { double a = 0, b = 0, c, d; while ((c = a * a) + (d = b * b) \u0026lt; 4 \u0026amp;\u0026amp; x[i][j]++ \u0026lt; 880) { b = 2 * a * b + j * 1024.0 / H * 8e-9 - 0.645411; a = c - d + i * 1024.0 / W * 8e-9 + 0.356888; } } done++; } void Tdisplay() { float ms = 0; while (1) { FILE *fp = popen(\u0026quot;viu -\u0026quot;, \u0026quot;w\u0026quot;); assert(fp); display(fp, W / 256); pclose(fp); if (done == NT) break; usleep(1000000 / 5); ms += 1000.0 / 5; } printf(\u0026quot;Approximate render time: %.1lfs\\n\u0026quot;, ms / 1000); FILE *fp = fopen(IMG_FILE, \u0026quot;w\u0026quot;); assert(fp); display(fp, 2); fclose(fp); } int main(int argc, char *argv[]) { assert(argc == 2); NT = atoi(argv[1]); for (int i = 0; i \u0026lt; NT; i++) { create(Tworker); } create(Tdisplay); join(); return 0; } 这段代码使用一些数学手法画出一幅清晰度很高，非常美观的分形图。代码中有一些有意思的小工具：\nTdisplay 线程中使用了 viu 命令行工具，它可以将一张图片以较低的分辨率打印在终端上，这可以在让我们看到图像生成的大致过程。我们可以看到该程序将画面切分成了多个部分，每个线程控制一个。\nTdisplay 线程最终将像素信息输出到了一个 ppm (portable pixel map) 文件中。对于 C 语言来说，这是一种非常方便的输出图像的方式：只需要在文件开头输出\nP6 W H COLOR // 宽，高，颜色数 然后一行一行地将每个点的 RGB 值输出即可。\nData Center 多副本情况下的低延迟、高可靠性问题。这其中存在一些互相矛盾的点\nAvailability - 数据在 data center 应该有多个副本，这样如果某个副本坏了，数据不会丢失。此外，为了各地地人可以快速读取，服务器会把本地城市 data center 的数据直接返回。 Consistency - ”我在南京屏蔽我妈，我妈在广州也要响应这个屏蔽。” 不能因为图快而不同步地直接读取本地副本。 Partition Tolerance 这门课的问题：如何在一台计算机上既可能高效地处理并行请求？\n我们的工具：线程、协程\n线程：可以在操作系统的调度算法下进行切换，但线程切换很“重”：需要保存上下文，需要陷入内核 (privilege level 的改变)…… 协程：更轻量级的并发 (只要遵守 calling convention，切换时不需要保存那么多寄存器，不需要进操作系统)，但只有执行 co_yield() 才会切换，如果某个线程执行了很慢的 I/O 系统调用，剩下的协程就都在摸鱼。 Goroutine Go 是一门专门服务系统编程的语言。go 支持所谓的 goroutine: 在概念上它是线程，但它是使用类似于协程的原理实现的。每个 CPU 上只有一个线程，但这个线程下有多个 goroutine，每个 CPU 上有一个 Go worker 负责调度这些 goroutine。goroutine 切换的方式和协程相似，因此非常轻量级。对于某些会导致阻塞的系统调用 (如 sleep, rand)，go 会将他们改成 non-blocking 的版本，如果需要陷入内核进行长时间操作，它就会 yield 到另一个 goroutine 执行。这样，goroutine 将操作系统和 CPU 都利用到了100%。\n// Example from \u0026quot;The Go Programming Language\u0026quot; package main import ( \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func main() { go spinner(100 * time.Millisecond) const n = 45 fibN := fib(n) // slow fmt.Printf(\u0026quot;\\rFibonacci(%d) = %d\\n\u0026quot;, n, fibN) } func spinner(delay time.Duration) { for { for _, r := range `-\\|/` { fmt.Printf(\u0026quot;\\r%c\u0026quot;, r) time.Sleep(delay) } } } func fib(x int) int { if x \u0026lt; 2 { return x } return fib(x - 1) + fib(x - 2) } 在主函数中，我们使用 go spinner 创建了一个新的 goroutine。该程序可以一边计算 Fibinacci 数列，一边在 spinner 协程中打印旋转的进度条。\n绝大部分的并发问题都可以通过生产者-消费者模型来解决。Go 语言封装了生产者-消费者队列，提供了用于 goroutines 之间通信的 API：\npackage main import \u0026quot;fmt\u0026quot; var stream = make(chan int, 10) const n = 4 func produce() { for i := 0; ; i++ { fmt.Println(\u0026quot;produce\u0026quot;, i) stream \u0026lt;- i } } func consume() { for { x := \u0026lt;-stream fmt.Println(\u0026quot;consume\u0026quot;, x) } } func main() { for i := 0; i \u0026lt; n; i++ { go produce() } consume() } make(chan int, 10) 定义了一个通道，并规定了其最大容量 (最大容量为 0 的 channel 可以用来同步)。生产者通过 stream \u0026lt;- i 往队列里面加东西，消费者通过 x := \u0026lt;-stream 从队列里面取东西。其内部的锁，睡眠等细节问题全部对程序员透明。\nWeb 2.0 在网页这种计算量、并发量都不大的场景下，我们使用的模型是单线程+事件模型。事件按照顺序执行，具有原子性 (减少了发生并发 bug 的可能)，遇到耗时的 API 就立刻返回 (结束一个事件)。\n为了代码的可维护性，描述流图的语言正在发展。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"a10ec3eb8ffc0a1b4bd5b84f6b8de638","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec07/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec07/","section":"notes","summary":"High Performance Computing HPC: 解决需要 massive computation 的任务。\n基本思路：计算图会分成若干层，每层会有很多要计算的节点。将每层的任务先分配到机器，机器里再分配到线程 (两级分解)，并行计算这些节点后，用一个 \u0026ldquo;join()\u0026rdquo; 汇总一下 (涉及线程、机器、共享内存之间的通信)。\nHPC 可以实现的原因：数据的局部性。例如我们想利用 HPC 进行一团气体的运动模拟，那么我们可以将立方体容器内的气体切分成很多块，每个线程管一块。每个线程管理的气体绝大部分的运动都是本地的，我们只需要处理少部分的相邻块的气体分子交换即可。\nExample: Mandelbrot Set // mandelbrot.c #include \u0026quot;thread.h\u0026quot; #include \u0026lt;math.h\u0026gt; int NT; #define W 6400 #define H 6400 #define IMG_FILE \u0026quot;.","tags":null,"title":"Lecture 07: Concurrent Programming: Real World","type":"docs"},{"authors":null,"categories":null,"content":"Bug 多的根本原因：软件是需求在计算机世界的投影，人类世界的很多性质在编程语言中丧失了。\nDefensive Programming 一个好的策略是添加很多的 assert()，assert() 的核心意义在于将程序的需求表达出来。\nassert() 虽然不一定能写得对，但如果 assert() 和代码出错的概率是独立的，那么写 assert() 就使得程序出错的概率降低了一个数量级。\nConcurrent Bugs Deadlock 一个中断相关的死锁\nvoid os_run() { spin_lock(\u0026amp;lk); spin_lock(\u0026amp;xxx); spin_unlock(\u0026amp;xxx); //------+ }\t// | //\t| Interrupt void on_interrupt()\t//\t| {\t//\t| spin_lock(\u0026amp;lk); // \u0026lt;-------+ ... spin_unlock(\u0026amp;lk); } 上锁的时候要关中断，且锁出现嵌套的时候，需要一个计数器来维护嵌套层数，只有完全无锁的时候才能开中断 (释放锁的时候不能莽开中断)。\nAA-deadlock：某个线程在试图获得自己已经获得的锁。这很容易检测出来。在编程的时候理应多使用如下的防御性编程：\nif (holding(lk)) panic(); ABBA-deadlock：进程在互相等待别人的锁。lock-ordering 是一种好的防御方法：系统中所有的锁必须排出一个无环的拓扑序。\nmodel checker 可以可视化地帮我们检查是否有死锁。如果某个节点所有的出边都指向自己，这就是一个陷入死锁的状态。\nData Race 两个线程在同一时间访问同一个地址，且至少有一个是写。之所以被称为“竞争”是因为运行的结果取决于“谁跑赢了”。\nAtomicity Violation (AV) \u0026amp; Order Violation (OV) TOCTTOU (time of check to time of use)：某段代码通常会检查某个条件 (time to check)，然后在认为这个条件的成立是 invariant 的情况下对其进行某种操作 (time of use)，但如果其他程序在中间插入做了某个改变 invariant 的操作，就会产生 bug。\nTIME\t/home/abc/mailbox | a symbolic link? | | | Delete /home/abc/mailbox | | | No | Create symbolic link | | ~/mailbox, pointing to | | /etc/passwd Append the new message | to /home/abc/mailbox | 在上述过程中，如果攻击者利用 TOC 和 TOU 之间的窗口期将 /home/abc/mailbox 指向某个非法的文件 (打破了 kernel 之前检查的条件)，kernel 就可能会给普通用户 root 权限。\nBugs Confrontation Lockdep 我们可以为每把锁一个全局唯一的 allocation site。在所有获得锁/释放锁的时间点记录一份日志，然后对日志进行分析 (观察上锁顺序)，如果对于某两把锁 $x,y$，我们能观测到 $x\\rightsquigarrow y\\and y\\rightsquigarrow x$，则检测出了可能的死锁。\n// lock-site.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;assert.h\u0026gt; typedef struct lock { int locked; const char *site; } lock_t; #define STRINGIFY(s) #s #define TOSTRING(s) STRINGIFY(s) #define LOCK_INIT() \\ ( (lock_t) { .locked = 0, .site = __FILE__ \u0026quot;:\u0026quot; TOSTRING(__LINE__), } ) lock_t lk1 = LOCK_INIT(); lock_t lk2 = LOCK_INIT(); void lock(lock_t *lk) { printf(\u0026quot;LOCK %s\\n\u0026quot;, lk-\u0026gt;site); } void unlock(lock_t *lk) { printf(\u0026quot;UNLOCK %s\\n\u0026quot;, lk-\u0026gt;site); } struct some_object { lock_t lock; int data; }; void object_init(struct some_object *obj) { obj-\u0026gt;lock = LOCK_INIT(); } int main() { lock(\u0026amp;lk1); lock(\u0026amp;lk2); unlock(\u0026amp;lk1); unlock(\u0026amp;lk2); struct some_object *obj = malloc(sizeof(struct some_object)); assert(obj); object_init(obj); lock(\u0026amp;obj-\u0026gt;lock); lock(\u0026amp;lk2); lock(\u0026amp;lk1); return 0; } 上面的 lock-site.c 提供了一种简单的为每个锁提供唯一 allocation site 的方法，其中的一些宏定义值得学习。\nSanitizer 运行时的动态检查。AddressSanitizer 可以检查内存访问的 bug (监控所有的内存访问)，ThreadSanitizer 可以检查数据竞争 (内存访问 + lock/unlock)，此外还有 UBSanitizer, MemorySanitizer 等。\n// uaf.c #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { int *ptr = malloc(sizeof(int)); *ptr = 1; free(ptr); *ptr = 1; } 上述程序存在 use-after-free 问题。在编译时加入 -fsanitize=address，运行程序时，我们可以得到丰富的报错信息。\nLightweight Tools Stack Canary 在栈顶和栈底设置一些存储了特殊值的内存单元 (金丝雀) 并定期检查这些单元。如果这些单元被修改了，说明发生了栈溢出。我们只需很短的代码就可以完成 stack canary：\n#define MAGIC 0x55555555 #define BOTTOM (STK_SZ / sizeof(u32) - 1) struct stack { char data[STK_SZ]; }; void canary_init(struct stack *s) { u32 *ptr = (u32 *)s; for (int i = 0; i \u0026lt; CANARY_SZ; i++) ptr[BOTTOM - i] = ptr[i] = MAGIC; } void canary_check(struct stack *s) { u32 *ptr = (u32 *)s; for (int i = 0; i \u0026lt; CANARY_SZ; i++) { panic_on(ptr[BOTTOM - i] != MAGIC, \u0026quot;underflow\u0026quot;); panic_on(ptr[i] != MAGIC, \u0026quot;overflow\u0026quot;); } } 我们有时在 windows 中会看到的 \u0026ldquo;烫烫烫\u0026rdquo; 等字，其实是 stack canary 在 GB2312 编码下的结果：\n未初始化栈: 0xcccccccc 未初始化堆: 0xcdcdcdcd 对象头尾: 0xfdfdfdfd 已回收内存: 0xdddddddd 我们可以用\n(b'\\xcc' * 80).decode('gb2312') 查看使用未初始化栈时得到的内容 (烫烫烫)。\nLightweight Lockdep 很多情况下，我们可以在自旋锁自旋次数过多的时候直接报警，然后利用 GDB 的 backtrace 功能观察是否真的发生了死锁。\nint spin_cnt = 0; while (xchg(\u0026amp;locked, 1)) { if (spin_cnt++ \u0026gt; SPIN_LIMIT) { printf(\u0026quot;Too many spin @ %s:%d\\n\u0026quot;, __FILE__, __LINE__); } } ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"12b7c556b2c42c094745e7efec9e35a3","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec08/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec08/","section":"notes","summary":"Bug 多的根本原因：软件是需求在计算机世界的投影，人类世界的很多性质在编程语言中丧失了。\nDefensive Programming 一个好的策略是添加很多的 assert()，assert() 的核心意义在于将程序的需求表达出来。\nassert() 虽然不一定能写得对，但如果 assert() 和代码出错的概率是独立的，那么写 assert() 就使得程序出错的概率降低了一个数量级。\nConcurrent Bugs Deadlock 一个中断相关的死锁\nvoid os_run() { spin_lock(\u0026amp;lk); spin_lock(\u0026amp;xxx); spin_unlock(\u0026amp;xxx); //------+ }\t// | //\t| Interrupt void on_interrupt()\t//\t| {\t//\t| spin_lock(\u0026amp;lk); // \u0026lt;-------+ .","tags":null,"title":"Lecture 08: Concurrent Bugs and Confrontation","type":"docs"},{"authors":null,"categories":null,"content":"Bare-metal \u0026amp; Software 数字电路本身就是一个巨大的状态机。硬件厂商会保证 CPU reset 后处理器处在一个确定的状态，各个单元的固定的值会写在手册中。以 x86 为例，手册规定了 CPU reset 后 rip 的值会是 0xfff0，EFLAGS 的值为 0x2，当前硬件运行在 16-bit 模式中，不响应中断。\nCPU 只是一个周而复始的取值译码执行的东西，因此它马上会做的事情就是取出 0xfff0 处的指令并执行。0xfff0 处通常是一个跳转指令，PC 会跳转到固件代码执行。固件 (Firmware) 是硬件厂商写死在一块 ROM 上的代码，常见的固件程序有 BIOS 和 UEFI 两种，后者更加现代机制更加复杂，这里简介 Legacy BIOS 的过程：\nBIOS 的主要工作是扫描各个硬盘/U盘/软盘……然后将第一个可引导的设备的第一个扇区 (512B) 加载到地址 0x7c00 处。可引导的设备的第一个扇区会遵循主引导记录 (Master Boot Record, MBR) 的格式。如果我们使用命令\ncat executable-x86_64-qemu | head -c 512 | xxd 查看一个镜像文件的前 512 个字节，我们可以看到其末尾一定是 0x55aa。这是 MBR 的结束标志。\n此时硬件仍然工作在 16-bit 模式上。规定 CS:IP=0x7c00 ，即 (R[CS]\u0026lt;\u0026lt;4) | R[IP] == 0x7c00 ，其他没有任何约束。Firmware 执行结束后，PC 跳转到 0x7c00 执行，刚刚加载过来的是 Legacy boot (boot loader)，它负责完成操作系统的加载：初始化栈和堆区，为 main() 传递参数等等。\nCode: Firmware QEMU 是一个全系统模拟器，我们可以通过 GDB 远程连接的方式来调试 QEMU，从而观测各个时刻的系统状态。\n一个启动 QEMU 并使用 GDB 监听的脚本如下：\n#!/bin/bash qemu-system-x86_64 \\ -smp 1\\ -S -s\\ -drive format=raw,file=amgame-x86_64-qemu \u0026amp; pid=$! gdb -x remote.gdb ; kill -9 $! qemu-system-x86_64 启动了一个 x86-64 架构的 QEMU 模拟器，之后的各个选项和参数的意义如下：\n-smp 1 指定了 QEMU 模拟单核 CPU。 -S 选项表示让 QEMU 停止在 CPU reset 后的第一条指令上。 -s 选项是 -gdb tcp::1234 的简写，表示在端口 1234 打开一个 gdbserver。 -drive format=raw,file=amgame-x86_64-qemu 告诉了 QEMU 用于引导的设备。这里笔者使用了 Lab0 中 amgame 的镜像。 gdb 的 -x 选项后面可以跟一个脚本，表示在启动 gdb 之后自动运行后面的脚本。笔者在脚本中只做了一行配置：\ntarget remote localhost:1234 表示连接到 gdbserver。之前我们给运行 QEMU 的进程分配了一个进程号，现在用 kill -9 $! 可以在退出 gdb 之后帮我们自动杀死 QEMU 的进程。\n运行这个脚本，我们可以看到 QEMU 停在了 CPU reset 后的初始状态。使用 i r 命令打印寄存器信息，可以看到 rip = 0xfff0，eflags = 0x2 等，符合手册的约定。此时如果使用命令 x/16xb 0x7c00 查看地址 0x7c00 附近的内存内容，可以看到全部是 0 (注：x 是打印，16 是打印 16 个 byte，x 是按照十六进制打印，b 是将各个 byte 分开)。\n0x7c00:\t0x00\t0x00\t0x00\t0x00\t0x00\t0x00\t0x00\t0x00 0x7c08:\t0x00\t0x00\t0x00\t0x00\t0x00\t0x00\t0x00\t0x00 想要监控 BIOS 的行为，我们可以用命令 wa *0x7c00 在这个地址上打一个断点，然后 continue，该地址的值出现变化时 GDB 会停下并通知我们。\n当前系统仍处于 16 位模式，因此需要用 cs 和 rip 两个寄存器来定位指令的位置。使用 x/i ($cs * 16 + $rip) 查看当前指令：\n0xfa591:\trep insl (%dx),%es:(%edi) 这是一条内存拷贝指令，刚开始可以看到 %es:(%edi) == 0x7c00 ，随着 repeat 的推进，(%edi) 的值逐渐变大。如果再查看 0x7c00 附近的内容，可以看到 MBR 正在被逐渐搬入：\n0x7c00:\t0xfa\t0x31\t0xc0\t0x8e\t0xd8\t0x8e\t0xc0\t0x8e 0x7c08:\t0xd0\t0xb8\t0x01\t0x4f\t0xb9\t0x12\t0x01\t0xbf 0x7c10:\t0x00\t0x40\t0xcd\t0x10\t0x00\t0x00\t0x00\t0x00 0x7c18:\t0x00\t0x00\t0x00\t0x00\t0x00\t0x00\t0x00\t0x00 State Machine of OS Firmware 和 boot loader 共同完成了操作系统的加载。进入 C 代码后，操作系统将完全遵循 C 语言的形式语义（当然，调用 AbstractMachine API 的部分是对 C 语言形式语义的补充）。\nAbstractMachine 对 C 程序语义的扩展主要是以下几个部分：\nTRM + MPE 完全等同于多线程。将整个系统的状态机从一条链变成多条链，之后的执行将是 non-deterministic 的。 IOE API 相当于库函数。 CTE 允许创建多个执行流。 yield() 会主动切换，中断会被动切换。 VME 创建一个“经过地址翻译的执行模式”。 整个系统的状态机大致可以看成如下过程：\nCode: AbstractMachine Unix Philosophy\nMakefile 中的变量的定义可能散落在世界各处，因此静态地读 Makefile 效果可能不好。好的方式是直接观测 Makefile 做了怎样的事情。这里提供一套命令：\nmake mainargs=HelloOS run -nB \\ | grep -ve '^\\(\\#\\|echo\\|mkdir\\|make\\)' \\ | sed \u0026quot;s#$AM_HOME#\\$AM_HOME#g\u0026quot; \\ | sed \u0026quot;s#$PWD#.#g\u0026quot; \\ | vim - make 的 -n 选项可以只输出执行的命令而不真正执行，-B 选项可以忽略已经编译好的内容从头编译。 grep 用于筛选，-v 选项表示反向筛选，-e 表示使用正则表达式匹配。 sed 可以作替换，这里将冗长的路径名替换成了短的。 vim - 命令可以将输出导入到 vim 中查看。 在 vim 中使用 :%s/ /\\r /g 可以将空格改为换行，从而提高可读性。\n通过观察 Makefile 的输出结果，我们可以看到它是如何创建镜像文件以及传输命令行参数的：\n( cat $AM_HOME/am/src/x86/qemu/boot/bootblock.o; head -c 1024 /dev/zero; cat ./build/threados-x86_64-qemu.elf ) \u0026gt; ./build/threados-x86_64-qemu bootblock.o 是主引导记录。head -c 1024 /dev/zero 取出了 1024B 的 \\0。threados-x86_64-qemu.elf 是我们之前编译、链接得到的 elf 文件。将这三者拼接起来输出到文件 threados-x86_64-qemu 中，就制作好了镜像文件。\n( echo -n HelloOS; ) | dd if=/dev/stdin of=./build/threados-x86_64-qemu bs=512 count=2 seek=1 conv=notrunc status=none 参数 HelloOS 被输出后，dd 指定 input file 为 stdin，output file 为我们刚刚制作的镜像，将参数写到了第二个扇区里 (即 MBR 后面紧跟着的扇区)。\n之前我们用 GDB 调试了固件将 MBR 加载到 0x7c00 的过程，现在我们可以继续用 GDB 调试 OS booter 的运行过程。\n没有 OS booter 的符号表怎么办？\n仔细阅读 AbstractMachine 的 Makefile，我们发现 bootblock.o 就是主引导记录，它的生成过程如下：\ngcc -static -m32 -fno-pic -g -Os -nostdlib -Ttext 0x7c00 -I$AM_HOME/am/src -o bootblock.o start.S main.c，该命令编译 am/src/x86/qemu/boot/ 目录下的 main.c 和 start.S 并链接成一个 bootblock.o。\n为了生成带有调试信息的二进制文件，我们应当加入 -g 选项。\npython genboot.py bootblock.o 对 bootblock.o 做了进一步的修改，阅读 genboot.py ：\nimport os, sys, pathlib, subprocess f = pathlib.Path(sys.argv[1]) try: objcopy = os.getenv('CROSS_COMPILE', '') + 'objcopy' data = subprocess.run( [objcopy, '-S', '-O', 'binary', '-j', '.text', f, '/dev/stdout'], capture_output=True).stdout assert len(data) \u0026lt;= 510 data += b'\\0' * (510 - len(data)) + b'\\x55\\xaa' f.write_bytes(data) except: f.unlink() raise 它的主要工作是用 objcopy 工具将 bootblock.o 中的关键内容拷贝出来，-S 选项表示丢弃重定位信息，符号信息，调试信息等不需要的内容；-j .text 表示只保留代码节。拷贝出来后在字节流的后面补上若干 0，最后加上 0x55aa，以形成一个 MBR。\n为了获得符号表，笔者做了如下修改：将第一步生成的 bootblock.o 备份一份重命名为 boot-sym.o 用于加载符号表，并在 gdb 启动时的自动化脚本中添加：\nsymbol-file /path/to/boot-sym.o 在 GDB 中打断点 wa ($rip != 0x7c00) (或者 b _start) 即可定位到 OS booter。此时机器仍然处于 16 位模式，GDB 不支持 16 位的调试，打印出来的汇编命令会出现错误。我们可以在 $AM_HOME/am/src/x86/qemu/boot/start.S 中找到对应的指令。可以看到在执行了不多的几条指令后，PC 跳转到了函数 start32。start32 执行了几条简单的指令后跳转到了 load_kernel()。(在 load_kernel() 中终于可以用 layout src 调试了)\nload_kernel() 和 nanos-lite 中的 loader() 功能类似：将 elf 文件中的各个段拷贝到内存的指定地址 0x8000，并跳转到入口函数启动内核。\nElf32_Ehdr *elf32 = (void *)0x8000; Elf64_Ehdr *elf64 = (void *)0x8000; int is_ap = boot_record()-\u0026gt;is_ap; if (!is_ap) { // load argument (string) to memory copy_from_disk((void *)MAINARG_ADDR, 1024, -1024); // load elf header to memory copy_from_disk(elf32, 4096, 0); if (elf32-\u0026gt;e_machine == EM_X86_64) { load_elf64(elf64); } else { load_elf32(elf32); } } 这段代码调用 copy_from_disk() 将 mainargs 以及 elf 文件从 disk 中拷贝出来，再调用 load_elf() 将其加载到 0x8000 位置。在执行 if 之前通过 p *elf64 查看 0x8000 附近的内容，可以看到各个字段全部为空。\n(gdb) p *elf64 $1 = {e_ident = '\\000' \u0026lt;repeats 15 times\u0026gt;, e_type = 0, e_machine = 0, e_version = 0, e_entry = 0, e_phoff = 0, e_shoff = 0, e_flags = 0, e_ehsize = 0, e_phentsize = 0, e_phnum = 0, e_shentsize = 0, e_shnum = 0, e_shstrndx = 0} static void load_program(uint32_t filesz, uint32_t memsz, uint32_t paddr, uint32_t offset) { copy_from_disk((void *)paddr, filesz, offset); char *bss = (void *)(paddr + filesz); for (uint32_t i = filesz; i != memsz; i++) { *bss++ = 0; } } static void load_elf64(Elf64_Ehdr *elf) { Elf64_Phdr *ph = (Elf64_Phdr *)((char *)elf + elf-\u0026gt;e_phoff); for (int i = 0; i \u0026lt; elf-\u0026gt;e_phnum; i++, ph++) { load_program( (uint32_t)ph-\u0026gt;p_filesz, (uint32_t)ph-\u0026gt;p_memsz, (uint32_t)ph-\u0026gt;p_paddr, (uint32_t)ph-\u0026gt;p_offset ); } } load_elf() 根据 elf 文件的 program header 调用 load_program() 将各个段加载到内存中。load_program() 中的一个小细节是：filesz 和 memsz 的差值是 elf 为 .bss 节预留的空位，根据 C 程序的约定，操作系统有义务将其填充为 0。\n执行完 load_elf() 后，再查看 0x8000 附近的内存，可以看到已经被填上了内容：\n(gdb) p *elf64 $1 = {e_ident = \u0026quot;\\177ELF\\002\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\u0026quot;, e_type = 2, e_machine = 62, e_version = 1, e_entry = 1049360, e_phoff = 64, e_shoff = 152256, e_flags = 0, e_ehsize = 64, e_phentsize = 56, e_phnum = 2, e_shentsize = 64, e_shnum = 17, e_shstrndx = 16} if (elf32-\u0026gt;e_machine == EM_X86_64) { ((void(*)())(uint32_t)elf64-\u0026gt;e_entry)(); } else { ((void(*)())(uint32_t)elf32-\u0026gt;e_entry)(); } 最后这两行，根据架构跳转到 elf 文件中 e_entry 所保存的入口函数地址。这里使用了 C 语言的技巧，将一个地址强制转换成一个函数指针并调用从而实现跳转。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"a54c71f9070283793c5b4153a2e6c04c","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec09/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec09/","section":"notes","summary":"Bare-metal \u0026amp; Software 数字电路本身就是一个巨大的状态机。硬件厂商会保证 CPU reset 后处理器处在一个确定的状态，各个单元的固定的值会写在手册中。以 x86 为例，手册规定了 CPU reset 后 rip 的值会是 0xfff0，EFLAGS 的值为 0x2，当前硬件运行在 16-bit 模式中，不响应中断。\nCPU 只是一个周而复始的取值译码执行的东西，因此它马上会做的事情就是取出 0xfff0 处的指令并执行。0xfff0 处通常是一个跳转指令，PC 会跳转到固件代码执行。固件 (Firmware) 是硬件厂商写死在一块 ROM 上的代码，常见的固件程序有 BIOS 和 UEFI 两种，后者更加现代机制更加复杂，这里简介 Legacy BIOS 的过程：","tags":null,"title":"Lecture 09: State Machine of OS","type":"docs"},{"authors":null,"categories":null,"content":"Compilers and Modern CPU 编译器的作用是将源代码状态机 $S$ 转换为二进制代码状态机 $C$：$C=Compile(S)$。只要两者的可观测行为严格一致，编译器可以随意修改指令执行的顺序，甚至修改指令内容。\n现代 CPU 本质上也是“编译器”：只要保证硬件状态机的可观测行为一致，它可以乱序执行，可以多发射，还可以将没有依赖关系的指令“并行”地执行，这就是指令级并行 (instruction level parallelism, ilp)。我们可以用一个例子感受超标量处理器 (CPI\u0026lt;1，平均每条指令所需的时钟周期小于 1) 的威力：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; #define LOOP 1000000000ul __attribute__((noinline)) void loop() { for (long i = 0; i \u0026lt; LOOP; i++) { asm volatile( \u0026quot;mov $1, %%rax;\u0026quot; \u0026quot;mov $1, %%rdi;\u0026quot; \u0026quot;mov $1, %%rsi;\u0026quot; \u0026quot;mov $1, %%rdx;\u0026quot; \u0026quot;mov $1, %%rcx;\u0026quot; \u0026quot;mov $1, %%r10;\u0026quot; \u0026quot;mov $1, %%r8;\u0026quot; \u0026quot;mov $1, %%r9;\u0026quot; :::\u0026quot;rax\u0026quot;, \u0026quot;rdi\u0026quot;, \u0026quot;rsi\u0026quot;, \u0026quot;rdx\u0026quot;, \u0026quot;rcx\u0026quot;, \u0026quot;r10\u0026quot;, \u0026quot;r8\u0026quot;, \u0026quot;r9\u0026quot;); } } int main() { clock_t st = clock(); loop(); clock_t ed = clock(); double inst = LOOP * (8 + 2) / 1000000000; double ips = inst / ((ed - st) * 1.0 / CLOCKS_PER_SEC); printf(\u0026quot;%.2lfG instructions/s\\n\u0026quot;, ips); } 该代码的逻辑是在 loop() 中执行 8 条互相没有依赖的指令。即使使用最激进的优化，一次循环至少还有更新循环变量和跳转两条指令，因此一次循环至少 10 条指令。通过计算执行时间和指令条数来估算每秒钟可以执行的指令数。\nMaybe a bug in GCC?\n如下代码理论上也可以达到相同的效果。它将变量 i 绑定到寄存器 %rbx 上，从而确保和下面 8 条指令互不冲突。\nregister volatile long i asm(\u0026quot;rbx\u0026quot;); for (long i = 0; i \u0026lt; LOOP; i++) { asm volatile( \u0026quot;mov $1, %rax;\u0026quot; \u0026quot;mov $1, %rdi;\u0026quot; \u0026quot;mov $1, %rsi;\u0026quot; \u0026quot;mov $1, %rdx;\u0026quot; \u0026quot;mov $1, %rcx;\u0026quot; \u0026quot;mov $1, %r10;\u0026quot; \u0026quot;mov $1, %r8;\u0026quot;fang shi | \u0026quot;mov $1, %r9;\u0026quot; ); } 但事实上，编译完成后使用反汇编查看，可以看到 $i$ 被绑定到了 %rax 上。\n笔者使用的计算机 CPU 型号如下：\nIntel® Core™ i7-10710U CPU @ 1.10GHz × 12 但运行该程序可以得到每秒钟能执行约 17G 条指令，CPI 远小于 1。这就是指令级并行的威力。\nTracer 我们总是希望可以在状态机执行的过程中观测状态机的行为，比如了解所有 system call 的执行时长，在某个状态停下来查看寄存器，PC 的值等等，于是我们有了 strace/gdb 等工具。\nShell 命令：strace\n在 strace 后加上 -T 选项即可看到执行某个程序过程中所有系统调用的耗时。\n我们平时使用 GDB 通常是 step/next/stepi/watchpoint，但基于状态机思想， GDB 可以实现更多炫酷的功能。比如我们可以给某个状态打快照，下次可以直接从快照状态开始执行。再比如我们可以实现反向执行。\nTime-Travel Debugging 让 GDB 实现回退的功能，最直观的想法是保存每个时刻的快照。但运行时刻太多，快照要保存的内容也太多，这样做代价太大。\n事实上，一条指令对状态机的影响很有限：它可能只能改变很少的几个寄存器的值或者几个内存地址的值。因此我们可以记录一个初始的状态机，和每条指令执行前后状态机的 diff。这样代价就小得多。想要实现回退，我们只要将增量撤销即可。\nGDB 的回退和重放功能对一些 non-deterministic 的程序的调试极其有力。比如如下的程序：\n// rdrand.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; int main() { uint64_t volatile val = 48; asm volatile (\u0026quot;rdrand %0\u0026quot;: \u0026quot;=r\u0026quot;(val)); printf(\u0026quot;rdrand returns %016lx\\n\u0026quot;, val); } rdrand 指令会生成一个随机数，从而使程序每次运行的结果无法预测。打开 GDB 后，使用 record full 命令打开记录，这样就可以在适当的时刻使用 rsi / rs 命令倒退执行，且一旦执行过一次 rdrand 之后，多次倒退回去再执行，变量 val 随机到的值都不会改变。\n注：GDB 的反向执行不是万能的。对于一些比较复杂的指令 (例如一些系统调用)，记录状态机增量比较困难，GDB 没有实现这部分功能。\nRecord \u0026amp; Replay 如果我们想要重现一个程序执行的行为，我们只需要记录 non-deterministic 的指令执行完成后的状态机状态—— deterministic 的指令是无需记录的：假设 $s_0$ 执行 10000 条确定指令后到达 $s_1$，那么我们只需要记下 $s_0$ 和 10000 即可重放这段执行。\n对于一个单线程的程序，我们需要记录的非确定事件包括系统调用，rdrand 等非确定指令等。Mozilla 的 rr 工具可以帮助我们记录并重放一个程序的执行过程。这对我们调试一些非确定程序的段错误极其有帮助。\nMozilla 的 rr 工具\n使用命令 rr record ./exec 即可记录运行程序 exec 的整个过程。使用 rr replay 命令即可重放整个过程。rr 会打开一个 GDB，我们可以自由地打断点并调试之前记录的执行过程。\nrr 工具要求 perf_event_paranoid 的值小于等于 1，可以使用命令\nsudo sysctl kernel.perf_event_paranoid=1 修改当前地 perf_event_paranoid 的值。\n对于一个单处理器的操作系统，我们需要记录的非确定事件包括 I/O 操作，中断等等。有了这些记录我们便可以重放操作系统启动和运行的全过程。\nProfiling 想要做好性能优化，我们需要知道时间花在了哪里，什么对象占用了空间……这要求我们对状态机的执行进行真实监测。但我们的监测不能太频繁，不能干扰到程序的正常工作。一个好的思路是每隔一段事件暂停程序，观察并记录状态机的信息，这样便可以得到统计意义的性能摘要。\nLinux perf 工具可以为我们提供一个程序运行的性能报告。以之前的 ilp-demo.c 为例，输入命令 perf stat ./ilp-demo，我们可以得到如下的精简报告，其中包括了上下文切换，缺页异常分支预测等多种信息：\nPerformance counter stats for './ilp-demo': 0.56 msec task-clock # 0.449 CPUs utilized 0 context-switches # 0.000 K/sec 0 cpu-migrations # 0.000 K/sec 55 page-faults # 0.098 M/sec 975,780 cycles # 1.731 GHz 751,657 instructions # 0.77 insn per cycle 146,602 branches # 260.113 M/sec 5,119 branch-misses # 3.49% of all branches 0.001255936 seconds time elapsed 0.001289000 seconds user 0.000000000 seconds sys 我们还可以使用 perf recode ./exec 和 perf report 查看详细的报告。\n实际工程中的大部分情况满足“二八定律”：80%的时间消耗在非常集中的几处代码。因此用好 profiling 工具，有的放矢进行优化才是科学的方式。\nModel Checker 我们之前使用 model checker 检查并发 bug。事实上 model checker 可以检查更多我们想要的东西。比如如下程序：\nu32 x = rdrand(); u32 y = rdrand(); if (x \u0026gt; y) if (x * x + y * y == 65) bug(); 我们想知道理论上 bug 是否可能会被触发。一个朴素的想法是对每种 x 和 y 的可能取值建立状态，但这样状态会太多，无法检查。更高效的 model checker 会将相似状态“合并”，或者引入符号计算——上述例子中，对于 rdrand()，我们可以给 x，y 赋值 uint32，if 语句的约束条件也一并写入状态机，最后调用约束求解器 (SMT Solver) 即可检查 bug 是否会被触发。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"9711f3e560299d9a889ff97bb016ac32","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec10/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec10/","section":"notes","summary":"Compilers and Modern CPU 编译器的作用是将源代码状态机 $S$ 转换为二进制代码状态机 $C$：$C=Compile(S)$。只要两者的可观测行为严格一致，编译器可以随意修改指令执行的顺序，甚至修改指令内容。\n现代 CPU 本质上也是“编译器”：只要保证硬件状态机的可观测行为一致，它可以乱序执行，可以多发射，还可以将没有依赖关系的指令“并行”地执行，这就是指令级并行 (instruction level parallelism, ilp)。我们可以用一个例子感受超标量处理器 (CPI\u0026lt;1，平均每条指令所需的时钟周期小于 1) 的威力：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; #define LOOP 1000000000ul __attribute__((noinline)) void loop() { for (long i = 0; i \u0026lt; LOOP; i++) { asm volatile( \u0026quot;mov $1, %%rax;\u0026quot; \u0026quot;mov $1, %%rdi;\u0026quot; \u0026quot;mov $1, %%rsi;\u0026quot; \u0026quot;mov $1, %%rdx;\u0026quot; \u0026quot;mov $1, %%rcx;\u0026quot; \u0026quot;mov $1, %%r10;\u0026quot; \u0026quot;mov $1, %%r8;\u0026quot; \u0026quot;mov $1, %%r9;\u0026quot; :::\u0026quot;rax\u0026quot;, \u0026quot;rdi\u0026quot;, \u0026quot;rsi\u0026quot;, \u0026quot;rdx\u0026quot;, \u0026quot;rcx\u0026quot;, \u0026quot;r10\u0026quot;, \u0026quot;r8\u0026quot;, \u0026quot;r9\u0026quot;); } } int main() { clock_t st = clock(); loop(); clock_t ed = clock(); double inst = LOOP * (8 + 2) / 1000000000; double ips = inst / ((ed - st) * 1.","tags":null,"title":"Lecture 10: Application of State Machines","type":"docs"},{"authors":null,"categories":null,"content":"在 thread-os.c 中，操作系统启动后会初始化若干个线程 (的状态机)，或者说加载若干个程序。真正的操作系统启动后会创建第一个进程。如果查看 Linux 的源码，我们可以看到：\nif (!try_to_run_init_process(\u0026quot;/sbin/init\u0026quot;) || !try_to_run_init_process(\u0026quot;/etc/init\u0026quot;) || !try_to_run_init_process(\u0026quot;/bin/init\u0026quot;) || !try_to_run_init_process(\u0026quot;/bin/sh\u0026quot;)) return 0; panic(\u0026quot;No working init found. Try passing init= option to kernel. \u0026quot; \u0026quot;See Linux Documentation/admin-guide/init.rst for guidance.\u0026quot;); 内核会按照一个特定的顺序加载“第一个程序”，如果都无法加载，Linux kernel 会直接拒绝启动。\nA Minimal Linux 我们可以在 qemu 上调试 vmlinuz 内核。如下命令会启动一个没有图形界面，128M 内存的 linux 内核：\nqemu-system-x86_64 \\ -nographic \\ -serial mon:stdio \\ -m 128 \\ -kernel vmlinuz \\ -initrd build/initramfs.cpio.gz \\ -append \u0026quot;console=ttyS0 quiet acpi=off\u0026quot; 其中 initramfs.cpio.gz 是内核启动时存放在内存中的一个很小的文件系统的镜像，它打包了如下目录结构中地 initramfs 中的内容。\n├── initramfs │ ├── bin │ │ └── busybox │ └── init ├── Makefile └── vmlinuz 启动内核后我们会得到一个 shell，当前的环境很简陋，但我们仍然可以用 /bin/busybox 命令 的方式使用一些 busybox 内置的命令，比如 ls 和 cat。\n操作系统启动的第一个进程是 init。init 是一个脚本，有一行命令：/bin/busybox sh，它启动一个 shell。我们可以试试将 /bin/busybox sh 换成 /bin/busybox echo hello：可以看到操作系统确实打印了 hello，但随即报了 kernel panic。这是因为初始进程 init 返回了。\n尽管现在的环境很简陋，但我们执行一些简单的代码就可以获得丰富的体验：\nc1=\u0026quot;arch ash base64 cat chattr chgrp chmod chown conspy cp cpio cttyhack date dd df dmesg dnsdomainname dumpkmap echo ed egrep false fatattr fdflush fgrep fsync getopt grep gunzip gzip hostname hush ionice iostat ipcalc kbd_mode kill link linux32 linux64 ln login ls lsattr lzop makemime mkdir mknod mktemp more mount mountpoint mpstat mt mv netstat nice nuke pidof ping ping6 pipe_progress printenv ps pwd reformime resume rev rm rmdir rpm run-parts scriptreplay sed setarch setpriv setserial sh sleep stat stty su sync tar touch true umount uname usleep vi watch zcat\u0026quot; c2=\u0026quot;[ [[ awk basename bc beep blkdiscard bunzip2 bzcat bzip2 cal chpst chrt chvt cksum clear cmp comm crontab cryptpw cut dc deallocvt diff dirname dos2unix dpkg dpkg-deb du dumpleases eject env envdir envuidgid expand expr factor fallocate fgconsole find flock fold free ftpget ftpput fuser groups hd head hexdump hexedit hostid id install ipcrm ipcs killall last less logger logname lpq lpr lsof lspci lsscsi lsusb lzcat lzma man md5sum mesg microcom mkfifo mkpasswd nc nl nmeter nohup nproc nsenter nslookup od openvt passwd paste patch pgrep pkill pmap printf pscan\u0026quot; c3=\u0026quot;pstree pwdx readlink realpath renice reset resize rpm2cpio runsv runsvdir rx script seq setfattr setkeycodes setsid setuidgid sha1sum sha256sum sha3sum sha512sum showkey shred shuf smemcap softlimit sort split ssl_client strings sum sv svc svok tac tail taskset tcpsvd tee telnet test tftp time timeout top tr traceroute traceroute6 truncate ts tty ttysize udhcpc6 udpsvd unexpand uniq unix2dos unlink unlzma unshare unxz unzip uptime users uudecode uuencode vlock volname w wall wc wget which who whoami whois xargs xxd xz xzcat yes\u0026quot; for cmd in $c1 $c2 $c3; do /bin/busybox ln -s /bin/busybox /bin/$cmd done mkdir -p /proc \u0026amp;\u0026amp; mount -t proc none /proc mkdir -p /sys \u0026amp;\u0026amp; mount -t sysfs none /sys export PS1='(linux) ' 现在我们可以直接使用命令不再需要加 /bin/busybox 的前缀 (得益于代码中的软链接)，我们还挂载了 procfs 和 sysfs。可以使用 ps 等命令查看进程。此外，我们可以运行任何放入到文件系统中的程序：例如之前的示例代码 minimal.S 和 logisim.c，只要是静态链接得到的可执行文件都可以在我们的 minimal Linux 中直接运行。\n这一切说明操作系统没有什么神秘的：**内核创建了第一个进程 init，然后这个进程通过各种各样的系统调用就能创造全世界。**完成一切以后操作系统将退到幕后成为一个“中断处理程序”。此外，操作系统为应用程序提供各类 API，让应用程序创建/管理进程，地址空间，文件系统等。\nfork() fork() 的含义非常简单：它会将当前进程的状态机完全复制一遍，作为当前进程的子进程。这两个进程几乎完全一样：相同的地址空间，相同的寄存器值…… (当然，进程号是不同的)，除了 fork() 的返回值在两个进程中不同：fork() 在父进程中返回子进程的进程号，在子进程中返回 0。\nFork Bomb\n状态机的复制也需要消耗一定的资源。如下的一段代码可以让 OS 崩溃：\n:() { :|:\u0026amp; };: 将其格式化后可以看出它的原理：\n:() { : | : \u0026amp; }; : bash 允许冒号作为标识符。: 这个函数的作用是用 fork 创建两个自己，用管道连接起来，然后放到后台执行。这样这个脚本就会像链式反应一样不断生成很多函数，直至系统资源耗尽。\nExample: fork-demo.c // fork-demo.c #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main() { pid_t pid1 = fork(); pid_t pid2 = fork(); pid_t pid3 = fork(); printf(\u0026quot;Hello World from (%d, %d, %d)\\n\u0026quot;, pid1, pid2, pid3); } 运行这段程序，我们可以看到所有的 8 种可能的结果：进程号是 0 / 真实值。我们可以画出状态机中的一条路径来理解这个输出 (即不考虑多个进程时程序的 non-deterministic 行为，总是挑选可以继续执行的进程号最小的进程走下一步)：\nExample: fork-printf.c // fork-printf.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/wait.h\u0026gt; int main(int argc, char *argv[]) { int n = 2; for (int i = 0; i \u0026lt; n; i++) { fork(); printf(\u0026quot;Hello\\n\u0026quot;); } for (int i = 0; i \u0026lt; n; i++) { wait(NULL); } } 从抽象的状态机的角度分析，刚开始只有一个进程，第一轮一个进程变成两个进程，并分别打印 hello；第二轮两个进程变成 4 个进程，并分别打印 hello，最后应该总共有 6 个 hello。\n运行该程序可以看到，终端上确实输出了 6 个 hello，但诡异的事情是：如果我们用管道或者重定向到文件的方式，都会得到 8 个 hello。\n./fork-printf | cat # 8个hello ./fork-printf \u0026gt; output # 8个hello ./fork-printf | wc -l # 8 这件“诡异”的事情和 printf 的缓冲区有关。我们认为 printf 的语义是立即输出给定的字符串，但 printf 为了性能考虑 (尽可能少地与 io 交互)，会设置 buffer，将要输出的内容先预留在 buffer 中，待 buffer 满了 / 进程结束时再将 buffer 中的内容一并输出。\nprintf 根据标准输出指向的文件不同会使用不同的 buffer。当 stdout 是 tty 时，printf 使用 line buffer，即遇到换行符会清空一次 buffer，所以当我们输出到终端时看到的结果是 6 个；当 stdout 是管道或者文件时，printf 使用 full buffer，只有 buffer 满了才会清空。在这种情况下，第一轮的两个进程不会输出 hello，而是会将 hello 保存在 buffer 中，第二轮两个进程变 4 个进程时，fork() 复制状态机，当然也会复制 buffer 里的内容，因此新生成的两个进程的 buffer 里自带一个 hello，再执行 printf 后，每个进程的 buffer 里都有两个 hello。进程结束时内核清空 buffer，于是 4 个进程每个打印两个 hello，最终有 8 个 hello。\n如果我们在程序开头加一句 setbuf(stdout, NULL)，指定 stdout 不使用 buffer，或者在 printf() 之后加 ffush(stdout) ，那么各种情况下我们都会得到 6 个 hello。\nTip: setbuf()\nsetbuf() 函数可以指定向某个文件输出时使用的 buffer。与之相关的还有 setvbuf() （可以用 _IONBF _IOLBF _IOFBF 制定无缓冲、行缓冲、全缓冲）等。\n使用 setbuf() 时要小心的一点是我们注册的 buffer 不能在输出流被关闭之前被释放，例如下面的程序就是错误的 (undefined behavior)：\nint main () { char buf[64]; setbuf(stdout, buf); printf(\u0026quot;Hello, world\\n\u0026quot;); return 0; } 计算机系统里没有魔法。机器永远是对的。\nexecve() execve() 的作用是重置一个状态机，运行 execve() 的参数中所写的程序。如果该系统调用执行成功，它不会返回，它后面的指令也不会被执行。结合运用 fork() 和 execve()，我们便可以创建新的状态机并运行新的程序。execve() 的声明如下：\nint execve(const char *filename, char * const argv, char * const envp); 其中 filename 为想要加载的程序，argv 为传给新程序入口函数的参数，envp 为环境变量列表。下面是一个简单的示例程序：\n// execve-demo.c #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main() { char * const argv[] = { \u0026quot;/bin/bash\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;env\u0026quot;, NULL, }; char * const envp[] = { \u0026quot;HELLO=WORLD\u0026quot;, NULL, }; execve(argv[0], argv, envp); printf(\u0026quot;Should not reach here!\\n\u0026quot;); } 它使用 execve() 执行了命令 /bin/bash -c env 来打印环境变量。运行该程序，我们可以看到我们指定的环境变量 HELLO=WORLD 被打印，且 \u0026ldquo;should not reach here\u0026rdquo; 没有被打印。\n系统中有很多有意思的环境变量。例如我们可以配置 $AM_HOME 来简写目录；bash 中的环境变量 PS1 决定了命令行提示符长什么样子；execvp()/gcc 等会根据 $PATH 中的目录一个一个去找有没有我们指定的程序 etc。我们可以 hack 这个行为：\nPATH= /bin/gcc program.c 便会看到\ngcc: fatal error: cannot execute ‘as’: execvp: No such file or directory compilation terminated. _exit() exit() 用于销毁一个状态机。_exit(int status) 会销毁当前状态机，并允许有一个返回值。子进程被销毁了会通知父进程。这其中有一些值得思考的问题，例如如果这是一个多线程程序，exit() 应当销毁当前的线程还是当前的进程？\n// exit-demo.c #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;sys/syscall.h\u0026gt; void func() { printf(\u0026quot;Goodbye, Cruel OS World!\\n\u0026quot;); } int main(int argc, char *argv[]) { atexit(func); setvbuf(stdout, NULL, _IOFBF, 1024); printf(\u0026quot;Unflushed Buffer\\n\u0026quot;); if (argc \u0026lt; 2) return EXIT_FAILURE; if (strcmp(argv[1], \u0026quot;exit\u0026quot;) == 0) exit(0); if (strcmp(argv[1], \u0026quot;_exit\u0026quot;) == 0) _exit(0); if (strcmp(argv[1], \u0026quot;__exit\u0026quot;) == 0) syscall(SYS_exit, 0); } exit-demo.c 展示了各种不同的 exit 方法行为的不同，其中 atexit() 注册了一个在 exit() 的时候会调用的函数。各种运行方式的结果如下：\n命令 执行内容 系统调用 是否调用 atexit 输出内容 ./exit-demo return EXIT_FAILURE exit_group(1) 是 func \u0026amp; buffer ./exit-demo exit exit(0) exit_group(0) 是 func \u0026amp; buffer ./exit-demo _exit _exit(0) exit_group(0) 否 无 ./exit-demo __exit syscall(SYS_exit, 0) exit(0) 否 无 注：C 程序中的 exit(0) 是 stdlib.h 中的 libc 函数。\n注：exit_group() 系统调用会终止当前进程的所有线程，而 exit() 系统调用只终止当前线程。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"0253c6034a3713d7ce44186a85eb3386","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec11/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec11/","section":"notes","summary":"在 thread-os.c 中，操作系统启动后会初始化若干个线程 (的状态机)，或者说加载若干个程序。真正的操作系统启动后会创建第一个进程。如果查看 Linux 的源码，我们可以看到：\nif (!try_to_run_init_process(\u0026quot;/sbin/init\u0026quot;) || !try_to_run_init_process(\u0026quot;/etc/init\u0026quot;) || !try_to_run_init_process(\u0026quot;/bin/init\u0026quot;) || !try_to_run_init_process(\u0026quot;/bin/sh\u0026quot;)) return 0; panic(\u0026quot;No working init found. Try passing init= option to kernel. \u0026quot; \u0026quot;See Linux Documentation/admin-guide/init.rst for guidance.","tags":null,"title":"Lecture 11: Processes in Operating Systems","type":"docs"},{"authors":null,"categories":null,"content":"Address Space 在 C 程序中，我们可以用指针访问任何可以访问的东西：比如 main() 函数的首地址，这个地址存储的内容就是 main() 的第一条指令。如果我们随便访问一个奇怪的地址，我们会得到段错误；如果我们往 main() 的首地址处写东西，我们也会得到段错误。\n命令行工具 pmap 可以帮助我们观察一个进程的地址空间。我们以最小的程序 minimal.S 为例，在 GDB 中调试时可以用 info inferiors 查看进程号，并用 pmap pid 来查看地址空间：\n0000000000400000 4K r---- a.out 0000000000401000 4K r-x-- a.out 00007ffff7ff9000 16K r---- [ anon ] 00007ffff7ffd000 8K r-x-- [ anon ] 00007ffffffde000 132K rw--- [ stack ] ffffffffff600000 4K --x-- [ anon ] total 168K 0x401000 之后的内容是代码段，这一段有可执行的权限。此外我们在栈上有环境变量，命令行参数等。\n我们可以通过 strace pmap pid 来观察 pmap 是如何实现的。可以看到 pmap 使用了 openat() 系统调用来打开 procfs 中的 /proc/pid/maps 文件。查看这个文件，我们能看到比 pmap 更丰富的地址空间信息。\nStatically Link 我们尝试查看一个静态链接的二进制文件 (空 main() 函数编译得到) 的地址空间：\n0000000000400000 4K r---- a.out 0000000000401000 560K r-x-- a.out 000000000048d000 160K r---- a.out 00000000004b5000 16K r---- a.out 00000000004b9000 12K rw--- a.out 00000000004bc000 140K rw--- [ anon ] 00007ffff7ff9000 16K r---- [ anon ] 00007ffff7ffd000 8K r-x-- [ anon ] 00007ffffffde000 132K rw--- [ stack ] ffffffffff600000 4K --x-- [ anon ] total 1052K 可以看到的地址空间的内容更加丰富。第一个段是 ELF header，后面的可读可执行段是代码段，再后面有只读数据段等等。我们可以将其和 ELF 文件的 program header 进行对比：\nProgram Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align LOAD 0x0000000000000000 0x0000000000400000 0x0000000000400000 0x0000000000000528 0x0000000000000528 R 0x1000 LOAD 0x0000000000001000 0x0000000000401000 0x0000000000401000 0x000000000008bf1d 0x000000000008bf1d R E 0x1000 LOAD 0x000000000008d000 0x000000000048d000 0x000000000048d000 0x0000000000027315 0x0000000000027315 R 0x1000 LOAD 0x00000000000b4908 0x00000000004b5908 0x00000000004b5908 0x00000000000059e8 0x00000000000072b8 RW 0x1000 可以看到地址和权限都能对应上。计算机系统的世界里没有魔法。\nDynamically Link 动态链接的结果会更复杂一些：\n555555554000-555555555000 r--p 103:0a /home/starling/a.out 555555555000-555555556000 r-xp 103:0a /home/starling/a.out 555555556000-555555557000 r--p 103:0a /home/starling/a.out 555555557000-555555558000 r--p 103:0a /home/starling/a.out 555555558000-555555559000 rw-p 103:0a /home/starling/a.out 7ffff7dbe000-7ffff7dc0000 rw-p 00:00 0 // ??? 7ffff7dc0000-7ffff7de6000 r--p 103:09 /usr/lib/x86_64-linux-gnu/libc-2.33.so 7ffff7de6000-7ffff7f51000 r-xp 103:09 /usr/lib/x86_64-linux-gnu/libc-2.33.so 7ffff7f51000-7ffff7f9d000 r--p 103:09 /usr/lib/x86_64-linux-gnu/libc-2.33.so 7ffff7f9d000-7ffff7fa0000 r--p 103:09 /usr/lib/x86_64-linux-gnu/libc-2.33.so 7ffff7fa0000-7ffff7fa3000 rw-p 103:09 /usr/lib/x86_64-linux-gnu/libc-2.33.so 7ffff7fa3000-7ffff7fae000 rw-p 00:00 0 // ??? 7ffff7fc3000-7ffff7fc7000 r--p 00:00 0 [vvar] 7ffff7fc7000-7ffff7fc9000 r-xp 00:00 0 [vdso] 7ffff7fc9000-7ffff7fca000 r--p 103:09 /usr/lib/x86_64-linux-gnu/ld-2.33.so 7ffff7fca000-7ffff7ff1000 r-xp 103:09 /usr/lib/x86_64-linux-gnu/ld-2.33.so 7ffff7ff1000-7ffff7ffb000 r--p 103:09 /usr/lib/x86_64-linux-gnu/ld-2.33.so 7ffff7ffb000-7ffff7ffd000 r--p 103:09 /usr/lib/x86_64-linux-gnu/ld-2.33.so 7ffff7ffd000-7ffff7fff000 rw-p 103:09 /usr/lib/x86_64-linux-gnu/ld-2.33.so 7ffffffde000-7ffffffff000 rw-p 00:00 0 [stack] ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0 [vsyscall] 我们看到多了很多的段，比如 libc 库的段和加载器的段。可以引起我们关注的一个问题是：有两个没有名字的东西是什么？这两个段可读可写不可执行，是否有可能是 bss 段？我们可以做实验验证这一点：\nchar ch[1 \u0026lt;\u0026lt; 30]; int main () {} 再次运行并查看，可以看到没有名字的段变大了很多。再做一次实验：\nchar ch[1 \u0026lt;\u0026lt; 30] = {1}; int main () {} 可以看到这次编译变慢了很多，生成的可执行文件非常大。查看地址空间，匿名段上方多了一个很大的段，显然是可读可写数据段，匿名段的大小很小。因此我们可以确定没有名字的段就是 bss 段。\n另外一个有意思的问题是：vvar 段和 vdso 段是什么？\n我们有时候想要执行系统调用，但又不想陷入操作系统内核 (因为这样比较耗时)，vdso 提供了这样一些不陷入内核就可以完成系统调用功能的函数。一个典型的例子是 __vdso_gettimeofday()。在使用时，我们并不需要加上 __vdso 的前缀，编译器会自动帮我们链接到 vdso 函数。下面是一个例子：\n// vdso.c #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;time.h\u0026gt; double gettime() { struct timeval t; gettimeofday(\u0026amp;t, NULL); // trapless system call return t.tv_sec + t.tv_usec / 1000000.0; } int main() { printf(\u0026quot;Time stamp: %ld\\n\u0026quot;, time(NULL)); // trapless system call double st = gettime(); sleep(1); double ed = gettime(); printf(\u0026quot;Time: %.6lfs\\n\u0026quot;, ed - st); } vdso.c 中调用了函数 time() 和 gettimeofday()，它们都不会陷入内核。我们可以用 GDB 调试它并查看汇编代码。我们发现 time() 函数的从一个奇怪的地方搬了一些数过来，这些数就构成了时间：\n0x7ffff7fc7c00 \u0026lt;time\u0026gt;: lea -0x4b87(%rip),%rax # 0x7ffff7fc3080 0x7ffff7fc7c07 \u0026lt;time+7\u0026gt;: lea -0x1b8e(%rip),%rdx # 0x7ffff7fc6080 0x7ffff7fc7c0e \u0026lt;time+14\u0026gt;: cmpl $0x7fffffff,-0x4b94(%rip) # 0x7ffff7fc3084 0x7ffff7fc7c18 \u0026lt;time+24\u0026gt;: cmove %rdx,%rax 0x7ffff7fc7c1c \u0026lt;time+28\u0026gt;: mov 0x20(%rax),%rax 0x7ffff7fc7c20 \u0026lt;time+32\u0026gt;: test %rdi,%rdi 0x7ffff7fc7c23 \u0026lt;time+35\u0026gt;: je 0x7ffff7fc7c28 \u0026lt;time+40\u0026gt; 0x7ffff7fc7c25 \u0026lt;time+37\u0026gt;: mov %rax,(%rdi) 0x7ffff7fc7c28 \u0026lt;time+40\u0026gt;: ret 如果我们在 GDB 中直接用 x 指令打印那个地址，会发现我们无权访问 (GDB 不允许我们访问另一个进程的地址空间)，但对照 /proc/pid/maps 的结果，我们可以看到 time() 函数在 vdso 段，它所抓取的数据在 vvar 段。\n7ffff7fc3000-7ffff7fc7000 r--p 00000000 00:00 0 [vvar] 7ffff7fc7000-7ffff7fc9000 r-xp 00000000 00:00 0 [vdso] 该虚拟系统调用实现的原理不太复杂：操作系统在 vvar 段维护一个大致时间的变量，每过一会儿去更新一下，系统中所有的进程都可以使用 vvar 段的数据。\nManaging Address Space 进程的地址空间不是一成不变的，在进程执行过程中可以修改。如果我们用 GDB 调试一个动态链接的程序，用 starti 让其暂停在第一条汇编指令 (此时 PC 在加载器中)，再用 pmap 查看地址空间，可以看到此时只有 .so，还没有 libc 相关的段。但执行到 main() 函数时，地址空间中有了 libc 相关的段。\n增加/删除/修改地址空间需要系统调用的支持。Linux 提供了 mmap() 系统调用添加映射，munmap() 系统调用删除映射，mprotect() 函数修改映射的权限。\nvoid *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); 手册中有对 mmap() 的详细描述，比如 addr 本身并不指定 mmap() 映射的地址，只会作为一个映射地址的参考；该函数返回的地址是实际映射的地址。有意思的一点是，mmap() 可以直接将文件中的一大块区域映射到地址空间中：事实上文件并不会被立刻搬入内存，而是在使用时才会将要使用的部分搬进来 (缺页异常)。(注：如果不想映射到文件，而只是开辟一段映射空间，可以在 flags 字段使用 MAP_ANONYMOUS，并将 fd 设置为 -1，操作系统会自动将这段填充为 0。)\n有了 mmap() 系统调用以后，操作系统的加载器变得非常好写：我们只需要根据 ELF 文件中所写的需要加载的内容一一调用 mmap() 即可。我们可以用 strace 观测一个程序加载、运行时的所有 mmap() 操作。\n有了文件映射之后，随之而来的是一系列一致性问题：进程对文件的修改是否需要立即生效？不同进程映射到同一个文件应当共享内存还是各自有本地副本？操作系统还提供了 msync() 系统调用处理同步相关的问题。这才是系统真正的复杂性。\n下面是两个 mmap() 的例子：\n// mmap-alloc.c #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #define GiB * (1024LL * 1024 * 1024) int main() { volatile uint8_t *p = mmap(NULL, 3 GiB, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0); printf(\u0026quot;mmap: %lx\\n\u0026quot;, (uintptr_t)p); if ((intptr_t)p == -1) { perror(\u0026quot;cannot map\u0026quot;); exit(1); } *(int *)(p + 1 GiB) = 114; *(int *)(p + 2 GiB) = 514; printf(\u0026quot;Read get: %d\\n\u0026quot;, *(int *)(p + 1 GiB)); printf(\u0026quot;Read get: %d\\n\u0026quot;, *(int *)(p + 2 GiB)); } 我们用 mmap() 映射了一点 3G 的内存空间，并在其中某个位置写了东西，并访问这个位置。我们可以看到虽然我们映射了很大的一块空间，但这个系统调用只用了极短的时间 (一些延迟映射相关的技术)。\n#!/usr/bin/env python3 # mmap-disk.py import mmap, hexdump with open('/dev/sda', 'rb') as fp: mm = mmap.mmap(fp.fileno(), prot=mmap.PROT_READ, length=128 \u0026lt;\u0026lt; 30) hexdump.hexdump(mm[:512]) 我们可以将整个磁盘映射到地址空间中，并打印第一个扇区的内容，可以看到结尾处标志 MBR 的 0x55aa。\nIsolation of Address Space 虚拟内存机制为我们提供了内存隔离：每个进程只能在自己的地址空间映射中做事，访问别的进程的地址会触发段错误，或者说，在本地的地址空间中根本看不到别的进程的地址。（真的吗？）\nJinshan Drifter 在访问检查不严格的程序中，其他进程有办法可以侵入，读取和修改数据。这里展示一个类似于“金山游侠”的红警外挂程序：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;stdbool.h\u0026gt; #define LENGTH(arr) (sizeof(arr) / sizeof(arr[0])) int n, fd, pid; uint64_t found[4096]; bool reset; void scan(uint16_t val) { uintptr_t start, kb; char perm[16]; FILE *fp = popen(\u0026quot;pmap -x $(pidof dosbox) | tail -n +3\u0026quot;, \u0026quot;r\u0026quot;); assert(fp); if (reset) n = 0; while (fscanf(fp, \u0026quot;%lx\u0026quot;, \u0026amp;start) == 1 \u0026amp;\u0026amp; (intptr_t)start \u0026gt; 0) { assert(fscanf(fp, \u0026quot;%ld%*ld%*ld%s%*[^\\n]s\u0026quot;, \u0026amp;kb, perm) \u0026gt;= 1); if (perm[1] != 'w') continue; uintptr_t size = kb * 1024; char *mem = malloc(size); assert(mem); assert(lseek(fd, start, SEEK_SET) != (off_t)-1); assert(read(fd, mem, size) == size); for (int i = 0; i \u0026lt; size; i += 2) { uint16_t v = *(uint16_t *)(\u0026amp;mem[i]); if (reset) { if (val == v \u0026amp;\u0026amp; n \u0026lt; LENGTH(found)) found[n++] = start + i; } else { for (int j = 0; j \u0026lt; n; j++) { if (found[j] == start + i \u0026amp;\u0026amp; v != val) found[j] = 0; } } } free(mem); } pclose(fp); int s = 0; for (int i = 0; i \u0026lt; n; i++) { if (found[i] != 0) s++; } reset = false; printf(\u0026quot;There are %d match(es).\\n\u0026quot;, s); } void overwrite(uint16_t val) { int s = 0; for (int i = 0; i \u0026lt; n; i++) if (found[i] != 0) { assert(lseek(fd, found[i], SEEK_SET) != (off_t)-1); write(fd, \u0026amp;val, 2); s++; } printf(\u0026quot;%d value(s) written.\\n\u0026quot;, s); } int main() { char buf[32]; setbuf(stdout, NULL); FILE *fp = popen(\u0026quot;pidof dosbox\u0026quot;, \u0026quot;r\u0026quot;); assert(fscanf(fp, \u0026quot;%d\u0026quot;, \u0026amp;pid) == 1); pclose(fp); sprintf(buf, \u0026quot;/proc/%d/mem\u0026quot;, pid); fd = open(buf, O_RDWR); assert(fd \u0026gt; 0); for (reset = true; !feof(stdin); ) { int val; printf(\u0026quot;(DOSBox %d) \u0026quot;, pid); if (scanf(\u0026quot;%s\u0026quot;, buf) \u0026lt;= 0) { close(fd); exit(0); } switch (buf[0]) { case 'q': close(fd); exit(0); break; case 's': scanf(\u0026quot;%d\u0026quot;, \u0026amp;val); scan(val); break; case 'w': scanf(\u0026quot;%d\u0026quot;, \u0026amp;val); overwrite(val); break; case 'r': reset = true; printf(\u0026quot;Search results reset.\\n\u0026quot;); break; } } } popen() 函数的声明如下：\nFILE *popen(const char *command, const char *type); 它的作用是创建一个管道，fork 当前进程，并执行 shell 命令 command。type 字段指示了管道的数据流向，“r\u0026quot; 表示当前进程从管道读取 command 的输出，\u0026ldquo;w\u0026rdquo; 表示当前进程通过管道向 command 输出。\nmain() 函数的主要工作是\n利用 popen() 执行命令 pidof dosbox，获得正在运行的 dosbox 进程的进程号，并用 open() 函数打开该进程下的一个文件 /proc/pid/mem，获得一个文件描述符 (open() 中的权限要设置为可读可写，因为我们既要读取游戏信息，又要修改数据)。根据 proc 的手册，我们可以通过这个文件访问该进程的地址空间信息。 不断从 stdin (控制台) 读取用户输入，对于 s val 型输入，在内存中尝试匹配所有的 val。对于 w val 型输入，将之前匹配到的所有位置改写为 val。对于 r ，重置之前的匹配结果，对于 q，退出外挂程序。 scan() 函数负责在 dosbox 的地址空间中匹配所有的 val，其具体工作是：\n利用 popen() 执行命令 pmap $(pidof dosbox) | tail -n +3，tail -n +3 可以指定从 pmap 输出结果的第 3 行开始读取。pmap 输出的第一行通常是进程号，第二行是 ELF 文件头，因此从第 3 行开始处理。 while () 循环访问 dosbox 地址空间的所有可读可写段 (游戏中值得关注的数据，例如金钱、资源，一定是可以修改的)，访问这些段中的每个地址，看其是否等于 val 并修改 found[] 数组。found[] 数组记录了上一次 reset 以来满足所有匹配结果的地址。 overwrite() 函数负责修改数据。它只要将 found[] 中所有地址处的数据改成我们想要的 val 即可。\n这个外挂需要动态使用：外挂刚开始也不知道存储金钱的地址在哪里，但我们可以不断花钱，并拿新的钱的剩余量去 scan，做若干轮之后我们就可以锁定金钱的地址。此时再修改该地址的值，便可以拥有钞能力。\nPseudo-hardware 有一些类似 \u0026ldquo;2秒17枪\u0026rdquo; 的外挂可以以人类无法达到的速度大量重复执行任务。这类外挂可以通过写一个驱动模仿假的硬件，或者利用操作系统/窗口管理器的 API 实现。\nVariable Speed Gear 变速齿轮是另外一类常见的外挂，可以调节游戏的进度 (比如加快动画播放的速度，减小延迟等)。其实现的机制通常和代码注入有关：我们需要找到类似于 gettimeofday() 等时间相关 API 的函数位置，然后改写这部分代码，让它跳转到我们自己编写的函数，这样就可以任意调节时间了。\nHooking 我们不仅可以修改数据，还可以修改代码，这就是代码注入技术 (hooking)。下面是一个简单的给程序打热补丁 (dynamic software update) 的示例：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; void foo() { printf(\u0026quot;In old function %s\\n\u0026quot;, __func__); } void foo_new() { printf(\u0026quot;In new function %s\\n\u0026quot;, __func__); } struct jmp { uint32_t opcode: 8; int32_t offset: 32; } __attribute__((packed)); #define JMP(off) ((struct jmp) { 0xe9, off - sizeof(struct jmp) }) #define PG_SIZE sysconf(_SC_PAGESIZE) static inline bool within_page(void *addr) { return (uintptr_t)addr % PG_SIZE + sizeof(struct jmp) \u0026lt;= PG_SIZE; } void DSU(void *old, void *new) { void *base = (void *)((uintptr_t)old \u0026amp; ~(PG_SIZE - 1)); size_t len = PG_SIZE * (within_page(old) ? 1 : 2); int flags = PROT_WRITE | PROT_READ | PROT_EXEC; printf(\u0026quot;Dynamically updating...\\n\u0026quot;); fflush(stdout); if (mprotect(base, len, flags) == 0) { *(struct jmp *)old = JMP((char *)new - (char *)old); // **PATCH** mprotect(base, len, flags \u0026amp; ~PROT_WRITE); } else { perror(\u0026quot;DSU fail\u0026quot;); } } int main() { foo(); DSU(foo, foo_new); foo(); } 运行这个程序，我们可以看到虽然两次调用的都是 foo()，但在执行过 DSU() 函数打补丁之后，第二次执行 foo() 其实跳转到了 foo_new() 执行。该程序的原理是改写 foo() 函数的第一条指令，在 foo 地址处写一个间接跳转指令跳到 foo_new()。为了实现这点，代码中的细节有：\n使用 mprotect() 系统调用修改 foo() 函数所在区域的权限。代码段本身是不可写的，我们要为其加上修改权限。这里的”区域“有一点微妙：如果我们要插入的跳转指令正好横跨了两个页面，则我们需要为连续两个页面开放修改权限。within_page() 函数判断了这一点。 *(struct jmp *)old = JMP((char *)new - (char *)old); 是打补丁的核心语句。JMP 宏的原理是写上一个间接跳转的操作码，然后计算两个函数地址的 delta。 Protection 防外挂的主要方法是保证控制流和数据流的完整性。事实上，大部分外挂都像是游戏程序的“调试器”：它们不断监听游戏状态并修改游戏数据/代码。我们可以对独立的进程/驱动做完整性检验，还可以拦截向本进程的 ReadProcessMemory 和 WriteProcessMemory 请求，发现后立刻拒绝执行并封号。\n其他的一些解决方法包括：从统计学的角度找出不符合规律的操作；让程序在云/沙盒中运行 (即“计算不再信任操作系统\u0026quot;)。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"501e3f1b58fbd027e1c405caa20776d6","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec12/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec12/","section":"notes","summary":"Address Space 在 C 程序中，我们可以用指针访问任何可以访问的东西：比如 main() 函数的首地址，这个地址存储的内容就是 main() 的第一条指令。如果我们随便访问一个奇怪的地址，我们会得到段错误；如果我们往 main() 的首地址处写东西，我们也会得到段错误。\n命令行工具 pmap 可以帮助我们观察一个进程的地址空间。我们以最小的程序 minimal.S 为例，在 GDB 中调试时可以用 info inferiors 查看进程号，并用 pmap pid 来查看地址空间：\n0000000000400000 4K r---- a.out 0000000000401000 4K r-x-- a.","tags":null,"title":"Lecture 12: Address Space of Processes","type":"docs"},{"authors":null,"categories":null,"content":" 我们是操作系统用户，但操作系统 API 并不是我们作为人类用户直接使用的，那么“我们”到底应该怎么使用操作系统？\nShell 我们需要一个与人类交互的程序，这就是 Shell。之所以叫做 shell，是因为它就像包裹住操作系统内核的一层“壳”：它向内使用系统调用与内核交互，向外与人类用户交互。(Shell 不一定是命令行终端！现在的图形界面也是一种 graphical shell。)\nShell 本质上是一门 “把用户指令翻译成系统调用的编程语言”。(在 CLI 时代这一点体现得更明显)\nXv6 Shell 关于 -ffreestanding\n-ffreestanding Assert that compilation targets a freestanding environment. This implies -fno-builtin. A freestanding environment is one in which the standard library may not exist, and program startup may not necessarily be at \u0026ldquo;main\u0026rdquo;. The most obvious example is an OS kernel. This is equivalent to -fno-hosted.\n以上是 man gcc 中关于 -ffreestanding 选项的说明。加上这个选项后，编译目标是一个类似于“裸机”的 freestanding 的环境。没有标准库，程序的入口不再是 main() 而是 _start()。\nsh-xv6.c 是一个零依赖的参考 xv6-riscv 实现的 shell，可以使用 -ffreestanding 选项编译到 .o 文件并直接用 ld 链接。为了实现零依赖，sh-xv6.c 做出了如下的改动：\nsh-xv6.c 将 xv6 中的系统调用换成了如下利用 x86-64 syscall 指令的內联汇编代码：\n// Minimum runtime library long syscall(int num, ...) { va_list ap; va_start(ap, num); register long a0 asm (\u0026quot;rax\u0026quot;) = num; register long a1 asm (\u0026quot;rdi\u0026quot;) = va_arg(ap, long); register long a2 asm (\u0026quot;rsi\u0026quot;) = va_arg(ap, long); register long a3 asm (\u0026quot;rdx\u0026quot;) = va_arg(ap, long); register long a4 asm (\u0026quot;r10\u0026quot;) = va_arg(ap, long); va_end(ap); asm volatile(\u0026quot;syscall\u0026quot; : \u0026quot;+r\u0026quot;(a0) : \u0026quot;r\u0026quot;(a1), \u0026quot;r\u0026quot;(a2), \u0026quot;r\u0026quot;(a3), \u0026quot;r\u0026quot;(a4) : \u0026quot;memory\u0026quot;, \u0026quot;rcx\u0026quot;, \u0026quot;r8\u0026quot;, \u0026quot;r9\u0026quot;, \u0026quot;r11\u0026quot;); return a0; } x86-64 系统调用的各个参数的安放位置可以通过 man 2 syscall 查阅。\nsh-xv6.c 将 xv6 中所有的 malloc() 替换成了如下的 zalloc()：\nstatic char mem[4096], *freem = mem; void *zalloc(size_t sz) { assert(freem + sz \u0026lt; mem + sizeof(mem)); void *ret = freem; freem += sz; return ret; } xv6 的写法中 malloc() 没有对应的 free()，这是因为命令总是在 fork 出的子进程上完成的，子进程结束时会自动释放分配的内存。因此 zalloc() 使用了一个 4KB 的数组来模拟堆区，只管分配不管释放，这样 zalloc() 的语义和 malloc() 是相同的 (注：fork() 的时候，父子进程的 mem[] 数组是互不影响的！)。\n剩余的部分和 xv6 的 sh.c 基本无异，代价解读见 Xv6 源码解读手册。\n近距离观测 sh-xv6.c 的执行过程，我们有以下两种途径：\nGDB。注意 GDB 默认追踪父进程，我们更希望关注子进程的行为，即指令执行的行为。可以通过 set follow-fork-mode set follow-exec-mode 等来修改 GDB 的追踪行为。\nstrace。为了不将 shell 的输出和 strace 的输出混起来，我们可以这样做：使用命令\nstrace -f -o /tmp/strace.log ./sh 将 strace 的输出打印到文件 /tmp/strace.log 中，-f 选项可以追踪所有子进程的系统调用。然后另开一个窗口执行\ntail -f /tmp/strace.log 其中 -f 选项会 \u0026ldquo;output appended data as the file grows\u0026rdquo; (from man tail)。配合 Tmux，我们将获得良好的 strace 观测体验。\nThe Shell Programming Language 使用 shell 本质上就是在编程。我们组合各种指令来完成复杂的任务。shell 提供基于文本替换的快速工作流的搭建：\n重定向：cmd \u0026gt; /dev/null 顺序结构：cmd1 ; cmd2 (两者都执行)，cmd1 \u0026amp;\u0026amp; cmd2 (前者返回值为 0 才继续执行后者)，cmd1 || cmd2 (前者返回值为 1 才继续执行后者) etc. 管道：cmd1 | cmd2 预处理：$() (将一个命令的输出作为另一个命令的参数)，\u0026lt;() (将一个命令的输出重定向到一个文件，返回文件描述符作为另一个命令的参数) etc. 环境变量 现代 GUI 能完成的事情绝大多数 CLI 也能完成，比如在图形界面中，我们通过点\u0026quot;叉\u0026quot; “最小化” 来管理前后台任务，窗口。在 CLI 中我们也有 job control。在执行命令时，我们可以在后面加上 \u0026amp; 使其在后台执行；对于一个正在前台运行的程序，我们可以通过 ctrl+z 将其暂时挂起，用 bg %num 将指定进程放到后台执行；对于在后台运行的程序，我们可以用 fg %num 将其拉到前台执行。\nUNIX shell 在自然语言、机器语言和1970s算力之间达到了一个优雅的平衡。但平衡意味着 UNIX shell 的设计也不是完美的。例如操作的优先级：\nls \u0026gt; a.txt | cat 重定向和管道的优先级谁高？使用不同的 shell会得到不同的结果。(bash 不会打印到终端，zsh 会打印到终端 etc.)\n再例如文件名中的空格会带来很大的危险：如果使用命令 vim \u0026quot;a b.txt\u0026quot;，事实上我们连续打开了 a 和 b.txt，这与我们的预期不同。这本质上是因为空格具有二义性：它有可能是分隔指令的符号。(Windows 的 powershell 有 object stream pipe，在管道中传递的东西不再是文本而是对象，这使得所有的东西都是 strongly typed 的，可以避免上述问题。)\n再比如，有些行为的意义可能是难以理解的：\necho hello \u0026gt; /etc/a.txt 无法执行，shell 会返回 permission denied。这时我们本能地在前面加上 sudo：\nsudo echo hello \u0026gt; /etc/a.txt 却发现仍然是 permission denied。联想 xv6-shell 中解析命令的机制，我们就不难理解这个问题的原因。shell 完成重定向输出的方法是：关闭 stdout 文件，打开 /etc/a.txt 文件 (其文件描述符绑定为 1)，然后执行左边的指令。也就是说，sudo 只修饰了左边的执行，打开文件的过程没有获得高权限，所以报错。\nTTY and Job Control 我们还有一些疑问：例如没有任何程序在读键盘输入的情况下为什么 Ctrl+C 可以退出程序？为什么在有些应用 (e.g. vim) 中 Ctrl+C 不能退出？如果当前程序 fork 出了多个进程，Ctrl+C 会退出所有程序吗？Tmux 为什么能管理多个窗口？\n答案是终端。终端是 UNIX 操作系统中的一类非常特别的设备。命令行中有工具 tty 可以查看连接到标准输入的终端文件名。如果我们在 Tmux 的不同窗口中使用 tty 命令，可以看到不同的窗口连接到了不同的终端设备。我们甚至可以做一些有趣的事情：在一个窗口中 echo hello \u0026gt; /dev/pts/other，hello 将显示在另一个窗口中。\n为什么 fork-printf.c 可以根据标准输出对象的不同选择不同的 buffer mode？\n通过 strace 观察，可以看到程序使用了 fstat() 系统调用查看 1 号文件 (标准输出) 的信息。在有重定向的版本的系统调用序列中，ioctl() 系统调用返回了 ENOTTY。\nSession, Process Group and Signal Ctrl+C 为什么能退出？\n简单来说，我们的终端负责识别 Ctrl+C 的按键组合，并给前台进程发送一个 SIGINT 信号。前台程序有自由决定如何处理这个 SIGINT 信号，绝大部分的程序会在接收到 SIGINT 信号后退出，但我们也可以自己写一个 signal handler：\n// signal-handler.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; void handler(int signum) { switch (signum) { case SIGINT: printf(\u0026quot;Received SIGINT!\\n\u0026quot;); break; case SIGQUIT: printf(\u0026quot;Received SIGQUIT!\\n\u0026quot;); exit(0); break; } } void cleanup() { printf(\u0026quot;atexit() cleanup\\n\u0026quot;); } int main() { signal(SIGINT, handler); signal(SIGQUIT, handler); atexit(cleanup); while (1) { char buf[4096]; int nread = read(STDIN_FILENO, buf, sizeof(buf)); buf[nread - 1] = '\\0'; printf(\u0026quot;[%d] Got: %s\\n\u0026quot;, getpid(), buf); if (nread \u0026lt; 0) { perror(\u0026quot;read\u0026quot;); exit(1); } sleep(1); } } 上面的程序为 SIGINT 和 SIGQUIT 两个信号注册了处理函数。运行该程序，我们发现按下 Ctrl+C 时程序不会退出，而是输出 Received SIGINT!。\n这时有一个更有意思的问题：如果我们在 main() 函数开头执行一个 fork()，那么父子进程的标准输入和输出会连向同一个 tty，这时按下 Ctrl+C 终端会将 SIGINT 发送给哪个进程呢？经过实验我们发现：fork() 以后的 signal-handler.c 在输入字符时，两个进程会争抢输入数据，呈现各打印了一部分内容的现象；如果按下 Ctrl+C，会出现两个 Received SIGINT!。这说明 SIGINT 信号同时发送给了这两个进程。\n阅读 setpgid() 的手册，我们可以看到更系统的解读：\n当我们打开一个 shell 时，我们就创建了一个会话 (session)，这个会话有一个 controlling terminal。一个会话里面可以有若干个进程组 (process group) (注：shell 本身也是一个进程组，通常称为 session leader)，一个进程 fork() 得到的子进程和父进程同属一个进程组，execve() 不会改变一个进程所属的进程组。在任何时刻，一个会话里有且仅有一个前台 (foreground) 进程组，剩余的进程组都是后台进程组。当终端给会话发送一个信号时，前台进程组里的每个进程都会接收到这个信号。只有前台进程组中的进程可以从终端读取数据，如果后台进程尝试从终端读取数据，会接收到一个 SIGTTIN 信号，该信号会将后台进程挂起。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"51f4789da767c900277c2c1efabf126f","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec13/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec13/","section":"notes","summary":"我们是操作系统用户，但操作系统 API 并不是我们作为人类用户直接使用的，那么“我们”到底应该怎么使用操作系统？\nShell 我们需要一个与人类交互的程序，这就是 Shell。之所以叫做 shell，是因为它就像包裹住操作系统内核的一层“壳”：它向内使用系统调用与内核交互，向外与人类用户交互。(Shell 不一定是命令行终端！现在的图形界面也是一种 graphical shell。)\nShell 本质上是一门 “把用户指令翻译成系统调用的编程语言”。(在 CLI 时代这一点体现得更明显)\nXv6 Shell 关于 -ffreestanding\n-ffreestanding Assert that compilation targets a freestanding environment. This implies -fno-builtin.","tags":null,"title":"Lecture 13: System Calls and UNIX Shell","type":"docs"},{"authors":null,"categories":null,"content":"sh-xv6.c 可以在 freestanding 的环境下直接运行：我们最终使用 ld sh-xv6.o -o sh 生成二进制文件，这意味着二进制文件中有且仅有 sh-xv6.o 中的函数。\n我们平时在编写程序的时候显然不希望在 freestanding 的环境下编程——联想我们在 sh-xv6.c 中，读取字符串都要用內联汇编的系统调用，这太糟糕了。我们自然而然地希望有一些封装好的库函数可以使用。\nLibc: Overview Portability 在 freestanding 环境下我们也有一些库可以使用。如果我们想写出可移植性强的代码，我们应该使用 libc 中提供的数据类型：\n比如我们要保存一个指针的值，瞎猜一个 int long 不是好的选择，我们应该用 intptr_t (该类型在 stdint.h 中定义)；比如我们想保存一个 4 字节的数据，应该使用 int32_t。(long 的长度是随架构变化的) 等等。\nC 语言支持边长参数。例如 printf() 的声明是：\nint printf(const char *format, ...); 在 x86 架构中，参数是一个接着一个放在栈上的，因此在一些 i386 的代码中我们可能会看见下面的这种写法：\nvoid **p = (void *)\u0026amp;fmt; // use p[i] to get the address of the ith argument 但 riscv64, x86-64 等架构是用寄存器传递参数的。为了写出可移植性更好的代码，我们应该使用 va_list 类型，然后用 va_start() va_arg() va_end() 等 API 去访问各个参数 (该类型在 stdarg.h 中定义)。\n使用 libc 一定高效吗?\n不一定。GCC 的遗留问题使得使用 libc 编译出的汇编代码可能会“很笨”。例如 sh-xv6.c 中关于系统调用的这段代码：\nlong syscall(int num, ...) { va_list ap; va_start(ap, num); register long a0 asm (\u0026quot;rax\u0026quot;) = num; register long a1 asm (\u0026quot;rdi\u0026quot;) = va_arg(ap, long); register long a2 asm (\u0026quot;rsi\u0026quot;) = va_arg(ap, long); register long a3 asm (\u0026quot;rdx\u0026quot;) = va_arg(ap, long); register long a4 asm (\u0026quot;r10\u0026quot;) = va_arg(ap, long); va_end(ap); asm volatile(\u0026quot;syscall\u0026quot; : \u0026quot;+r\u0026quot;(a0) : \u0026quot;r\u0026quot;(a1), \u0026quot;r\u0026quot;(a2), \u0026quot;r\u0026quot;(a3), \u0026quot;r\u0026quot;(a4) : \u0026quot;memory\u0026quot;, \u0026quot;rcx\u0026quot;, \u0026quot;r8\u0026quot;, \u0026quot;r9\u0026quot;, \u0026quot;r11\u0026quot;); return a0; } 如果我们分别为 1,2,3,4 个参数的系统调用写 4 个接口，像下面这样：\nlong syscall4(long num, long a1, long a2, long a3, long a4) { long a0 = num; asm volatile(\u0026quot;syscall\u0026quot; : \u0026quot;+r\u0026quot;(a0) : \u0026quot;r\u0026quot;(a1), \u0026quot;r\u0026quot;(a2), \u0026quot;r\u0026quot;(a3), \u0026quot;r\u0026quot;(a4) : \u0026quot;memory\u0026quot;, \u0026quot;rcx\u0026quot;, \u0026quot;r8\u0026quot;, \u0026quot;r9\u0026quot;, \u0026quot;r11\u0026quot;); return a0; } 观察两者在 -O2 优化下反汇编的结果，可以看到前者在寄存器和栈上来回倒腾数据，而后者只用了很少的代码就完成了工作。\nprintf() 的模式串中也涉及可移植性的问题。比如我们可能常常这么写程序：\nint64_t a = 1; printf(\u0026quot;%ld\\n\u0026quot;, a); 但 %ld 是用于打印一个 long 长度的变量的，long 的长度随架构变化而变化，上述代码在 32 位的架构上就会报 warning。inttypes.h 其实为模式串的可移植性也设计了一套符号 (但很复杂)。\nConvenience 并不是所有的系统调用都像 fork() 那样简单易用，因此库函数有义务将系统调用封装成更易用的样子，比如：\nextern char **environ; char *argv[] = {\u0026quot;echo\u0026quot;, \u0026quot;hello\u0026quot;, \u0026quot;world\u0026quot;, NULL, }; if (execve(argv[0], argc, environ) \u0026lt; 0) perror(\u0026quot;exec\u0026quot;); 运行上述程序，我们会得到 exec: No such file or directory。这是因为 execve() 要求第一个参数必须是完整的 pathname。一些高情商的 API 是这样封装的：\nexeclp(\u0026quot;echo\u0026quot;, \u0026quot;echo\u0026quot;, \u0026quot;hello\u0026quot;, \u0026quot;world\u0026quot;, NULL); system(\u0026quot;echo hello world\u0026quot;); exec() 家族的库函数有很多：\nl 系列的函数支持变长参数，我们不用单独开一个参数数组 argv[] 而可以直接把要传的参数放进去。与之相对地，v 系列的函数将参数保存好以后，将 argv[] 放到函数中即可，这对于多次使用同样参数很有利。 p 系列的参数在第一个 pathname 中没有 / 的情况下，会遍历 PATH 环境变量中的所有路径，将其接在文件名前面并尝试 execve()。 e 系列可以不使用系统环境默认的环境变量，而是传入一个 envp[] 数组指定环境变量 (非 e 系列的函数默认以 extern char *environ[] 的内容作为环境变量)。 更多的内容可以查看手册。\nEncapsulation: Calculation 纯计算的工作是我们大量使用并想要封装的，比如统计字符串的长度、给一段内存赋值等等。这看上去是非常简单的事情，但如果考虑到效率，安全性等因素，事情就变得复杂了。比如如下一段 memset 的实现：\nvodi *memset(void *s, int c, size_t n) { for (size_t i = 0; i \u0026lt; n; i++) ((char *)s)[i] = c; return s; } 如果有多个线程调用该程序，它能保证安全性吗？数据会互相覆盖吗？我们可以先用 libc 标准的 memset() 来测试一下多线程下的表现：\n// memset-race.c#include \u0026quot;thread.h\u0026quot;char buf[1 \u0026lt;\u0026lt; 30];void foo(int id) { memset(buf, '0' + id, sizeof(buf) - 1);}int main() { for (int i = 0; i \u0026lt; 4; i++) create(foo); join(); puts(buf);} 多个线程同时对一段内存赋值，这是一个标准的数据竞争。运行这段程序我们可以看到 1,2,3,4 都有被输出。根据标准，标准库只对“标准库内部数据”的线程安全性负责 (比如 printf 的 buffer 是有锁保护的)，对外部数据库函数没有义务处理数据竞争。\n除此之外，封装的“好用”也是我们的一大目标。我们可以对比 C 语言的排序函数和 C++ 的排序函数：\nvoid qsort(void *base, size_t nmemb, size_t size, int (*compar)(const void *, const void *)); sort(xs.begin(), xs.end(), [](auto \u0026amp;a, auto *b) {...}); 可以看到 C++ 的库函数明显更好用：我们可以直接用迭代器的 begin 和 end，还可以用 lambda 表达式把比较函数直接写在 sort() 里面。\nEncapsulation: File Descriptors 操作系统有义务封装对象 (比如终端，管道，文件 etc.) 并暴露合适的 API 给应用程序。由于 UNIX 秉持 everything is a file 的哲学，所以封装对象的核心就是文件描述符。\n考虑如下程序：\nint main () { FILE *fp = fopen(\u0026quot;a.txt\u0026quot;, \u0026quot;w\u0026quot;); fprintf(fp, \u0026quot;Hello, world\\n\u0026quot;); return 0;} 它会向 a.txt 输出 Hello, world。这里的文件指针事实上指向的就是文件结构体。我们可以尝试用 GDB 调试这段代码，用 p *fp 打印 fp 指针指向的内容：\n{_flags = -72539004, _IO_read_ptr = 0x0, _IO_read_end = 0x0, _IO_read_base = 0x0, _IO_write_base = 0x0, _IO_write_ptr = 0x0, _IO_write_end = 0x0, _IO_buf_base = 0x0, _IO_buf_end = 0x0, _IO_save_base = 0x0, _IO_backup_base = 0x0, _IO_save_end = 0x0, _markers = 0x0, _chain = 0x7ffff7fa15e0 \u0026lt;_IO_2_1_stderr_\u0026gt;, _fileno = 3, _flags2 = 0, _old_offset = 0, _cur_column = 0, _vtable_offset = 0 '\\000', _shortbuf = \u0026quot;\u0026quot;, _lock = 0x555555559380, _offset = -1, _codecvt = 0x0, _wide_data = 0x555555559390, _freeres_list = 0x0, _freeres_buf = 0x0, __pad5 = 0, _mode = 0, _unused2 = '\\000' \u0026lt;repeats 19 times\u0026gt;} 可以看到这是一个文件描述符为 3 的文件。如果我们用 p *stdin/*stdout/*stderr 打印，也可以看到类似的内容，标准输入/输出/错误都是文件。\n另一个有意思的 API 是 popen()，它可以打开一个管道。这其实是一个设计的有缺陷的 API：手册中明确提到 UNIX pipe 是单向的：它有一个读口和一个写口，而文件指针 FILE * 只能封装一个文件描述符，所以使用 popen() 必须指定从管道读还是写向管道。(现代的编程语言对管道 API 封装的更好。)\nEncapsulation: Utilities err 为什么 cat nonexist.c gcc nonexist.c 等命令输出的都是 \u0026ldquo;xxx: nonexist.c: No such file or directory\u0026rdquo;?\n我们也可以用库函数山寨一个类似的版本：\n// err-message.c#include \u0026lt;err.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;int main (){\tconst char *filename = \u0026quot;nonexist.c\u0026quot;;\tFILE *fp = fopen(filename, \u0026quot;r\u0026quot;);\tif (!fp) warn(\u0026quot;%s\u0026quot;, filename);\treturn 0;} err.h errno.h 提供若干这样将错误信息输出到标准错误的函数，好用的函数还有 perror()，err() 等。err() 可以在输出错误信息后直接退出程序，如：\nfd = open(filename, O_RONLY, 0);if (fd == -1) err(EXIT_FAILURE, \u0026quot;%s\u0026quot;, filename); 这些函数的原理是根据全局变量 errno 的数值，打印上一次错误的原因。手册中对于 errno 的解释为：\nerrno is defined by the ISO C standard to be a modifiable lvalue of type int, and must not be explicitly declared; errno may be a macro. errno is thread-local; setting it in one thread does not affect its value in any other thread.\n值得注意的一点是 errno 是线程独享的 thread-local 变量。从这里我们可以看到协程相对于线程更轻量级体现在何处。\nenviron // env.c#include \u0026lt;stdio.h\u0026gt;int main() { extern char **environ; for (char **env = environ; *env; env++) { printf(\u0026quot;%s\\n\u0026quot;, *env); }} C 库函数为我们提供了一个指针 environ，通过它我们可以找到环境变量列表。一个自然的问题是：这个指针是什么时候指向正确的位置的？\n我们可能认为在 CPU reset 到 boot 完成期间 environ 就被设置好了，但考虑到一个程序的环境变量是在 execve() 的时候传进去的，不同程序可以不一样，这个变量显然应该是在进程加载启动时才设置的。\n我们可以用 GDB 观测这个行为。在静态加载下，用 gdb ./env 启动上述程序并用 starti 停在第一条汇编指令，查看 p (char **)environ ，发现此时 environ 还是空指针。我们可以在 environ 上加监视点 wa (char **)environ ，即可看到在 __libc_start_main() 函数中修改了 environ。\n为什么我动态链接时无法查看 environ 的信息？\nEncapsulation: Address Space libc 为我们封装好了地址空间。我们可以通过 mmaps() 修改地址空间映射，也可以通过 malloc() 和 free() 从堆区里申请/释放空间。\n想要优化 malloc()/free() 的性能，我们要对 workload 有正确的假设。指导思想：$O(n)$ 大小的对象分配后至少有 $\\Omega(n)$ 的读写操作，否则就是 performance bug。\n越小的对象创建/分配越频繁 (e.g. 字符串，临时对象等，生存周期不长) 较为频繁地分配中等大小对象 (e.g. 复杂的对象，较大的数组) 低频率的大对象 (e.g. 巨大的容器，分配器；很长的生存周期) 核心优化思想：Fast path + slow path，争取在 fast path 上做到 $O(1)$ (无锁或无 contention)。计算机系统的世界中处处是 fast path + slow path，比如 memory hierarchy。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"f6a8b4fb882c353ae5d94e04c59b1986","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec14/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec14/","section":"notes","summary":"sh-xv6.c 可以在 freestanding 的环境下直接运行：我们最终使用 ld sh-xv6.o -o sh 生成二进制文件，这意味着二进制文件中有且仅有 sh-xv6.o 中的函数。\n我们平时在编写程序的时候显然不希望在 freestanding 的环境下编程——联想我们在 sh-xv6.c 中，读取字符串都要用內联汇编的系统调用，这太糟糕了。我们自然而然地希望有一些封装好的库函数可以使用。\nLibc: Overview Portability 在 freestanding 环境下我们也有一些库可以使用。如果我们想写出可移植性强的代码，我们应该使用 libc 中提供的数据类型：\n比如我们要保存一个指针的值，瞎猜一个 int long 不是好的选择，我们应该用 intptr_t (该类型在 stdint.","tags":null,"title":"Lecture 14: C Library","type":"docs"},{"authors":null,"categories":null,"content":"fork() Semantics fork() 的语义是将当前进程的状态机完整地复制一份，这两个进程除了 fork() 的返回值以外全部相同。\nFile Descriptors 我们这里关注文件描述符：根据 fork() 的语义，子进程和父进程会拥有相同的文件描述符 (文件描述符可以理解为指向操作系统对象的指针)。execve() 会重置状态机，但会继承原进程持有的所有操作系统对象。这个设计使我们在 UNIX shell 中可以利用管道技术，在 execve() 之前修改 stdin, stdout 以完成进程之间数据的传输。\nexecve() 会无条件继承所有的对象吗？\n在 open() 的手册中，我们可以看到打开文件时有一个标志是 O_CLOEXEC，这样打开的文件在 execve() 的时候不会被继承。\n文件描述符其实不仅仅是指向对象的指针。我们在一个程序中写两句话\nwrite(fd, \u0026quot;Hello\u0026quot;, 5); write(fd, \u0026quot;World\u0026quot;, 5); 我们得到的会是 \u0026ldquo;HelloWorld\u0026rdquo; 而不是 \u0026ldquo;World\u0026rdquo;，这说明文件描述符中还保存了一个对象当前的 offset。那么一个自然的问题是：如果我们 fork 出一个子线程，然后父子线程分别打印 Hello 和 World，我们会得到两个字符串还是一个字符串呢？我们可以写一个程序验证一下：\n// fork-fd.c #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;wait.h\u0026gt; int main () { int fd = open(\u0026quot;a.txt\u0026quot;, O_RDWR | O_CREAT | O_TRUNC); int rt = fork(); if (rt == 0) write(fd, \u0026quot;World\u0026quot;, 5); else write(fd, \u0026quot;Hello\u0026quot;, 5); wait(NULL); if (rt == 0) write(fd, \u0026quot;\\n\u0026quot;, 1); return 0; } 该程序会输出 \u0026ldquo;HelloWorld\u0026rdquo; (或者 \u0026ldquo;WorldHello\u0026rdquo;)，而不是只有五个字符。这说明 fork 之后的两个进程后续仍然是共享文件偏移的。这样的设计显然符合一个“正常“的程序员的需求。查阅 dup() 系统调用的手册，我们可以看到 dup() 获得的新文件描述符和被复制的文件描述符也是共享文件偏移的。\n共享偏移对操作系统内核提出了较强的挑战。内核必须非常小心，保证对文件描述符的操作是原子的 (在 man 2 write 中可以看到 Linux 内核关于 file offset 的 bug 在内核 3.14 版本中才得到修复)。\nCopy-on-write Fork fork() 的语义是完整复制了状态机，但在实现层面，现代内核并不是立即复制所有的数据。fork() 有大量的场景都是为了启动一个新程序，即 fork() + execve() 的组合，这种情况下我们复制完的地址空间会立刻被新的程序镜像覆盖，复制工作就很浪费。\n现代内核普遍使用 copy-on-write fork (写时拷贝) 技术，即 fork() 时子进程完整复制父进程的页表，两者指向相同的页面，并暂时将页面的写权限去掉。这样之后如果父子进程读取数据，两者可以并行不悖。如果某个进程需要写数据，会因为没有写权限触发 page fault，内核的 page fault handler 发现这是一个 cow 页面，便会现场复制一个新的页面，让父子进程指向不同的页面，并把写权限恢复。\ncow fork 在实现层面还有一些细节，比如每个页面需要维护一个 reference count，之后对一个页面 malloc() 和 free() 的语义要做出一些修改，以及根据 ISA 确定如何在页表项中添加 cow 页面标志位等等。\n我们可以通过一个小程序感受 Linux 内核的 copy-on-write fork：\n// cow-test.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;string.h\u0026gt; #define NPROC 1000 #define MB 128 #define SIZE (MB * (1 \u0026lt;\u0026lt; 20)) #define xstr(s) str(s) #define str(s) #s int main() { char *data = malloc(SIZE); // 128MB shared memory memset(data, '_', SIZE); for (int i = 0; i \u0026lt; NPROC - 1; i++) { if (fork() == 0) break; } // NPROC processes go here asm volatile(\u0026quot;.fill 1048576 * \u0026quot; xstr(MB) \u0026quot;, 1, 0x90\u0026quot;); // 128MB shared code unsigned int idx = 0; int fd = open(\u0026quot;/dev/urandom\u0026quot;, O_RDONLY); assert(fd \u0026gt; 0); read(fd, \u0026amp;idx, sizeof(idx)); close(fd); idx %= 1048576 * MB; data[idx] = '.'; printf(\u0026quot;pid = %d, write data[%u]\\n\u0026quot;, getpid(), idx); while (1) { sleep(1); // not terminate } } 在 cow-test.c 中，我们用 fork() 创建了 1000 个子进程，每个进程都有一个大小为 128M 的代码区 (都是 nop 指令)，每个进程还会随机挑选一个位置进行修改。编译后，我们的可执行文件大小就在 128M 左右。如果内核使用普通的 fork，这个程序运行到一半就会因内存不足而崩溃。但事实上 Linux 运行的很好。这证明了 Linux 中使用了 cow fork 策略。\ncow fork 策略的一个推论便是：想要统计一个程序运行时占用的内存空间是一个伪命题 (比如操作系统里的 libc 代码只有一份，不知道有多少程序的页表指向了它)。\nState Machine, fork() and Magic fork() 可以完整复制状态机，这可以帮助我们完成很多炫酷的事情，比如开平行宇宙做 non-deterministic 的事情。\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;sys/wait.h\u0026gt; #define DEST '+' #define EMPTY '.' struct move { int x, y, ch; } moves[] = { { 0, 1, '\u0026gt;' }, { 1, 0, 'v' }, { 0, -1, '\u0026lt;' }, { -1, 0, '^' }, }; char map[][512] = { \u0026quot;#######\u0026quot;, \u0026quot;#.#.#+#\u0026quot;, \u0026quot;#.....#\u0026quot;, \u0026quot;#.....#\u0026quot;, \u0026quot;#...#.#\u0026quot;, \u0026quot;#######\u0026quot;, \u0026quot;\u0026quot;, }; void display(); void dfs(int x, int y) { if (map[x][y] == DEST) { display(); } else { int nfork = 0; for (struct move *m = moves; m \u0026lt; moves + 4; m++) { int x1 = x + m-\u0026gt;x, y1 = y + m-\u0026gt;y; if (map[x1][y1] == DEST || map[x1][y1] == EMPTY) { int pid = fork(); assert(pid \u0026gt;= 0); if (pid == 0) { // map[][] copied map[x][y] = m-\u0026gt;ch; dfs(x1, y1); exit(0); // clobbered map[][] discarded } else { nfork++; waitpid(pid, NULL, 0); // wait here to serialize the search } } } while (nfork--) wait(NULL); } } int main() { dfs(1, 1); } void display() { for (int i = 0; ; i++) { for (const char *s = map[i]; *s; s++) { switch (*s) { case EMPTY: printf(\u0026quot; \u0026quot;); break; case DEST : printf(\u0026quot; ○ \u0026quot;); break; case '\u0026gt;' : printf(\u0026quot; → \u0026quot;); break; case '\u0026lt;' : printf(\u0026quot; ← \u0026quot;); break; case '^' : printf(\u0026quot; ↑ \u0026quot;); break; case 'v' : printf(\u0026quot; ↓ \u0026quot;); break; default : printf(\u0026quot;▇▇▇\u0026quot;); break; } } printf(\u0026quot;\\n\u0026quot;); if (strlen(map[i]) == 0) break; } fflush(stdout); sleep(1); // to see the effect of parallel search } dfs-fork.c 是一个走迷宫程序，不同于基本的 dfs 走迷宫，它的 dfs() 函数中每发现一个新的路，便会 fork 一个新的进程去做它，结尾处的 sleep(1) 用于模拟一个耗时很长的任务。现在的 dfs-fork.c 还不能做到并行，因为 dfs 函数中当前进程会 wait 一个分支的子进程结束才会探索下一个分支。但我们如果把 dfs 循环内的 wait 去掉，就可以观测到程序“秒”完成任务。\nfork() 相较于搜索-回溯还有一个好处：当我们探索一个分支失败时，我们不用一步一步撤回去，而是可以直接销毁当前进程，然后从之前保存的副本出发搜索新的分支。\nParallel Universe: Skipping Initialization 以 NEMU 举例，我们可能需要运行很多个 benchmark，但 NEMU 的初始化过程很长，我们能不能只进行一次初始化，然后让多个 benchmark 共享这一次初始化呢？\nint main() { nemu_init(); while (1) { file = get_start_request(); if ((pid = fork()) == 0) { load_file(); ... } } } 上面一段 C 代码大致实现了我们的想法。我们在 init() 结束后，每次 fork 一个子进程做一个 benchmark，就可以让多个 benchmark 共享初始化刚结束时的状态机了。\n类似的思想在实际中也有广泛应用：\nZygote Process：zygote 是受精卵的意思，这是 Android 里的一个机制。Java 程序启动需要加载很多的 class node，这个过程很慢，但事实上现在的 Android app 基本都是秒起的。这是因为 Android 的一个 zygote process 完成所有的初始化工作，然后每开一个 app 直接在 zygote process 的基础上 fork，设置一些权限、用户 id 之后很快就可以开始执行 app 代码。 Chrome site isolation：Chrome 的每个标签页都是一个独立的进程，这其中也有共享初始化资源的技术，这让 chrome 的速度变得很快。 …… Parallel Universe: Backup and Fault-tolerence 有了平行宇宙，我们就有了犯错的底气：我们可以时不时地对状态机 fork，如果某个时刻程序 crash 了，我们就恢复最近一次保存的状态机副本；如果到了下一个存档点仍然没有 crash，我们在 fork 出新的存档的同时可以把上一份存档销毁。\n平行宇宙还可以为我们提供容错机制：比如有一些并发 bug 触发的概率很小。那么如果某一次不幸地触发了并发 bug，我们可以利用存档点回到过去，然后再跑一遍，说不定就绕过了 bug 可以继续执行了。\nA fork() in the Road 将状态机完整地复制一遍在早期是一件轻量级的事情，但现在随着系统中的机制越来越丰富，fork() 要做的事情越来越繁重：信号、线程、ptrace 等等。fork() 的语义也变得越来越复杂。比如：\n有了信号机制后，当操作系统给进程发送信号时，子进程是否也接收到这个信号？答案是子进程也会接收到信号，这就设计了 process group 等一系列概念。 当线程加入后，fork 是把当前进程的所有线程复制，还是只复制执行 fork 的线程？答案是后者。 …… POSIX 给出的一个更安全的创建子进程的 API 是 posix_spawn()：\nint posix_spawn(pid_t *pid, const char *path, const posix_spawn_file_actions_t *file_actions, const posix_spawnattr_t *attrp, char *const argv[], char *const envp[]); 它有相当复杂的参数。这是一个非常明显的 fork 后时代设计的 API，它打包执行 fork 和 execve，将执行过程分为 fork, pre-exec 和 exec 三个阶段，并在 pre-exec 阶段对 signal handler, file action 等东西做一系列设置。\nA fork() in the Road 一文中提出了 fork() 的七宗罪：\nFork is no longer simple - 要考虑的机制越来越多； Fork doesn’t compose - 比如 fork-printf.c，将标准库中 buffer 的内容复制很可能不是程序员的初衷； Fork isn’t thread-safe Fork is insecure - fork() 出的子进程和父进程地址空间完全相同，打破了 ASLR； Fork is slow Fork doesn’t scale Fork encourages memory overcommit ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"7c67e5e45d68e6bc544a903cc48be8be","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec15/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec15/","section":"notes","summary":"fork() Semantics fork() 的语义是将当前进程的状态机完整地复制一份，这两个进程除了 fork() 的返回值以外全部相同。\nFile Descriptors 我们这里关注文件描述符：根据 fork() 的语义，子进程和父进程会拥有相同的文件描述符 (文件描述符可以理解为指向操作系统对象的指针)。execve() 会重置状态机，但会继承原进程持有的所有操作系统对象。这个设计使我们在 UNIX shell 中可以利用管道技术，在 execve() 之前修改 stdin, stdout 以完成进程之间数据的传输。\nexecve() 会无条件继承所有的对象吗？\n在 open() 的手册中，我们可以看到打开文件时有一个标志是 O_CLOEXEC，这样打开的文件在 execve() 的时候不会被继承。\n文件描述符其实不仅仅是指向对象的指针。我们在一个程序中写两句话","tags":null,"title":"Lecture 15: More about fork()","type":"docs"},{"authors":null,"categories":null,"content":" 本节课默认只有静态链接。\nOverview 可执行文件的本质描述状态机初始状态 (数据) 和迁移 (指令) 的数据结构：可执行文件在 execve() 的时候使用，操作系统根据可执行文件的描述设置状态机并开始执行。\n更具体地说，可执行文件是一个描述了状态机初始状态的数据结构。状态机的初始状态一般包括以下几个方面：\n寄存器：大部分寄存器的值由 ABI 规定 (比如哪些寄存器应该清零)，由操作系统负责设置。但也有一些重要的寄存器的值是可执行文件指定的，比如 PC 的值。 地址空间 (内存)：由二进制文件和 ABI 共同决定，比如某一段数据应该放到内存中的哪里，以及 argv, envp 的内容。 其他有用的信息 (比如调试信息) 什么样的文件可以被执行？\n一个文件需要满足若干条件才能被执行。假设我们有源代码 a.c，直接执行它 (./a.c) 会获得 Permission denied (bash)，即使我们用 chmod +x a.c 给其加上了执行权限，仍然不能正常执行。\n决定一个文件是否能执行的是 execve() 系统调用。我们可以用 strace 追踪加载 a.c 的过程。如果 a.c 没有被赋予可执行权限，我们得到的是 EACCES (Permission denied)\nexecve(\u0026quot;./a.c\u0026quot;, [\u0026quot;./a.c\u0026quot;], 0x7fff24451760 /* 66 vars */) = -1 EACCES (Permission denied) strace: exec: Permission denied +++ exited with 1 +++ 如果我们给 a.c 赋予执行权限，得到的则是 ENOEXEC (目标文件的格式不是可识别的可执行文件格式)。\nexecve(\u0026quot;./a.c\u0026quot;, [\u0026quot;./a.c\u0026quot;], 0x7ffe24eca680 /* 66 vars */) = -1 ENOEXEC (Exec format error) strace: exec: Exec format error +++ exited with 1 +++ 这时我们再阅读 execve() 的手册的 ERROR 部分，就会有更好的理解。手册告诉我们 EACCES 类型的错误不只是因为缺少执行权限，也可能是因为对象不是正常的文件类型，比如 strace /dev/null 也会得到 EACCES。除了 EACCES 和 ENOEXEC 还有更多的错误类型，比如 E2BIG 表示参数/环境变量列表太长，ENOMEM 表示内核的内存空间不足等。\nCommon Executable File Formats Executable file 就是操作系统中的一个普通的对象。\nWindows 中使用的是 PE 格式 (Portable Executable)。\nUNIX/Linux 默认的可执行文件格式是 ELF (Executable Linkable Format)，但 UNIX/Linux 还支持 She-bang 格式的文件 (即文件开头有 #! 的文件)。比如我们可以在一个 .c 文件中书写\n#!/bin/python3 print('Hello') 给它加上执行权限后它便可以用 python 解释器运行下面的代码并输出 Hello。更神奇的是 She-bang 后面还可以跟我们自己写的程序，例如我们书写下面的两个程序：\n// args.c int main (int argc, char *argv[]) { for (int i = 0; i \u0026lt; argc; i++) { printf(\u0026quot;argv[%d] = %s\\n\u0026quot;, i, argv[i]); } return 0; } #!./args 第二个程序随便是什么类型 (不妨给其命名 she-bang)。将第一个 C 程序编译出可执行文件 args 后，给第二个文件加上可执行权限后，输入 ./she-bang ，便可得到\nargv[0] = ./args argv[1] = ./she-bang 其实 she-bang 的原理可以理解为一个偷换参数的 execve()：我们在输入命令 ./file 的时候，本来传给 execve() 的参数是 \u0026ldquo;./file\u0026rdquo;，但如果 file 文件的开头是 she-bang：\n#!intepreter [optional-args] 那么相当于给 execve() 传入了参数 \u0026ldquo;intepreter\u0026rdquo;, \u0026ldquo;[optional-args]\u0026rdquo;, \u0026ldquo;file\u0026rdquo;。这部分在 execve() 的手册中也有叙述。\n关于 optional args 的有趣现象\n我们即使在 she-bang 后跟多个空格分开的单词，也只能传一个参数。这是一个 UNIX 的历史遗留问题。比如我们将刚才的 she-bang 修改为\n#!./args Hello OS World 则输出结果为\nargv[0] = ./args argv[1] = Hello OS World argv[2] = ./she-bang 为什么我使用 strace ./she-bang 观测，但没有看到显式的 “偷梁换柱” 现象？\n在 linux kernel 的源码中，execve() 会调用 do_open_execat(\u0026quot;./she-bang\u0026quot;)，里面有一个函数是 loadelf，有一个函数是 loadscript，在 load_script() 中，内核有权限打开一个文件并检查器开头是不是 #!，如果是就会把后面的解释器路径读出来，然后递归地调用 do_open_execat(\u0026quot;./args\u0026quot;)。因此这个“偷梁换柱”的过程是在 execve() 内部完成的。\nParsing Executable File GNU binutils 提供了一系列与二进制文件打交道的工具。这些工具的本质都是查看/修改数据结构中的内容。\nDebugging Information // segfault.c #include \u0026lt;stddef.h\u0026gt; void bar() { *(int *)NULL = 1; } void foo() { bar(); } int main() { foo(); } 上述程序对一个空指针解引用，显然会发生段错误。如果我们用 GDB 调试，我们可以抓到出错的行。使用 backtrace / where 还可以打印出完整的函数调用序列，以及每个函数对应到源代码的行数：\n(gdb) where #0 bar () at segfault.c:4 #1 0x0000555555555151 in foo () at segfault.c:8 #2 0x0000555555555166 in main () at segfault.c:12 我们还可以感受 addr2line 工具的威力：在可执行文件 segfault 中找到 foo() 函数对应的地址 ADDR，然后输入\naddr2line ADDR segfault 便可以得到该地址对应到源代码 segfault.c 中的行号：\n~/os-demo/Lecture16/segfault.c:7 我们针对二进制文件操作，却可以得到源代码相关的信息，这是因为我们的二进制文件中保留了调试信息 (当然，如果我们编译的时候不带 -g 选项，使用 GDB backtrace 的时候就无法定位到源文件行号)。如果我们用 readelf -S file 查看可执行文件 file 的 section header table，可以看到有 debug info 等节，这就是调试信息。\n现在调试信息采用的标准是 DWARF debugging standard。调试信息可以理解为将 assembly (机器状态) 映射到 \u0026ldquo;C语言世界\u0026rdquo; 状态的函数。我们 C 语言的形式语义是状态机之间的转移 (high level 的状态机，比如栈帧，行号等)，编译器的工作是将其翻译成汇编指令，汇编指令描述了更底层的状态机的转移 (memory, register etc.)，调试信息的作用就是将一个底层的状态机状态映射到 C 语言世界的一个状态机状态。\n编译器的“摆烂”\n将机器状态映射到 C 语言状态是一件很困难的事情。比如我们可能有函数內联，这让 backtrace 变得困难；再比如比较激进的编译优化会在语义不变的前提下改写汇编程序而不是逐句翻译，这使得有些汇编状态其实根本找不到对应的 C 语言状态。因此，我们在调试时经常碰到各种各样不正确的调试信息，以及一些明明可以打印，却被摆烂的 \u0026lt;optimized out\u0026gt;。\n// popcount.c #include \u0026lt;stdio.h\u0026gt; __attribute__((noinline)) int popcount(int x) { int s = 0; int b0 = (x \u0026gt;\u0026gt; 0) \u0026amp; 1; s += b0; int b1 = (x \u0026gt;\u0026gt; 1) \u0026amp; 1; s += b1; int b2 = (x \u0026gt;\u0026gt; 2) \u0026amp; 1; s += b2; int b3 = (x \u0026gt;\u0026gt; 3) \u0026amp; 1; s += b3; return s; } int main() { printf(\u0026quot;%d\\n\u0026quot;, popcount(0b1101)); } popcount.c 可以正确地打印出一个数二进制表示中有多少个 1。但如果我们用 GDB 调试，在不开 O2 的情况下，我们刚进入 popcount() 时 p x 会发现 GDB 输出了不正确的值 0。在开 O2 的情况下，我们运行到 popcount() 的 ret 时，会发现变量 s 被 optimized out 了，但 %eax 的值 3 是正确的……这都是错误或不得当的调试信息。\nExample: Stack Unwinding 这些功能其实并不神秘，利用 x86 架构的栈帧结构，我们也可以实现一个简易的 stack unwinding：\n// unwind.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; const char *binary; struct frame { struct frame *next; // push %rbp void *addr; // call f (pushed retaddr) }; void backtrace() { struct frame *f; char cmd[1024]; extern char end; asm volatile (\u0026quot;movq %%rbp, %0\u0026quot; : \u0026quot;=g\u0026quot;(f)); for (; f-\u0026gt;addr \u0026lt; (void *)\u0026amp;end; f = f-\u0026gt;next) { printf(\u0026quot;%016lx \u0026quot;, (long)f-\u0026gt;addr); fflush(stdout); sprintf(cmd, \u0026quot;addr2line -e %s %p\u0026quot;, binary, f-\u0026gt;addr); system(cmd); } } void bar() { backtrace(); } void foo() { bar(); } int main(int argc, char *argv[]) { binary = argv[0]; foo(); } 运行代码 (不开优化)，我们确实可以得到一个完整的函数调用链：\n000000000040199e /home/starling/os-demo/Lecture16/unwind.c:26 00000000004019b3 /home/starling/os-demo/Lecture16/unwind.c:30 00000000004019e1 /home/starling/os-demo/Lecture16/unwind.c:34 00000000004039b2 ??:? backtrace() 函数的实现原理很简单：我们默认该程序运行在 x86 架构上，x86 架构在调用一个函数时总是使用 call 指令，call 指令会向栈中写入返回地址，然后 PC 跳转到目标函数的第一条指令。目标函数的前两条指令一定是\npush %rbp mov %rsp, %rbp 执行完了以后，栈上的内容为返回地址和旧 rbp 值，现在的 rbp 寄存器指向存储旧 rbp 值的地址。因此我们只要不断向前寻找 rbp 值，就可以实现栈帧的回溯，每次找 rbp 值上一个 8 字节区域的内容，就能找到返回地址，利用 addr2line 对这个返回地址定位，就能找到调用当前函数的 caller。\n上述示例代码使用一个 struct frame 结构比较精巧地完成了这件事，它刚开始用一句內联汇编把 %rbp 的值放到了 f 中，f 的结构为\nstruct frame { struct frame *next; void *addr; } 这样 next 存储的正好是旧 rbp，addr 存储的正好是当前函数的返回地址 (栈是从上往下生长的)。end 变量记录了代码段的结束位置，回溯到 end 之上就可以结束了。\nGDB 的强大\n如果我们使用 O2 优化，示例代码将不能正常工作，因为这些函数都被內联了，我们只能看到一层调用。但如果用 GDB 的 backtrace，我们仍然可以看到完整的函数调用链——这个调用过程是 GDB 虚构出来的正确信息。\nLinking and Relocation // hello.c void hello() {} // main.c void hello(); int f(int a, int b) {return a + b;} int main () { hello(); } 上述两个文件分别编译成可重定位文件后，最后链接在一起就可以执行。我们关心 main.c 到底是如何找到外部的 hello() 函数的地址的。如果我们查看 main.o 的代码段信息：\n0000000000000000 \u0026lt;f\u0026gt;: 0: f3 0f 1e fa endbr64 4: 8d 04 37 lea (%rdi,%rsi,1),%eax 7: c3 ret 0000000000000000 \u0026lt;main\u0026gt;: 0: f3 0f 1e fa endbr64 4: 48 83 ec 08 sub $0x8,%rsp 8: 31 c0 xor %eax,%eax a: e8 00 00 00 00 call f \u0026lt;main+0xf\u0026gt; f: 31 c0 xor %eax,%eax 11: 48 83 c4 08 add $0x8,%rsp 15: c3 ret 会看到像 f() 这样完全确定的函数编译器已经完全生成好了代码，编译器还没有填的是 call 后面的地址偏移，因为链接之前它不知道 hello() 在哪里，因此只能暂时填 0 摆烂。\n链接结束后 main() 在 0xb 处填写的 offset 应该满足下面的 assertion：\n// hello.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;assert.h\u0026gt; void main(); void hello() { void *p = (void *)main + 0xa + 1; int32_t offset = *((int32_t *)p); assert((char *)main + 0xf + offset == (char *)hello); } (注：开始跳转的地址是 main +0xf 是因为 x86 的 call 指令是从下一条指令的地址开始跳转的。)\n为了满足这个 assertion，我们容易计算出要填写的 offset 应该满足 $S+A-P$ 的格式，其中 $S$ 是目标函数的地址 (在这里是 (void *)hello)，$A$ 是一个偏移量，(在这里是 $-4$)，$P$ 是下一条指令的地址 (在这里是 (void *)main + 0xb)。如果我们用 readelf 查看 main.o 的重定位表，可以看到\nOffset Info Type Sym. Value Sym. Name + Addend 00000000000b 000c00000004 R_X86_64_PLT32 0000000000000000 hello - 4 这里的 \u0026ldquo;Offset\u0026rdquo; 就是 $P$，\u0026ldquo;Addend\u0026rdquo; 就是 $A$，\u0026ldquo;Sym\u0026rdquo; 就是 $S$。\n因此，通俗来说，\n编译器 (gcc) 就是将 high-level semantics (C 语言) 转换成 low-level semantics (汇编)。 汇编器 (as) 就是将 low-level semantics 转换成 binary semantics (状态机容器)，这个部分几乎是一一对应地翻译，对于暂时没法填的要留下重定位信息，重定位信息本质上就是对填写内容的 assertion。 链接器 (ld) 负责合并所有容器，得到一个完整的状态机，除了我们指定的 .o 文件外，链接器还会将一些 C Runtime Objects 链接进来。找不到符号/重复强符号的错误也是在链接阶段报出。 在这种理解下，我们很容易设计一个自己的“简易二进制文件格式“：\nstruct executable { uint32_t entry; struct segment *segments; struct reloc *relocs; struct symbol *symbols; }; struct segment {uint32_t flags, size; char data[0];} struct reloc {uint32_t S, A, P; const char *name;} struct symbol {uint32_t offset, const char *name;} 随着各种需求的加入，我们就会慢慢理解 ELF 中各种信息设置的含义。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"aedffb6d8a985102aeafceef65c7cb72","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec16/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec16/","section":"notes","summary":"本节课默认只有静态链接。\nOverview 可执行文件的本质描述状态机初始状态 (数据) 和迁移 (指令) 的数据结构：可执行文件在 execve() 的时候使用，操作系统根据可执行文件的描述设置状态机并开始执行。\n更具体地说，可执行文件是一个描述了状态机初始状态的数据结构。状态机的初始状态一般包括以下几个方面：\n寄存器：大部分寄存器的值由 ABI 规定 (比如哪些寄存器应该清零)，由操作系统负责设置。但也有一些重要的寄存器的值是可执行文件指定的，比如 PC 的值。 地址空间 (内存)：由二进制文件和 ABI 共同决定，比如某一段数据应该放到内存中的哪里，以及 argv, envp 的内容。 其他有用的信息 (比如调试信息) 什么样的文件可以被执行？\n一个文件需要满足若干条件才能被执行。假设我们有源代码 a.c，直接执行它 (./a.c) 会获得 Permission denied (bash)，即使我们用 chmod +x a.","tags":null,"title":"Lecture 16: Executable Files","type":"docs"},{"authors":null,"categories":null,"content":"Static Loader Loader on OS 可执行文件是一个描述了状态机的初始状态的数据结构。加载器根据可执行文件的描述设置好初始状态机。我们很容易写一个静态加载器：\n// loader-static.c #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;elf.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #define STK_SZ (1 \u0026lt;\u0026lt; 20) #define ROUND(x, align) (void *)(((uintptr_t)x) \u0026amp; ~(align - 1)) #define MOD(x, align) (((uintptr_t)x) \u0026amp; (align - 1)) #define push(sp, T, ...) ({ *((T*)sp) = (T)__VA_ARGS__; sp = (void *)((uintptr_t)(sp) + sizeof(T)); }) void execve_(const char *file, char *argv[], char *envp[]) { // WARNING: This execve_ does not free process resources. int fd = open(file, O_RDONLY); assert(fd \u0026gt; 0); Elf64_Ehdr *h = mmap(NULL, 4096, PROT_READ, MAP_PRIVATE, fd, 0); assert(h != (void *)-1); assert(h-\u0026gt;e_type == ET_EXEC \u0026amp;\u0026amp; h-\u0026gt;e_machine == EM_X86_64); Elf64_Phdr *pht = (Elf64_Phdr *)((char *)h + h-\u0026gt;e_phoff); for (int i = 0; i \u0026lt; h-\u0026gt;e_phnum; i++) { Elf64_Phdr *p = \u0026amp;pht[i]; if (p-\u0026gt;p_type == PT_LOAD) { int prot = 0; if (p-\u0026gt;p_flags \u0026amp; PF_R) prot |= PROT_READ; if (p-\u0026gt;p_flags \u0026amp; PF_W) prot |= PROT_WRITE; if (p-\u0026gt;p_flags \u0026amp; PF_X) prot |= PROT_EXEC; void *ret = mmap( ROUND(p-\u0026gt;p_vaddr, p-\u0026gt;p_align), // addr, rounded to ALIGN p-\u0026gt;p_memsz + MOD(p-\u0026gt;p_vaddr, p-\u0026gt;p_align), // length prot, // protection MAP_PRIVATE | MAP_FIXED, // flags, private \u0026amp; strict fd, // file descriptor (uintptr_t)ROUND(p-\u0026gt;p_offset, p-\u0026gt;p_align)); // offset assert(ret != (void *)-1); memset((void *)(p-\u0026gt;p_vaddr + p-\u0026gt;p_filesz), 0, p-\u0026gt;p_memsz - p-\u0026gt;p_filesz); } } close(fd); static char stack[STK_SZ], rnd[16]; void *sp = ROUND(stack + sizeof(stack) - 4096, 16); void *sp_exec = sp; int argc = 0; // argc while (argv[argc]) argc++; push(sp, intptr_t, argc); // argv[], NULL-terminate for (int i = 0; i \u0026lt;= argc; i++) push(sp, intptr_t, argv[i]); // envp[], NULL-terminate for (; *envp; envp++) { if (!strchr(*envp, '_')) // remove some verbose ones push(sp, intptr_t, *envp); } // auxv[], AT_NULL-terminate push(sp, intptr_t, 0); push(sp, Elf64_auxv_t, { .a_type = AT_RANDOM, .a_un.a_val = (uintptr_t)rnd } ); push(sp, Elf64_auxv_t, { .a_type = AT_NULL } ); asm volatile( \u0026quot;mov $0, %%rdx;\u0026quot; // required by ABI \u0026quot;mov %0, %%rsp;\u0026quot; \u0026quot;jmp *%1\u0026quot; : : \u0026quot;a\u0026quot;(sp_exec), \u0026quot;b\u0026quot;(h-\u0026gt;e_entry)); } int main(int argc, char *argv[], char *envp[]) { if (argc \u0026lt; 2) { fprintf(stderr, \u0026quot;Usage: %s file [args...]\\n\u0026quot;, argv[0]); exit(1); } execve_(argv[1], argv + 1, envp); } 编译好 loader-static.c 后，使用命令 ./loader ELF文件名 可以正确地加载并执行一个静态链接的 ELF 文件。我们可以用 strace 证明我们并没有在 loader 中使用 execve() 系统调用，但我们实现了 execve() 的功能。\n我们来仔细阅读这份代码：main() 函数的 execve_() 实现了 execve() 系统调用的功能。不过这个 execve_() 是我们自己实现的。execve_() 主要做了以下这些事：\nexecve_() 获得的参数，file 是要打开的文件名，argv[] 和 envp[] 是参数列表和环境变量列表。我们打开文件并读出 ELF 文件头，对其进行一系列检查 (比如架构是否正确，类型是否是 EXEC 等)。\n将要加载的段加载到内存中。我们遍历 ELF 文件的程序头表，将那些标有 PT_LOAD 的段加载到指定位置 (即 p-\u0026gt;p_vaddr)。我们使用 mmap() 来完成“加载”，它的本质是将地址空间中的一段区域映射到文件中。这里有一些比较琐碎的细节，比如在使用了 MAP_FIXED 标志后，我们必须保证传给 mmap 的地址是对齐的，因此需要 ROUND()，对齐后我们加载的长度也相应要增加，因此有了第二行的 MOD()。\n关于 MAP_FIXED\n通常情况下，传给 mmap() 的第一个参数 addr 内核只是将其当作一个 hint，内核会尽量将要加载的内容放到 addr 附近，但不给出任何保证。但如果使用了 MAP_FIXED 标志，内核会将要加载的内容确定地放到 addr 位置，这种情况下，addr 要保证对齐。\nMAP_FIXED 标志一定要非常小心地使用，在不同的操作系统，内核版本，libc 版本下进程的地址空间布局可能有很大的差异，MAP_FIXED 会使程序的可移植性下降。\n还有一个小细节是：我们要将 [p-\u0026gt;p_filesz, p-\u0026gt;p_memsz) .bss 节的部分清零。\n为程序准备一个运行时栈，这里我们直接开了 1 MiB 的数组作为栈，并保存了 argc 的地址待会传给 stack pointer (我们为各种参数准备了 4KiB 的空间)。接下来我们要将 argv[]，envp[]，aux[] 等放到栈上，这些内容都可以在 System V ABI Figure 3.9 的 Initial Process Stack 中找到。这里示例代码定义了一个非常优雅的宏 push()\n#define push(sp, T, ...) ({ *((T*)sp) = (T)__VA_ARGS__; sp = (void *)((uintptr_t)(sp) + sizeof(T)); }) 它的作用是将当前参数放在 sp 的位置，并把 sp 加上 sizeof(T) 移动到下一个空白位置。我们这里做出的一个小修改是不将带下划线的环境变量上栈，这可以帮助我们确信我们的程序对各种内容的掌控。\n最后是几个內联汇编语句，完成的工作是根据 ABI 规定将 %rdx 设置为 0，将栈指针 %rsp 设置为 argc 的地址，最后根据 ELF 的入口地址将 PC 跳转过去 (此处带 * 表示绝对跳转)。\n这个 loader 存在一个小问题：loader 本身也是一个 ELF，它运行起来的时候地址空间中本身就有自己的映射。我们进行新状态机的映射时可能会出现映射冲突的情况，如果强行映射可能会使 loader 崩溃。这时我们应该将 loader 的映射挪一个地方，但这会使 loader 的复杂度大幅上升。为了解决这个问题，我们采用的方法是让 loader 动态链接，动态链接和静态链接的地址空间通常差异很大，不会重叠。\nLoader on OS 与操作系统设计\n这是一个完全处在用户态的 loader——我们发现操作系统的 execve() 系统调用其实是多余的。我们在用户态通过 open(), mmap() 等系统调用可以实现 execve() 的功能。这不禁让我们思考：操作系统是不是应该把加载的过程从内核移出来，让用户对加载过程有更强的可定制性？……\nBoot Loader // bootmain.c #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;elf.h\u0026gt; #include \u0026lt;x86/x86.h\u0026gt; #define SECTSIZE 512 #define ARGSIZE 1024 static inline void wait_disk(void) { while ((inb(0x1f7) \u0026amp; 0xc0) != 0x40); } static inline void read_disk(void *buf, int sect) { wait_disk(); outb(0x1f2, 1); outb(0x1f3, sect); outb(0x1f4, sect \u0026gt;\u0026gt; 8); outb(0x1f5, sect \u0026gt;\u0026gt; 16); outb(0x1f6, (sect \u0026gt;\u0026gt; 24) | 0xE0); outb(0x1f7, 0x20); wait_disk(); for (int i = 0; i \u0026lt; SECTSIZE / 4; i ++) { ((uint32_t *)buf)[i] = inl(0x1f0); } } static inline void copy_from_disk(void *buf, int nbytes, int disk_offset) { uint32_t cur = (uint32_t)buf \u0026amp; ~(SECTSIZE - 1); uint32_t ed = (uint32_t)buf + nbytes; uint32_t sect = (disk_offset / SECTSIZE) + (ARGSIZE / SECTSIZE) + 1; for(; cur \u0026lt; ed; cur += SECTSIZE, sect ++) read_disk((void *)cur, sect); } static void load_program(uint32_t filesz, uint32_t memsz, uint32_t paddr, uint32_t offset) { copy_from_disk((void *)paddr, filesz, offset); char *bss = (void *)(paddr + filesz); for (uint32_t i = filesz; i != memsz; i++) { *bss++ = 0; } } static void load_elf64(Elf64_Ehdr *elf) { Elf64_Phdr *ph = (Elf64_Phdr *)((char *)elf + elf-\u0026gt;e_phoff); for (int i = 0; i \u0026lt; elf-\u0026gt;e_phnum; i++, ph++) { load_program( (uint32_t)ph-\u0026gt;p_filesz, (uint32_t)ph-\u0026gt;p_memsz, (uint32_t)ph-\u0026gt;p_paddr, (uint32_t)ph-\u0026gt;p_offset ); } } static void load_elf32(Elf32_Ehdr *elf) { Elf32_Phdr *ph = (Elf32_Phdr *)((char *)elf + elf-\u0026gt;e_phoff); for (int i = 0; i \u0026lt; elf-\u0026gt;e_phnum; i++, ph++) { load_program( (uint32_t)ph-\u0026gt;p_filesz, (uint32_t)ph-\u0026gt;p_memsz, (uint32_t)ph-\u0026gt;p_paddr, (uint32_t)ph-\u0026gt;p_offset ); } } void load_kernel(void) { Elf32_Ehdr *elf32 = (void *)0x8000; Elf64_Ehdr *elf64 = (void *)0x8000; int is_ap = boot_record()-\u0026gt;is_ap; if (!is_ap) { // load argument (string) to memory copy_from_disk((void *)MAINARG_ADDR, 1024, -1024); // load elf header to memory copy_from_disk(elf32, 4096, 0); if (elf32-\u0026gt;e_machine == EM_X86_64) { load_elf64(elf64); } else { load_elf32(elf32); } } else { // everything should be loaded } if (elf32-\u0026gt;e_machine == EM_X86_64) { ((void(*)())(uint32_t)elf64-\u0026gt;e_entry)(); } else { ((void(*)())(uint32_t)elf32-\u0026gt;e_entry)(); } } bootmain.c 是 AbstractMachine 中加载内核的代码。我们已经知道固件中的代码会帮我们把启动磁盘的第一个扇区 (512B) 的 MBR 搬到一个指定的位置并开始执行，上述代码就是主引导扇区的代码。我们的内核镜像第一个扇区是 MBR，第二、三个扇区存储了传给 main() 函数的参数，后面的部分是内核的 ELF，MBR 代码的工作和之前的 loader on OS 一样，将内核 ELF 中该加载的东西放到指定的地方。\n该代码和 loader on OS 不一样的地方在于：操作系统中我们有 mmap() 系统调用，可以将一段地址空间直接映射到文件中的内容，但在 boot loader 中我们没有操作系统。幸运的是我们有对于全部硬件资源的掌控：现在还没有虚拟地址，我们可以直接指定物理地址，指哪打哪。bootmain.c 中的 read_disk() 函数负责将一个扇区的内容拷贝到 buf 数组中，从硬盘中读取数据的代码非常琐碎，需要参考硬件 I/O 相关的手册。copy_from_disk() 是对 read_disk() 的进一步封装，剩余的 load_program()，load_elf32/64() 的代码和 loader on OS 没有本质区别。\nLinux Kernel Loader Linux 内核没什么可怕的，只是我们之前写的 loader 的放大版本。\n学会使用正确的工具\n使用 vscode 调试代码，可以充分可视化；函数跳转，查找等会非常方便。\nDynamic Linking 随着库函数越来越大，我们希望项目能够在运行时再链接，这样我们不需要每个文件都链接 libc 库函数，节省内存空间。此外，如果我们的库函数要打一个安全补丁，在没有动态链接的情况下，系统中所有链接库的文件都要重新编译一遍 (非常可怕)，有了动态链接我们就可以免除这个麻烦。\n假设我们要实现一个自己的二进制文件格式，支持动态加载，那么我们需要有以下字段：\nDL_HEAD LOAD(\u0026quot;libc.dl\u0026quot;) // 加载动态库 IMPORT(putchar) // 加载外部符号 EXPORT(hello) // 为动态库导出本地符号 DL_CODE hello: ... CALL DSYM(putchar) // DSYM(func) 表示 func 是外部的函数 DL_END 假设我们有配套的编译器可以生成这种格式的位置无关代码。我们可以实现这种格式上的“全家桶”工具集：gcc 对标 ld ，readdl 对标 readelf，objdump 对标 objdump，interp 用于执行：\n// main.S #include \u0026quot;dl.h\u0026quot; DL_HEAD LOAD(\u0026quot;libc.dl\u0026quot;) LOAD(\u0026quot;libhello.dl\u0026quot;) IMPORT(hello) EXPORT(main) DL_CODE main: call DSYM(hello) call DSYM(hello) call DSYM(hello) call DSYM(hello) movq $0, %rax ret DL_END main.S 加载了 libc 库和 libhello 库，引入了 hello 符号，然后在 main() 函数中调用了 4 次 hello()。\n// libhello.S #include \u0026quot;dl.h\u0026quot; DL_HEAD LOAD(\u0026quot;libc.dl\u0026quot;) IMPORT(putchar) EXPORT(hello) DL_CODE hello: lea str(%rip), %rdi mov count(%rip), %eax push %rbx mov %rdi, %rbx inc %eax mov %eax, count(%rip) add $0x30, %eax movb %al, 0x6(%rdi) loop: movsbl (%rbx),%edi test %dil,%dil je out call DSYM(putchar) inc %rbx jmp loop out: pop %rbx ret str: .asciz \u0026quot;Hello X\\n\u0026quot; count: .int 0 DL_END libhello.S 加载了 libc 库，引入了 putchar 符号，并为动态库提供了 hello() 函数。hello() 函数的功能很简单：每次调用 putchar() 输出字符串 \u0026ldquo;Hello X\\n\u0026rdquo;，其中 X 会每轮 +1。\n// libc.S #include \u0026quot;dl.h\u0026quot; #include \u0026lt;sys/syscall.h\u0026gt; DL_HEAD EXPORT(putchar) EXPORT(exit) DL_CODE putchar: mov %dil, buf(%rip) mov $SYS_write, %rax mov $1, %rdi lea buf(%rip), %rsi mov $1, %rdx syscall ret buf: .byte 0 exit: movq $SYS_exit, %rax syscall DL_END libc.S 为动态库提供了 putchar() 函数和 exit() 函数，putchar() 函数通过 write 系统调用输出字符，exit() 函数通过 exit 系统调用退出。\n利用全家桶工具 dlbox.c，我们可以分别链接三个汇编文件，生成对应的 .dl 文件：\n./dlbox gcc main.S ./dlbox gcc libc.S ./dlbox gcc libhello.S 我们可以用 readdl 工具查看 dl 文件的内容：\n\u0026gt; ./dlbox readdl main.dl DLIB file main.dl: LOAD libc.dl LOAD libhello.dl EXTERN hello 000000c0 main 可以看到 main.S 加载了 libc 和 libhello，导入了外部符号 hello，本地有一个符号 main。\n我们可以用 objdump 工具查看反汇编代码：\n\u0026gt; ./dlbox objdump libc.dl Disassembly of binary libc.dl: 0000000000000000 \u0026lt;putchar\u0026gt;: 00000000 40883D1F000000 mov [rel 0x26],dil 00000007 48C7C001000000 mov rax,0x1 0000000E 48C7C701000000 mov rdi,0x1 00000015 488D350A000000 lea rsi,[rel 0x26] 0000001C 48C7C201000000 mov rdx,0x1 00000023 0F05 syscall 00000025 C3 ret 00000026 00 db 0x00 0000000000000027 \u0026lt;exit\u0026gt;: 00000027 48C7C03C000000 mov rax,0x3c 0000002E 0F05 syscall (注：需要在本地安装 nasm 工具集。)\n最后，我们不需要将这些 dl 文件汇集在一起链接，就可以直接运行 main.dl：\n\u0026gt; ./dlbox interp main.dl Hello 1 Hello 2 Hello 3 Hello 4 我们现在关注这个动态加载器是如何实现的。首先看 dl.h。\n// dl.h #define REC_SZ 32 #define DL_MAGIC \u0026quot;\\x01\\x14\\x05\\x14\u0026quot; #ifdef __ASSEMBLER__ #define DL_HEAD __hdr: \\ /* magic */ .ascii DL_MAGIC; \\ /* file_sz */ .4byte (__end - __hdr); \\ /* code_off */ .4byte (__code - __hdr) #define DL_CODE .fill REC_SZ - 1, 1, 0; \\ .align REC_SZ, 0; \\ __code: #define DL_END __end: #define RECORD(sym, off, name) \\ .align REC_SZ, 0; \\ sym .8byte (off); .ascii name #define IMPORT(sym) RECORD(sym:, 0, \u0026quot;?\u0026quot; #sym \u0026quot;\\0\u0026quot;) #define EXPORT(sym) RECORD( , sym - __hdr, \u0026quot;#\u0026quot; #sym \u0026quot;\\0\u0026quot;) #define LOAD(lib) RECORD( , 0, \u0026quot;+\u0026quot; lib \u0026quot;\\0\u0026quot;) #define DSYM(sym) *sym(%rip) #else #include \u0026lt;stdint.h\u0026gt; struct dl_hdr { char magic[4]; uint32_t file_sz, code_off; }; struct symbol { int64_t offset; char type, name[REC_SZ - sizeof(int64_t) - 1]; }; #endif 上半部分是给汇编看的，后半部分是给 C 语言看的 (即 dlbox.h)。dl.h 是对我们的 DIY 二进制文件格式的一个 specification。我们的二进制文件格式如下：\nheader symbol1 symbol2 \u0026hellip; symboln 00\u0026hellip;0 code 其中每个部分都是 32 字节对齐的。header 的结构如 C 语言代码部分所示。header 中有一个 4B 的魔数用于检查文件格式，一个变量 file_sz 记录整个文件的大小，一个变量 code_off 记录代码段距离文件开头的 offset。通过汇编部分的宏可以看到，在汇编代码中添加了一些符号后这些值都是很容易算出的。\n比较关键的宏是 IMPORT()，EXPORT() 和 LOAD()。可以看到它们的本质是在符号表中添加一个表项。符号表的结构如 C 语言代码部分所示，前 8 个字节是这个符号所在位置与文件开头的 offset (如果这是一个外部符号则暂时填 0，加载的时候由动态加载器补全)，type 表示这是一个内部导出的符号，外部导入的符号还是要加载一个动态库。最后的 name[] 数组记录了名字。将这个结构体和宏定义对比起来看也很容易懂，这里值得注意的一个小细节是：IMPORT(sym) 中，直接使用 sym 表示的是汇编文件中定义的 sym 符号，在前面加上 # 才表示 sym 本身这个字符串。\n另外可以看到，DSYM() 宏是一个 PC 相对跳转。DSYM(sym) 会被翻译为 call *sym(%rip)。该指令的语义是 PC = mem[next-pc + offset]。因此在汇编阶段 PC 和本文件符号表中的 sym 的差值 offset 就能确定。在加载时，随着符号表 sym 里面填写的地址被确定，call 就能完成正确的跳转。\n// dlbox.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026quot;dl.h\u0026quot; #define SIZE 4096 #define LENGTH(arr) (sizeof(arr) / sizeof(arr[0])) struct dlib { struct dl_hdr hdr; struct symbol *symtab; // borrowed spaces from header const char *path; }; static struct dlib *dlopen(const char *path); struct dlib *dlopen_chk(const char *path) { struct dlib *lib = dlopen(path); if (!lib) { fprintf(stderr, \u0026quot;Not a valid dlib file: %s.\\n\u0026quot;, path); exit(1); } return lib; } // Implementation of binutils void dl_gcc(const char *path) { char buf[256], *dot = strrchr(path, '.'); if (dot) { *dot = '\\0'; sprintf(buf, \u0026quot;gcc -m64 -fPIC -c %s.S \u0026amp;\u0026amp; \u0026quot; \u0026quot;objcopy -S -j .text -O binary %s.o %s.dl\u0026quot;, path, path, path); system(buf); } } void dl_readdl(const char *path) { struct dlib *h = dlopen_chk(path); printf(\u0026quot;DLIB file %s:\\n\\n\u0026quot;, h-\u0026gt;path); for (struct symbol *sym = h-\u0026gt;symtab; sym-\u0026gt;type; sym++) { switch (sym-\u0026gt;type) { case '+': printf(\u0026quot; LOAD %s\\n\u0026quot;, sym-\u0026gt;name); break; case '?': printf(\u0026quot; EXTERN %s\\n\u0026quot;, sym-\u0026gt;name); break; case '#': printf( \u0026quot;%08lx %s\\n\u0026quot;, sym-\u0026gt;offset, sym-\u0026gt;name); break; } } } void dl_objdump(const char *path) { struct dlib *h = dlopen_chk(path); char *hc = (char *)h, cmd[64]; FILE *fp = NULL; printf(\u0026quot;Disassembly of binary %s:\\n\u0026quot;, h-\u0026gt;path); for (char *code = hc + h-\u0026gt;hdr.code_off; code \u0026lt; hc + h-\u0026gt;hdr.file_sz; code++) { for (struct symbol *sym = h-\u0026gt;symtab; sym-\u0026gt;type; sym++) { if (hc + sym-\u0026gt;offset == code) { int off = code - hc - h-\u0026gt;hdr.code_off; if (fp) pclose(fp); sprintf(cmd, \u0026quot;ndisasm - -b 64 -o 0x%08x\\n\u0026quot;, off); fp = popen(cmd, \u0026quot;w\u0026quot;); printf(\u0026quot;\\n%016x \u0026lt;%s\u0026gt;:\\n\u0026quot;, off, sym-\u0026gt;name); fflush(stdout); } } if (fp) fputc(*code, fp); } if (fp) pclose(fp); } // binutils: interpreter void dl_interp(const char *path) { struct dlib *h = dlopen_chk(path); int (*entry)() = NULL; for (struct symbol *sym = h-\u0026gt;symtab; sym-\u0026gt;type; sym++) if (strcmp(sym-\u0026gt;name, \u0026quot;main\u0026quot;) == 0) entry = (void *)((char *)h + sym-\u0026gt;offset); if (entry) { exit(entry()); } } struct cmd { const char *cmd; void (*handler)(const char *path); } commands[] = { { \u0026quot;gcc\u0026quot;, dl_gcc }, { \u0026quot;readdl\u0026quot;, dl_readdl }, { \u0026quot;objdump\u0026quot;, dl_objdump }, { \u0026quot;interp\u0026quot;, dl_interp }, { \u0026quot;\u0026quot;, NULL }, }; int main(int argc, char *argv[]) { if (argc \u0026lt; 3) { fprintf(stderr, \u0026quot;Usage: %s {gcc|readdl|objdump|interp} FILE...\\n\u0026quot;, argv[0]); return 1; } for (struct cmd *cmd = \u0026amp;commands[0]; cmd-\u0026gt;handler; cmd++) { for (char **path = \u0026amp;argv[2]; *path \u0026amp;\u0026amp; strcmp(argv[1], cmd-\u0026gt;cmd) == 0; path++) { if (path != argv + 2) printf(\u0026quot;\\n\u0026quot;); cmd-\u0026gt;handler(*path); } } } // Implementation of dlopen() static struct symbol *libs[16], syms[128]; static void *dlsym(const char *name); static void dlexport(const char *name, void *addr); static void dlload(struct symbol *sym); static struct dlib *dlopen(const char *path) { struct dl_hdr hdr; struct dlib *h; int fd = open(path, O_RDONLY); if (fd \u0026lt; 0) goto bad; if (read(fd, \u0026amp;hdr, sizeof(hdr)) \u0026lt; sizeof(hdr)) goto bad; if (strncmp(hdr.magic, DL_MAGIC, strlen(DL_MAGIC)) != 0) goto bad; h = mmap(NULL, hdr.file_sz, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE, fd, 0); if (h == (void *)-1) goto bad; h-\u0026gt;symtab = (struct symbol *)((char *)h + REC_SZ); h-\u0026gt;path = path; for (struct symbol *sym = h-\u0026gt;symtab; sym-\u0026gt;type; sym++) { switch (sym-\u0026gt;type) { case '+': dlload(sym); break; // (recursively) load case '?': sym-\u0026gt;offset = (uintptr_t)dlsym(sym-\u0026gt;name); break; // resolve case '#': dlexport(sym-\u0026gt;name, (char *)h + sym-\u0026gt;offset); break; // export } } return h; bad: if (fd \u0026gt; 0) close(fd); return NULL; } static void *dlsym(const char *name) { for (int i = 0; i \u0026lt; LENGTH(syms); i++) if (strcmp(syms[i].name, name) == 0) return (void *)syms[i].offset; assert(0); } static void dlexport(const char *name, void *addr) { for (int i = 0; i \u0026lt; LENGTH(syms); i++) if (!syms[i].name[0]) { syms[i].offset = (uintptr_t)addr; // load-time offset strcpy(syms[i].name, name); return; } assert(0); } static void dlload(struct symbol *sym) { for (int i = 0; i \u0026lt; LENGTH(libs); i++) { if (libs[i] \u0026amp;\u0026amp; strcmp(libs[i]-\u0026gt;name, sym-\u0026gt;name) == 0) return; // already loaded if (!libs[i]) { libs[i] = sym; dlopen(sym-\u0026gt;name); // load recursively return; } } assert(0); } dlbox.c 实现了 dl 格式的工具全家桶。它有很多的功能都是借用了 GNU 工具链实现的。这其中最重要的函数是 dlopen()，它可以打开一个 .dl 文件，将其中的内容解析出来，并返回一个 dlib 结构体，dlib 结构体的内容和之前绘制的二进制文件结构相同。\ndlopen() 做了如下的事情：\n调用 open() 打开目标文件，从中读取了 sizeof(dl_hdr) 的数据，即把文件头读了出来，进行魔数检查，并获得了整个文件的大小。 利用 mmap() 系统调用将整个目标文件加载到内存中 (其本质是 copy-on-write 的，因此即使文件很大速度也很快)，将符号表首地址设置为 header 下面一个，设置好 h-\u0026gt;path。 遍历符号表，对于 EXPORT 类型调用 dlexport() 将当前符号加载时在内存中的绝对地址填写到数据结构中；对于 IMPORT 类型调用 dlsym() 在数据结构中查找地址并将本文件符号表中的 offset 填上正确的值；对于 LOAD 型调用 dlload() 加载一个新的文件，dlload() 的本质是递归地调用 dlopen()，不过它会记录当前已经打开过的文件，保证不会重复加载同一个动态库。 在 dlopen() 的基础上， gcc readdl objdump interp 四个工具的实现是简单的：\ngcc 工具实际上使用的是外部 gcc 中的汇编器，我们要求汇编器生成 64 位架构的位置无关代码，然后用 objcopy 工具把二进制文件的代码节复制出来，输出到一个 dl 文件中。 readdl 工具首先调用 dlopen() 打开对应的文件，然后遍历整个符号表，根据 type 打印相应的信息。 objdump 工具首先调用 dlopen() 打开对应文件，然后把反汇编的工作交给 ndisasm 工具，objdump 主要负责扫描符号表，看当前地址是不是一个新函数，并把函数名打印出来。 interp 工具首先调用 dlopen() 打开对应文件，然后在符号表中寻找是 main 的符号，跳转到 main 的首地址开始执行，并将 main() 的返回值喂给 exit() 退出 dlbox。 我们很快会发现我们设计的二进制文件格式有很多可改进的地方：\n我们的字符串名时常达不到上限，这使得二进制文件中有大量的 0。我们应该将所有的名字放在一个字符串常量池中，然后其他地方保存指向字符串的指针。\n我们每个 .dl 文件中只有一个代码段，这个代码段是可读可写可执行的。我们希望有更多的代码段，不同的段有不同的权限，这就有了 program header table。\n在我们自己的二进制文件格式中，来自外部库的函数需要在前面加上 DSYM() 以确保被编译成一个 call *sym(%rip) 指令。但实际情况下我们写代码时并不会标注一个函数究竟时来自外部库的函数还是来自外部编译单元的函数——前者必须要到加载的时候才能确定位置，后者在链接的时候就能确定。因此我们不得不将所有的函数都编译成 DSYM() 的形式。这是一个万能的形式，但这种跳转相较于直接相对于 PC 的跳转多了一次访存，效率低。\n我们可以考虑这样一种处理方式：我们准备一个叫 PLT 的东西存储在可执行文件里，向函数 f 的跳转统一编译为静态的跳转到本文件的 f@plt() 函数的简单跳转。这样链接的时候如果发现 f() 其实是来自外部编译单元的函数，就修改一下跳转的目标函数；如果 f() 是外部库的函数，就在 f@plt() 中加一条 jmp *off(%rip) 指令。这样我们编译时可以统一使用静态的跳转指令。加载时填写好各个 symbol 的加载时地址后，jmp 指令就可以正常工作了。\n这里存储各个 symbol 地址，在加载时填写的东西就叫 global offset table (GOT)，用于间接跳转的东西就叫 procedure linkage table (PLT)。我们独立发明了 PLT 和 GOT 的概念！\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"15f73bc32392647b171cc09dcf1318f2","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec17/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec17/","section":"notes","summary":"Static Loader Loader on OS 可执行文件是一个描述了状态机的初始状态的数据结构。加载器根据可执行文件的描述设置好初始状态机。我们很容易写一个静态加载器：\n// loader-static.c #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;elf.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #define STK_SZ (1 \u0026lt;\u0026lt; 20) #define ROUND(x, align) (void *)(((uintptr_t)x) \u0026amp; ~(align - 1)) #define MOD(x, align) (((uintptr_t)x) \u0026amp; (align - 1)) #define push(sp, T, .","tags":null,"title":"Lecture 17: Linking and Loading","type":"docs"},{"authors":null,"categories":null,"content":" Xv6 中的 .d .sym .asm 文件是什么？\n.d 文件描述了 Makefile 中文件所需的依赖关系。我们考虑如下程序：\na.o: a.c gcc -c a.c // a.c #include \u0026quot;a.h\u0026quot; // a.h // Cannot compile Makefile 的逻辑是：a.o 依赖文件 a.c，在执行 make 时，如果 a.c 相较于上一次 make 发生过改动，则会再次执行编译指令，如果没有改动则不执行。但当我们的 a.c include 了 a.h 之后，实际上 a.o 多了一个间接的依赖关系：当 a.h 发生改动时，我们也应该重新执行编译指令。但很遗憾，除非在 Makefile 中添加 a.h 依赖，否则 Makefile 不会自己做到这一点。\n大型项目中一个 C 程序可能有很多很多的 include。如果将这些 include 全部填到 Makefile 中，Makefile 将变得难以维护。因此我们利用编译器生成了 .d 文件，.d 文件中包含了一个程序依赖的头文件列表，且这个列表是 Makefile 可以直接解析的，这样我们解决了依赖问题。\nXv6 Framework /kernel 是内核代码，Makefile 会将所有的源代码文件编译后根据 /kernel/kernel.ld 的链接脚本链接生成一个 kernel 可执行文件。/user 是用户程序代码，Makefile 会给将每个形如 name.c 的用户程序编译生成一个 _name 可执行文件。/mkfs 是生成文件系统的代码，/user 中所有下划线开头的可执行文件会被放入文件系统。\n工具的配置\n好的工具会提升阅读代码的体验，使用 vscode 是一个很好的选择。为 vscode 添加正确的 compile_command.json 可以使 vscode 正确地跳转。compile_command.json 的原理是提供每个文件依赖的 include path。我们可以用 bear 工具直接爬 make qemu 的信息，它会自动生成 .json 文件。\nCode: xv6 System Call 因为启动第一个进程的时候 xv6 还没有初始化文件系统，无法通过 exec() 系统调用来加载 image，所以 xv6 的第一个进程 initcode 是写死的一段汇编代码 (在 forkret() 中有初始化文件系统的相关代码)，具体的信息可以见 MIT 6.S081 Lecture 03。\n通过 ecall 指令走 trampoline 然后进入 usertrap() 的流程可以见 MIT 6.S081 Lecture 6。\n为什么我在 GDB 中加断点 b *0x0 会报错：\u0026ldquo;cannnot access memory?\u0026rdquo;\n2020版之前的 xv6 需要在 .gdbinit.tmpl-riscv 中添加一条配置：\nset riscv use-compressed-breakpoints yes ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"6ed449169a1e18a27701adbed36f3307","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec18/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec18/","section":"notes","summary":"Xv6 中的 .d .sym .asm 文件是什么？\n.d 文件描述了 Makefile 中文件所需的依赖关系。我们考虑如下程序：\na.o: a.c gcc -c a.c // a.c #include \u0026quot;a.h\u0026quot; // a.h // Cannot compile Makefile 的逻辑是：a.o 依赖文件 a.c，在执行 make 时，如果 a.","tags":null,"title":"Lecture 18: Xv6 Code Guide","type":"docs"},{"authors":null,"categories":null,"content":"如果我们的用户程序有死循环，计算机并不会被卡死——因为操作系统有进程调度；但操作系统有对整个计算机完全的掌控权，如果在操作系统代码中加一个死循环，那计算机就真的卡死了。\nVirtualization of CPUs 每一个进程都是一个状态机，其中有寄存器、内存，看内存的 \u0026ldquo;VR 眼镜\u0026rdquo; (页表) 等等。操作系统是一个状态机的管理者：它要维护各个进程的状态机，此外内核对应的状态机也归 OS 管理。正在运行的状态机的状态保存在硬件上 (CPU, DRAM)，其他未运行的进程的状态机以某种方式被暂存起来。\n现代操作系统通常借助时钟中断，使用抢占式多任务的方式来在状态机之间切换。中断相当于一个强行插入的 ecall，打断正在运行的执行流。操作系统负责将这个进程当前的状态机从硬件上复制下来，挑选下一个准备执行的进程，然后将其状态机搬上硬件。\nCode: Xv6 trapframe \u0026amp; Thread Switching 该部分内容可以参考 MIT 6.S081 Lecture 6 和 Lecture 11。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"a0c977dcb0559d34c7377f4c89d7bf43","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec19/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec19/","section":"notes","summary":"如果我们的用户程序有死循环，计算机并不会被卡死——因为操作系统有进程调度；但操作系统有对整个计算机完全的掌控权，如果在操作系统代码中加一个死循环，那计算机就真的卡死了。\nVirtualization of CPUs 每一个进程都是一个状态机，其中有寄存器、内存，看内存的 \u0026ldquo;VR 眼镜\u0026rdquo; (页表) 等等。操作系统是一个状态机的管理者：它要维护各个进程的状态机，此外内核对应的状态机也归 OS 管理。正在运行的状态机的状态保存在硬件上 (CPU, DRAM)，其他未运行的进程的状态机以某种方式被暂存起来。\n现代操作系统通常借助时钟中断，使用抢占式多任务的方式来在状态机之间切换。中断相当于一个强行插入的 ecall，打断正在运行的执行流。操作系统负责将这个进程当前的状态机从硬件上复制下来，挑选下一个准备执行的进程，然后将其状态机搬上硬件。\nCode: Xv6 trapframe \u0026amp; Thread Switching 该部分内容可以参考 MIT 6.S081 Lecture 6 和 Lecture 11。","tags":null,"title":"Lecture 19: Context Switching","type":"docs"},{"authors":null,"categories":null,"content":"处理器调度问题的简单假设 (1960s)：\n系统中有一个处理器 系统中有多个进程/线程共享 CPU 包括系统调用 (进程/线程的一部分在内核代码中) 偶尔会等待 I/O 返回，不使用 CPU。 Policy Round-Robin 按照时间片轮转，轮流运行所有的进程/线程。\n问题：假设当前有一个前台的 vim 进程和很多计算型的后台进程，如果使用 round robin，很容易出现前台 vim 进程很卡的现象 (vim 进程一旦被切出去了，就要等一整轮才能获得一个时间片)。\n我们希望引入某种“优先级”，使得和用户交互比较频繁的前台进程可以获得更高的调度优先级，优化用户的使用体验。\nUNIX Niceness UNIX 的 niceness 是一个 -20 ... 19 的整数，nice 值越高的进程越”和善“，越容易让出 CPU。\n基于优先级的调度策略：\n在一些实时的操作系统中 (尤其是物理相关，比如火箭/机械手 etc.)，CPU 会完全根据优先级，每次选择 niceness 最低的进程执行。这样的做法是有道理的：比如火箭要运行应急程序，我们自然不希望时钟中断后收集火箭运行数据的进程插入进来执行。\n在桌面操作系统中，让“坏人”霸占 CPU 的做法不太可取。在 Linux 中，niceness 相差 10，CPU 资源获得率相差大约 10 倍。\n我们可以做一个实验来验证这一点：\ntaskset -c 0 nice -n 19 yes \u0026gt; /dev/null \u0026amp; taskset -c 0 nice -n 9 yes \u0026gt; /dev/null \u0026amp; 其中 taskset 命令可以指定让一个进程在某个 CPU 核上执行。创建这两个后台进程后，我们可以通过 top 来观测它们的 CPU 占用情况。\n// office hour: 为什么我使用这两个指令创建出的进程 nice 值是 14 和 19？\u0026hellip;\nMLFQ (Multi-level Feedback Queue) 仍然考虑 round-robin 在遇到一堆计算密集型线程和一个交互型线程时的问题。我们现在考虑：能否让操作系统观测进程的行为，然后动态地调整进程的优先级？这就是 MLFQ 的基本思想。\n操作系统观测每个进程对时间片的使用情况：如果一个进程每次都用满整个时间片，那么它是一个“坏进程”，我们就适当降低它的优先级；如果一个进程经常 sleep()，等待 I/O etc. CPU 占用比较小，那么它是一个“好进程”，我们就适当增加它的优先级。我们动态调整进程的优先级，为每种优先级创建一个 round robin 的队列。\n当然，一个纯粹的”坏进程”可以通过如下的方式来欺骗这样的策略：\nwhile (1) { compute(); if (时间片快用完了) usleep(1);\t} 此外，如果像 Vim 这样的高优先级进程过多，后台的计算进程可能就会几乎卡死；进程的“好坏”其实是动态变化的，不能“一棍子打死”等等。操作系统的设计者会试图补救这些问题，比如 priority boost 策略会每隔一段时间把所有进程的优先级拉平，使得进程有“重新做人”的机会。\n如果我们考虑进程之间的通信，这个问题就会变得更加复杂：假设进程中有 producer/consumer，以及其他的 while(1) 线程，在 round-robin 中 producer/consumer 会频繁让出 CPU，这导致 while(1) 获得了过多的运行时间；在 MLFQ 中，producer/consumer 因为频繁让出 CPU 会获得高优先级，但这种让出并不是出于人机交互的目的——producer/consumer 组合起来仍然是一个纯计算任务，因此它获得高优先级也是不合理的。\nCFS (Complete Fair Scheduling) 完全公平调度的指导思想很简单：让每个进程公平地享用 CPU。因此操作系统内核会记录每个进程运行的时间，每次调度器选择当前执行时间最少的进程执行。\n为了避免落入 round robin 的结局，CFS 通过类似于“变速齿轮”的方法实现优先级：每个进程实际上享用的是相同的虚拟运行时间 (vruntime)，但不同进程的虚拟运行时间和物理运行时间的比例不同：优先级高的进程一个单位的 vruntime 对应更长的物理时间，反之亦然。这种方式类似于变速齿轮是因为它实际上“欺骗”了进程：进程能直接感受到的物理时间是虚拟的。进程其实可以通过其他方式感知到“不对劲”：比如 \u0026ldquo;我 1s 怎么只执行了 1M 的指令？\u0026rdquo; 但现在的进程还没有这样的能力。\nCFS Complexity: New Process/Thread 考虑如下一段代码：\n#include \u0026lt;stdio.h\u0026gt; int main () { setbuf(stdout, NULL); int pid = fork(); if (pid \u0026lt; 0) perror(\u0026quot;fork\u0026quot;); else if (pid == 0) for (const char *s = \u0026quot;child\u0026quot;; *s; s++) putchar(*s); else for (const char *s = \u0026quot;parent\u0026quot;; *s; s++) putchar(*s); return 0; } 在较新版本的 linux 内核中，多次运行上述程序会看到几乎总是 parent 先被打印。这是因为现在的内核是 parent first 的，曾经的内核版本是 child first，这其中存在一个权衡问题：绝大部分情况下 fork() 执行完会紧接着执行 execve()，我们的 fork() 是 copy-on-write 的，如果先执行子进程，有很大概率 execve() 会销毁原先的页表，这样父进程执行时就不需要额外的复制操作；但先执行子进程意味着当前 CPU 的 cache, TLB 等需要被全部刷新，这又会有一个立即可见的额外代价。\n除了 parent/child first 问题，另一个问题是：我们的 CFS 应该为这个新进程创建怎样的 vruntime? 早期的版本会给子进程较少的 vruntime，也就是让它有机会稍微多执行一点。但这个策略导致恶意程序可以疯狂 fork 子进程来占据 CPU，因此现在的内核代码中子进程继承父进程的 vruntime。\n// linux kernel static void task_fork_fair(struct task_struct *p) { ... if (curr) { update_curr(cfs_rq); se-\u0026gt;vruntime = curr-\u0026gt;vruntime; // \u0026lt;------------ here } } CFS Complexity: I/O 考虑如下场景：有一个进程等待了 1min 的 I/O 操作，这段时间内它一直处于 blocked 的状态，不会被调度上 CPU。那么 I/O 操作结束后，该进程的 vruntime 会显著低于别的进程。从而未来的相当长时间内 CPU 会被这个 I/O 进程独占，这显然不是我们想看到的情况。\n操作系统理应在 I/O 进程结束等待后将其 vruntime 补齐到一个基准点，这个基准点到地设置在哪里又是很有讲究的事。\nCFS Complexity: Integer Overflow 在一个需要长时间运行的系统中，我们即使用 uint64_t 来存储 vruntime 也要面临溢出的问题。这意味着我们不能用 vruntime 的绝对大小来比较两个进程的优先级。\nLinux 中采取的解决方案是：保证任意时刻系统中最大的 vruntime 和 最小的 vruntime 之差不超过数轴的一半 (i.e. UINT64_MAX / 2 )。这样我们可以用比较相对大小的方式来解决问题：\n// linux kernel bool less(uint64_t a, uint64_t b) { return (int64_t)(a - b) \u0026lt; 0; } 我们可以考虑一下 a 是很小的正数 (溢出了一轮)，b 是很大的正数 (还没溢出) 的情况，此时应有 $a\u0026gt;b$。$a-b$ 的结果是小于 0 的，但由于这个值大于 INT64_MAX，所以强制转换成 int64_t 后会下溢出变成正的，从而正确实现功能 (非常 tricky 的代码)。\nCFS Complexity: Implementation 我们要实现一个数据结构，支持高效的插入、删除、找最小值等。Linux 采取了主流的红黑树设计，但我们的数据结构要保证并行状态下的正确性，为了效率还不能上大锁……\nThe First Bug on Mars 在实时操作系统中，高优先级意味着必须先被调度。简单的调度处理可能会出现优先级反转的情况：\nvoid high() {sleep(1); mutex_lock();} void medium() {while (1);} void low() {mutex_lock();} 假设低优先级进程先执行，获得了锁；然后 medium() 到来，将 low() 踢出 CPU，low() 带着锁进入了睡眠；这时 high() 来了但发现无法获得锁——因为锁在 low() 手里。high() 因为锁的语义等待 low() 是可以接受的 (锁可能很快就被释放)，但 low() 在等待 medium()，这导致 high() 间接等待了一个与自己毫无关系的进程 medium()，这是不可接受的。\n这个 bug 在第一辆火星车上真实地发生过，这导致了火星车系统的重启。解决优先级反转地方法通常有优先级继承 (priority inheritance)/优先级提升 (priority ceiling)，简单来说，当 high() 因为锁资源等待时，low() 的优先级可以暂时提升到和 high() 一样高，这样很快 low() 就可以把 medium() 踢下 CPU 运行，释放了锁 high() 就可以正常执行了，low() 的优先级也恢复最低。\nMulti-core Scheduling 多核处理器上的调度处于一个两难的境地：\n如果简单地将线程分配到处理器，那么容易出现“一核有难他核围观”的局面。 如果简单地将线程安排到一个空闲处理器上，那么之前的 cache/TLB 就全部白给了。 Complexity: Multi-user 假设用户 A 和 B 共用一台服务器，A 的程序只能单线程，而 B 的程序可以 1000 个线程，那就会出现 A 只获得了很少的资源的情况。糟糕的是，A 不能通过提高自己线程的优先级的方法来解决这个问题：在 Linux 中，非特权用户只能提升自己的 nice 值，不能降低。\nLinux 采用的解决方案是 namespaces control groups，大致思想是创建了“操作系统中的操作系统”，将属于一个用户的进程归成一组管理。\nComplexity: Big.LITTLE and Energy Consumption 现在的 CPU 有大小核的概念：大核频率高，小核频率小，我们在调度的时候不得不将这些因素考虑进来。此外，现在的软件可以配置 CPU 的工作模式：CPU 的频率越低，它的延迟越高，但能耗越小，吞吐量越高。那么如何根据不同类型的任务调整 CPU 工作模式以及调度也是非常复杂的问题。\nComplexity: Non-Uniform Memory Access 共享内存在某种程度上只是一个假象。L1 Cache 花了巨大的代价才让各个 CPU 看到了共享的内存。多个线程在同一个/不同的核上跑，效率可能有很大的区别。\n在实际情况下，连”核心越多，速度越快”的假设都可能是错的。以 sum-atomic.c 为例，如果我们用命令\ntastset -c 0 ./sum-atomic 来让 sum-atomic.c 的所有线程只工作在一个核上，会发现运行时间竟小于多个核！调度器把程序当作黑盒的假设可能是不对的。\nComplexity: CPU Hot-plug 现在的 CPU 支持热插拔，可能运行一会儿会发现多了一个或者少了一个……\n调度是一个非常复杂的问题，将这个任务完全丢给操作系统的调度器是不合理的。一种可能的想法是：让程序提供一些 scheduling hints 来指导调度行为。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"358a5a40daafd9fff68e94e9f523ec03","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec20/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec20/","section":"notes","summary":"处理器调度问题的简单假设 (1960s)：\n系统中有一个处理器 系统中有多个进程/线程共享 CPU 包括系统调用 (进程/线程的一部分在内核代码中) 偶尔会等待 I/O 返回，不使用 CPU。 Policy Round-Robin 按照时间片轮转，轮流运行所有的进程/线程。\n问题：假设当前有一个前台的 vim 进程和很多计算型的后台进程，如果使用 round robin，很容易出现前台 vim 进程很卡的现象 (vim 进程一旦被切出去了，就要等一整轮才能获得一个时间片)。\n我们希望引入某种“优先级”，使得和用户交互比较频繁的前台进程可以获得更高的调度优先级，优化用户的使用体验。\nUNIX Niceness UNIX 的 niceness 是一个 -20 .","tags":null,"title":"Lecture 20: Scheduling","type":"docs"},{"authors":null,"categories":null,"content":"操作系统的设计：一组对象+访问对象的 API；操作系统的实现：一个 C 程序完成上面的设计\n我们关心的问题是：操作系统到底应该提供什么样的对象和 API？\nMonolithic Kernel Unix 系列： The Open Group Base Specifications Issue 7 (2018 Ed.)\nWindows 系列： Windows API Index\n不同的 API 系列可以互相模拟，于是有了 WSL 和 WINE。\nReal Operating Systems\n真正的操作系统要考虑的事情总是比想象中的复杂。比如我们写一个简单的重命名函数：\nvoid rename_file(char *oldname, char *newname) { char buf[SIZE]; int fd = open(oldname, O_RONLY); fread(fd, buf); close(fd); delete(oldname); // \u0026lt;------------------ fd = open(newname, O_CREAT | O_TRUNC | O_WONLY); write(fd, buf, sizeof(buf)); } 如果在箭头指向的时刻操作系统突然掉电了，那么文件内容就全部丢失了！这显然是不合理的现象。阅读 rename() 系统调用的手册，可以看到手册保证了删除旧文件，创建新文件操作的原子性。\nMicrokernel 复杂系统的正确性难以保证。像 Linux 这样以 C 为主要语言的操作系统，C 的 undefined behavior 会给系统带来无穷的灾难：比如文件系统一旦出错，整个内核中的任何模块都可能受到损坏。\n微内核的想法是：将尽可能多的功能用普通进程实现，将问题隔离在进程级。比如文件操作，UNIX 的 write() 会陷入内核，但另一种想法是：调用一个 remote_write() 和一个 File server 交互，FS进程有访问磁盘的权限即可。\n一些好的想法：\n一些和状态机管理密切相关的系统调用没法被搬出内核：比如 fork(), mmap()。 如果操作系统提供一个 mmio() 系统调用，让进程通过访问内存的方式来控制设备寄存器、磁盘 etc，那么设备驱动代码，文件系统代码都可以放在用户态。 赋予进程最少的权限，就能降低错误带来的影响。\nMinix Minix 是一个具有跨时代意义的教学操作系统，它采取的是微内核设计。在 Minix 2.0 中，内核只提供了两个 API：send 和 receive。基于这两个系统调用，我们实现一些 RPC (remote procedure call) 来实现进程之间的通信。Kernel 里只有很少的状态机相关的机制：比如中断，异常，时钟驱动，内存映射 etc. 其他的功能，比如文件系统，设备驱动，网络 etc. 都在用户态。跨模块的调用会跨越进程边界 i.e. 地址空间的切换等，这样一个模块的错误就可以被隔离在本地，UB 不会波及到模块外部。\nseL4 seL4 是第一个完成了正确性证明、运行时间上界证明的微内核。\nseL4 的证明思路大致如下：以 thread-os.c 的 round-robin 调度器为例，首先我们用适合描述行为的语言建立一个模型 (这里以 python 为例, seL4 在这里实际上有两层建模)：\ndef rr_sched(cpu): cpu.threads = cpu.threads[1:] + cpu.threads[:1] assert anything_you_need return cpu.threads[0] 我们可以用 model checker 确认这个 high level 语言编写的程序的正确性，然后我们希望证明 thread-os.c 和 python 代码的行为等价性。除去访问硬件的部分 (AbstractMachine)，操作系统本质上是纯计算的程序 (数学模型)，因此我们只需要观测所有的 AM call 行为是否等价即可。如果我们使用被 verified 的编译器，我们还可以进一步证明 C 程序和汇编指令的等价性。\nUniKernel 很早的时候就有了 exokernel (外核) 的概念，即操作系统不应该有任何的策略，只需要提供最小的硬件抽象。在有了虚拟机的时代，这催生了 unikernel：将操作系统的内核代码和应用程序直接链接起来跑，因为硬件都是虚拟机抽象出来的，所以没有安全问题。这时的 OS 类似于一个 libOS 的功能。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"ddcc9b19f3068105b2a2134ec8c32e06","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec21/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec21/","section":"notes","summary":"操作系统的设计：一组对象+访问对象的 API；操作系统的实现：一个 C 程序完成上面的设计\n我们关心的问题是：操作系统到底应该提供什么样的对象和 API？\nMonolithic Kernel Unix 系列： The Open Group Base Specifications Issue 7 (2018 Ed.)\nWindows 系列： Windows API Index\n不同的 API 系列可以互相模拟，于是有了 WSL 和 WINE。","tags":null,"title":"Lecture 21: OS Design","type":"docs"},{"authors":null,"categories":null,"content":"L1 一把大锁保平安策略：全局用一把锁，把所有需要保护的代码都用 atomic {} 框起来。\n#define atomic \\ for (int __i = (lock(), 0); i \u0026lt; 1; unlock(), __i++) 这个 for 循环的语义如下：\nlock(); __i = 0;\t// C语言逗号表达式总是取后面的值 check i \u0026lt; 1 =\u0026gt; yes body __i++; unlock(); check i \u0026lt; 1 =\u0026gt; no, break 使用这个 atomic {} 我们要保证程序不能在 atomic 内部 break 或 return。\nProgramming Philosophy\n在书写不是 performance bottle neck 的代码时，我们应该尽可能将代码写得简单，尽量不要写奇技淫巧，以牺牲可读性、可维护性为代价换取微不足道的性能。此外，我们应该在程序中添加足够的 assertion 来尽早抓取到 bug。\nL2 一个允许嵌套的大锁：\nint locked; void lock() { int c = cpu_current(); bool i = ienabled(); iset(false); nest[c]++; if (nest[c] == 1) { intena[c] = i; while (atomic_xchg(\u0026amp;locked, 1)); } } void unlock() { int c = cpu_current(); nest[c]--; if (nest[c] == 0) { atomic_xchg(\u0026amp;locked, 0); if (intena[c]) iset(true); } } Programming Philosophy\n在写代码的过程中，在一行里写很多表达式，让一行变得很长是一种 bad practice。我们可以适时地用一些临时变量保存一些值，这样可以大幅提高代码的可读性和可维护性。\n线程创建：\nstruct task { Context ctx[4]; int nc; int stk[STK_SZ]; }; struct percpu { struct task *avail[NPROC]; int n, c; }percpu[MAX_CPU]; struct task *kcreate(void *entry, void *arg, int cpu) { struct task *t = kalloc(sizeof(struct task)); atomic { t-\u0026gt;ctx[0] = *kcontext((Area){\u0026amp;t-\u0026gt;stk, \u0026amp;t-\u0026gt;stk + STK_SZ}, entry, arg); t-\u0026gt;nc = 1; percpu[cpu].avail[percpu[cpu].n++] = t; } return t; } 一个最简单的 round-robin 调度器：保存当前线程的上下文，切换到下一个线程，返回目标线程的上下文。\n#define CPU (\u0026amp;percpu[cpu_current()]) #define current (CPU-\u0026gt;avail[CPU-\u0026gt;c]) Context *trap(Event ev, Context *ctx) { current-\u0026gt;ctx[current-\u0026gt;nc++] = *ctx; atomic { CPU-\u0026gt;c = (CPU-\u0026gt;c + 1) % (CPU -\u0026gt; n); } assert(!ienabled()); return \u0026amp;(current-\u0026gt;ctx[--current.nc]); } 信号量最简单的语义就是：在没有资源的时候 yield()。\nstruct semaphore { int count; } void sem_wait(sem_t *sem) { bool succ = false; while (!succ) { atomic { if (sem-\u0026gt;count \u0026gt; 0) { sem-\u0026gt;count--; succ = true; } } if (!succ) yield(); } } void sem_post(sem_t *sem) { atomic { sem-\u0026gt;count++; } } Programming Philosophy\n上述的信号量实现是一个比较基础的实现。一个性能更好的实现是调用 sleep()，当前条件不满足的话就释放自旋锁并将自己加入一个等待队列，但这种实现就会引入更多可能错误的点。事实上，我们可以为各个模块都准备一份 functional 的代码 (非常简单，保证正确，类似于模型) 和一份注重性能的代码。当项目出现 bug 的时候，我们就将一个一个模块换回 dummy 的实现，从而快速定位问题。\nL3 ucreate 和 kcreate 结构差不多，这次我们使用 ucontext 创建初始上下文。我们假设代码段总是被加载到地址空间的开头。此外，现在 task 结构体中还需要加入一个地址空间 AddrSpace as。\ntask_t *ucreate(int cpu) { task_t *t = kalloc(sizeof(task_t)); atomic { protect(\u0026amp;t-\u0026gt;as); t-\u0026gt;ctx[0] = *ucontext(\u0026amp;t-\u0026gt;as, (Area){\u0026amp;(t-\u0026gt;stk), \u0026amp;(t-\u0026gt;stk)+STK_SIZE}, \u0026amp;t-\u0026gt;as); t-\u0026gt;nc = 1; percpu[cpu].avail[percpu[cpu].n++] = t; } return t; } 在 os_trap 中，我们要检查更多的事件，例如 page fault，syscall 等：\nswitch (ev.event) { case EVENT_PAGEFAULT: { pagefault(ev, ctx); break; } case EVENT_SYSCALL: { assert(current-\u0026gt;nc == 1); current-\u0026gt;ctx[0].GPRx = syscall(ctx); break; } case EVENT_ERROR: { panic(); break; } default: break; } 缺页异常我们的处理是在虚拟地址空间中为当前虚拟地址映射一个物理页面。此外如果缺少的是第一个页面 (即 init 进程的代码段) 我们要把代码段拷贝进来。\nvoid pgmap(task_t *t, void *va, void *pa) { t-\u0026gt;va[t-\u0026gt;np] = va; t-\u0026gt;pa[t-\u0026gt;np] = pa; t-\u0026gt;np++; map(\u0026amp;t-\u0026gt;as, va, pa, MMAP_READ | MMAP_WRITE); } void pagefault(Event e, Context *c) { atomic { AddrSpace *as = \u0026amp;(current-\u0026gt;as); void *pa = kalloc(as-\u0026gt;pgsize); void *va = (void *)(e.ref \u0026amp; ~(as-\u0026gt;pgsize - 1L)); if (va == as-\u0026gt;area.start) memcpy(pa, _init, _init_len); pgmap(current, va, pa); } } 处理各种系统调用：\nint syscall(Context *c) { int ret = 0; ise(true); switch (c-\u0026gt;GPRx) { case SYS_kputc: { putch(c-\u0026gt;GPR1); break; } case SYS_sleep: { uint64_t wakeup = io_read(AM_TIMER_UPTIME).us + 1000000L * c-\u0026gt;GPR1; while (io_read(AM_TIMER_UPTIME).us \u0026lt; wakeup) yield(); } case SYS_fork: { atomic { struct task *t = ucreate(cpu_current()); uintptr_t rsp0 = t-\u0026gt;ctx[0].rsp0; void *cr3 = t-\u0026gt;ctx[0].cr3; t-\u0026gt;ctx[0] = *c; t-\u0026gt;ctx[0].rsp0 = rsp0; t-\u0026gt;ctx[0].cr3 = cr3;\t// 子进程的页表和内核栈不能复制父进程 t-\u0026gt;ctx[0].GPRx = 0;\t// 子进程的返回值应该是0 for (int i = 0; i \u0026lt; current-\u0026gt;np; i++) { int sz = current-\u0026gt;as.pgsize; void *va = current-\u0026gt;va[i]; void *pa = current-\u0026gt;pa[i]; void *npa = kalloc(sz); memcpy(npa, pa, sz); pgmap(t, va, npa); } } } } iset(false); } ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"adb680e2242ace1af1c89d623ee0d140","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec22/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec22/","section":"notes","summary":"L1 一把大锁保平安策略：全局用一把锁，把所有需要保护的代码都用 atomic {} 框起来。\n#define atomic \\ for (int __i = (lock(), 0); i \u0026lt; 1; unlock(), __i++) 这个 for 循环的语义如下：\nlock(); __i = 0;\t// C语言逗号表达式总是取后面的值 check i \u0026lt; 1 =\u0026gt; yes body __i++; unlock(); check i \u0026lt; 1 =\u0026gt; no, break 使用这个 atomic {} 我们要保证程序不能在 atomic 内部 break 或 return。","tags":null,"title":"Lecture 22: OSLab Speedrun","type":"docs"},{"authors":null,"categories":null,"content":"机器指令模型只有两种当前状态：寄存器和物理内存。这些状态在物理世界中应当有真实的对应。我们的需求是：\n可以寻址：比如可以根据编号访问某个单元格。 访问速度尽可能快 (甚至不惜掉电后丢失状态)。 “当前状态”的存储\n延迟线 (delay line)：像一根存储了数据的绳子不断地转，信号会随着时间衰减，因此数据会不断通过放大器来保持不丢失。\n磁芯内存 (Magnetic core)：类似于一个二维的小磁铁阵列，当给第 $i$ 行第 $j$ 列加电时，坐标在 $(i,j)$ 处的小磁铁就有足够大的电流可以旋转。磁芯内存是 non volatile memory - 掉电后 core 的信息是不会丢失的。但信息的改变依赖小磁铁转动这一物理动作，因此速度不够高。\n\u0026ldquo;Segmentation fault (core dumped)\u0026rdquo;\n这里的“核心已转储”的说法就是源自于磁芯内存。Linux 系统中默认的 core file size 是 0 (可以通过命令 ulimit -a 查看)，可以通过 ulimit -c size 来修改。\n此外，在 Ubuntu 系统中，我们还需要在 root 权限下通过\necho core \u0026gt; /proc/sys/kernel/core_pattern 修改对应文件。这样发生段错误后，系统将在程序当前目录下生成一个 core 文件。我们可以用 segfault.c 做一个实验。段错误后，使用 gdb segfault core 再次运行，就可以恢复 crash 的现场。\nSRAM/DRAM：flip-flop\nMagnetism 用小磁铁的方向来表示 0 和 1，不同方向的小磁铁会有不同方向的磁场，从而可以感应出不同方向的电流。此外，电流产生的磁场也可以用来修改小磁铁的方向。\nMagnetic Tape (1928) 磁带本质上是一个 1D 的存储设备，但我们可以通过把磁带卷起来使其变成一个近似 2D 的存储设备。因此可以在小空间内存放大量的 bit。在中间位置放一个读写头，然后通过机械转轮来定位当前读写的位置。\n优点：便宜，容量大，存储时间相对较长 缺点：完全无法随机读取 (只能靠机械转轮移动) 因此磁带主要用于大量冷数据的长时间存储。\nMagnetic Drum (1932) 磁鼓一定程度解决了磁带无法随机读取的问题：将磁带一圈一圈绕在一个金属棒上，然后在棒子的侧面放很多读写头，这样读取一个 bit 的时间控制在棒子转一圈的时间之内。磁鼓的缺点是：占用的空间太大了\nHard Disk (1956) 将磁带内卷在一个二维平面上，中间是转轴。磁盘中只有一个读写头，但读写头上有一个电动机，读写头的移动可以使其快速定位磁带的某个圈，磁带的旋转可以使圈上某个位置的信息到达读写头的位置。这样不仅速度快，而且占用体积大幅下降。\n工程上对磁盘还有一些优化，比如在 z 轴上排列若干个圆盘，放置多个读写头等等。此外磁盘中的每个盘实际上不是用磁带绕出来的，而是使用了更先进的生产工艺。\n优点：便宜，容量大，有勉强可用的随机读取能力 缺点：可靠性低，存在机械部件，磁头划伤盘片可能导致数据丢失。 磁盘是当今计算机系统的主力数据存储。\n磁盘当中有很多事情是可以调度的，从前这个调度由操作系统负责，但现在的磁盘越做越复杂，很多内部参数已经超出了操作系统的控制，因此现代的磁盘通常会有一个片上系统 (system on chip, SoC)，这种写死的固件负责磁盘中的调度算法。\nFloppy Disk (1971) 能不能将盘片和读写头分开，从而实现数据移动？这就有了软盘。刚开始软盘真的是软的，后来的 3.5 英寸软盘为了可靠性已经是硬的了。\n优点：价格低，数据可移动 缺点：由于是暴露的存储介质，所以可靠性低，且数据密度不能太大。 Pits 在一个平整的平面上挖一些坑，这样光照在平整的地方可以很好地反射，照在坑上就不能很好地反射，从而实现 0 和 1。\nCompact Disk (CD, 1980) 在反射平面 (1) 上挖上粗糙的坑 (0)，激光扫过表面，就可以读出信息。CD 的一大问题在于只读性——挖坑容易填坑难。有一些例如 PCM (phase-change material) 的材料可以做出 rewritable disk。\n优点：价格低，容量大，可靠性很高\n光盘的一个很有意思的优点是它很容易通过“压盘”来复制：我们可以制作一个母盘，在该挖坑的地方凸起，然后一张平整盘往上一压就是一张盘。\n缺点：随机读取能力不高，改写困难。\nElectricity 之前的持久存储介质都有一个致命的缺陷：存在一些机械部件，机械部件可靠性不高且速度跟不上，要跟上电路的速度，我们必须用电来做存储介质。\nSolid State Drive (SSD, 1991) Flash memory 的 floating gate 的充电放电实现了 0-1。\n优点：大规模集成电路价格低，容量很大；flash memory 的最大优势在于读写速度，而且它有一个不讲道理的特性：容量越大速度越快 (电路级并行)；可靠性非常高：没有机械部件，所以可以随便摔。\n缺点：几乎无。\nUSB Flash Disk (1999) 迅速击败软盘，成为人手 $n$ 个的移动存储设备。\nFlash memory 有一个关键的问题：放电会放不干净，一个 cell 经过了成千上万次读写操作后，剩余的电子就会多到好像是 1 的状态，这个 cell 成为了一个 dead cell。\n该问题的解决方法类似于虚拟内存：在 OS 眼中不论是 SSD 还是 HDD 都类似于一个大数组，但事实上 SSD 里面有一个小型的计算机系统：系统会根据每个 cell 的读写次数，将所谓的 “100号cell\u0026quot; 映射到一个其他的 cell，就像一个 MMU 一样。这样可以保证每个 cell 使用次数差不多，也可以绕开一些 dead cell。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"711c8d42cbaadd7729a5b67df5817e84","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec23/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec23/","section":"notes","summary":"机器指令模型只有两种当前状态：寄存器和物理内存。这些状态在物理世界中应当有真实的对应。我们的需求是：\n可以寻址：比如可以根据编号访问某个单元格。 访问速度尽可能快 (甚至不惜掉电后丢失状态)。 “当前状态”的存储\n延迟线 (delay line)：像一根存储了数据的绳子不断地转，信号会随着时间衰减，因此数据会不断通过放大器来保持不丢失。\n磁芯内存 (Magnetic core)：类似于一个二维的小磁铁阵列，当给第 $i$ 行第 $j$ 列加电时，坐标在 $(i,j)$ 处的小磁铁就有足够大的电流可以旋转。磁芯内存是 non volatile memory - 掉电后 core 的信息是不会丢失的。但信息的改变依赖小磁铁转动这一物理动作，因此速度不够高。\n\u0026ldquo;Segmentation fault (core dumped)\u0026rdquo;\n这里的“核心已转储”的说法就是源自于磁芯内存。Linux 系统中默认的 core file size 是 0 (可以通过命令 ulimit -a 查看)，可以通过 ulimit -c size 来修改。","tags":null,"title":"Lecture 23: 1Bit Storage","type":"docs"},{"authors":null,"categories":null,"content":"Overview 用户直接使用的其实并不是计算设备，而是 I/O 设备。CPU 只是一个无情的指令执行器，我们希望计算机可以感知外部世界的状态，并对外实施动作。\nI/O 设备就是与 CPU 交换数据的一组接口。I/O 设备会提供“几条约定好功能的线”，CPU 与设备通过握手信号可以从线上读出或写入数据。通常来说，CPU 和 I/O 设备交互的数据主要有状态 (比如 CPU 查看打印机是否空闲)，指令 (比如 CPU 让显示屏发光) 和数据 (比如 CPU 告诉打印机应该打印什么)。\n从抽象层的角度来说，CPU 完全不需要管 I/O 设备内部是怎么实现的，CPU 可以直接使用指令 (in/out/mmio) 和设备交换数据。但各种设备的复杂性还是使得驱动代码成为操作系统内核中非常庞大、bug非常多的一部分代码。\nExample: UART #define COM1 0x3f8 static int uart_init() { outb(COM1 + 2, 0); // 控制器相关细节 outb(COM1 + 3, 0x80); outb(COM1 + 0, 115200 / 9600); ... } static void uart_tx(AM_UART_TX_T *send) { outb(COM1, send-\u0026gt;data); } static void uart_rx(AM_UART_RX_T *recv) { recv-\u0026gt;data = (inb(COM1 + 5) \u0026amp; 0x1) ? inb(COM1) : -1; } 这是 AbstractMachine 中关于串口的一部分实现。可以看到 CPU 和 IO 设备交互的基本方式是：CPU 通过 in/out 指令从设备寄存器中读取信息 (这里使用了 memory mapped io，设备寄存器是地址 COM1 开始的若干内存单元)。\nExample: Keyboard 键盘相较于串口更加复杂，现在的很多键盘是可编程的，比如我们可以软件控制 ScrollLock, CapsLock, NumLock 等灯的亮暗，可以设置按下按键时产生字符的重复速度等等。事实上 AM 采用的键盘接口只提供了两个设备寄存器，一个是数据 data (0x60)，一个是 status/command 复用的寄存器 (0x64)，各种丰富的功能都靠这两个寄存器的值的组合来实现，因此这其中有大量的约定/协议。我们的驱动程序相当于要完成这样一个 API：\nint keyboard_handler(int *rega, int *regb); 只有两个参数，但要识别出各种功能，所以代码相当难写。\nExample: Disk Controller void readsect(void *dst, int sect) { waitdisk(); out_byte(0x1f2, 1); // sector count (1) out_byte(0x1f3, sect); // sector out_byte(0x1f4, sect \u0026gt;\u0026gt; 8); // cylinder (low) out_byte(0x1f5, sect \u0026gt;\u0026gt; 16); // cylinder (high) out_byte(0x1f6, (sect \u0026gt;\u0026gt; 24) | 0xe0); // drive out_byte(0x1f7, 0x20); // command (write) waitdisk(); for (int i = 0; i \u0026lt; SECTSIZE / 4; i ++) ((uint32_t *)dst)[i] = in_long(0x1f0); // data } 这段代码是 AbstractMachine 中的 readsect()。它的逻辑要比串口更加复杂一些，首先调用 waitdisk() 等待设备准备就绪，然后向设备控制寄存器写入一些数据控制磁盘向我们返回我们需要的数据 (这些内容是手册规定的)，写完 command 后我们再调用 waitdisk() 等待设备准备就绪，最终把数据给读出来。\nExample: Printer 如果要设计一个打印机对外接口，最简单的实现就是一个表示状态的寄存器 status 和一个传输打印数据流的寄存器 data。在这个简单的模型下，我们也可以做到一些很优雅的事情。\nPostScript 是一种描述页面布局的比较底层的编程语言。一个小例子如下：\n%! % http://www.cs.cmu.edu/afs/andrew/scs/cs/15-463/98/pub/www/assts/ps.html 72 72 scale\t% scale coordinate system so units are inches, not points 2 2 translate\t% put origin 2 inches from lower left of page /Courier findfont .6 scalefont setfont % current font is now Courier about .6 inches high gsave\t% save graphics state (coordinate system \u0026amp; stuff) .5 setgray 60 rotate 0 0 moveto (Read the friendly manual) show grestore\t% restore previous graphics state /Helvetica-Bold findfont .2 scalefont setfont % current font is now slanted Helvetica about .2 inches high 0 4 moveto (Read the friendly source code) show /Times-Italic findfont .5 scalefont setfont % current font is now italic Times about .5 inches high 1 0 0 setrgbcolor 0 6 moveto (Search the friendly Web) show showpage 它可以指定画笔的位置、颜色、角度，指定字体、大小等等。由于它是矢量绘图，所以清晰度很高。\n我们完全可以以 PostScript 作为标准做一套完整的工具链：比如以 Latex 为前端，写一个编译器将 Latex 编译成 PostScript，然后我们给设备传输的字节流就是 PostScript 格式的数据。硬件设备里写一个 PostScript 的解释器将 PostScript 翻译成打印机物理硬件的动作。\n当然，像打印机这种有切实物理机械部件的设备，会有很多情况需要处理，比如卡纸，缺墨等等，因此打印机的手册相当相当长。\nBus, Interrupt Controller and DMA Bus 如果我们的世界里只有鼠标，键盘，显示屏几个固定的 I/O 设备，那么将它们和 CPU 连起来的最简单的方式就是在 CPU 上留几个对应的接口——每个设备插一个。但 I/O 设备会越来越多，如果要让 CPU 支持未来可能出现的更多的 I/O 设备，我们就需要一个更聪明的实现方案。\n我们可以假设有这样一个特殊的 I/O 设备，它上面有若干个插槽，我们可以将各式各样的 I/O 设备插在上面。这个 I/O 设备负责管理插在它上面的其他 I/O 设备。CPU 只需要和这个 I/O 设备通信，当 CPU 需要某个设备的某个寄存器的值时，这个 I/O 设备就会到对应的插槽的对应的寄存器去找数据。这样一个提供设备的注册和地址到设备的转发的特殊 I/O 设备就是总线 (bus)。\n我们可以做的更彻底一点：我们把内存 DRAM 也连到总线上面，这样 CPU 就真的只需要和总线交互了。内存单元有对应的地址，我们可以给设备寄存器也编上地址，这样 CPU 和总线之间只需要一根地址线和一根数据线 (当然，其实还需要一根用于握手的控制线)，CPU 就可以通过一个简单的地址来任意读写内存和 I/O 设备上的数据。\n这里有一段示例代码：\n// pci-probe.c #include \u0026lt;am.h\u0026gt; #include \u0026lt;klib.h\u0026gt; static inline uint32_t inl(int port) { uint32_t data; asm volatile (\u0026quot;inl %1, %0\u0026quot; : \u0026quot;=a\u0026quot;(data) : \u0026quot;d\u0026quot;((uint16_t)port)); return data; } static inline void outl(int port, uint32_t data) { asm volatile (\u0026quot;outl %%eax, %%dx\u0026quot; : : \u0026quot;a\u0026quot;(data), \u0026quot;d\u0026quot;((uint16_t)port)); } uint32_t pciconf_read(uint32_t bus, uint32_t slot, uint32_t func, uint32_t offset) { uint32_t reg = (bus \u0026lt;\u0026lt; 16) | (slot \u0026lt;\u0026lt; 11) | (func \u0026lt;\u0026lt; 8) | (offset) | 0x80000000; outl(0xcf8, reg); return inl(0xcfc); } int main() { ioe_init(); for (int bus = 0; bus \u0026lt; 256; bus ++) { for (int slot = 0; slot \u0026lt; 32; slot ++) { uint32_t info = pciconf_read(bus, slot, 0, 0); uint16_t id = info \u0026gt;\u0026gt; 16, vendor = info \u0026amp; 0xffff; if (vendor != 0xffff) { printf(\u0026quot;%02d:%02d device %x by vendor %x\u0026quot;, bus, slot, id, vendor); if (id == 0x100e \u0026amp;\u0026amp; vendor == 0x8086) { printf(\u0026quot; \u0026lt;-- This is an Intel e1000 NIC card!\u0026quot;); } printf(\u0026quot;\\n\u0026quot;); } } } } 该代码扫描 PCI 总线上的每个插槽并检查上面是否有设备，此外它会额外指出以太网卡。运行该程序可以看到结果\n0: 0 device 1237 by vendor 8086 0: 1 device 7000 by vendor 8086 0: 2 device 1111 by vendor 1234 0: 3 device 100e by vendor 8086 \u0026lt;-- This is an Intel e1000 NIC card! 我们还可以通过 qemu 的选项来模拟出一些新的设备：-device AC97 选项可以模拟出一个声卡。我们添加这个选项运行后，得到的结果确实多了一个设备：\n0: 0 device 1237 by vendor 8086 0: 1 device 7000 by vendor 8086 0: 2 device 1111 by vendor 1234 0: 3 device 100e by vendor 8086 \u0026lt;-- This is an Intel e1000 NIC card! 0: 4 device 2415 by vendor 8086 Interrupt Controller CPU 是无情的执行指令和响应外部中断的机器。CPU 上有一个专门的 IRQ 引脚用来接收中断信号，接收到代表中断的电信号以后，CPU 会保存一些寄存器，然后根据中断向量表对应项跳转执行中断处理程序。以前 IRQ 引脚引出的线会接到一个 Intel 8259 PIC 上 (programmable interrupt controller)，这个可编程的中断控制器可以设置各种中断屏蔽，中断优先级等等。现在有了总线之后，IRQ 连到了总线上。现在的 CPU 中有一个 APIC 模块 (Advanced PIC)，其中 local APIC 每个 CPU 一个，负责处理时钟中断，IPI 等；I/O APIC 全局一个，负责处理设备中断。\nInter Processor Interrupt (IPI)\n在多核处理器中，一个 CPU 核可以给另一个 CPU 核发送中断。比如在开机的时候，刚开始只有一个 CPU 核被唤醒，它执行完一些初始化操作后，就需要通过 IPI 来唤醒其他的 CPU 核开始并发执行。\nIPI 还有更多重要的用途。假设当前有两个 CPU 核，这两个核运行了两个线程，有独立的 cache 和 TLB，但共享内存。第一个核执行了一个 mmap 操作，将内存中的某一段做了映射。但这期间如果第二个核没有任何系统调用/中断，那么第二个核的 TLB 就没有更新！多核之间的内存可见性就消失了。因此第一个核需要发送一个 IPI 给第二个核来做一些更新，这个操作叫做 TLB shotdown。\nDirect Memory Access (DMA) 中断 I/O 相较于轮询 I/O 解决了一个问题：我们的 CPU 不用浪费时钟周期轮询等待 I/O 设备准备就绪，而是可以在设备准备好的时候给 CPU 发送一个中断信号。但我们还有一个问题没有解决：向设备传输数据这件事本身也是很慢的，比如我现在要将 1GiB 的数据写入磁盘，如果我的代码是这么写的：\nfor (int i = 0; i \u0026lt; 1 GB / 4; i++) outl(PORT, ((uint32 *)buf)[i]); 那这个拷贝过程要花相当长时间。事实上，由于电气特性的限制，CPU 和总线之间存在性能 gap：总线上的设备无法做到 CPU 那么快，这无疑浪费了 CPU 的时间。\n我们自然的想法是：如果我们有一个小 CPU 专门帮我们做数据拷贝就好了。它不需要通用 CPU 那么复杂，它只要能做 memcpy() 就行了，这样大 CPU 就可以被解放出来干别的事情。这就是 DMA，DMA 的本质就是一个专职 memcpy() 的小 CPU。DMA 支持从 memory 到 memory，从 memory 到 device(register)，从 device(register) 到 memory 等若干种 memcpy()，现在的 DMA 控制器直接连在总线和内存上。\nGPU and Heterogeneous Computing DMA 相当于一个专门执行 memcpy 的小 CPU。I/O 设备和计算机之间的边界逐渐模糊。我们能不能将一些其他任务交给小 cpu 做呢？显卡就是专门绘图的 I/O 设备。\n让 CPU 绘图会遇到一些性能瓶颈：以 NES 为例，如果我们要实现 60fps，就要在 10K 指令内完成一帧的绘制，而一帧的像素有 60K，这是不可能完成的任务。NES 的做法是：画面其实是用若干方块拼出来的，CPU 只需要描述将哪些方块放在什么位置，将这样一个脚本 (本质上和 PostScript) 一样发送给 NES Picture Processing Unit (PPU)，让 PPU 来完成图形显示。由于 PPU 只负责绘制图形，功能单一但算力强大，所以可以支持 60fps。\n现代的 GPU 是一个通用的计算设备：它是一个完整的众核多处理器系统，有很多很多 (远多于 CPU core) 的核心数量和一个很大的 memory (显存)，GPU 从 DMA 拉数据和要执行的代码放到 memory 里，然后完成计算后再将结果推出去。\nDark Silicon Age 的到来意味着功耗成为限制 CPU 性能优化的瓶颈，CPU 的频率很难再往上提，CPU core 的数量也要受到 cache coherence 等因素的制约。因此现在很多的需求都是通过开发新的 system on chip (SoC) 来实现，比如神经网络相关的 NPU 等。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"8b6cdb4675034ebe1a2085689caf93e4","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec24/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec24/","section":"notes","summary":"Overview 用户直接使用的其实并不是计算设备，而是 I/O 设备。CPU 只是一个无情的指令执行器，我们希望计算机可以感知外部世界的状态，并对外实施动作。\nI/O 设备就是与 CPU 交换数据的一组接口。I/O 设备会提供“几条约定好功能的线”，CPU 与设备通过握手信号可以从线上读出或写入数据。通常来说，CPU 和 I/O 设备交互的数据主要有状态 (比如 CPU 查看打印机是否空闲)，指令 (比如 CPU 让显示屏发光) 和数据 (比如 CPU 告诉打印机应该打印什么)。\n从抽象层的角度来说，CPU 完全不需要管 I/O 设备内部是怎么实现的，CPU 可以直接使用指令 (in/out/mmio) 和设备交换数据。但各种设备的复杂性还是使得驱动代码成为操作系统内核中非常庞大、bug非常多的一部分代码。","tags":null,"title":"Lecture 24: I/O Devices","type":"docs"},{"authors":null,"categories":null,"content":"在操作系统眼里，I/O 设备 = 一组寄存器 + 一个控制协议。不同设备的控制协议千差万别，如果让软件直接和这些设备寄存器打交道，即使操作系统仔细地管理好访问权限，应用程序也很容易出错。所以我们的想法是：对不同的设备做一个抽象，使得上层应用可以通过尽可能统一的接口来访问设备。\nOverview I/O 设备最基本的需求就是 read 和 write。UNIX 世界里的设备通常分为两种：\n字符设备 (character device)，设备与 OS 之间传送的是字节流。我们可以把这种设备想象成一个管道。终端、打印机等都是典型的字符设备。\n块设备 (block device)，我们可以把这种设备想象成一个字符数组，这样的设备通常有 persistence 的需求，比如磁盘。\n显卡是一种什么样的设备？\n显卡中其实既有字节流 (比如控制信号修改显卡的参数)，又有字节数组 (显卡里面有显存)。(不过显存不是按照块设备的方式来抽象的)\n操作 I/O 设备，我们至少需要如下的三个 API：\nread：从设备的某个指定的位置读出数据 (如果是字符设备，则是从当前的最新位置)。 write：向设备的某个指定的位置写入数据。 ioctl：读取/设置设备的状态 (比如对于 GPU 来说，设置分辨率，对于打印机来说，检查纸张等)。 设备驱动程序的作用之一就是将这些统一的系统调用 API 翻译成对应到具体设备的寄存器的操作。在计算机系统的世界中这样的抽象层很多：\nShell 负责将人类发出的命令行指令翻译成底层的系统调用；\nDriver 负责将系统调用翻译成设备相关的寄存器操作；\n……\n计算机系统世界就是这样一层一层抽象垒起来的。\n虚拟设备\n在操作系统眼里，设备就是在执行系统调用的时候运行对应的驱动程序，操作系统不关心驱动程序究竟干了什么，因此我们可以有虚拟设备的概念：驱动程序可以真的和一个物理设备进行了交互，也可以只是模拟了一些行为。\n/dev/null 就是一个典型的虚拟设备。它像一个黑洞一样，可以吃掉所有向它输出的内容。它的设备驱动程序非常简单：对于 write，不论写入的内容是什么，它直接返回一个写入成功即可。对于 read，不论要读入什么，也都直接返回。\n设备的复杂性\n虽然设备的数据传输是其“主要”的功能，但剩下的控制功能种类繁多：比如现代的键盘可以支持呼吸灯、跑马灯、按键编程，现代打印机可以控制打印质量、卡纸、清洁、自动装订等等。这些控制功能全部依赖 ioctl 系统调用，导致其中有无比复杂的 hidden specification。\nLinux Device Drivers 这里有一个非常简单的，用于“引爆核弹”的设备驱动：\n// launcher.c #include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; #include \u0026lt;linux/cdev.h\u0026gt; #include \u0026lt;linux/device.h\u0026gt; #include \u0026lt;linux/fs.h\u0026gt; #include \u0026lt;linux/uaccess.h\u0026gt; #define MAX_DEV 2 static int dev_major = 0; static struct class *lx_class = NULL; static struct cdev cdev; static ssize_t lx_read(struct file *, char __user *, size_t, loff_t *); static ssize_t lx_write(struct file *, const char __user *, size_t, loff_t *); static struct file_operations fops = { .owner = THIS_MODULE, .read = lx_read, .write = lx_write, }; static struct nuke { struct cdev cdev; } devs[MAX_DEV]; static int __init lx_init(void) { dev_t dev; int i; // allocate device range alloc_chrdev_region(\u0026amp;dev, 0, 1, \u0026quot;nuke\u0026quot;); // create device major number dev_major = MAJOR(dev); // create class lx_class = class_create(THIS_MODULE, \u0026quot;nuke\u0026quot;); for (i = 0; i \u0026lt; MAX_DEV; i++) { // register device cdev_init(\u0026amp;devs[i].cdev, \u0026amp;fops); cdev.owner = THIS_MODULE; cdev_add(\u0026amp;devs[i].cdev, MKDEV(dev_major, i), 1); device_create(lx_class, NULL, MKDEV(dev_major, i), NULL, \u0026quot;nuke%d\u0026quot;, i); } return 0; } static void __exit lx_exit(void) { device_destroy(lx_class, MKDEV(dev_major, 0)); class_unregister(lx_class); class_destroy(lx_class); unregister_chrdev_region(MKDEV(dev_major, 0), MINORMASK); } static ssize_t lx_read(struct file *file, char __user *buf, size_t count, loff_t *offset) { if (*offset != 0) { return 0; } else { uint8_t *data = \u0026quot;This is dangerous!\\n\u0026quot;; size_t datalen = strlen(data); if (count \u0026gt; datalen) { count = datalen; } if (copy_to_user(buf, data, count)) { return -EFAULT; } *offset += count; return count; } } static ssize_t lx_write(struct file *file, const char __user *buf, size_t count, loff_t *offset) { char databuf[4] = \u0026quot;\\0\\0\\0\\0\u0026quot;; if (count \u0026gt; 4) { count = 4; } copy_from_user(databuf, buf, count); if (strncmp(buf, \u0026quot;\\x01\\x14\\x05\\x14\u0026quot;, 4) == 0) { const char *EXPLODE[] = { \u0026quot; ⠀⠀⠀⠀⠀⠀⠀⠀⣀⣠⣀⣀⠀⠀⣀⣤⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⠀⠀⣀⣠⣤⣤⣾⣿⣿⣿⣿⣷⣾⣿⣿⣿⣿⣿⣶⣿⣿⣿⣶⣤⡀⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⢠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣶⡀⠀\u0026quot;, \u0026quot; ⠀⢀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀\u0026quot;, \u0026quot; ⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠿⠟⠁⠀\u0026quot;, \u0026quot; ⠀⠀⠻⢿⡿⢿⣿⣿⣿⣿⠟⠛⠛⠋⣀⣀⠙⠻⠿⠿⠋⠻⢿⣿⣿⠟⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⠀⠀⠀⠀⠀⠈⠉⣉⣠⣴⣷⣶⣿⣿⣿⣿⣶⣶⣶⣾⣶⠀⠀⠀⠀⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⠀⠀⠀⠀⠀⠀⠀⠉⠛⠋⠈⠛⠿⠟⠉⠻⠿⠋⠉⠛⠁⠀⠀⠀⠀⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣶⣷⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⠀⠀⠀⠀⠀⢀⣀⣠⣤⣤⣤⣤⣶⣿⣿⣷⣦⣤⣤⣤⣤⣀⣀⠀⠀⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⠀⠀⠀⢰⣿⠛⠉⠉⠁⠀⠀⠀⢸⣿⣿⣧⠀⠀⠀⠀⠉⠉⠙⢻⣷⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⠀⠀⠀⠀⠙⠻⠷⠶⣶⣤⣤⣤⣿⣿⣿⣿⣦⣤⣤⣴⡶⠶⠟⠛⠁⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⣿⣿⣿⣿⣿⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u0026quot;, \u0026quot; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠒⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠓⠀⠀⠀⠀⠀⠀⠀⠀⠀\u0026quot;, }; int i; for (i = 0; i \u0026lt; sizeof(EXPLODE) / sizeof(EXPLODE[0]); i++) { printk(\u0026quot;\\033[01;31m%s\\033[0m\\n\u0026quot;, EXPLODE[i]); } } else { printk(\u0026quot;nuke: incorrect secret, cannot lanuch.\\n\u0026quot;); } return count; } module_init(lx_init); module_exit(lx_exit); MODULE_LICENSE(\u0026quot;GPL\u0026quot;); MODULE_AUTHOR(\u0026quot;jyy\u0026quot;); 该驱动在 linux 系统启动后被编译成一个 .ko 文件后“动态加载”，其中 lx_init() 和 lx_exit() 的内容非常琐碎 (所以驱动是 bug 重灾区！)，lx_read() 和 lx_write() 是 read()/write() 系统调用会使用的驱动函数。如果我们读 /dev/nuke0 这个设备，会得到 “This is dangerous!\u0026quot;，如果我们向这个设备写入数据，lx_write() 会检查写入的数据是否是 SECRET，如果是就会打印核弹爆炸的图案。\n为什么 Linux 中有两种 ioctl?\n在单处理器时代 Linux 中只有 ioctl，后来多处理器时代 Linux 内核加装了 big kernel lock (BKL)，ioctl 执行时默认持有 BKL，从而驱动的执行 (本身较慢) 会使得很多线程被阻塞。后来 Linux 推出了 unlocked_ioctl，高性能的驱动可以使用该 ioctl 来避免上锁，再后来 ioctl 被删除，只剩下 unlocked_ioctl。\ncompact_ioctl 是在 64-bit 机器的兼容模式下运行 32-bit 程序时使用的 ioctl。\nProgramming for GPU GPU 使用的是一种 SIMT (single instruction multiple thread) 的架构：相当于 GPU 里有很多的 CPU core，每个 CPU core 有自己的寄存器，core 之间共享内存 (显存)，但使用同一个 \u0026ldquo;PC指针\u0026rdquo;。因此 GPU 适合处理大量计算的简单任务，众核的优势可以使得重复计算被并行分解。\n// mandelbrot.cu #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #define MAX_ITER 100 #define DIM 12800 static uint32_t colors[MAX_ITER + 1]; static uint32_t data[DIM * DIM]; __device__ uint32_t mandelbrot(double x, double y) { double zr = 0, zi = 0, zrsqr = 0, zisqr = 0; int i; for (i = 0; i \u0026lt; MAX_ITER; i++) { zi = zr * zi * 2 + y; zr = zrsqr - zisqr + x; zrsqr = zr * zr; zisqr = zi * zi; if (zrsqr + zisqr \u0026gt; 4.0) break; } return i; } __global__ void mandelbrot_kernel(uint32_t *data, double xmin, double ymin, double step, uint32_t *colors) { int pix_per_thread = DIM * DIM / (gridDim.x * blockDim.x); int tId = blockDim.x * blockIdx.x + threadIdx.x; int offset = pix_per_thread * tId; for (int i = offset; i \u0026lt; offset + pix_per_thread; i++) { int x = i % DIM; int y = i / DIM; double cr = xmin + x * step; double ci = ymin + y * step; data[y * DIM + x] = colors[mandelbrot(cr, ci)]; } if (gridDim.x * blockDim.x * pix_per_thread \u0026lt; DIM * DIM \u0026amp;\u0026amp; tId \u0026lt; (DIM * DIM) - (blockDim.x * gridDim.x)) { int i = blockDim.x * gridDim.x * pix_per_thread + tId; int x = i % DIM; int y = i / DIM; double cr = xmin + x * step; double ci = ymin + y * step; data[y * DIM + x] = colors[mandelbrot(cr, ci)]; } } int main() { float freq = 6.3 / MAX_ITER; for (int i = 0; i \u0026lt; MAX_ITER; i++) { char r = sin(freq * i + 3) * 127 + 128; char g = sin(freq * i + 5) * 127 + 128; char b = sin(freq * i + 1) * 127 + 128; colors[i] = b + 256 * g + 256 * 256 * r; } colors[MAX_ITER] = 0; uint32_t *dev_colors, *dev_data; cudaMalloc((void**)\u0026amp;dev_colors, sizeof(colors)); cudaMalloc(\u0026amp;dev_data, sizeof(data)); cudaMemcpy(dev_colors, colors, sizeof(colors), cudaMemcpyHostToDevice); double xcen = -0.5, ycen = 0, scale = 3; mandelbrot_kernel\u0026lt;\u0026lt;\u0026lt;512, 512\u0026gt;\u0026gt;\u0026gt;(dev_data, xcen - (scale / 2), ycen - (scale / 2), scale / DIM, dev_colors); cudaMemcpy(data, dev_data, sizeof(data), cudaMemcpyDeviceToHost); cudaFree(dev_data); cudaFree(dev_colors); FILE *fp = fopen(\u0026quot;mandelbrot.ppm\u0026quot;, \u0026quot;w\u0026quot;); fprintf(fp, \u0026quot;P6\\n%d %d 255\\n\u0026quot;, DIM, DIM); for (int i = 0; i \u0026lt; DIM * DIM; i++) { fputc((data[i] \u0026gt;\u0026gt; 16) \u0026amp; 0xff, fp); fputc((data[i] \u0026gt;\u0026gt; 8) \u0026amp; 0xff, fp); fputc((data[i] \u0026gt;\u0026gt; 0) \u0026amp; 0xff, fp); } return 0; } mandelbrot.cu 绘制了一个 $12800\\times 12800$ (16亿像素) 的图片，每个像素迭代 100 次。程序中的 __device__ 使得代码可以被编译成 GPU 可以运行的语言。main() 函数中使用了几个 cuda 的 API：cudaMalloc() 在显存中申请了一些空间，cudaMemcpy() 把计算所需的数据拷贝了过去 (当然是通过 DMA)，cudaFree() 释放显存空间。这样庞大的计算量 GPU 只需要 1.7s 左右就可以完成。\nGPU 上有一套完整的工具链：比如 gcc \u0026ndash;\u0026gt; nvcc，objdump \u0026ndash;\u0026gt; cuobjdump，gdb \u0026ndash;\u0026gt; cuda-gdb，perf \u0026ndash;\u0026gt; nvprof 等等。全套工具链的实现都在驱动里，因此 NVIDIA 的驱动非常复杂。\nAbstraction of Storage Devices 存储设备属于块设备，数据块 (block) 是访问的最小单元，且不支持任意的随机访问。应用程序通常通过文件系统来读写存储设备。\nLinux 的 bio (Block I/O) layer 是文件系统和磁盘设备之间的接口。通常一次磁盘访问会包括多个块的读/写，因此 bio layer 中可以有一些调度策略，比如 Linux 总是优先满足 read 操作 (因为执行 read 的程序一般总是依赖数据继续执行)，延缓 write 操作 (只要没有超过 ddl)。\n简单来说，block I/O layer 的 API 是 bread()，bwrite() 和 bflush()，其中最后一个用于处理一些同步问题。我们的文件系统就是在 bio API 的基础上构建一个持久数据结构，并向上层应用提供更简单易用的接口。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"509635abc2a3ad8d0b31b0525156b323","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec25/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec25/","section":"notes","summary":"在操作系统眼里，I/O 设备 = 一组寄存器 + 一个控制协议。不同设备的控制协议千差万别，如果让软件直接和这些设备寄存器打交道，即使操作系统仔细地管理好访问权限，应用程序也很容易出错。所以我们的想法是：对不同的设备做一个抽象，使得上层应用可以通过尽可能统一的接口来访问设备。\nOverview I/O 设备最基本的需求就是 read 和 write。UNIX 世界里的设备通常分为两种：\n字符设备 (character device)，设备与 OS 之间传送的是字节流。我们可以把这种设备想象成一个管道。终端、打印机等都是典型的字符设备。\n块设备 (block device)，我们可以把这种设备想象成一个字符数组，这样的设备通常有 persistence 的需求，比如磁盘。\n显卡是一种什么样的设备？\n显卡中其实既有字节流 (比如控制信号修改显卡的参数)，又有字节数组 (显卡里面有显存)。(不过显存不是按照块设备的方式来抽象的)\n操作 I/O 设备，我们至少需要如下的三个 API：","tags":null,"title":"Lecture 25: Device Drivers","type":"docs"},{"authors":null,"categories":null,"content":"Why File System? 如果设备直接将读/写/控制的接口暴露给应用程序，那么多个应用程序在并发地使用设备时很容易发生竞争。我们考虑下面的例子：\n// printf-race.c #include \u0026lt;stdio.h\u0026gt; #include \u0026quot;thread.h\u0026quot; void use_printf(const char *s) { printf(\u0026quot;%s\u0026quot;, s); } void use_putchar(const char *s) { for (; *s; s++) { putchar(*s); } } void (*print)(const char *) = use_printf; void Tworker() { char buf[128]; int c = gettid() % 4 + 1; sprintf(buf, \u0026quot;\\033[3%dm%d\\033[0m\u0026quot;, c, c); while (1) { print(buf); } } int main(int argc, char *argv[]) { if (argc \u0026gt; 1) { print = use_putchar; } setbuf(stdout, NULL); for (int i = 0; i \u0026lt; 4; i++) { create(Tworker); } } 在 printf-race.c 中，我们创建了 4 个线程，每个线程通过 ANSI Escape Code 用某种颜色打印自己的线程号。如果我们直接运行 ./printf-race，线程会使用 use_printf() 调用库函数 printf() 输出，这时我们能看到正确的结果。但如果我们运行时添上一个参数，比如 ./printf-race xxx，那么线程会使用 use_putchar() 输出，这时我们就会看到大量的错误输出。产生错误的原因是：当 4 个线程并发/并行地使用 putchar() 输出时，它们的输出内容是交织在一起的，这就会导致 Escape Code 被隔断，从而产生预期之外的结果。printf() 函数使用 write 系统调用来输出给定内容，write 系统调用保证了它输出所有内容这个动作是原子的。\n即使我们在设备上面封装一层有原子性的 API，对于块设备我们仍然有难以解决的问题：多个应用程序都需要从磁盘中读写数据，这就像全班人要在一张很大的纸上各自写作业，那么如何保证大家写的内容不会互相覆盖？对于系统来说，如果一个程序出了 bug 会把整个磁盘全部写上垃圾，那就没得玩了。\n多个进程并发地使用内存会导致隔离被打破，我们引入了虚拟内存，给每个进程一个虚拟地址空间。在这里我们的思想是相似的：文件系统向下和物理设备 (磁盘) 打交道，向上为每个程序提供一个虚拟磁盘。虚拟磁盘就是一个可以读写的动态字节序列，我们可以直接把它想象成一个 vector\u0026lt;char\u0026gt;。文件系统不仅需要维护这些 vector，还要负责管理虚拟磁盘的名称，负责检索和遍历。\nVirtual Disk: Naming and Management 维护虚拟磁盘最简单的方法就是存储一堆 名字-vector\u0026lt;char\u0026gt; 的键值对。但这样的形式非常不利于快速检索。因此文件系统采取了树形结构。\nWindows 的文件系统中，每个设备驱动器是一棵树，例如 C 盘，D 盘等。所谓的 “C 盘根目录” 就是 C:\\，根目录下面可以构建一个错综复杂的文件树。如果插入了 U 盘等外设，系统会为它分配一个新的盘符。\n为什么没有 A:\\ 和 B:\\？\nA 盘和 B 盘是曾经的软盘。\nUNIX/Linux 的文件树和 Windows 不同。Linux 中只有一个根 /，更多的设备依靠 Linux 的挂载机制访问。Linux 的挂载类似于“目录树的拼接”，可以指定一个目录，将一个设备的目录树挂到该目录下面。比如当前我们有一个 disk.img 文件，则我们使用\nsudo mount disk.img /mnt 之后，使用 tree /mnt 就可以看到磁盘镜像 disk.img 内的目录树结构。\nLinux 的 mount 命令基于 mount 系统调用实现：\nint mount(const char *source, const char *target, const char *filesystemtype, unsigned long mountflags, const void *data); mount 系统调用的接口更加复杂，除了要指定 source 和 target 外，还要指定文件系统的类型，挂载标志位等等。Linux 的 mount 命令使用起来容易一些，因为它可以自动监测文件系统 (busybox 的 mount 没有这个功能)。\n事实上，真正的 Linux 启动的过程中也是通过挂载完成了文件系统的初始化。我们在 Linux-minimal 里面模拟了这个过程：我们用 qemu 启动的 Linux 内核只包含一个非常小的“文件系统\u0026quot; initramfs，这个文件系统只有非常少的一些文件，而且是存放在内存中的。我们的 Linux-minimal 做了这样一个流程：\nexport PATH=/bin busybox mknod /dev/sda b 8 0 busybox mkdir -p /newroot busybox mount -t ext2 /dev/sda /newroot exec busybox switch_root /newroot/ /etc/init 其中第二行的命令使用 mknod 创建了一个设备文件 /dev/sda，也就是真正的磁盘。第三个命令创建了一个目录 /newroot (在 initramfs 中)，然后我们用 mount 命令将磁盘挂载到了 /newroot 上，这时候我们的 /newroot 其实就是真正意义上的根目录了。最后我们通过 switch_root 命令把 / 切换到 /newroot 上，并删除 initramfs 中的剩下那些多余的东西。\n一个比较微妙的问题是：我们对文件的抽象是磁盘上的一个虚拟磁盘，这个虚拟磁盘是在真实物理磁盘上虚拟出来的。但如果我们做挂载，那么被挂载目录的虚拟磁盘就不是在真实物理磁盘上虚拟出来的，而是在一个虚拟磁盘 (比如 disk.img) 上虚拟出的虚拟磁盘，嵌套了两层。物理磁盘上的虚拟磁盘和虚拟磁盘上的虚拟磁盘显然应该有一些区别。Linux 的处理方式是创建一个 loopback (回环) 设备。回环设备的驱动会把对设备的 read/write 操作转化为对文件的 read/write 操作。我们可以通过 strace 来近距离观察 mount 的过程：\nopenat(AT_FDCWD, \u0026quot;/dev/loop-control\u0026quot;, O_RDWR | O_CLOEXEC) = 3 ioctl(3, LOOP_CTL_GET_FREE) = 1 close(3) 当 Linux 想要创建一个回环设备时，它会先打开设备 /dev/loop-control，然后通过 ioctl 获取一个当前空闲的回环设备号。这里的返回值是 1，所以待会儿创建的回环设备就是 /dev/loop1。\nopenat(AT_FDCWD, \u0026quot;/tmp/demo/disk.img\u0026quot;, O_RDWR | O_CLOEXEC) = 3 openat(AT_FDCWD, \u0026quot;/dev/loop1\u0026quot;, O_RDWR | O_CLOEXEC) = 4 ioctl(4, LOOP_SED_FD, 3) 可以看到，回环设备持有文件描述符 4，Linux 通过一个 ioctl 系统调用将其指向了 disk.img 对应的文件描述符。这样后续对回环设备的读写操作会翻译成对 disk.img 文件的读写操作。\nDirectory API (System Calls) 创建一个目录：mkdir 系统调用，同时可以设置访问权限 删除一个目录：rmdir 系统调用。注意 UNIX 中没有“递归删除”的系统调用。毕竟可以交给软件做的事情就不需要交给操作系统了。rm -rf 会遍历目录递归删除。 遍历一个目录：getdents 系统调用。getdents 在 glibc 中没有封装好的同名库函数。但我们可以使用 readdir() 函数。 Linux 中的一个有趣的机制是链接。Linux 中的链接分硬链接和软链接两种。\n如果我们对一个文件创建一个硬链接，那么这相当于创建了两个“指针” (文件名)，它们指向同一个文件实体。如果修改了一个另一个呈现的内容也会变。如果我们用 ls -i 查看两个文件的 inode 号，我们会发现硬链接的 inode 号和原文件是一样的。事实上，在硬链接创建后，我们无法区分出哪个是原体那个是后复制的。我们可以在 Linux 中通过 ln a b 创建硬链接。\n软链接相当于一个“快捷方式”，当我们访问这个文件时，其实会跳转去访问另一个文件。软链接的使用非常灵活，它可以链接到一个目录 (硬链接只能链接文件)，可以跨文件系统，甚至可以链接到一个当前不存在的目录。我们可以在 Linux 中通过 ln -s a b 创建软链接。\n软链接的任意性和灵活性使得我们的文件树变成了一个文件图，它甚至可以成环：\n#!/bin/bash # fish-dir.sh # Create directories mkdir -p A B C D E F # Create automaton ln -s ../B 'A/\u0026lt;' ln -s ../C 'B/\u0026gt;' ln -s ../D 'C/\u0026lt;' ln -s ../E 'A/\u0026gt;' ln -s ../F 'E/\u0026lt;' ln -s ../D 'F/\u0026gt;' ln -s ../A 'D/_' 我们可以在文件系统中通过软链接创建一个之前 fish.c 中的自动机。通过访问目录来模拟转移。\n每个进程都有一个当前的工作目录，可以用 pwd 命令查看。如果想要修改当前工作目录，则要使用 chdir 系统调用。一个有趣的事情是：像 cat, ls 等命令在 /bin 下都有对应的可执行文件，但 cd 是没有的，这是因为 cd 是一个 shell 内置的命令——基本上所有的命令都是先 fork 出一个子进程再执行命令对应的可执行文件，但 cd 命令要修改的是当前进程的工作目录，显然不能用这种 fork 的方式。\n一个进程下的多个线程是共享 working directory，还是线程之间独立？\nworking directory 是一个环境变量 $PWD，环境变量是每个进程一份，因此线程之间共享 working directory。\nFile API (System Calls) 我们通过 open/pipe 等系统调用可以获得文件描述符。文件描述符可以理解为指向文件的指针，供进程访问。事实上，文件描述符里还保存了当前访问文件的偏移量，比如\nint fd = open(\u0026quot;a.txt\u0026quot;, O_RDWR | O_TRUNC); read(fd, buf, 512); read(fd, buf, 512) 第一次 read 读到的是前 512 字节，第二次 read 读到的就是后 512 字节。lseek 系统调用可以修改当前的文件偏移量。\n偏移量的管理其实有很多的复杂性：比如我们知道 fork 时子进程会继承父进程的文件描述符，那么如果 fork 之后父进程向文件写入 parent，子进程向文件写入 child，我们显然不希望获得 \u0026ldquo;childt\u0026rdquo;，因此在 fork 的设计中，父子进程的文件描述符共享偏移量。此外，操作系统的每个 API 都可能和其他 API 交互，open, execve, dup 等系统嗲用中偏移量的行为各不相同，open 甚至提供了一大堆 flag 设置偏移量的行为。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"493ef6496cb0af17dbc31e14628ea367","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec26/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec26/","section":"notes","summary":"Why File System? 如果设备直接将读/写/控制的接口暴露给应用程序，那么多个应用程序在并发地使用设备时很容易发生竞争。我们考虑下面的例子：\n// printf-race.c #include \u0026lt;stdio.h\u0026gt; #include \u0026quot;thread.h\u0026quot; void use_printf(const char *s) { printf(\u0026quot;%s\u0026quot;, s); } void use_putchar(const char *s) { for (; *s; s++) { putchar(*s); } } void (*print)(const char *) = use_printf; void Tworker() { char buf[128]; int c = gettid() % 4 + 1; sprintf(buf, \u0026quot;\\033[3%dm%d\\033[0m\u0026quot;, c, c); while (1) { print(buf); } } int main(int argc, char *argv[]) { if (argc \u0026gt; 1) { print = use_putchar; } setbuf(stdout, NULL); for (int i = 0; i \u0026lt; 4; i++) { create(Tworker); } } 在 printf-race.","tags":null,"title":"Lecture 26: File System API","type":"docs"},{"authors":null,"categories":null,"content":"数据结构课的一些潜藏的假设：\nrandom access memory，word addressing (不同于磁盘，磁盘是以块为单位访问的) load/store 指令和计算指令执行的代价都是 $O(1)$。 在块设备中，即使访问一个 byte 也需要将它所在的一整个 block 拿出来，因此内存中的数据结构用在磁盘上会造成极大的性能问题。\n块设备提供的设备抽象：\nstruct block blocks[NBLK]; // 磁盘 void bread(int id, struct block *buf) { memcpy(buf, \u0026amp;blocks[id], sizeof(struct block)); } void bwrite(int id, const struct block *buf) { memcpy(\u0026amp;blocks[id], buf, sizeof(struct block)); } bread() 将磁盘中的一个块拉到内存里，bwrite() 将内存中的一个块写入磁盘。\n我们的文件系统在 bread()/bwrite() 上一层层抽象出来：\n我们可以在 read/write 上实现两个 API：balloc() 和 bfree()，这样我们就把整个磁盘中所有的块管理了起来。 在此基础上我们可以实现一个文件数据结构，它向上呈现一个可以随机访问、修改以及变长的 byte array (C++中的 vector 容器)，向下使用 balloc()/bfree() 申请 block 并把它们串起来。 我们可以在文件的基础上实现目录：目录本身也是一个特殊的文件 (字节序列)，目录文件中存放了它里面有哪些文件以及它们的位置索引 (将 vector\u0026lt;char\u0026gt; 当作 vector\u0026lt;dir_entry\u0026gt; 来解读)。 File Allocation Table (FAT) 在计算机使用软盘作为存储设备的年代，我们要在很少的存储空间上实现文件系统，因此链表是不二之选。关于链表，我们有以下两种设计：\n数据结构课上的经典设计：让每个块有数据和 next 指针两部分：\nstruct block { char data[NBLOCK]; void *next; } 这是一个很自然的想法，但有一些缺陷：比如每个 block 都有一点空间要用来存储指针，所以数据的对齐会不太好。一个更致命的缺陷是：我们在块设备上并不能 $O(1)$ 地去访问 next 指针，想要读取 next 我们要把整个 block 读出来。如果我们要执行一个 lseek(SEEK_END)，我们得把整个文件读一遍，这非常糟糕，而且无法克服。\n我们花费开头的几个 block，把所有的 next 指针全部存储在这些 block 中，后面的 block 专门存储数据。这个设计就非常好地利用了数据访问的局部性：当我们在随机访问一个文件是，我们需要快速通过 next 指针跳转，这种设计将 next 指针集中存放在一起，有利于提高访问效率。\n但这个设计在数据可靠性方面有比较大的问题：一方面，所有的 next 指针都存放在开头的几个 block 内，一旦这些 block 损坏，整个文件系统就完全损坏了 (每个文件的 block 链表都完全断开)，单个 block 损坏对全局的影响过大：另一方面，由于我们经常要 lseek，所以存放 next 指针的 block 又恰恰是我们读写最频繁的区域，也就是说它们损坏的几率要远高于其他 block。不过这个问题不是完全不可解决的：我们可以备份一些 next 指针数组在磁盘的其他地方，并准备一些应急预案。\n这个磁盘开头集中存放 next 指针的 block，就叫做 file allocation table (FAT)。\n若要了解 FAT 文件系统的细节，最好的方法便是 RTFM。 这里有 FAT 的手册。\next2/Unix File System FAT 使用最简单的链表来管理每个文件的 data block，这使得大文件的随机访问比较慢。ext2 的设计一部分解决了这个问题：ext2 中的每个文件都有一个 inode：inode 存储了每个文件的 metadata，比如文件的大小、名称等，inode 会有一个区域叫做 direct block，这样对于小文件，其 data block 可以直接放在 direct block 里，对于大文件，其 data block 可以用类似页表的方式组织起来，这样随机访问效率非常高。\n所有文件的 inode 在磁盘上统一连续存储，这使得 inode 的索引非常方便，因此我们的目录文件只需要存储文件名到 inode 编号的 key-value mapping 即可。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"4426ffe65af6171db54960827f954d9e","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec27/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec27/","section":"notes","summary":"数据结构课的一些潜藏的假设：\nrandom access memory，word addressing (不同于磁盘，磁盘是以块为单位访问的) load/store 指令和计算指令执行的代价都是 $O(1)$。 在块设备中，即使访问一个 byte 也需要将它所在的一整个 block 拿出来，因此内存中的数据结构用在磁盘上会造成极大的性能问题。\n块设备提供的设备抽象：\nstruct block blocks[NBLK]; // 磁盘 void bread(int id, struct block *buf) { memcpy(buf, \u0026amp;blocks[id], sizeof(struct block)); } void bwrite(int id, const struct block *buf) { memcpy(\u0026amp;blocks[id], buf, sizeof(struct block)); } bread() 将磁盘中的一个块拉到内存里，bwrite() 将内存中的一个块写入磁盘。","tags":null,"title":"Lecture 27: FAT and UNIX File System","type":"docs"},{"authors":null,"categories":null,"content":"内存在掉电后丢失数据是可以被接受的，但在持久化存储设备上我们必须保证数据的可靠性。硬盘损坏虽然是小概率事件，但只要有大量的重复 (比如数据中心)，这类事情还是经常发生的。我们希望即使发生这样的事情，系统仍然能照常运转。\nRAID Redundant Array of Inexpensive Disks 的核心思想是：把多个 (不可靠的) 虚拟磁盘虚拟成一块非常可靠且性能极高的虚拟磁盘。RAID 的虚拟化是一种“反向”的虚拟化：我们之前接触的虚拟化，比如进程把一个 CPU 分时虚拟成多个 virtual CPU，虚拟内存把一份内存通过 MMU 虚拟成多个 virtual address space，文件把一个物理设备虚拟成多个 virtual disk……而 RAID 是 $多\\to 1$ 的虚拟化。\nRAID 的 Fault Model 为：任何一块磁盘都可能突然坏掉，就好像“突然消失了”。\nRAID-1 最简单的想法：准备两块磁盘 $A$ 和 $B$，它们存储了同一份虚拟磁盘的镜像，这样损坏的概率就从 $p$ 变成了 $p^2$。该做法还能提升读取的效率：比如我要从虚拟磁盘中读取 10000 个 block，那么我可以从 $A$ 中读取前 5000 块，$B$ 中读取后 5000 块，只要 CPU core 个数足够，内存带宽足够，这件事是可以做到的 (不过该做法牺牲了一些存储空间)。\nRAID-0 如果我们不考虑容错，专注于提升性能：假设两块磁盘 $A$ 和 $B$，有 $A_1,A_2$，$B_1,B_2$ 四块。虚拟磁盘有 $V_1,V_2,V_3,V_4$ 四块。如果我们的映射是 $A_1\\to V_1,A_2\\to V_2,B_1\\to A_3,B_2\\to V_4$，那么如果我们读写前两个块，就只有 $A$ 在工作，$B$ 在摸鱼；如果我们采取交错映射：$A_1\\to V_1,B_1\\to V_2,A_2\\to V_3,B_2\\to V_4$，那么我们读取任意连续的两块都能让 $A,B$ 并行地工作，性能翻倍。\n(RAID-1)-0 当我们有多块盘的时候，令 $f(i,j)$ 表示第 $i$ 块物理盘的第 $j$ 个区域对应到虚拟磁盘的哪一个区域，这里的函数 $f$ 有很大的设计空间。比如当我们有 4 块盘的时候，我么可以将之前的两种设计方法综合起来，组合成一个 (RAID-1)-0。这个写法有点像函数的复合，我们每两块盘做一个 RAID-1，这样有两组 RAID-1，再把它们用 RAID-0 连起来，这样我们就兼顾了容量、容错和性能。\n这个做法有一个很有意思的点：我们可以保证任意一块物理盘出错都不会丢失信息，但我们不能保证两块盘出错时不会丢失信息——如果我们在两个 RAID-1 中各丢了一块盘，那么我们仍然能恢复信息；但如果我们丢失了第一个 RAID-1 中的所有两块盘，那么我们就真的丢失了数据。如果我们认为同时丢失了两块盘属于几乎不可能发生的小概率事件，那么这个 (RAID-1)-0 的做法似乎在容错方面就有一些“性能过剩”，有没有什么非常经济实惠的做法呢？\nRAID-4 一个块的信息可以抽象成一个 bit，于是这个问题等价于我们如何用最少的冗余信息来保证一个 bit 的错误和纠正。我们容易联想到可以用校验码来完成这件事。要保证可以纠一位错，我们只需要使用奇偶检验码即可。\n假设我们现在用 $A,B,C,D$ 四块盘组合出一个虚拟磁盘，则我们的映射为 $V_1\\to A_1,V_2\\to B_1,V_3\\to C_1$，$D_1=V_1\\oplus V_2\\oplus V_3$。之后 $V_4,V_5,V_6$ 依次类推。这样如果 $A,B,C$ 三块盘中的某个损坏，我们可以用 $D$ 来恢复；如果 $D$ 损坏，我们没有丢失任何实际信息，再插一块新盘算一遍异或即可。\nRAID-4 在保证坏一块盘不会丢失数据的情况下将冗余数据量做到了最小，使得我们的虚拟磁盘容量大。此外，我们将 $V_1,V_2,\\cdots$ 交错映射在多个盘上，这样我们在连续读取/写入时，可以同时把三块盘的性能拉满，并行度高。\n但这个设计有一个微妙的缺陷：它应对随机读写的效果较差。假设我们有多次随机的写操作，我们会发现每次写操作都要奇偶校验盘 $D$ 中的数据进行修改。此外因为 $D_i=A_i\\oplus B_i\\oplus C_i$，所以我们还没法直接去修改 $D_i$，假设我们现在要修改 $A_1$，那么我们必须先 bread(A1, D1)，然后 D1^=A1，将 A1 修改为 A1' 后，D1'=D1^A1'，最后 bwrite(A1, D1)。每次随机写 (不论是 $A,B,C$ 中的哪一个盘)，我们都要对 $D$ 一读一写，奇偶校验盘成为了性能瓶颈。\nRAID-5 RAID-5 的设计非常聪明：我们不用单独安排一块盘作为奇偶校验盘，我们可以把奇偶检验的信息分散到各各盘上去，每块盘上既有数据也有校验：\n在连续读写上，$n$ 块盘可以达到 $n-1$ 块的带宽 (每 $n$ 个 block 就有一个是冗余的校验 block)，在随机读上，由于每个盘都存储了数据，因此带宽接近 100%。在随机写上，校验信息的读写仍然是瓶颈，但由于校验信息的修改被平摊到了所有盘的头上，所以基本可以保证随着盘数量的增多效率提高，有 scalability。\nCrash Consistency 另一种 Fault model：磁盘并没有故障，但操作系统可能会 crash (比如掉电)。即使是文件系统中的简单操作也可能涉及若干个 block，如果我们在一轮操作的中途掉电，那么文件系统就会进入一个 inconsistent 的状态，这样的状态可能导致严重的错误或安全问题。磁盘本身无法直接支持原子操作 (all or nothing)，甚至为了效率它不会保证 bwrite 操作是按顺序进行的 (因此 block layer 还额外提供了 bflush 操作来保证数据落盘 (和并发中的 barrier(mfence) 是类似的) )。\nFile System Checking (FSCK) FSCK 的核心原理是当磁盘上出现 inconsistent 的现象时，根据磁盘上已有的信息恢复出“最可能”的数据结构。但这套方案不是完美的：有一些无法恢复的文件可能会被放入 lost\u0026amp;found 中，造成一些麻烦；此外，如果 fsck 执行过程中又发生掉电，可能会产生意想不到的后果。因此 FSCK 不是一个根本的解决方法。\nJournaling 我们通常看文件系统的视角，比如目录树，是文件系统的直观表示，它是 crash unsafe 的。但如果我们从状态机视角去看文件系统，我们可以把文件系统看作一系列修改操作的序列。如果我们可以把这个 append-only 的序列存储下来，我们就可以在 crash 之后恢复出文件系统。\n因此我们的想法是：在数据结构修改操作发生时，先不去做实际的修改，而是记录下一条修改日志。当日志落盘后，根据日志内容修改实际的数据结构。这样如果发生 crash，我们可以重放日志 (redo log) 来恢复文件系统。\n在 bread(), bwrite() 和 bflush() 三个 API 的基础上我们可以写出一个 journal.append() 的伪代码：\nJournal_append(operations) using bread() to find the end of current journal bwrite(Transaction_begin) for operation in operation: bwrite(operation) bflush() # 确保所有 operation 落盘 bwrite(Transaction_end) bflush() # 确保 TxEnd 标记落盘 再之后我们就可以将日志的内容付诸实施，实施结束后删掉日志。如果实施的过程中掉电，重启后 TxEnd 标签将成为我们确认日至是否完整的唯一标志：因为我们有 bflush() 保证同步性，因此如果 TxEnd 标志存在，那么之前所有操作的信息一定已经写入了，我们可以安全地重放日志；如果 TxEnd 标志不存在，那我们就忽略这次日志，且这时日志中的操作尚未对数据结构产生真正影响。这样就做到了 all or nothing。\nOSLAB 中的小彩蛋\n为了提高 journaling 的效率，很多系统做出了很多的优化。比如 git 采用 metadata journaling，提升效率的同时降低了一致性，这导致有时强行关闭虚拟机会导致 git repo 处于一个不一致的状态，因此 OSLAB 的 Makefile.lab 中添加了一条命令：\ngit: @git add $(shell find . -name \u0026quot;*.c\u0026quot;) $(shell find . -name \u0026quot;*.h\u0026quot;) -A --ignore-errors @while (test -e .git/index.lock); do sleep 0.1; done @(uname -a \u0026amp;\u0026amp; uptime) | git commit -F - -q --author='tracer-nju \u0026lt;tracer@nju.edu.cn\u0026gt;' --no-verify --allow-empty + @sync sync 的作用是 \u0026ldquo;synchronize cached writes to persistent storage\u0026rdquo;。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"2a12466027b147c44534498ea3e1f1ac","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec28/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec28/","section":"notes","summary":"内存在掉电后丢失数据是可以被接受的，但在持久化存储设备上我们必须保证数据的可靠性。硬盘损坏虽然是小概率事件，但只要有大量的重复 (比如数据中心)，这类事情还是经常发生的。我们希望即使发生这样的事情，系统仍然能照常运转。\nRAID Redundant Array of Inexpensive Disks 的核心思想是：把多个 (不可靠的) 虚拟磁盘虚拟成一块非常可靠且性能极高的虚拟磁盘。RAID 的虚拟化是一种“反向”的虚拟化：我们之前接触的虚拟化，比如进程把一个 CPU 分时虚拟成多个 virtual CPU，虚拟内存把一份内存通过 MMU 虚拟成多个 virtual address space，文件把一个物理设备虚拟成多个 virtual disk……而 RAID 是 $多\\to 1$ 的虚拟化。\nRAID 的 Fault Model 为：任何一块磁盘都可能突然坏掉，就好像“突然消失了”。","tags":null,"title":"Lecture 28: Reliability of Persistent Storage","type":"docs"},{"authors":null,"categories":null,"content":"Review 文件系统 = 图书馆\n目录：图书馆操作，mkdir, rmdir, link, unlink etc. 文件：图书，read, write, mmap etc. 文件描述符 (offset)：书签，lseek etc. FAT：\nmetadata FAT FAT data clusters FAT 区域存放文件链表的 next 指针。FAT 的一个缺点在于一个文件的信息散落在磁盘的各个地方。\nUNIX：\n磁盘中的一个区域存放所有文件的 inode。inode 里包括文件的几乎所有信息 (除了所有的 data block 以一个类页表的方式存储，inode 里存放了“页表”的根)，更好地利用了数据的 locality。\n/mkfs/mkfs.c mkfs 的代码写的非常琐碎。RTFSC 的优雅姿势为：读代码的执行比读代码容易。\n# trace.py TRACED = 'bwrite balloc ialloc iappend rinode winode rsect wsect'.split() IGNORE = 'ip xp buf'.split() class trace(gdb.Breakpoint): def stop(self): f, bt = gdb.selected_frame(), [] while f and f.is_valid(): if (name := f.name()) in TRACED: lvars = [f'{sym.name}={sym.value(f)}' for sym in f.block() if sym.is_argument and sym.name not in IGNORE] bt.append(f'\\033[32m{name}\\033[0m({\u0026quot;, \u0026quot;.join(lvars)})') f = f.older() print(' ' * (len(bt) - 1) + bt[0]) return False # won't stop at this breakpoint gdb.execute('set prompt off') gdb.execute('set pagination off') for fn in TRACED: trace(fn) gdb.execute('run fs.img README user/_ls') gdb.execute('quit') 上面的一段代码可以帮我们自动在 mkfs.c 中比较重要的 API 函数上打断点，并追踪栈帧打印函数调用链和关键参数。通过阅读 mfks.c 的执行过程，我们可以更快地了解 mfks 大致做了哪些事情。\nBuffer Cache 内存中的 buffer cache 是磁盘的 cache，所有的读写操作都会经过 buffer cache，buffer cache 提供了和磁盘一样的接口 bread/bwrite，这样反复的读取/反复的写入不用每次都与磁盘交互，提高了效率。\n具体的代码细节见 Xv6 源码解读手册。\nLog Xv6 的 logging layer 保证了崩溃一致性。具体的代码细节可以见 Xv6 源码解读手册。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"3c9dabd7b4dd349270687ff92ebd2b1e","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec29/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec29/","section":"notes","summary":"Review 文件系统 = 图书馆\n目录：图书馆操作，mkdir, rmdir, link, unlink etc. 文件：图书，read, write, mmap etc. 文件描述符 (offset)：书签，lseek etc. FAT：\nmetadata FAT FAT data clusters FAT 区域存放文件链表的 next 指针。FAT 的一个缺点在于一个文件的信息散落在磁盘的各个地方。\nUNIX：\n磁盘中的一个区域存放所有文件的 inode。inode 里包括文件的几乎所有信息 (除了所有的 data block 以一个类页表的方式存储，inode 里存放了“页表”的根)，更好地利用了数据的 locality。","tags":null,"title":"Lecture 29: Xv6 File System Implementation","type":"docs"},{"authors":null,"categories":null,"content":"Abilities and Limitations of FS OJ 最简单的实现方式可以就是一个文件系统。比如 OS2022 课程的学生名单存放在 /OS2022/students.csv 中，向 Lab1 提交的代码以一个压缩包的形式存放在 /OS2022/L1/studentid/xxxxxxxx.tar.bz2 中。OJ 的前端和后端部署在不同的机器上，后端机器通过 ssh 连接前端，扫描文件系统寻找符合格式的提交拉回后台，评测以后发送一个 .tar.bz2.result 文件给前端，前端就可以将评测结果显示出来。\n使用文件系统的最大好处是简单：我们有海量的 UNIX 工具/标准库可以处理文件。比如查询某个同学的提交可以使用如下 python 代码：\nfor f in wiki.UPLOAD_PATH.glob( f'{course}/{module}/{stuid}/{file_pattern}'): if not f.name.endswith('.result'): # f是一个提交, do something 再比如添加了测试数据/更新了测试代码后我们只需要一行 UNIX 命令就可以开启 rejudge：\nfind OS2022/L1 -name \u0026quot;*.result\u0026quot; | xargs rm 删除所有的 .result 结尾的文件后，后端便会自动抓取没有对应 .result 文件的提交压缩包评测，从而实现重测。\n文件系统的局限在于：\nscalability 不好：任何一个页面的渲染都要遍历所有目录，对于庞大系统来说效率太低； 可靠性低：几乎无法抵抗崩溃。比如后端完成评测后会通过 scp 命令将 .result 文件传送到前端服务器，但如果传送的过程中网断了，那么文件系统无法做到 all or nothing，从而前端可能会处于一个 inconsistent 的状态， 比如已经创建了 .result 文件但由于复制没有完成，文件是空的。这便是评测结果中 \u0026ldquo;server error\u0026rdquo; 的一种来源。 Relational Database 所有的数据都可以以二维表的形式存储在数据库内。Structured Query Language (SQL) 用于描述需求，数据库引擎负责将需求翻译成具体的实现。比如如下的 SQL 语句：\nSELECT * FROM students, submissions WHERE students.sid == submissions.sid AND submissions.course == 'OS2022' AND submissions.module == 'L1' 它在功能上等价于\nfor student in students: for submission in submissions: if students.sid == submissions.sid and submission.course == 'OS2022' and submissions.module == 'L1': yield student, submission 但要注意的是：SQL 只是一种 high level 的描述需求的语言，它底层的实现并不一定像这段 python 代码一样。比如在这个例子中，用双重循环在两个表单中 join 是非常低效的，数据库会使用数据结构 (hash, B tree etc.) 来优化实现。SQL 将上层需求和底层实现解耦，这样的设计有诸多好处，比如比较容易实现原子性：\nBEGIN WORK; -- all or nothing INSERT INTO students VALUES(...); INSERT INTO students VALUES(...); INSERT INTO students VALUES(...); COMMIT; 直到 commit 前，数据都不会真正落实。\n例子：稍大型的 Online Judge\n数据库需要保证 ACID - Atomicity, Consistency, Isolation, Durability。对于数千个连接的并发事务，数据库要在保证并发正确性的基础上提升查询效率。一个典型的简单应用场景是 Online Judge：\n比赛中 Online Judge 评测结果的即时性要求很高，因此我们要组建一个小的分布式系统来并行地评测多组数据。上图所示系统的工作原理是：100 个 worker 负责评测，supervisor 负责给 worker 分配任务 (supervisor 会不断 ping 各个 worker 以了解机器实时的状态)，所有的数据都存储在 database 中。supervisor 和所有的 worker 与数据库相连。当 Online Judge 前端接收到一个新的提交后，他会把文件存储到数据库中，supervisor 会指挥一个 worker 把源代码从数据库拉到本地编译，并将可执行文件传回数据库。接着 supervisor 指挥一部分 worker 从数据库中获取可执行文件 (这一瞬间会产生一个很大的带宽)，然后执行对应的测试数据，worker 将执行结果发送给数据库保存。最后前端从数据库中查询所有测试点的运行结果并显示在网页上。\n从这个例子中我们可以看到数据库作为整个系统的存储枢纽，其可靠性，处理大量并发事务的效率等是整个系统能力的关键。\nDistributed System 在新时代，存储系统需要应对海量的实时数据。构造一个 planet-scale 的数据库遭遇了前所未有的挑战。我们通常用 CAP Theorem 来衡量一个数据库的性能：\nAvailability (A)：用户能否在短时间内迅速获取需要的数据 Consistency (C)：系统是否处于一个一致的状态，同步是否正确 (比如先“取关”再“发送pyq”的操作顺序如果在地理上的另一个数据中心反序会造成严重的后果)。 Partition Tolerance (P)：系统可以忍受怎样规模的延迟。 分布式系统要面对的问题比“并发编程”要更加严峻：多个线程至少有一个共享的内存可以交换数据、实现同步，而分布式系统各个节点之间没有这样的共享资源；此外，分布式系统的假设是任何一个节点都可以在任何一个时刻“突然消失”。\n对分布式系统更友好的数据模型是 key-value (可以理解为 C++ 的 std::map\u0026lt;\u0026gt;)。LevelDB 是 Google 开发的实现 key-value storage 的库。我们最基本的需求是增加/删除 key-value 对，以及对当前的状态打快照。LevelDB 使用类似于日志的想法，并不是维护一个“平衡树“，而是记录所有操作的内容。为了解决读放大的问题，LevelDB 构建了一个多级的类似于 memory hierarchy 的日志，读操作优先到 Level 0 的 tree 里寻找信息，找不到去下一层，以此类推。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"b42896d5ed23dc5f1de9d71f31a0884f","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/lectures/lec30/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/lectures/lec30/","section":"notes","summary":"Abilities and Limitations of FS OJ 最简单的实现方式可以就是一个文件系统。比如 OS2022 课程的学生名单存放在 /OS2022/students.csv 中，向 Lab1 提交的代码以一个压缩包的形式存放在 /OS2022/L1/studentid/xxxxxxxx.tar.bz2 中。OJ 的前端和后端部署在不同的机器上，后端机器通过 ssh 连接前端，扫描文件系统寻找符合格式的提交拉回后台，评测以后发送一个 .tar.bz2.result 文件给前端，前端就可以将评测结果显示出来。\n使用文件系统的最大好处是简单：我们有海量的 UNIX 工具/标准库可以处理文件。比如查询某个同学的提交可以使用如下 python 代码：\nfor f in wiki.UPLOAD_PATH.glob( f'{course}/{module}/{stuid}/{file_pattern}'): if not f.","tags":null,"title":"Lecture 30: Modern Storage System","type":"docs"},{"authors":null,"categories":null,"content":"操作系统：为上层多个应用程序的正常运行提供支持。操作系统实现这一目的的重要方法是虚拟化：将硬件资源抽象成简单易用的虚拟资源。为了方便上层应用程序使用这些资源，操作系统会提供数百个系统调用。从这个角度来看，操作系统也很像一个标准库。\n2.1 Virtualizing The CPU cpu.c 的作用是每过一秒钟输出一次字符串。Spin(1) 表示等待一秒，其实现在 common.h 中，其中 GetTime() 是对系统调用 gettimeofday() 的进一步封装，返回系统启动以来的秒数。Spin() 会不断调用 GetTime()，直到间隔时间达到输入值 howlong。\n键入命令 ./cpu A \u0026amp; ; ./cpu B \u0026amp; ; ./cpu C \u0026amp; ; ./cpu D \u0026amp;，可以看到A,B,C,D 交替输出，仿佛各自独占了 CPU。操作系统通过虚拟化 CPU 的方式，给上层应用程序一种系统中有很多很多个 CPU 的假象。至于多个进程谁在真正的物理 CPU 上运行，这取决于操作系统的调度策略。\n为什么程序会不停输出，按 Ctrl+C 也无法停止？\n上文中，用分号隔开各个命令表示这些命令都要执行。它和 \u0026amp;\u0026amp; 的区别在于：\u0026amp;\u0026amp; 要求第一个命令执行成功才会执行第二个命令，而 ; 不论第一个命令是否成功都会执行第二个命令 (可以用 gcc notexist.c ; ls 和 gcc notexist.c \u0026amp;\u0026amp; ls 做实验验证)。\n在命令最后加上 \u0026amp; 表示将这个进程放到后台执行， Ctrl+C 的意义是中断所有正在运行的前台进程，因此该组合键无法终止后台运行的进程。如果某个命令所需要的执行时间很长，可以用 \u0026amp; 将其放在后台执行，从而终端界面仍然可以继续操作。在使用 \u0026amp; 时，bash 会提示分配给该任务的进程号。如果想要结束后台任务，可以使用命令 kill pid 。\n这里我们使用 \u0026amp; 的原因在于：用 ; 分隔的若干命令总是会依次执行，即第一个执行结束才会执行第二个。而 cpu 程序中有一个死循环，为了观测“并发”，我们必须让四个任务同时运行起来。\n2.2 Virtualizing Memory 物理内存本身没有任何特殊之处，就是一个大数组，每个位置有一个物理地址。\nmem.c 会调用 malloc() 分配一个地址，并不断向该地址写入内容。如果我们使用 ./mem 1 \u0026amp; ; ./mem 1 \u0026amp; 命令，我们会发现两个进程分配的地址是一样的，然而两个进程都在完好地运行。这是因为每个进程都有自己的虚拟地址空间，输出的地址是进程的虚拟地址，不同进程的相同虚拟地址会指向不同的物理地址。操作系统负责虚拟化内存，保证每个进程只能访问自己的地址空间。\n为什么我使用上述命令无法复现，两个地址不一样？\nLinux 默认使用了地址空间随机化 (Address Space Layout Randomization, ASLR) 技术。ASLR 是一种针对缓冲区溢出攻击的安全保护技术，通过对堆、栈、共享库映射等布局的随机化增加攻击者预测目的地址的难度，关于利用固定地址进行攻击的方法可以见 这篇文章。在 /proc/sys/kernel/randomize_va_space 文件中，我们可以查看当前 ASLR 是否打开：0 表示关闭，1 表示对于部分函数打开，2 表示完全打开。\n为了暂时关闭 ASLR 以复现上述情境，我们可以使用命令：\nsetarch `uname -m` -R /bin/zsh 其中 uname -m 命令会输出机器架构，该参数可以省略；-R 参数 (对应长参数 --addr-no-randomize) 表示关闭 ASLR。执行该命令会暂时打开一个新的 shell (默认 /bin/sh，可以通过最后一个参数指定其他 shell)，该 shell 和其子进程会在关闭 ASLR 的情况下执行命令 (退出该 shell 后，一切恢复)。\n另外一种方法是使用命令\nsysctl -w kernel.randomize_va_space=0 机器重启后该改变会消失。如果想要永久性的关闭 ASLR，可以将 kernel.randomize_va_space=0 写到 /etc/sysctl.conf 中。\n如果使用 GDB 调试，可以通过命令 set disable-randomization off 关闭 ASLR。\n2.3 Concurrency threads.c 创建了两个线程，创建线程调用的函数是 Pthread_create()，它在 common_threads.h 中定义，是对 POSIX 线程库的简单封装：\n#define Pthread_create(thread, attr, start_routine, arg) assert(pthread_create(thread, attr, start_routine, arg) == 0); #define Pthread_join(thread, value_ptr) assert(pthread_join(thread, value_ptr) == 0); 让两个线程各执行 N 次 +1 操作，可以观测到结果不是 2N。这主要是因为核心语句 counter++ 会被编译成三条汇编语句：\nmov \u0026amp;counter, register add $1, register mov register, \u0026amp;counter 由于原子性的丧失，可能出现 race condition。\n2.4 Persistence 数据的持久性是一个重要的话题。内存中存储的数据是不稳定的——机器一旦断点，DRAM 中的信息就会丢失。我们需要硬盘来存储长期数据，硬盘在现代系统中被看作 I/O 设备的一部分，管理硬盘信息的软件称为文件系统。\n操作系统对于硬盘的抽象和 CPU，内存不同。我们针对 CPU 抽象出了进程，对于内存抽象出了虚拟地址空间，其目的都是为了让某一个程序“独占”整个计算机资源。而硬盘上的数据理应让各个程序共享，比如编辑器创建了一个文件，然后编译器负责编译它，接着加载器负责加载、运行这个程序。操作系统通过系统调用来抽象硬盘：将复杂的硬件读写操作封装成简单的接口。\n在 io.c 中我们使用了 open() 和 write() 系统调用来创建，写入文件。这些系统调用底层的实现非常复杂 (比如为了性能的提升，读写都有缓冲区)，但上层使用这些 API 非常简便。OS 在这里充当了标准库的角色。\n2.5 Design Goals 操作系统应当努力追求的目标：\n高性能； 保护/隔离：应用程序之间不能互相“伤害“； 可靠：操作系统一旦崩溃，在其上运行的所有应用程序都无法使用，因此操作系统必须是非常可靠的软件。 …… ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"d6f5abd56e37fe44c65ccd703d1a8af9","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch02/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch02/","section":"notes","summary":"操作系统：为上层多个应用程序的正常运行提供支持。操作系统实现这一目的的重要方法是虚拟化：将硬件资源抽象成简单易用的虚拟资源。为了方便上层应用程序使用这些资源，操作系统会提供数百个系统调用。从这个角度来看，操作系统也很像一个标准库。\n2.1 Virtualizing The CPU cpu.c 的作用是每过一秒钟输出一次字符串。Spin(1) 表示等待一秒，其实现在 common.h 中，其中 GetTime() 是对系统调用 gettimeofday() 的进一步封装，返回系统启动以来的秒数。Spin() 会不断调用 GetTime()，直到间隔时间达到输入值 howlong。\n键入命令 ./cpu A \u0026amp; ; ./cpu B \u0026amp; ; ./cpu C \u0026amp; ; .","tags":null,"title":"Chapter 02: Introduction to Operating Systems","type":"docs"},{"authors":null,"categories":null,"content":"进程就是正在运行的程序。程序本身只是存储在硬盘上的指令和数据的集合，只有 OS 将其加载到内存中运行起来时程序才会发挥作用。\n通常操作系统上会运行多个程序 - 比 CPU 核个数更多的程序。但每个程序并不需要关心 CPU 当前是否可用，这是因为 OS 为进程虚拟化了 CPU。OS 的基本操作是运行一个进程，然后暂停它去运行一会儿另外一个进程，这是分是运行的基本思想。\n为了实现 CPU 的虚拟化，OS 既需要底层的机制，也需要上层的智慧。所谓机制 (mechanism) 指的是实现某个功能所需要的一些底层的方法或协议。比如操作系统为了实现进程的切换，必须要有上下文切换的机制。分时运行也是一种机制，被所有的现代操作系统采用。\nTime Sharing 和 Space Sharing\nTime Sharing 是 OS 共享资源的一种基本方式，即每个人用一会儿，然后把资源交给下一个人。Time sharing 不仅仅用在多个进程/线程共享 CPU 上，共享的资源都可以使用这种机制，比如网络连接。\n与 time sharing 互为补充的是 space sharing。磁盘就是一种 space sharing 的模型。\n在机制之上是策略。策略 (policy) 是操作系统做出决定的一些算法，比如如何调度各个进程就需要一个 scheduling policy，这里有多种可能性，比如根据优先级，根据历史运行时长等等 (如果说机制是 OS 必须的东西，那么策略影响的其实只是效率)。\n区分机制和策略\n我们可以这样区分机制和策略：机制回答的是一个 how question，比如“如何实现上下文切换？” 而策略回答的是一个 which question，比如“下一个用 CPU 的应该是哪个进程？”\n区分好机制和策略，我们在修改策略时就不必关注底层的机制，更利于模块化编程。\n4.1 The Abstraction: A Process OS 为正在运行的程序提供的抽象是进程。进程中包括的内容当然是一个正在运行的程序所拥有的机器状态：\nMemory：每一个程序都有自己可以读写的内存区域，称为地址空间 (address space)。 Regitsters：进程中应该有各个寄存器的信息，尤其是几个比较重要的寄存器：PC，stack pointer，frame pointer 等。 I/O Information：程序要和可持久化存储设备打交道，因此进程会存储一些 I/O 相关信息，比如当前打开了哪些文件。 4.2 Process API 从抽象模型的角度，我们可以提出如下几类进程相关的 API：\ncreate：创建一个新的进程。 destroy：虽然一个运行的程序结束时会自动退出，但我们仍然应该有 API 可以强制杀死一个进程。 wait：等待一个进程结束。 Miscellaneous Control：比如暂时挂起一个进程，或让一个进程继续运行。 Status：访问一个进程的信息，比如总运行时长，现在处于什么状态 (running, suspended etc.) 等。 4.3 Process Creation: A Little More Detail 创建一个进程 (让一个程序跑起来) 通常要经过以下步骤：\n将程序的代码和静态数据 (比如初始化过的全局变量) 加载到内存中。程序本身是以某种可执行文件的格式存放在硬盘上的 (比如 Linux 中默认使用 ELF)，文件会告诉 OS 应该把哪些代码加载到内存的哪些位置。\n早期的操作系统会 eagerly 地完成加载这个动作。但现代操作系统通常使用延迟加载：当程序真正要用到某一部分的代码/数据时再将数据从交换分区复制进来。\n为该程序准备一个 run-time stack。以 C 程序为例，程序通常在栈上存储局部变量，此外传给 main() 的参数也保存在栈上。\nOS 准备一些空间用作该程序的堆区。堆区负责为程序中的动态内存申请提供支持，即 malloc()/free()。\n做一些和 I/O 相关的准备工作，比如 UNIX 系统中默认为程序打开 stdin, stdout, stderr 三个文件。\n让 PC 跳转到该程序的入口地址，开始运行。\n4.4 Process State 进程的状态通常包括以下几种：\nRunning：进程正在 CPU 上运行。 Ready：程序可以运行，但当前不在 CPU 上。 Blocked：程序因为做了某种操作使得当前还不能运行 (比如执行 I/O，正在等待数据返回)。 下面的图很好地反映了三种状态的切换：\nstateDiagram Running --\u0026gt; Ready: Descheduled Ready --\u0026gt; Running: Scheduled Running --\u0026gt; Blocked: I/O Initiate Blocked --\u0026gt; Ready: I/O Done OS 的调度器有很多事情要决定：比如 process 1 因为 I/O 操作被阻塞时，是否需要将其他进程 process 2切换上来？如果 process 2 运行时 I/O 操作完成，process 1 从 blocked 变成 ready，那么 OS 是将 process 1 立刻请回来还是先做 process 2？……\n4.5 Data Structure OS 中有很多维护信息的数据结构，比如对于进程我们应该有一个 process list，链表中的每个节点存储一个进程的相关信息，通常被称为 process control block (PCB)，再比如我们应该有上下文结构体用于 context switching。\n// the registers xv6 will save and restore // to stop and subsequently restart a process struct context { int eip; int esp; int ebx; int ecx; int edx; int esi; int edi; int ebp; }; // the different states a process can be in enum proc_state { UNUSED, EMBRYO, SLEEPING, RUNNABLE, RUNNING, ZOMBIE }; // the information xv6 tracks about each process // including its register context and state struct proc { char *mem; // Start of process memory uint sz; // Size of process memory char *kstack; // Bottom of kernel stack for this process enum proc_state state; // Process state int pid; // Process ID struct proc *parent; // Parent process void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory struct context context; // Switch here to run process struct trapframe *tf; // Trap frame for the current interrupt }; 这是 xv6-x86 中的上下文结构体和 PCB。可以看到它存储了比之前提到的更多的一些信息，比如每个进程的内核栈地址，父进程，如果睡眠睡在了哪个地址上，kernel trap 的页面地址等。\n进程的状态也比之间提到的 ready, running, blocked 要多。一些很有用的状态包括 zombie，它表示一个程序已经运行结束，但相关的信息还没有被清空。这种状态可以让调用 wait() 的父进程去检查子进程的返回值是否符合要求。\n4.6 Summary 略。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"a3a6bfb2f4aa3641cb5026afbf10de2a","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch04/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch04/","section":"notes","summary":"进程就是正在运行的程序。程序本身只是存储在硬盘上的指令和数据的集合，只有 OS 将其加载到内存中运行起来时程序才会发挥作用。\n通常操作系统上会运行多个程序 - 比 CPU 核个数更多的程序。但每个程序并不需要关心 CPU 当前是否可用，这是因为 OS 为进程虚拟化了 CPU。OS 的基本操作是运行一个进程，然后暂停它去运行一会儿另外一个进程，这是分是运行的基本思想。\n为了实现 CPU 的虚拟化，OS 既需要底层的机制，也需要上层的智慧。所谓机制 (mechanism) 指的是实现某个功能所需要的一些底层的方法或协议。比如操作系统为了实现进程的切换，必须要有上下文切换的机制。分时运行也是一种机制，被所有的现代操作系统采用。\nTime Sharing 和 Space Sharing\nTime Sharing 是 OS 共享资源的一种基本方式，即每个人用一会儿，然后把资源交给下一个人。Time sharing 不仅仅用在多个进程/线程共享 CPU 上，共享的资源都可以使用这种机制，比如网络连接。","tags":null,"title":"Chapter 04: The Abstraction: The Process","type":"docs"},{"authors":null,"categories":null,"content":"5.1 The fork() System Call fork() 系统调用会创建一个和当前进程完全相同的子进程，这两个进程除了 fork() 的返回值不同，其他完全相同。fork() 在父进程中返回子进程的进程号，在子进程中返回 0，这可以用于区分两个进程。\np1.c 展示了一个使用 fork() 的例子，其中 getpid() 函数可以获得当前进程的进程号。注意这个程序的运行结果是 non-deterministic 的：父进程和子进程谁会先输出，这取决于 OS 的调度器。现代操作系统的调度策略极其复杂，可以看 这篇文章 有一个大概的了解。\n5.2 The wait() System Call p2.c 展示了一个使用 wait() 的例子，wait() 提供一种同步机制，保证了父进程在子进程结束之后再执行。如果父进程先被调度器选中，那么它执行 wait() 会被阻塞，直到子进程结束；如果子进程先被调度器选中，那么父进程执行 wait() 时看到子进程已经退出则会立刻返回。\nZombie Process\n一个子进程如果已经退出但还没有被它的父进程 wait()，那它就是一个僵尸进程。内核保存了僵尸进程的一份 minimal 的信息，包括进程号、退出状态等，这样以后如果父进程 wait() 了，父进程就可以获取子进程的信息。\n被 wait() 过的僵尸进程会被从 process table 中移除。一个 zombie process 如果不被 wait，就会一直待在 process table 中，一旦内核的 process table 满了，就不能再创建新的进程。因此父进程应该及时清理自己的僵尸子进程。如果父进程退出了，那么它的僵尸子进程会被 init 进程 (或其他某个指定的进程) wait 掉。\n5.3 Finally, The exec() System Call p3.c 展示了一个使用 exec() 的例子。exec() 传入一个可执行程序的文件名，它会将该文件的代码和数据加载到内存中覆盖当前的代码和数据，重新初始化堆区和栈，并跳转到新程序的入口开始执行。exec() 不创建新的进程，它只是重启当前的状态机。exec() 如果执行成功就不会返回。\n5.4 Why? Motivating the API 将 fork() 和 exec() 分开的设计似乎有一些反人类：我们创建一个新进程运行新程序需要两个系统调用。这样设计的真正目的是让我们有机会在 fork() 和 exec() 之间做一些有意思的事情。\np4.c 展示了一个重定向的例子。我们在 fork() 之后 exec() 之前关闭 stdout，再打开一个新的文件，这样新打开的文件的描述符就是 1 (stdout)，这是再 exec()，我们就实现了将标准输出重定向到文件。除了重定向，UNIX 的管道机制也是通过在 fork() 和 exec() 中间操作实现的。\n5.5 Process Control And Users 除了 fork(), wait() 和 exec()，UNIX 系统中还有很多其他控制进程的 API，比如 kill() 用于给进程发送信号。信号机制可以向进程通知外部事件的发生，常见的信号有 SIGINT (interrupt，通常用于结束程序)，SIGTSTP (暂时挂起程序)，SIGSEGV (段错误) 等。\n既然信号的能力这么强，那么肯定不能让任意用户随便给别人的进程发送 SIGINT。你需要通过密码登录获取管理员权限，或者你本身是 root 用户，才能执行这些系统资源相关的操作。在用户态，你只能管理你自己的进程。\n5.6 Useful Tools ps 命令可以查看当前活跃的进程。top 命令可以查看所有进程的详细信息。\n5.7 Summary 略。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"c3f256f949d066bbdd30648e722a1aa5","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch05/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch05/","section":"notes","summary":"5.1 The fork() System Call fork() 系统调用会创建一个和当前进程完全相同的子进程，这两个进程除了 fork() 的返回值不同，其他完全相同。fork() 在父进程中返回子进程的进程号，在子进程中返回 0，这可以用于区分两个进程。\np1.c 展示了一个使用 fork() 的例子，其中 getpid() 函数可以获得当前进程的进程号。注意这个程序的运行结果是 non-deterministic 的：父进程和子进程谁会先输出，这取决于 OS 的调度器。现代操作系统的调度策略极其复杂，可以看 这篇文章 有一个大概的了解。\n5.2 The wait() System Call p2.c 展示了一个使用 wait() 的例子，wait() 提供一种同步机制，保证了父进程在子进程结束之后再执行。如果父进程先被调度器选中，那么它执行 wait() 会被阻塞，直到子进程结束；如果子进程先被调度器选中，那么父进程执行 wait() 时看到子进程已经退出则会立刻返回。","tags":null,"title":"Chapter 05: Interlude: Process API","type":"docs"},{"authors":null,"categories":null,"content":"13.1 Early Systems 早期的系统非常简单，操作系统没有为程序提供任何的抽象，整个计算机中只有一个物理地址空间，操作系统代码以及操作系统为程序提供的一些库函数存放在内存中，此外还有一个运行的程序，它可以使用剩下的内存。\n13.2 Multiprogramming and Time Sharing 随着时代发展，人们对计算机的需求激增，于是一个计算机上需要运行多个程序，由操作系统负责调度程序的运行，time sharing 的概念也被提了出来。一个最简单的想法是：先将第一个程序加载到内存中，让它拥有全部的地址空间，它的时间片用完之后，将整个内存状态保存到磁盘上，然后加载下一个程序。这个做法因为效率太低而被淘汰。\n人们希望在进程切换的时候，被切的程序的状态可以仍然保留在内存中，等待下次被切回来的时候继续使用。这样 OS 调度就会更有效率。将各个进程的状态同时保存在内存中就必然涉及到保护问题，我们不希望一个进程可以干扰另一个进程的状态。\n13.3 The Address Space 地址空间是操作系统提供给运行中的程序的内存的模样。运行中的程序看到的内存包括三个部分：代码区，栈区和堆区。代码区的内容是固定不变的，通常放在地址空间底部。栈区和堆区的大小都是会动态变化的，因此他们通常一个在底部一个在顶部，两者往相反的方向生长。\n需要注意的是，虽然在进程眼中地址空间是这种简洁的结构，但这是操作系统提供给进程的 illusion，在实际的物理内存中，一个进程的地址空间可能会被存放在任意位置。操作系统通过虚拟化内存的方式来为进程提供这种 illusion：进程眼中的地址都是虚拟地址，操作系统/MMU硬件负责将虚拟地址映射到正确的物理地址。\nThe Principle Of Isolation\n隔离是构建一个可靠系统的必要条件。在有效隔离的情况下，一个程序的崩溃不会影响别的程序的运行。操作系统通过虚拟内存等各种手段保证隔离，一些现代的内核通过将内核各个模块拆开的方式做到了更强的隔离，这种微内核设计比传统的宏内核更安全。\n13.4 Goals 虚拟内存的目标如下：\n透明 (transparency)：程序不应该感受到它们获得的内存是虚拟的，每个程序都应该觉得自己在独占整个物理内存。 效率 (efficiency)：一方面虚拟内存机制不能太慢，另一方面存储映射表不能耗费太多空间。为了达到这一点，一方面操作系统需要设计精巧的数据结构 (页表)，一方面也需要硬件的帮助 (比如 TLB 作为页表的 cache)。 保护 (protection)：任何程序的行为都不能影响别的程序。不同的程序之间应当形成隔离。 Every Address You See Is Virtual\n我们程序员在用户态能看到的所有地址都是虚拟地址。不论是代码段的地址，malloc() 获得的堆区地址，还是任意一个指针的值，都是虚拟地址。只有操作系统 (和硬件) 知道真正的物理地址。\n下面的程序 va.c 打印了一个代码地址、一个堆区地址和一个栈上的地址。\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(int argc, char *argv[]) { printf(\u0026quot;location of code : %p\\n\u0026quot;, (void *) main); printf(\u0026quot;location of heap : %p\\n\u0026quot;, (void *) malloc(1)); int x = 3; printf(\u0026quot;location of stack : %p\\n\u0026quot;, (void *) \u0026amp;x); return x; } 在 Linux 下，该程序输出结果为\nlocation of code : 0x55aa61491189 location of heap : 0x55aa62a0b6b0 location of stack : 0x7ffd13ff4374 可以看到虚拟地址空间中，代码段在底部，堆区在代码段之上，栈在地址空间的另一头。不过这整个结构都是操作系统为我们虚拟出来的。\n13.5 Summary 虚拟内存系统的任务是为每个进程提供一个大的，私有的地址空间，让程序存储其所有的代码和相关数据。操作系统和相关的硬件会在背后负责虚拟地址到物理地址的翻译。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"34718d25f26a364d35e6614c8ea42fad","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch13/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch13/","section":"notes","summary":"13.1 Early Systems 早期的系统非常简单，操作系统没有为程序提供任何的抽象，整个计算机中只有一个物理地址空间，操作系统代码以及操作系统为程序提供的一些库函数存放在内存中，此外还有一个运行的程序，它可以使用剩下的内存。\n13.2 Multiprogramming and Time Sharing 随着时代发展，人们对计算机的需求激增，于是一个计算机上需要运行多个程序，由操作系统负责调度程序的运行，time sharing 的概念也被提了出来。一个最简单的想法是：先将第一个程序加载到内存中，让它拥有全部的地址空间，它的时间片用完之后，将整个内存状态保存到磁盘上，然后加载下一个程序。这个做法因为效率太低而被淘汰。\n人们希望在进程切换的时候，被切的程序的状态可以仍然保留在内存中，等待下次被切回来的时候继续使用。这样 OS 调度就会更有效率。将各个进程的状态同时保存在内存中就必然涉及到保护问题，我们不希望一个进程可以干扰另一个进程的状态。\n13.3 The Address Space 地址空间是操作系统提供给运行中的程序的内存的模样。运行中的程序看到的内存包括三个部分：代码区，栈区和堆区。代码区的内容是固定不变的，通常放在地址空间底部。栈区和堆区的大小都是会动态变化的，因此他们通常一个在底部一个在顶部，两者往相反的方向生长。\n需要注意的是，虽然在进程眼中地址空间是这种简洁的结构，但这是操作系统提供给进程的 illusion，在实际的物理内存中，一个进程的地址空间可能会被存放在任意位置。操作系统通过虚拟化内存的方式来为进程提供这种 illusion：进程眼中的地址都是虚拟地址，操作系统/MMU硬件负责将虚拟地址映射到正确的物理地址。\nThe Principle Of Isolation\n隔离是构建一个可靠系统的必要条件。在有效隔离的情况下，一个程序的崩溃不会影响别的程序的运行。操作系统通过虚拟内存等各种手段保证隔离，一些现代的内核通过将内核各个模块拆开的方式做到了更强的隔离，这种微内核设计比传统的宏内核更安全。\n13.4 Goals 虚拟内存的目标如下：","tags":null,"title":"Chapter 13: The Abstraction: The Address Space","type":"docs"},{"authors":null,"categories":null,"content":"14.1 Types of Memory 在一个 C 程序中，程序使用的内存有两种：\n栈内存，这部分内存的分配和回收由编译器隐式地完成，因此也被称为“自动内存”。在 C 程序中声明使用栈内存是非常简单的，比如 void func() { int x; // declares an integer on the stack ... } 编译器会自动在栈上为变量 x 分配空间，且函数 func() 结束时编译器会自动回收这部分内存。\n堆内存：如果我们想要一些长生存周期 (不只存活在函数内部) 的内存，我们就要使用堆内存。堆内存是由程序员在程序中显式申请的，分配和释放都由程序员负责。一个例子如下：\nvoid func() { int *x = (int *)malloc(sizeof(int)); ... } malloc() 函数负责在堆区申请了一个 int 大小的内存，而这个内存的地址被保存在了指针变量 x 中，这个地址是存储在栈上的。\n14.2 The malloc() Call malloc() 的声明如下：\n#include \u0026lt;stdlib.h\u0026gt; void *malloc(size_t size); 传入需要分配的大小，malloc() 要么返回 NULL 表示分配失败，要么返回一个地址表示分配区域的起始位置。\n小心 sizeof() 的行为！\n下面两段代码的输出行为是不同的！\nint x[10]; printf(\u0026quot;%d\\n\u0026quot;, sizeof(x)); 这里 sizeof() 会返回整个数组的大小 40。\nint *x = malloc(10 * sizeof(int)); printf(\u0026quot;%d\\n\u0026quot;, sizeof(x)); 这里 sizeof() 会认为你只是想知道 int 指针的大小，因此会返回 4 (32/64bit machine)。\n14.3 The free() Call free() API 的参数只有一个，只需要给他传某个 malloc() 返回的首地址指针即可。分配区域的大小是由内存分配库自己记录的。\n14.4 Common Errors 程序员自己管理 malloc() 和 free() 总是会出现各种细微的错误，因此很多现代的编程语言支持自动内存分配，即某些场景下即使程序员只管分配不管回收，垃圾收集器 (garbage collector) 也会帮你把回收的脏活干完。\nForgetting To Allocate Memory 错误的例子：\nchar *src = \u0026quot;Hello\u0026quot;; char *dst; strcpy(dst, src); 正确的例子：\nchar *src = \u0026quot;Hello\u0026quot;; char *dst = (char *)malloc(strlen(src) + 1); // 小心！别忘了+1,'\\0'也要被复制过来 strcpy(dst, src); 事实上 glibc 还提供了 strdup() 函数，我们只需要指定需要复制的函数，它就会自动帮我们 malloc() 空间，复制字符串，并返回指向复制字符串的指针。\nNot Allocating Enough Memory 分配的内存不够不一定会暴露问题，但一旦有别的变量被覆盖就会导致严重的后果。\nForgetting to Initialize Allocated Memory 对 malloc() 得到的内存中的初始值作出任何假设都属于 undefined behavior。\nForgetting to Free Memory 内存泄漏是一种常见的错误。如果程序员总是忘了释放内存，那么长时间运行的软件就有可能将堆区消耗殆尽，最终只能重启机器。需要注意的是，即使你使用的是带有 garbage collector 的语言，你仍然可能无法避免这种错误：如果你还有任何一个指针指向某段内存，即使你将来不再用这段内存，garbage collector 也不会将其回收。\n在某些情况下不使用 free() 可能是无害的，比如你写一个短生命周期的程序 (OJ程序)，那么进程退出的时候操作系统会把该进程使用的所有资源释放。但只分配不释放是很坏的编程习惯。\nFreeing Memory Before You Are Done With It 在释放了一段内存后仍然使用其中的内容是危险的，这种指针被称为 dangling pointer。use-after-free 属于 undefined behavior，可能导致严重后果：比如如果内存分配器将这段内存又分配给了别人，就会出现两人同时使用一段内存的情况。\nFreeing Memory Repeatly double free 也是 undefined behavior，可能导致内存分配器崩溃。\nCalling free() Incorrectly 给 free() 传递错误的指针 (不是之前某个 malloc() 的返回值) 也可能造成严重的后果。\n14.5 Underlying OS Support 操作系统提供 brk() 和 sbrk() 两个系统调用，用于修改进程的 break：break 指向进程堆区的顶部。需要注意的是 malloc() 和 free() 这两个库函数会使用 OS 的系统调用，在程序员层面我们不要跨级去使用系统调用，否则可能导致意想不到的结果，在用户层面我们只要使用库函数即可。\n另外一个可以获得内存的系统调用是 mmap()，传入正确的参数后，mmap() 可以返回一段匿名的内存区域，这个区域并不属于任何一个文件，而是磁盘上交换空间 (swap space) 的一部分。对于应用程序来说，这样一段内存可以被当作堆区内存使用。\n14.6 Other Calls 一些其他有用的库函数包括但不限于：\ncalloc()：先 malloc() 再将分配的内存清零。 realloc()：当你调用 malloc() 分配了一段内存，但发现大小不足时，可以调用 realloc()，它会分配一段更大的内存，将旧内存中的内容复制到新内存区域中，并返回新内存的指针。 14.7 Summary 略。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"5afef218a131830fa7d3bda3843029df","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch14/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch14/","section":"notes","summary":"14.1 Types of Memory 在一个 C 程序中，程序使用的内存有两种：\n栈内存，这部分内存的分配和回收由编译器隐式地完成，因此也被称为“自动内存”。在 C 程序中声明使用栈内存是非常简单的，比如 void func() { int x; // declares an integer on the stack ... } 编译器会自动在栈上为变量 x 分配空间，且函数 func() 结束时编译器会自动回收这部分内存。\n堆内存：如果我们想要一些长生存周期 (不只存活在函数内部) 的内存，我们就要使用堆内存。堆内存是由程序员在程序中显式申请的，分配和释放都由程序员负责。一个例子如下：","tags":null,"title":"Chapter 14: Interlude: Memory API","type":"docs"},{"authors":null,"categories":null,"content":"动态大小的内存分配是比较困难的：随着反复的分配和释放，空闲内存会被切分成很多碎片，此时即使空闲空间的总量大于某个分配需求，分配也可能因为剩余空间过于碎片化而失败。因此，我们在管理空闲空间时要兼顾效率、空闲空间连续性、内存消耗等多方面因素。\n17.1 Assumptions 这里我们假设内存申请和释放的接口和 C 库中的 malloc()/free() 相同：\nvoid *malloc(size_t size); void free(void *ptr); 注意：释放空间时，调用者只传入起始地址，不传入空间的 size，因此我们在分配时就要想办法记录每块分配出去的空间的大小。\n分配空间的过程中严禁出现 double-alloc 的情况。\n17.2 Low-level Mechanisms Splitting and Coalescing 我们用一个链表维护所有的空闲内存区间，链表的每个节点代表一段连续的空闲内存，有起始地址，块大小等字段。当我们要分配一段内存出去，且分配大小小于当前链表节点大小时，我们可以将链表节点的前半部分切出去给调用者，后半部分保留在链表中。这就是 splitting。\n当 free() 将一段内存空间释放时，如果我们不加任何操作地将其放到链表头，时间久了就会出现完整的空闲内存被我们人为地切成了若干个首尾相接的段的情况。一个好的维护方法是：链表中的所有节点按照顺序排列，每当新插入节点时，将其与前后相邻的节点比较，如果地址连在了一起就合并节点。这就是 coalescing。\nTracking The Size Of Allocated Regions free() 函数传入的只有待释放内存空间的起始地址，我们必须在分配的时候想办法记录分配出去的空间大小。一种方法是在分配区域首地址的前面记录一个 header：\ntypedef struct __header_t { int size; int magic; }header_t; 当 free(void *ptr) 来到时，我们首先在 ptr 前方的 header 处检查魔数是否正确以判定这是否是一个合法的可释放地址。如果魔数检查通过，我们便可以取出 size。注意最后加入空闲空间链表的总大小应为 size + sizeof(header_t)。\nEmbedding A Free List 我们需要空间来保存链表，但我们作为 memory allocator 本身，当然不能调用 malloc() 去申请内存。我们应当将链表节点直接保存在空闲的内存空间里。\n当一个 alloc() 需求来临时，选择一个合法的节点 split 出需要的空间。当一个 free() 来临时，将新的空闲空间节点加入链表，并在可以时与相邻节点合并。\nGrowing The Heap 当扫描完整个空闲空间链表但仍然无法分配出所需大小的空间时，返回 NULL 表示无法分配是完全合情合理的。对于应用层的 memory allocator 来说，如果内存耗尽，它会用系统调用 (如 sbrk()) 向操作系统申请更多的内存并将其加入到空闲空间链表中。\n17.3 Basic Strategies 由于申请内存和释放内存的行为是完全由上层程序决定的，所以任何策略都会在针对性的 input 下把内存搞得很破碎。我们无法给出完美的解决方案，但至少可以提出一些比较有可能较优的解决方案。\nBest Fit (Smallest Fit) Best fit 策略是：alloc() 需求来临时，根据大小从链表中找出可以满足要求且大小最小的链表节点 split 出一块。该策略可以比较好地减少破碎的内存块，但每次 alloc() 都完整地遍历链表代价太大。\nWorst Fit Worst Fit 每次挑最大的内存块切割，这样可以避免出现很多破碎的小内存块，但它也要遍历整个链表，而且实际情况下效果不好。\nFirst Fit First Fit 总是寻找第一个足够切割的内存块 alloc()，这样不需要遍历整个链表。但做久了以后链表的头部会充斥比较多的内存碎片。\nNext Fit Next Fit 的做法是保存上一次分配的位置，下一次要分配时从上一次的位置开始 First Fit。实践中这种方法的表现和 First Fit 差不多。\n17.4 Other Approaches Segregated List slab 的基本思路时：对于一些比较常见的分配大小 (比如 4B, 2B, page size) 等，可以准备一个链表专门存储这种大小的块块，这样分配的时候直接从链表中取一个节点即可，不需要之前所说的繁琐的切分、合并等步骤。slab 有点像全局 memory manager 的一个 cache，如果某个时刻 slab 里的节点用完了，它会从全局的大链表中再批发一些节点。\nBuddy Allocation Buddy Allocation 比较像“线段树”：它把一个长度为 $2^N$ 的区间分成左右各 $2^{N-1}$ 的，每个节点再一分为二，依次类推。这样我们不需要仔细地维护拆分、合并相关的问题。Buddy Allocation 的弱点在于：为了对齐我们只能分配 2 的幂次大小的块，会造成一些 internal fragmentation。\n17.5 Summary 略。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"79db30a695a4fda92e37de43ac02ee50","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch17/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch17/","section":"notes","summary":"动态大小的内存分配是比较困难的：随着反复的分配和释放，空闲内存会被切分成很多碎片，此时即使空闲空间的总量大于某个分配需求，分配也可能因为剩余空间过于碎片化而失败。因此，我们在管理空闲空间时要兼顾效率、空闲空间连续性、内存消耗等多方面因素。\n17.1 Assumptions 这里我们假设内存申请和释放的接口和 C 库中的 malloc()/free() 相同：\nvoid *malloc(size_t size); void free(void *ptr); 注意：释放空间时，调用者只传入起始地址，不传入空间的 size，因此我们在分配时就要想办法记录每块分配出去的空间的大小。\n分配空间的过程中严禁出现 double-alloc 的情况。\n17.2 Low-level Mechanisms Splitting and Coalescing 我们用一个链表维护所有的空闲内存区间，链表的每个节点代表一段连续的空闲内存，有起始地址，块大小等字段。当我们要分配一段内存出去，且分配大小小于当前链表节点大小时，我们可以将链表节点的前半部分切出去给调用者，后半部分保留在链表中。这就是 splitting。\n当 free() 将一段内存空间释放时，如果我们不加任何操作地将其放到链表头，时间久了就会出现完整的空闲内存被我们人为地切成了若干个首尾相接的段的情况。一个好的维护方法是：链表中的所有节点按照顺序排列，每当新插入节点时，将其与前后相邻的节点比较，如果地址连在了一起就合并节点。这就是 coalescing。","tags":null,"title":"Chapter 17: Free Space Management","type":"docs"},{"authors":null,"categories":null,"content":"一个多线程程序会有多个执行流，即有好几个 PC 并发/并行地取指执行，我们可以将其理解为多个进程，不过它们共享同一个地址空间。每个线程有自己的 PC 和一套寄存器，因此类似于进程切换，我们也需要线程切换。不过由于线程共享地址空间，所以线程切换时无需切换页表。\n虽然线程可以共享地址空间，但每个线程要有自己独立的栈。不同于单线程地址空间，多线程程序的地址空间中有多个栈，每个线程一个，这个线程栈也被称为 thread-local storage。\n26.1 Why Use Threads? 使用线程至少有以下两点好处：\n提高并行度。在一个多核处理器上，我们可以让多个线程每个占据一个 CPU 核，分摊一部分工作，从而达到并行提速的效果。 避免 I/O 操作阻塞程序。如果一个线程在等待 I/O 操作，CPU 可以通过线程切换让别的线程上 CPU 工作，这样就实现了等 I/O 和做其他事情同时进行。 26.2 An Example: Thread Creation t0.c 中创建了两个进程并让它们打印不同的内容。在多线程程序中，各个线程执行的顺序是不确定的：先被创建的进程可能会后执行；一个线程被创建了之后可能在 wait 它时才执行，也可能会立即执行，然后 wait 时立即返回 etc.\n26.3 Why It Gets Worse: Shared Data t1.c 中创建了两个线程，两个线程都对共享变量进行 N 次 +1，在 N 较大时可以观测到共享变量的结果小于 2N。\nThread-local Variables\n在线程调用的函数里定义的变量都会是 thread local 的变量。t1.c 中打印了局部变量 i 的地址，可以看到不同的线程打印出的地址不一样 (在各自的线程栈上)。\n在函数体外，用 __thread 修饰的变量也是 thread local 的。\nValgrind\nValgrind 中的 memchecker 是强大的内存检测工具。编译好一个文件 proc.c 后用 valgrind ./proc 执行，可以检测 memory leak, use after free 等问题。\n26.4 The Heart Of The Problem: Uncontrolled Scheduling counter ++ 这条语句在汇编层面是三条指令：\nmov (addr), %eax add $0x1, %eax mov %eax, (addr) 其中 addr 是 counter 变量的内存地址。如果两个线程轮流执行汇编语句，那么它们各执行一次 +1 后，事实上 counter 只加了 1,并没有 +2。\n我们称这两个线程触发了竞争条件 (race condition)，准确说是一次数据竞争。导致这一竞争的代码称为临界区域 (critical section)。我们希望实现一种互斥机制，使得一个线程执行临界区域代码时不会被另一个线程打断。\n26.5 The Wish For Atomicity 我们希望有这样的一条原子指令：\nmomory-add (addr), 0x1 可以一下子帮我们完成 +1 操作。这里的原子性指的是：操作在执行过程中不会被中途打断。这个操作是一个最小的单元，它要么被完全执行了，要么没有被执行 (all or none)，不会在某时刻处于执行了一半的状态。\n将若干个操作打包成一个原子指令的过程我们称为一个交易 (transaction)。但硬件不能允许我们无限制地添加原子指令。我们要实现的是一种同步机制，它可以保证多个线程以一种可控的方式进入临界区域，从而使得执行正确。\n26.6 One More Problem: Waiting For Another 在某些情境下，一个线程需要等待某件事情做好了才能继续进行，比如等待 I/O 操作完成。操作系统不仅要支持线程之间的同步，还要支持在某些条件下挂起/唤醒线程，这会通过条件变量 (condition variables) 来实现。\n26.7 Summary: Why in OS Class? 操作系统本身也是一个并发程序。如果有多个程序使用 write() 系统调用，那么操作系统就必须非常小心地处理内核中和 write() 有关的并发数据结构。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"efc1e3ba2d9457f87831e3f1758ae303","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch26/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch26/","section":"notes","summary":"一个多线程程序会有多个执行流，即有好几个 PC 并发/并行地取指执行，我们可以将其理解为多个进程，不过它们共享同一个地址空间。每个线程有自己的 PC 和一套寄存器，因此类似于进程切换，我们也需要线程切换。不过由于线程共享地址空间，所以线程切换时无需切换页表。\n虽然线程可以共享地址空间，但每个线程要有自己独立的栈。不同于单线程地址空间，多线程程序的地址空间中有多个栈，每个线程一个，这个线程栈也被称为 thread-local storage。\n26.1 Why Use Threads? 使用线程至少有以下两点好处：\n提高并行度。在一个多核处理器上，我们可以让多个线程每个占据一个 CPU 核，分摊一部分工作，从而达到并行提速的效果。 避免 I/O 操作阻塞程序。如果一个线程在等待 I/O 操作，CPU 可以通过线程切换让别的线程上 CPU 工作，这样就实现了等 I/O 和做其他事情同时进行。 26.2 An Example: Thread Creation t0.","tags":null,"title":"Chapter 26: Concurrency: An Introduction","type":"docs"},{"authors":null,"categories":null,"content":"27.1 Thread Creation 创建线程的 API 为\nint pthread_create( pthread_t *thread, const pthread_attr_t *attr, void * (*start_routine)(void*), void * arg); thread 是指向 pthread_t 类型变量的指针，我们将来要通过这个结构体来控制这个线程，所以现在需要对其进行初始化。 attr 表明了希望该线程拥有的属性，大多数情况下可以传 NULL，表示按照默认属性创建。 start_routine 是一个指向函数的指针，新创建的线程会从这个函数开始执行。 arg 是传给 start_routine() 的参数。 这里参数的类型和返回值类型都是 void * 类型的指针 (相当于只要求地址，不要求对地址类型的解读)，这是为了使得函数支持任意类型的参数和返回值。\n27.2 Thread Completion 等待线程完成的 API 为\nint pthread_join(pthread_t thread, void **value_ptr); thread 表示要等待运行完成的线程结构体。 value_ptr 是一个指向 void * 类型指针的指针，pthread_join() 返回时， value_ptr 会指向线程创建时的 start_routine() 函数的返回值。如果我们不在乎这个返回值，可以直接传入 NULL。 很多时候，我们需要的线程函数返回值只是一个数 (如 0 表示成功，1 表示失败)，这时我们有比较简单的写法：\nvoid *mythread(void *arg) { return (void *)(arg + 1); } int main () { int r; pthread_t p; pthread_create(\u0026amp;p, NULL, mythread, (void *)100); pthread_join(p, (void **)\u0026amp;r); } 在线程函数中将返回值转换成 void * 类型，在主函数中我们只要将整型变量 r 的地址转换成 void ** 类型，就可以直接把返回值存到 r 里面。\n使用线程返回时要格外注意：返回值的实体不能在线程栈上，因为线程返回时线程栈会被释放。比如\nvoid *mythread(void *arg) { myret_t r; r = {10, 20}; return (void *)\u0026amp;r; } 这个写法是不合理的，返回时 r 已经被释放，返回结果是 UB。将结构体定义在堆区可以避免这个问题：\nvoid *mythread(void *arg) { myret_t *r = malloc(sizeof(myret_t)); *r = {10, 20}; return (void *)r; } 27.3 Locks 用于获得互斥锁和释放互斥锁的 API 为：\nint pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); 第一个函数会尝试获得锁，直到获得了之后返回 (互斥锁不会轮询锁的状态，在得不到时会进入睡眠状态)。第二个第二个函数用于释放锁。\n注：这两个函数是有返回值的。正常情况下它们应该返回 0。一个好的编程习惯是在调用这些 API 时随手检查返回值，比如封装成这样：\nvoid Pthread_mutex_lock(pthread_mutex_t *mutex) { int rc = pthread_mutex_lock(mutex); assert(rc == 0); } 互斥锁在使用之前需要先初始化。初始化有两种方式：\n在定义互斥锁变量时直接使用 INITIALIZER，它会按照默认属性初始化锁：\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; 在运行过程中初始化：\nvoid Pthread_mutex_init(pthread_mutex_t *mutex) { int rc = pthread_mutex_init(mutex, NULL); assert(rc == 0); } int main () { pthread_mutex_t lock; Pthread_mutex_init(\u0026amp;lock); } pthread_mutex_init() 的第二个参数用于指定初始化锁的属性，通常情况下使用 NULL 即可。\n锁用完之后，应当使用和初始化函数相对应的 pthread_mutex_destroy() 函数来销毁一个锁。\n另有两个 API：\nint pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_timedlock(pthread_mutex_t *mutex, struct timespec *abs_timeout); trylock() 会尝试获得锁，如果锁正在被占用则直接返回。timedlock() 会在一个指定的时间范围内尝试获得锁，如果这个时间段内未能获得锁就返回。trylock() 可以理解为 timedlock() 的 0 秒版本；之前的 lock() 可以理解为 timedlock() 的无限长时间版本。\n这两个 API 不常用，但在一些情境下可以用于避免死锁。\n27.4 Condition Variables 条件变量的两个主要 API 为\nint pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex); int pthread_cond_signal(pthread_cond_t *cond); 调用 cond_wait() 时，当前线程必须已经拥有互斥锁 mutex。cond_wait() 会释放 mutex 并将当前线程睡眠在条件变量 cond 上。当另外的某个线程调用 cond_signal() 唤醒了该线程时，该线程会重新尝试获得互斥锁 mutex，获得了之后从 cond_wait() 函数返回。\n使用条件变量之前要先对条件变量初始化，其方法和互斥锁是类似的：\npthread_cond_t cond = PTREAD_COND_INITALIZER; 27.5 Compiling and Running 要使用上述的 POSIX 线程库中的函数，我们需要在源代码中 #include \u0026lt;pthread.h\u0026gt; ，并在编译时加入 -lpthread 选项。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"421d05f9f7252296267a9debab2db0c6","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch27/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch27/","section":"notes","summary":"27.1 Thread Creation 创建线程的 API 为\nint pthread_create( pthread_t *thread, const pthread_attr_t *attr, void * (*start_routine)(void*), void * arg); thread 是指向 pthread_t 类型变量的指针，我们将来要通过这个结构体来控制这个线程，所以现在需要对其进行初始化。 attr 表明了希望该线程拥有的属性，大多数情况下可以传 NULL，表示按照默认属性创建。 start_routine 是一个指向函数的指针，新创建的线程会从这个函数开始执行。 arg 是传给 start_routine() 的参数。 这里参数的类型和返回值类型都是 void * 类型的指针 (相当于只要求地址，不要求对地址类型的解读)，这是为了使得函数支持任意类型的参数和返回值。","tags":null,"title":"Chapter 27: Interlude: Thread API","type":"docs"},{"authors":null,"categories":null,"content":"29.1 Concurrent Counters 一个最简单的 thread-safe 的计数器实现如下 (用锁保护每次读写)：\ntypedef struct __counter_t { int value; pthread_mutex_t lock; } counter_t; void init(counter_t *c) { c-\u0026gt;value = 0; Pthread_mutex_init(\u0026amp;c-\u0026gt;lock, NULL); } void increment(counter_t *c) { Pthread_mutex_lock(\u0026amp;c-\u0026gt;lock); c-\u0026gt;value++; Pthread_mutex_unlock(\u0026amp;c-\u0026gt;lock); } void decrement(counter_t *c) { Pthread_mutex_lock(\u0026amp;c-\u0026gt;lock); c-\u0026gt;value--; Pthread_mutex_unlock(\u0026amp;c-\u0026gt;lock); } int get(counter_t *c) { Pthread_mutex_lock(\u0026amp;c-\u0026gt;lock); int rc = c-\u0026gt;value; Pthread_mutex_unlock(\u0026amp;c-\u0026gt;lock); return rc; } 但这种实现的 scalability 很差：如果给 $n$ 个核分配等量的任务，最终所消耗的时间几乎是单个任务时长的 $n$ 倍。大部分时间 CPU 核之间在互相等锁，我们没有利用多处理器达到并行的效率。\n如果愿意牺牲一部分精确性，我们可以设计一种 approximate counter 来提升效率。approximate counter 中，每个 CPU 核有一个单独的 counter，此外还有一个全局的 counter。全局和本地的 counter 都有锁保护。修改操作中 (假设只有 increment)，CPU 核直接修改本地的 counter，因此各个核可以并行。当本地 counter 的值达到一个阈值时，本地 counter 会和全局 counter 做一次同步，将本地值加到全局值上并将本地值清零。查询操作中直接返回全局 counter 的值即可。\ntypedef struct __counter_t { int global; pthread_mutex_t glock; int local[NUMCPUS]; pthread_mutex_t llock[NUMCPUS]; int threshold; }counter_t; void init(counter_t *c, int threshold) { c-\u0026gt;threshold = threshold; c-\u0026gt;global = 0; Pthread_mutex_init(\u0026amp;c-\u0026gt;glock, NULL); for (int i = 0; i \u0026lt; NUMCPUS; ++i) { c-\u0026gt;local[i] = 0; Pthread_mutex_init(\u0026amp;c-\u0026gt;llock[i], NULL); } } void update(counter_t *c, int threadID, int amt) { int cpu = threadID % NUMCPUS; Pthread_mutex_lock(\u0026amp;c-\u0026gt;llock[cpu]); c-\u0026gt;local[cpu] += amt; if (c-\u0026gt;local[cpu] \u0026gt;= c-\u0026gt;threshold) { Pthread_mutex_lock(\u0026amp;c-\u0026gt;glock); c-\u0026gt;glocal += c-\u0026gt;local[cpu]; Pthread_mutex_unlock(\u0026amp;c-\u0026gt;glock); c-\u0026gt;local[cpu] = 0; } Pthread_mutex_unlock(\u0026amp;c-\u0026gt;llock[cpu]); } int get(counter_t *c) { Pthread_mutex_lock(\u0026amp;c-\u0026gt;glock); int rt = c-\u0026gt;global; Pthread_mutex_unlock(\u0026amp;c-\u0026gt;glock); return rt; } 在该实现版本中，每个线程并不会去确认自己所处的核，而是直接随机 (进程号取模) 分配一个核对应的本地计数器。这样做和之前描述的算法无异。\n上述算法中，如果阈值是 0 则与精确的计数器无异。随着阈值的提高，计数器的并行效率会越来越高 (大致呈反比例函数)，但返回的结果会越来越不精确。\n29.2 Concurrent Linked List 一个朴素的做法是用一把大锁保护整个链表的修改和查询。一种很容易出错的情形是：如果函数中间有多处 return，则每处 return 前都要记得释放锁。为了避免这种 bug，书写代码时可以考虑多用 break 替代 return 减少 return 分支数，或者另写一个 wrapper 调用真正的函数，在 wrapper 中维护锁。\n一种增加链表访问并行度的方案是所谓的 hand-over-hand locking (lock coupling)。在查询链表中是否有某个元素时，我们平常的做法是用一个大锁保护整个链表，然后依次扫描链表节点。hand-over-hand locking 的思想是为每个链表节点创建一把锁，每次准备访问下一个节点时，先获得下一个节点的锁，再释放本节点的锁。这样多个线程就可以并行地查询链表。\n这个方案在理论上可行，但实际操作中，频繁地获得和释放锁会带来昂贵的代价。一个更可行的方案是每 $n$ 个节点用一把锁保护，准备进入下一个“区域”时做一次 overhead acquiring and releasing。\n29.3 Concurrent Queues 我们可以在队头和队尾分别维护一把锁，这样从队头取元素和向队尾添加元素的操作可以并行地执行：\ntypedef struct __node_t { int val; struct __node_t *next; }node_t; typedef struct __queue_t { node_t *head; node_t *tail; pthread_mutex_t headlock; pthread_mutex_t taillock; }queue_t; void queue_init(queue_t *q) { node *tmp = malloc(sizeof(node_t)); tmp-\u0026gt;next = NULL; q-\u0026gt;head = q-\u0026gt;tail = tmp; pthread_mutex_init(\u0026amp;q-\u0026gt;headlock, NULL); pthread_mutex_init(\u0026amp;q-\u0026gt;taillock, NULL); } int queue_enqueue(queue_t *q, int val) { node *tmp = malloc(sizeof(node_t)); if (tmp == NULL) return -1; tmp-\u0026gt;val = val; tmp-\u0026gt;next = NULL; pthread_mutex_lock(\u0026amp;q-\u0026gt;taillock); q-\u0026gt;tail-\u0026gt;next = tmp; q-\u0026gt;tail = tmp; pthread_mutex_unlock(\u0026amp;q-\u0026gt;taillock); } int queue_dequeue(queue_t *q, int *val) { pthread_mutex_lock(\u0026amp;q-\u0026gt;headlock); node *tmp = q-\u0026gt;head; node *newhead = tmp-\u0026gt;next; if (newhead == NULL) { pthread_mutex_unlock(\u0026amp;q-\u0026gt;headlock); return -1; // queue was empty } *val = tmp-\u0026gt;val; q-\u0026gt;head = newhead; pthread_mutex_unlock(\u0026amp;q-\u0026gt;headlock); free(tmp); return 0; } 这里的一个重要的技巧是：我们在初始化队列时创建了一个 dummy node，并让 q-\u0026gt;head 和 q-\u0026gt;tail 都指向它。这个 dummy node 是永远不会出队的。这样我们避免了队列在形状上完全为空的情况，从而保证 headlock 和 taillock 做的工作永远是没有交叉的。\n29.4 Concurrent Hash Table 一个支持并发访问的 Hash table 实现很简单：使用多个之前提到的链表即可：\n#define BUCKETS (101) typedef struct __hash_t { list_t lists[BUCKETS]; }hash_t; void Hash_Init(hash_t *H) { for (int i = 0; i \u0026lt; BUCKETS; i++) List_Init(\u0026amp;H-\u0026gt;lists[i]); } int Hash_Insert(hash_t *H, int key) { int bucket = key % BUCKETS; return List_Insert(\u0026amp;H-\u0026gt;lists[bucket], key); } int Hash_Lookup(hash_t *H, int key) { int bucket = key % BUCKETS; return List_Lookup(\u0026amp;H-\u0026gt;lists[bucket], key); } 这个实现在实际中效率不低的原因是：我们并没有用一把大锁保护整个哈希表，而是对每个链表单独用一把所保护。多个线程同时访问哈希表的一个 bucket 的几率较低，这使得 lock contention 发生次数较少。\nTip: Avoid Premature Optimization\n\u0026ldquo;Premature Optimization is the root of all evil.\u0026rdquo; - Knuth\n很多操作系统内核开发时，都是先使用一个大内核锁 (big kernel lock, BKL)，先保证正确性，再考虑如何把锁拆开提升效率。\n29.5 Summary 略。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"88bb0c5429d7fcb79eb2688cc6947794","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch29/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch29/","section":"notes","summary":"29.1 Concurrent Counters 一个最简单的 thread-safe 的计数器实现如下 (用锁保护每次读写)：\ntypedef struct __counter_t { int value; pthread_mutex_t lock; } counter_t; void init(counter_t *c) { c-\u0026gt;value = 0; Pthread_mutex_init(\u0026amp;c-\u0026gt;lock, NULL); } void increment(counter_t *c) { Pthread_mutex_lock(\u0026amp;c-\u0026gt;lock); c-\u0026gt;value++; Pthread_mutex_unlock(\u0026amp;c-\u0026gt;lock); } void decrement(counter_t *c) { Pthread_mutex_lock(\u0026amp;c-\u0026gt;lock); c-\u0026gt;value--; Pthread_mutex_unlock(\u0026amp;c-\u0026gt;lock); } int get(counter_t *c) { Pthread_mutex_lock(\u0026amp;c-\u0026gt;lock); int rc = c-\u0026gt;value; Pthread_mutex_unlock(\u0026amp;c-\u0026gt;lock); return rc; } 但这种实现的 scalability 很差：如果给 $n$ 个核分配等量的任务，最终所消耗的时间几乎是单个任务时长的 $n$ 倍。大部分时间 CPU 核之间在互相等锁，我们没有利用多处理器达到并行的效率。","tags":null,"title":"Chapter 29: Lock-based Concurrent Data Structures","type":"docs"},{"authors":null,"categories":null,"content":"很多时候，我们有一个任务等待另一个任务的需求，比如主线程等到子线程结束后再继续执行 (这个函数通常被称为 join() )。一个朴素的想法是利用一个共享变量实现：\nvolatile int done = 0; void *child(void *arg) { do_something(); done = 1; return NULL; } int main () { pthread_t c; Pthread_create(\u0026amp;c, NULL, child, NULL); while (done == 0) ; do_something_else(); return 0; } 但这样做主线程会在 done 变量上不停地自旋，占 CPU 不干活。我们希望有更高效的实现方法。\n30.1 Definition and Routines 为了让一个线程等待一个条件成立，我们通常使用条件变量 (condition variable)。条件变量可以理解为一个显式的队列，线程可以将自己加入到这个队列中挂起，当其他线程的操作使得条件变化时，它会唤醒这个“队列”中的线程。我们提供两个 API：wait() 可以让线程将自己加入到队列中等待；signal() 可以让别的线程改变了条件状态时向队列中的线程“发送信号”。\nPOSIX 提供的条件变量 API 为\nint pthread_cond_wait(pthread_cont_t *c, pthread_mutex_t *m); int pthread_cond_signal(pthread_cond_t *c); 注意到 wait() 的参数中除了条件变量 c 还有一个自旋锁 m。wait() 的语义要求调用时线程必须拥有自旋锁 m，wait() 会负责释放这个自旋锁并使当前线程进入睡眠状态 (这两步是原子的)；当 signal() 使当前线程被唤醒后，wait() 会负责让线程重新获得自旋锁 m，然后返回。\njoin.c 提供了一个主线程等待子线程结束的正确实现。事实上这个过程是很容易实现错的，比如如下一些写法：\nvoid thr_exit() { Pthread_mutex_lock(\u0026amp;m); Pthread_cond_signal(\u0026amp;c); Pthread_mutex_unlock(\u0026amp;m); } void thr_join() { Pthread_mutex_lock(\u0026amp;m); Pthread_cond_wait(\u0026amp;c, \u0026amp;m); Pthread_mutex_unlock(\u0026amp;m); } 这个写法只有在 thr_join() 在 thr_exit() 之前执行的情况下才是正确的。如果颠倒了顺序，thr_join() 将永远不会被唤醒 ( join_no_state_var.c 中，主线程里使用了 sleep() 以精确复现这一情形)。因此我们可以看到，使用条件变量时理应有一个条件状态的判断。\nvoid thr_exit() { done = 1; Pthread_cond_signal(\u0026amp;c); } void thr_join() { while (done == 0) Pthread_cond_wait(\u0026amp;c); } 这个写法没有用锁保护状态变量 done 的读写，缺失了原子性。这里的原子性缺失指的是：虽然在 while 判断时 done == 0，但在 wait() 时 done 可能已经不等于 0 了。考虑这样一种执行流：thr_join() 做完 while 判断进入循环，还没来得及 wait() 时，执行流被打断，thr_exit() 执行并 signal()，但此时队列中并没有线程。接着 thr_join() 继续执行陷入睡眠，那么它将永远不会被唤醒 ( join_no_lock() 中在主线程使用了比子线程时间更长的 sleep() 以精确复现这一情况)。\nTip: Always Hold The Lock While Signaling\nPOSIX 的 wait() 函数的语义已经要求了我们在调用 wait() 时必须要拥有自旋锁；虽然少数情况下我们可以无锁地调用 signal()，但为了安全和简单，我们应当在 signal() 时也用自旋锁保护。\n30.2 The Producer/Consumer (Bounded Buffer) Problem 生产者-消费者问题在系统中很常见，比如下面的例子：\ngrep foo file.txt | wc -l grep 找到的内容通过管道传送给 wc 统计个数。管道在内核中就是一个缓冲区，因此这里 grep 是一个生产者，wc 是一个消费者，wc 不能在 buffer 为空的时候从管道里读东西，grep 也不能在缓冲区满了的时候再往里填。\nA Broken Solution 一个比较自然但却错误的实现如下所示：\nvoid *producer(void *arg) { for (int i = 0; i \u0026lt; LOOP; i++) { lock(\u0026amp;lk); if (count == 1) wait(\u0026amp;cond, \u0026amp;lk); put(i); // count becomes 1 signal(\u0026amp;cond); unlock(\u0026amp;lk); } } void *consumer(void *arg) { while (1) { lock(\u0026amp;lk); if (count == 0) wait(\u0026amp;cond, \u0026amp;lk); int rt = get(); // count becomes 0 signal(\u0026amp;cond); unlock(\u0026amp;lk); printf(\u0026quot;%d\\n\u0026quot;, rt); } } 如果只有一个生产者线程和一个消费者线程，这个实现是正确的。但如果有多个，比如一个生产者和两个消费者，就会有并发 bug。考虑如下执行过程：\n$T_{c_1}$ 运行，发现 count == 0，挂起； $T_p$ 运行，往 buffer 里放了一个数，然后通过 signal() 唤醒 $T_{c_1}$。 $T_{c_1}$ 刚被唤醒，还没来得及获得自旋锁返回的时候，$T_{c_2}$ 运行，从 buffer 里取走了这个数打印； 这时返回到 $T_{c_1}$，获得自旋锁返回后，由于之前的判断是 if 语句，它无法发现 count 此时又变成 0 了，于时再次从 buffer 中取数，触发 assertion fail。 并发 bug 产生的原因是：从消费者线程被唤醒到消费者线程真正获得自旋锁开始工作这段时间内，buffer 的状态改变了。signal() 的语义只是通知一个正在等待的线程：世界的状态改变了，但它不保证世界的状态被改变成了调用 signal() 之前那一瞬的状态。 这种 signal() 的语义被称为 Mesa semantics。与之相对的是 Hoare Semantics，它保证调用 signal() 之后一个线程被唤醒并立即被执行 (原子性)。但后者难实现的多，现在绝大部分系统的 signal() 使用的都是 Mesa semantics。\nBetter, But Still Broken: While, Not If Mesa semantics 是比较容易克服的：我们只要将上面程序中对状态变量做判断的 if 换成 while 即可。这样即使被唤醒后状态又被改变，线程获得自旋锁后会再次检查状态，发现不对后可以再次进入睡眠。\nAlways use while loops when working with condition variables!\n但即使将 if 改成 while，我们的程序仍然有并发 bug。考虑如下执行过程：\n$T_{c_1}$ 运行，发现 count == 0，挂起； $T_{c_2}$ 运行，发现 count == 0，挂起； $T_p$ 运行，往 buffer 里添加了一个数字，然后通过 signal() 唤醒了 $T_{c_1}$。唤醒后 $T_{c_1}$ 并未立刻执行，而是 $T_p$ 继续运行，第二次循环时 $T_p$ 发现 count == 1，挂起； $T_{c_1}$ 运行，从 buffer 里读取了一个数字 (count 变为 0) 然后通过 signal() 唤醒一个线程。注意此时睡眠在条件变量上的线程有 $T_p$ 和 $T_{c_2}$ 两个。$T_{c_1}$ 选择唤醒 $T_{c_2}$。 $T_{c_1}$ 和 $T_{c_2}$ 都发现没有数据可读，挂起。 到这里，三个线程全部陷入睡眠，程序停滞。从这个例子中我们可以看出：消费者线程消费完后应该唤醒生产者线程；生产者线程生产完后应该唤醒消费者线程，我们应该有两个条件变量。\nThe Correct Producer/Consumer Solution pc.c 提供了一个完整、正确的生产者-消费者实现，其中的要点如下：\n使用两个条件变量，保证消费者只能唤醒生产者，生产者只能唤醒消费者。 判断状态变量使用 while 语句。 使用一个循环数组作为 buffer，count 的上限不再是 1 而是一个指定的 max，这使得 buffer 有了一定的容量。 这是一个单生产者-多消费者的程序，生产者最后为每个消费者准备了一个 -1，以保证消费者线程能够全部退出。 Tip: Use While (Not If) for Conditions\n使用 while 总是对的，在少数场合下使用 if 也可以达到目的，但为了安全性最好通通使用 while。\n我们推荐使用 while 而不是 if 的另一个原因是：一些实现的有问题的 signal() 可能会唤醒不止一个等待的线程。这种情况下，while 仍然能帮我们保证正确。\n30.3 Covering Conditions 假设我们希望用条件变量实现一个内存分配器，alloc() 时如果剩余内存不足则挂起，一段伪代码如下：\nint bytesLeft = MAX_HEAP_SIZE; void *allocate(int size) { lock(\u0026amp;lk); while (bytesLeft \u0026lt; size) wait(\u0026amp;cond, \u0026amp;lk); void *ptr = GetMemoryFromHeap(size); bytesLeft -= size; unlock(\u0026amp;lk); return ptr; } void free(void *ptr, int size) { lock(\u0026amp;lk); bytesLeft += size; FreeMemoryToHeap(ptr, size); signal(\u0026amp;cond); unlock(\u0026amp;lk); } 假设我们有一个 alloc(100) 和 alloc(10) 处于睡眠状态，现在来了一个 free(50)，问题出现了：如果我们随意挑一个线程唤醒，假如挑了 alloc(100) 的那个，分配还是会失败，且我们错过了让 alloc(10) 成功的机会。一种解决方案是：用一个 broadcast() 函数替代 signal() 函数，它可以唤醒睡眠在条件变量上的所有线程。这种方式被称为 covering conditions。\nbroadcast() 相较于 signal() 的坏处在于：并不是所有的线程都能在被唤醒后运行下去，比如现在 buffer 里只有一个字符，而 broadcast() 唤醒了 100 个消费者，那么只有一个消费者能得到字符。运行不下去的字符会释放锁并再次进入睡眠，这种无谓打搅了睡眠线程的方式对性能影响很大。\n正因如此，虽然我们在之前的生产者-消费者问题中可以使用一个条件变量+broadcast 的方式解决问题，但那时我们显然有很简单的 2-条件变量解决方案，所以不考虑这种效率较低的方式。不过在内存分配的场景中，broadcast() 几乎是唯一的选择。\n30.4 Summary 略。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"78f9e1402c1b9556a1c713df45ecbbd8","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch30/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch30/","section":"notes","summary":"很多时候，我们有一个任务等待另一个任务的需求，比如主线程等到子线程结束后再继续执行 (这个函数通常被称为 join() )。一个朴素的想法是利用一个共享变量实现：\nvolatile int done = 0; void *child(void *arg) { do_something(); done = 1; return NULL; } int main () { pthread_t c; Pthread_create(\u0026amp;c, NULL, child, NULL); while (done == 0) ; do_something_else(); return 0; } 但这样做主线程会在 done 变量上不停地自旋，占 CPU 不干活。我们希望有更高效的实现方法。","tags":null,"title":"Chapter 30: Condition Variables","type":"docs"},{"authors":null,"categories":null,"content":"信号量的概念最早由 Dijkstra 提出，它既可以作为锁使用也可以作为条件变量使用。\n31.1 Semaphores: A Definition 使用一个信号量之前我们要定义其初始值：\n#include \u0026lt;semaphore.h\u0026gt; sem_t s; sem_init(\u0026amp;s, 0, 1); sem_init() 的第一个参数是信号量，第三个参数是初始值，第二个参数为 0 表示该信号量在同进程下的所有线程之间共享 (如果想让信号量在不同进程之间共享，可以设置为其他数值)。\nPOSIX 标准提供了信号量操作相关的 API：sem_wait() 和 sem_post()。相较于条件变量，信号量使用起来非常简单：我们不需要关注什么时候获得锁，用 while 还是 if 等问题，在用户层面我们可以认为这些 API 都是原子的。它们的语义可以用如下伪代码描述：\nvoid sem_wait(sem_t *s) { decrement the value of s by one; wait if value of s is negative; } void sem_post(sem_t *s) { increment the value of s by one; if there are one or more threads waiting, wake one; } 当 s 的值为正时，其意义是剩余的资源量；当 s 的值为负时，其意义是当前正在等待的线程数量。\n(注：不同于锁，sem_post() 并不需要一个线程曾经调用过 sem_wait()，这相当于线程可以凭空“创造”一份资源。因此使用时一定要格外小心，注意 sem_wait() 和 sem_post() 的对应。)\n31.2 Binary Semaphores (Locks) 信号量可以当作锁来使用，这种信号量被称为 binary semaphore。 binary.c 展示了具体的实现。\nsem_t m; sem_init(\u0026amp;m, 0, 1); sem_wait(\u0026amp;m); // critical section sem_post(\u0026amp;m); 信号量的初始值设置为 1，我们可以把它想象成一个单位的资源 (任何时刻只能上一把锁)。考虑一个 lock contention 的情况：\n线程 1 调用 sem_wait()，m 的值变为 0，线程 1 成功进入临界区域。 线程 2 调用 sem_wait()，m 的值变为 -1，该线程进入等待序列。 线程 3 调用 sem_wait()，m 的值变为 -2，该线程进入等待序列。 线程 1 离开临界区域，调用 sem_post()，m 的值变为 -1，线程 1 唤醒一个等待序列里的线程 (假设是线程 2) 继续执行。线程 2 成功进入临界区域。 线程 2 离开临界区域，调用 sem_post()，m 的值变为 0，线程 2 唤醒线程 3，线程 3 成功进入临界区域。 线程 3 离开临界区域，调用 sem_post()，m 的值恢复为 1 (锁当前空闲)，线程 3 没有唤醒任务。 用信号量实现的锁是 sleep lock 而不是 spinlock。\n31.3 Semaphores For Ordering 信号量可以用来实现等待 (类似于 join() 的功能)。这时信号量的初始值应当被设为 0。在等待的线程中使用 sem_wait()，在被等待的线程结尾使用 sem_post()。 join.c 给出了具体的实现。\n我们分析两种可能的情况：\n主线程在子线程结束之前调用 sem_wait()，此时信号量的值变为 -1，主线程被挂起。待子进程执行结束后，调用 sem_post()，信号量的值恢复为 0，并唤醒等待的主线程继续执行。 主线程在子线程结束之后调用 sem_wait()，那么子线程结束时调用 sem_post() 后，信号量的值变为 1。主线程调用 sem_wait()，信号量的值恢复为 0，因为非负，所以主线程可以直接继续执行。 31.4 The Producer/Consumer (Bounded Buffer) Problem 最直接的想法是将之前双条件变量的生产者-消费者模型直接套用过来：\nvoid put(int val) {buffer[fill] = val; fill = (fill + 1) % MAX;} int get() {int rt = buffer[use]; use = (use + 1) % MAX; return rt;} void *producer(void *arg) { for (int i = 0; i \u0026lt; LOOP; i++) { sem_wait(\u0026amp;empty); put(i); sem_post(\u0026amp;full); } } void *consumer(void *arg) { while (1) { sem_wait(\u0026amp;full); printf(\u0026quot;%d\\n\u0026quot;, get()); sem_post(\u0026amp;empty); } } sem_init(\u0026amp;empty, 0, MAX); sem_init(\u0026amp;full, 0, 0); 这个做法在 MAX=1 时是可以正确执行的，但 MAX 大于等于 2 时会出现并发 bug。考虑两个生产者线程并发执行的过程：T1 执行完 sem_wait() 之后进入函数 put()，刚将 val 放进 buffer，还没有来得及给 fill +1 时，T1 被打断，T2 开始执行，因为 MAX\u0026gt;=2，这时 empty 不为 0，T2 可以顺利进入 put()，这时发生了问题：T1 放进 buffer 的内容被 T2 的内容覆盖了。\n可以看到出现并发 bug 的根本原因在于两个进程同时进入了临界区域，发生了数据竞争。联想条件变量的写法，线程在 wait() 中被唤醒后有一个尝试重新获得自旋锁的过程，而在这里的信号量实现中我们没有用锁把临界区域保护起来。因此我们只要加锁即可。\n真的随便加一个锁就可以了吗？\n考虑如下加锁后的实现：\nvoid *producer(void *arg) { for (int i = 0; i \u0026lt; LOOP; i++) { lock(\u0026amp;lk); sem_wait(\u0026amp;empty); put(i); sem_post(\u0026amp;full); unlock(\u0026amp;lk); } } void *consumer(void *arg) { while (1) { lock(\u0026amp;lk); sem_wait(\u0026amp;full); printf(\u0026quot;%d\\n\u0026quot;, get()); sem_post(\u0026amp;empty); unlock(\u0026amp;lk); } } 假设一个消费者线程先运行，它获得了锁之后，调用 sem_wait()，发现 full == -1，于是带着锁陷入了睡眠。这样别的线程再要尝试获得锁时就会陷入死锁：消费者线程拥有锁，在等待 full 信号；生产者线程可以 signal，但得先获得锁，这是一个标准的死锁。\n联想条件变量的实现，cond_wait() 和 sem_wait() 的不同在于，cond_wait() 接收一个锁的参数，会原子地完成线程睡眠和锁释放，而 sme_wait() 没有帮我们释放锁的功能。\n事实上，条件变量要把锁加在前面是因为我们要保证对全局的状态变量的访问 ( while (!cond) ) 是原子的。但信号量本身已经保证原子性了。我们只要把锁加在里面就是正确的实现：\nvoid *producer(void *arg) { for (int i = 0; i \u0026lt; LOOP; i++) { sem_wait(\u0026amp;empty); lock(\u0026amp;lk); put(i); unlock(\u0026amp;lk); sem_post(\u0026amp;full); } } void *consumer(void *arg) { while (1) { sem_wait(\u0026amp;full); lock(\u0026amp;lk); printf(\u0026quot;%d\\n\u0026quot;, get()); unlock(\u0026amp;lk); sem_post(\u0026amp;empty); } } produer_consumer_works.c 提供了完整的实现。\n31.5 Reader-Writer Locks 动机：对于并发数据结构，我们会用锁保护与之相关的函数。我们用锁保护读函数是为了避免写的过程中读取函数执行导致奇怪的问题，但这也导致了如果当前只有很多个线程读取而没有写操作，我们的读取无法并行。Reader-Writer Locks 致力于解决这个问题 (事实上以下方法中的信号量都在模拟锁的行为，可以只使用自旋锁完成)。\n解决这个问题的基本思路是：写操作每次要获得一个写锁，完成任务后要释放写锁。读操作的行为有所不同：我们维护一个变量 reader 记录当前正在读的线程的个数，当 reader == 1 时，读线程要获得写锁，这样就屏蔽了写操作，后续更多的读操作可以加入进来。当 reader == 0 时，读线程要释放写锁。(当然，读线程修改 reader 变量的过程还需要一个锁保护)。大致的伪代码实现如下：\ntypedef struct _rwlock_t { sem_t reader_lock; sem_t writelock; int readers; }rwlock_t; void rwlock_init(rwlock_t *rw) { rw-\u0026gt;readers = 0; sem_init(\u0026amp;rw-\u0026gt;reader_lock, 0, 1); // 信号量作为睡眠锁 sem_init(\u0026amp;rw-\u0026gt;writelock, 0, 1); // 信号量作为睡眠锁 } void rwlock_acquire_readlock(rwlock_t *rw) { sem_wait(\u0026amp;rw-\u0026gt;reader_lock); reader++; if (reader == 1) sem_wait(\u0026amp;rw-\u0026gt;writelock); sem_post(\u0026amp;rw-\u0026gt;reader_lock); } void rwlock_release_readlock(rwlock_t *rw) { sem_wait(\u0026amp;rw-\u0026gt;reader_lock); reader--; if (reader == 0) sem_post(\u0026amp;rw-\u0026gt;writelock); sem_post(\u0026amp;rw-\u0026gt;reader_lock); } void rwlock_acquire_writelock(rwlock_t *rw) {sem_wait(\u0026amp;rw-\u0026gt;writelock);} void rwlock_release_writelock(rwlock_t *rw) {sem_post(\u0026amp;rw-\u0026gt;writelock);} rwlock.c 提供了完整的实现。\n该算法存在一定的公平性隐患：如果读线程比较多，源源不断地加入，写线程可能会一直调度不上。(一个可能的维护公平性的方法是为 reader 设置一个上限，如果 reader == MAX_READER，则把读线程挂起。)\nHill\u0026rsquo;s Law\nHill\u0026rsquo;s Law 大致的意思是在很多情况下，那些看上去简单笨拙的实现反而是好的。在这里，reader-writer lock 虽然看起来很 fancy，但实际使用时未必好过简单的自旋锁，这是因为维护精巧的结构总需要更多的开销。因此，抛开 workload 谈优化就是耍流氓。\n31.6 The Dining Philosophers 一个哲学家的行为可以用如下函数描述：\nvoid *philosopher(void *arg) { while (1) { think(); getforks(); eat(); putforks(); } } 如果我们简单地为每把叉子建立一个信号量，然后这样构建 getforks() 和 putforks()：\nint left(int p) {return p;} int right(int p) {return (p + 1) % PHI_NUM;} void getforks(int p) { sem_wait(forks[left(p)]); sem_wait(forks[right(p)]); } void putforks(int p) { sem_post(forks[left(p)]); sem_post(forks[right(p)]); } 容易发现这个程序有死锁风险：如果每个哲学家都拿起了自己左手的叉子，那么所有人都会等待自己右手边的叉子，而又没有任何人会放下自己左手上的叉子——死锁。 dining_philosophers_deadlock_print.c 打印出了死锁的局面。\n如果锁的需求链出现了环，就会发生死锁，Dijkstra 用一个简单的方法解决了这个问题：只要安排某一个哲学家先拿右手叉子再拿左手叉子，就可以破这个局：\nvoid getforks(int p) { if (p == PHI_NUM) { sem_wait(forks[right(p)]); sem_wait(forks[left(p)]); } else { sem_wait(forks[left(p)]); sem_wait(forks[right(p)]); } } dining_philosophers_no_deadlock.c 提供了完整的实现。\n31.7 How To Implement Semaphores 我们在 31.1 已经建立了信号量的语义，因此用条件变量实现信号量 (不妨称之为 zemaphore) 非常简单：\ntypedef struct _zem_t { int val; pthread_cond_t cond; pthread_mutex_t lock; }zem_t; void zem_init(zem_t *z, int val) { z-\u0026gt;val = val; Cond_init(\u0026amp;z-\u0026gt;cond); // 带返回值检查的 pthread_cond_init() Mutex_init(\u0026amp;z-\u0026gt;lock); } void zem_wait(zem_t *z) { Mutex_lock(\u0026amp;z-\u0026gt;lock); while (z-\u0026gt;val \u0026lt;= 0) Cond_wait(\u0026amp;z-\u0026gt;cond, \u0026amp;z-\u0026gt;lock); z-\u0026gt;val--; Mutex_unlock(\u0026amp;z-\u0026gt;lock); } void zem_post(zem_t *z) { Mutex_lock(\u0026amp;z-\u0026gt;lock); z-\u0026gt;val++; Cond_signal(\u0026amp;z-\u0026gt;cond); Mutex_unlock(\u0026amp;z-\u0026gt;lock); } zemaphore.h 提供了完整的实现， zemaphore.c 提供了一个使用 zemaphores 的例子。\n31.8 Summary 略。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"bf66ee416f3064ccbc869b0cfa08e580","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch31/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch31/","section":"notes","summary":"信号量的概念最早由 Dijkstra 提出，它既可以作为锁使用也可以作为条件变量使用。\n31.1 Semaphores: A Definition 使用一个信号量之前我们要定义其初始值：\n#include \u0026lt;semaphore.h\u0026gt; sem_t s; sem_init(\u0026amp;s, 0, 1); sem_init() 的第一个参数是信号量，第三个参数是初始值，第二个参数为 0 表示该信号量在同进程下的所有线程之间共享 (如果想让信号量在不同进程之间共享，可以设置为其他数值)。\nPOSIX 标准提供了信号量操作相关的 API：sem_wait() 和 sem_post()。相较于条件变量，信号量使用起来非常简单：我们不需要关注什么时候获得锁，用 while 还是 if 等问题，在用户层面我们可以认为这些 API 都是原子的。它们的语义可以用如下伪代码描述：","tags":null,"title":"Chapter 31: Semaphores","type":"docs"},{"authors":null,"categories":null,"content":"输入输出对于计算机来说非常重要：如果没有输入，计算机每次输出的都是相同的结果；如果没有输出，那我们让计算机运行程序的目的是什么呢？因此我们的问题是如何将 Input/Output 融入计算机系统。\n36.1 System Architecture 一个经典的计算机系统的结构布局如下图所示：\nCPU 和内存通过内存总线连接。有一些设备通过通用 I/O 总线 (在现代系统中通常是 PCI 总线) 连入系统，这类设备通常是一些高速设备，比如显卡。再往下一层，一些比较低速的设备会通过外围总线 (peripheral bus，比如 SATA, USB 等) 连入系统，包括鼠标，键盘等。\n使用这种 hierarchical 主要是处于性价比的考量。通常来说一条总线速度越快，它的单价就越贵，它的长度也越短，上面可以插的设备数量就越少。因此系统设计者采用这种层级结构，让速度更快的设备更靠近 CPU，下方的低速总线上则可以插很多设备。\n现代的系统更多地采用芯片组和快速的点对点互连来提升效率。Intel Z270 芯片组的结构如下图所示：\n在这种结构中，CPU 和内存之间的连接很近，此外有一条高速的通道直接连接 CPU 和显卡，从而使 graphic-intensive 的应用有更流畅的使用体验。CPU 和 I/O 芯片之间通过一个专门的 DMI (Direct Media Interface) 连接，剩下的设备都通过 I/O 芯片与 CPU 交互。I/O 芯片提供了多种类型的接口：右侧有很多的硬盘驱动器通过 eSATA 接口与 I/O 芯片连接。下方有很多的 USB 接口，通常用于连接键盘、鼠标等低速设备。左侧的 PCIe (Peripheral Component Interconnect Express) 接口可以接一些高速设备，比如高速网卡等。\n36.2 A Canonical Device 一个典型的设备通常由两个部分组成：第一个部分是它暴露给系统的硬件接口，系统可以根据设备的协议，通过这些硬件接口来操纵设备。第二部分是设备的内部结构，用于实现设备提供给系统的抽象。简单的设备可能只有一个或几个很小的芯片，但也有比较复杂的设备，里面甚至会有一个简单的 CPU，比如现代的 RAID 控制器中包含了几千行固件代码。\n36.3 The Canonical Protocol 一个抽象的设备向外暴露的接口通常有以下部分：\n一个状态寄存器，操作系统读取它的值可以获知设备的状态； 一个指令寄存器，操作系统向它写入命令可以控制设备的行为； 一个数据寄存器，用于操作系统和设备的数据交换。 一个典型的 OS 和设备交互的协议如下：\nwhile (STATUS == BUSY) ; Write data to DATA register; Write command to COMMAND register; (Doing so starts the device and executes the command) while (STATUS == busy) ; // wait until device is done with your request 整个过程分为四步：\n首先 OS 等待直到设备的状态寄存器表示设备已经准备就绪，这个过程称为 OS 轮询 (polling) 设备。 OS 将数据通过数据寄存器传送给设备，如果这个数据迁移的过程是由主 CPU 完成的，我们称这种方式为 programmed I/O (PIO)。 OS 向指令寄存器写入命令，这样相当于隐式地告诉设备数据也已经传送完成，于是设备会开始工作执行这条命令。 OS 再次通过轮询的方式等待设备工作完成。 该协议的最大优点是简单，但它的效率比较低。一个比较明显的缺点是 CPU 轮询设备状态会浪费大量的时间。\n36.4 Lowering CPU Overhead With Interrupts 解决轮询浪费时间问题的一个方法是使用中断。当 OS 发现当前设备正忙时，它可以将当前进程睡眠。当设备准备就绪时，设备可以生成一个硬件中断发送给操作系统，OS 中的中断处理程序会根据情况进行进程切换。\n中断 I/O 的方式可以在设备工作时让 OS 做别的事情，从而达到更好的并行度。但中断并不是在任何情况下都比轮询来得好。中断本身是有一定的代价的 (比如处理中断，上下文切换等)，因此对于一些工作的很快的高速设备，使用轮询反而可以获得更好的效率。对于一些工作得时快时慢的设备，OS 可以采取综合的方式：先轮询一小段时间，如果设备没有准备就绪，则走中断流程。这种两阶段的方法对于快慢两种情况都可以有不错的效果。\n另一个不能滥用中断的原因在网络领域。如果有大量到来的网络数据包，每个都会生成中断，那么我们的服务器就会陷入一个 livelock 的状态：OS 一直在中断处理程序中处理中断，很长时间内都没有用户台进程有进展。在这种情况下，时不时地使用一些轮询可以更好地控制当前系统中正在发生的事情：即使有大量的数据包到来，服务器也可以选择处理一部分 request，然后再去响应数据包。\n另一种基于中断的优化叫做 coalescing (合并)。当设备需要发出中断时，它先不急着发送而是等一小会儿，这段时间可能又有别的事件发生 (比如一个其他任务完成了)，这样我们就可以把多个事件放在一个中断里发送，提高了效率。但等待的事件如果过长中断的时效性就降低了，因此这其中也有 trade-off。\n36.5 More Efficient Data Movement With DMA Canonical Protocol 的另一个问题在于：当我们使用 programmed I/O 的方式来搬运大量数据时，大量的 CPU 时间被浪费在了这种非常重复和简单的事情上。我们希望把这部分 CPU 时间节省下来用来处理进程相关的事件。\n这个问题的处理方法称为 Direct Memory Access (DMA)。DMA 可以理解为一个专门用来搬运数据的设备。当 OS 需要搬运数据的时候，它会发送信号给 DMA，告诉它数据在内存中的地址，数据的长度，以及目标设备，然后 DMA 便会帮 CPU 搬数据，与此同时 CPU 就可以并行地做其他事情。\n36.6 Methods Of Device Interaction OS 和设备到底是如何交互的？历史上主要有两种方法。第一种是在 ISA 中专门设计一组显式的 I/O 交互指令 (in/out)。该指令可以让 OS 指定将什么数据发送到哪个设备的哪个寄存器。这样的指令一般都是特权指令，即只有操作系统内核可以执行这样的操作，否则用户态的恶意程序很容易扰乱机器状态。第二种方法是使用所谓的内存映射 I/O (memory-mapped I/O)。这种方式下设备寄存器被绑定到特定的内存单元，操作系统可以使用普通的访存指令 (load/store) 通过特定的地址来访问设备，硬件 (MMU) 会将该访问路由到正确的设备上。\n这两种方法没有明显的优劣，虽然内存映射 I/O 因为没有引入新的指令看上去更简洁，但两种方法事实上现在都有在使用。\n36.7 Fitting Into The OS: The Device Driver 这个章节我们关注的问题是：不同的设备有各异的接口，我们如何让 OS 可以以一个比较统一的方式来访问设备呢？比如，文件系统可能建立在 SCSI 磁盘、IDE 磁盘、USB 设备上等等，我们希望有一个东西能帮我们抽象掉这些设备底层的细节差异，提供统一的接口 (比如 read/write)，让文件系统可以以一个统一的方式读写数据。\n设备驱动就是帮助我们抽象掉设备的底层细节，向上提供统一接口的系统软件。当然，盲目的抽象也有其弊端：如果一个设备有丰富的功能，那么为了使其适配简单统一的接口，设备驱动可能就不得不丢弃一些信息。比如 SCSI 磁盘有丰富的报错信息，但由于其他的块设备的 error handling 都非常简单，所以上层软件一般都只接受一个 error code，这导致 SCSI 提供的信息无法进入到文件系统。\n设备驱动代码占据了操作系统内核代码的一大部分，也是操作系统内核 bug 的重灾区。\n36.8 Case Study: A Simple IDE Disk Driver 这一章节主要关注一个实际的例子：IDE 磁盘的驱动程序。IDE 磁盘提供的协议如下：\n下面是 Xv6 中关于 IDE 磁盘驱动的代码：\nstatic int ide_wait_ready() { while ((int r = inb(0x1f7)) \u0026amp; IDE_BSY || !(r \u0026amp; IDE_READY)) ; // 轮询设备的当前状态，直到设备准备就绪 } static void ide_start_request(struct buf *b) { ide_wait_ready(); outb(0x3f6, 0); // 生成中断信号 outb(0x1f2, 1); // 要读/写的sector的个数 outb(0x1f3, b-\u0026gt;sector \u0026amp; 0xff); // 目标sector的LBA outb(0x1f4, (b-\u0026gt;sector \u0026gt;\u0026gt; 8) \u0026amp; 0xff); outb(0x1f5, (b-\u0026gt;sector \u0026gt;\u0026gt; 16) \u0026amp; 0xff); outb(0x1f6, 0xe0 | ((b-\u0026gt;dev\u0026amp;1)\u0026lt;\u0026lt;4) | ((b-\u0026gt;sector\u0026gt;\u0026gt;24)\u0026amp;0xff)); if (b-\u0026gt;flags \u0026amp; B_DIRTY) { // buf的B_DIRTY位为1说明这是一次写入操作 outb(0x1f7, IDE_CMD_WRITE); // 向0x1f7传入写的command outsl(0x1f0, b-\u0026gt;data, 512/4); // 传输要写入的数据 } else { outb(0x1f7, IDE_CMD_READ); // 向0x1f7传入读的command } } void ide_rw(struct buf *b) { acquire(\u0026amp;ide_lock); for (struct buf **pp = \u0026amp;ide_queue; *pp; pp = \u0026amp;(*pp)-\u0026gt;qnext) ; *pp = b; // 将任务放到队列末尾 if (ide_queue == b) ide_start_request(b); // 如果该任务是当前的唯一任务，立刻开始做 while ((b-\u0026gt;flags \u0026amp; (B_VALID|B_DIRTY)) != B_VALID) sleep(b, \u0026amp;ide_lock); // 等待任务完成时中断处理程序唤醒该进程 release(\u0026amp;ide_lock); } void ide_intr() { struct buf *b; acquire(\u0026amp;ide_lock); if (!(b-\u0026gt;flags \u0026amp; B_DIRTY) \u0026amp;\u0026amp; ide_wait_ready() \u0026gt;= 0) insl(0x1f0, b-\u0026gt;data, 512/4); // 如果是读取任务的数据准备好，则将数据读进来 b-\u0026gt;flags |= B_VALID; b-\u0026gt;flags \u0026amp;= B_DIRTY; wakeup(b); // 唤醒对应进程，通知它任务已完成 if ((ide_queue = b-\u0026gt;qnext) != 0) ide_start_request(ide_queue); // 当前任务做完，继续做下一个任务 release(\u0026amp;ide_lock); } 36.9 Historical Notes 计算机系统的进步中没有 revolution，只有 evolution。中断、DMA 等想法都是为了提高系统性能可以自然而然想到的。\n36.10 Summary 略。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"6cdfc3899408e9b66a0de197b8f91e4d","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch36/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch36/","section":"notes","summary":"输入输出对于计算机来说非常重要：如果没有输入，计算机每次输出的都是相同的结果；如果没有输出，那我们让计算机运行程序的目的是什么呢？因此我们的问题是如何将 Input/Output 融入计算机系统。\n36.1 System Architecture 一个经典的计算机系统的结构布局如下图所示：\nCPU 和内存通过内存总线连接。有一些设备通过通用 I/O 总线 (在现代系统中通常是 PCI 总线) 连入系统，这类设备通常是一些高速设备，比如显卡。再往下一层，一些比较低速的设备会通过外围总线 (peripheral bus，比如 SATA, USB 等) 连入系统，包括鼠标，键盘等。\n使用这种 hierarchical 主要是处于性价比的考量。通常来说一条总线速度越快，它的单价就越贵，它的长度也越短，上面可以插的设备数量就越少。因此系统设计者采用这种层级结构，让速度更快的设备更靠近 CPU，下方的低速总线上则可以插很多设备。\n现代的系统更多地采用芯片组和快速的点对点互连来提升效率。Intel Z270 芯片组的结构如下图所示：\n在这种结构中，CPU 和内存之间的连接很近，此外有一条高速的通道直接连接 CPU 和显卡，从而使 graphic-intensive 的应用有更流畅的使用体验。CPU 和 I/O 芯片之间通过一个专门的 DMI (Direct Media Interface) 连接，剩下的设备都通过 I/O 芯片与 CPU 交互。I/O 芯片提供了多种类型的接口：右侧有很多的硬盘驱动器通过 eSATA 接口与 I/O 芯片连接。下方有很多的 USB 接口，通常用于连接键盘、鼠标等低速设备。左侧的 PCIe (Peripheral Component Interconnect Express) 接口可以接一些高速设备，比如高速网卡等。","tags":null,"title":"Chapter 36: I/O Devices","type":"docs"},{"authors":null,"categories":null,"content":"我们对磁盘有三个维度的需求：我们希望它读写速度快 (I/O 操作速度慢，因而成为整个系统的速度瓶颈)，我们希望它容量大，我们还希望它可靠 (如果发生磁盘损坏，仍然能恢复数据)。\n本章节主要介绍 Redundant Arrays of Inexpensive Disks (RAIDs) 技术，它的核心思想是用多块物理磁盘去构建一个大容量的，高速的，可靠性高的磁盘。对外来看，RAID 虚拟出了一块可读可写的磁盘；在其内部，RAID 由一个非常复杂的系统构成，包含了若干个物理磁盘和一个或多个用于控制的芯片，可以说 RAID 内部就是一个小型的计算机系统。\nRAID 的优点在于：它可以通过多块磁盘并行的读写来提供很好的 performance；通过叠加磁盘的数量来获得 capacity；通过存储一部分的冗余数据来保证数据的 reliability。更重要的是，RAID 可以透明地提供这些优势，这里透明的意思是对于其他硬件/OS来说，RAID 看上去就像是一整块普通的磁盘。整个系统的其他部分不需要做任何修改就可以兼容 RAID。这一点极大地提升了 RAID 的可部署性 (deployability)。用户可以放心地将自己现有的磁盘更换成 RAID，不需要担心兼容问题。\n38.1 Interface And RAID Internals 对于上层的文件系统来说，RAID deng |看上去就像一个磁盘。和其他单块磁盘的抽象一样，RAID 对外暴露成一个线性的 block array，每个块都可读可写。\n当文件系统向 RAID 发送一个 logical I/O 请求时，RAID 内部需要搞清楚这个逻辑地址对应的块究竟在哪些盘的什么位置，并通过一次或多次 physical I/O 请求来完成这次任务。RAID 的内部结构相当复杂，通常会有一个 microcontroller 执行固件代码来控制 RAID 的行为；会有 DRAM 来作为数据块的 buffer cache；有时还会有一些非易失性的存储用来进行校验计算等。RAID 有一个完整计算机系统的大部分设施 (处理器，内存，磁盘等等)，但它是一个专门运行磁盘管理程序的专用系统。\n38.2 Fault Model 我们在这里考虑的错误模型是一个比较简单的错误模型，称为 fail-stop。在这个模型中，每块磁盘只会处于 working 或 failed 的状态。在 working 状态，磁盘一切正常，可读可写；在 failed 状态，磁盘损坏，可以理解为该磁盘内部的数据永久丢失。\n在 fail-stop 模型中，我们认为我们总是可以立刻检测到磁盘的损坏，即当某块磁盘从 working 变为 failed 时，我们可以迅速发现。因此我们不用考虑一些非常微妙的 silent failure (虽然这是实际中更可能发生的错误)。\n38.3 How To Evaluate A RAID 我们主要从三个尺度来衡量 RAID：\n容量 (capacity)：假设 RAID 中有 $N$ 块磁盘，每块磁盘中有 $B$ 个 block，那么理论上的最大存储量是 $N\\cdot B$ 个 block，但由于我们需要存储一些必要的冗余数据来保证可靠性，实际上的容量达不到这个最大值。 可靠性 (reliability)：我们的 RAID 系统至多可以容忍多少个磁盘同时损坏？(容忍指损坏后可以恢复数据) 性能 (performance)：性能是比较难衡量的一个尺度，因为它和 workload 息息相关。 38.4 RAID Level 0: Striping 最简单的一种设计方法是将 block 以条带状放在各个物理磁盘上，下面展示了 4 块物理磁盘时的摆放顺序：\nDisk 0 Disk 1 Disk 2 Disk 3 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 block 以一种 round-robin 的方式放在各个磁盘上，我们称一行中的 block 为一个 stripe。这种方式的好处是我们在读写一串连续的 block 时可以达到最佳的并行性能。上面的摆放方式是 chunk size = 1 block 的方式，即每次放放一个 block 就转到下一个 disk。我们可以调整 chunk size，比如下面展示了 chunk size = 2 block 的摆放方式\nDisk 0 Disk 1 Disk 2 Disk 3 0 2 4 6 1 3 5 7 8 10 12 14 9 11 13 15 The RAID Mapping Problem\n在 RAID 中我们总是要处理的一个问题就是 mapping problem：给定一个逻辑块号，我们要确定它在哪一个物理磁盘上，以及在物理磁盘上的偏移量。对于 chunk size = 1 block 的 RAID 0，mapping problem 是容易的：假设逻辑块号为 $A$，则\nDisk = A % number_of_disks; Offset = A / numbre_of_disks; Chunk Size chunk size 主要影响读写的性能。小的 chunk size 可以带来更好的并行性，但每个物理磁盘上的 chunk 的个数会比较多，定位 chunk 也是需要时间代价的。\n下面的讨论中默认 chunk size = 1 block。\nBack To RAID-0 Analysis RAID-0 的 capacity 是完美的：物理磁盘的每个 block 都被用来存储信息了；RAID-0 的 reliability 是糟糕的：任何一个磁盘的任何一个部分损坏都会导致数据丢失；RAID-0 的 performance 是比较好的，基本可以达到百分之百的带宽。\nEvaluating RAID Performance 我们衡量 RAID 的性能时通常从两种尺度出发：一种是单次请求的延迟，一种是稳定状态下的吞吐率。在衡量稳定状态下的吞吐率时，我们对两种 wordload 比较感兴趣：一种是 sequential 的，即一次性读取连续的多个 block；另一种是 random 的，即多次读取少量的 block。可以预见地，因为物理磁盘有寻道时间和旋转延迟，所以 random 的 workload 下磁盘要不停地重新定位，吞吐率会比 sequential 的情况低很多。下面的分析中，我们令 $S$ 表示 sequential 的一段长的数据的平均读取速度，$R$ 表示 random 的一块短的数据的平均读取速度。\nBack To RAID-0 Analysis, Again 从单次请求延迟的角度来看， RAID-0 的延迟基本等于一块物理磁盘的延迟，因为一个 single-block request 会被 RAID 的系统定向到某一块物理磁盘上。\n从稳定状态下的吞吐率来看，RAID-0 可以达到最大的带宽，因为不论是 sequential 还是 random，当读取的 block 个数足够多时，期望情况下所有的物理磁盘都在满负荷运作。即 sequential 的吞吐率为 $N\\cdot S\\text{ MB/s}$，random 的吞吐率为 $N\\cdot R\\text{ MB/s}$。\n38.5 RAID Level 1: Mirroring RAID 1 的基本思想是镜像：为每个 block 保存副本，这样我们就可以忍受 disk failure。下面是一个例子：\nDisk 0 Disk 1 Disk 2 Disk 3 0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 这种方式也被称为 RAID-10 (RAID-1+0)，因为它是先复制再按照 RAID-0 的方式排开。相应地也有 RAID-01 (RAID-0+1)，先排开再做镜像。我们所说的 RAID-1 通常指 RAID-10。\nRAID-1 在读取一个块时有两个选择，但 RAID-1 的写入操作必须同时修改两个副本。不过 RAID-1 的设计中一个块的两个副本位于不同的物理磁盘上，对两个副本的修改可以并行进行。\nRAID-1 Analysis 从 capacity 的角度，RAID-1 比较糟糕：只有一半的容量真正存储了信息，剩下的一半都是副本。\n从 reliability 的角度，RAID-1 很可靠，因为任何一个物理磁盘损坏都不会导致数据丢失。甚至在上述例子中，如果 disk 0 和 disk 2 同时损坏，RAID-1 也不会丢失数据。RAID-1 reliability 的下限是 1 个磁盘，运气好的情况下甚至可以做到 $N/2$ 块磁盘。\n从 performance 的角度，首先考虑 latency：对于读操作来说延迟就是一块物理磁盘的延迟；写操作则有一点不同，写操作需要更新两个副本，虽然这两个写入在不同的物理磁盘上可以并行，但两块磁盘中寻道+旋转时间较长的那块磁盘将决定写操作的延迟，因此写操作延迟略高于一块物理磁盘的期望延迟。\n接下来考虑吞吐率。首先是 sequential 的 workload。写入方面，因为每个逻辑块的写入都要同时写入两个副本，所以吞吐率为 $\\frac{N\\cdot S}{2}$。一个有点反直觉的结论是：读取的吞吐率也是 $\\frac{N\\cdot S}{2}$。虽然我们每个块有两个副本，但精心安排读取顺序并不能给我们带来效率提升。比如我们要读取 0, 1, 2, 3, 4, 5, 6, 7，如果我们只使用 Disk 0 和 Disk 2，吞吐率显然为 $\\frac{N\\cdot S}{2}$；我们可能会想出这样的安排方案：Disk 0 和 Disk 2 读 0 和 1，Disk 1 和 Disk 3 读 2 和 3，后面依次类推，这样是不是可以用满带宽呢？实际上不然。我们考虑一个 Disk 接受到的任务，比如 Disk 0：它要读取 0, 4, 8\u0026hellip;\u0026hellip; 这些 block，这些 block 在 Disk 0 上不是连续存放的，所以磁盘在旋转的时候每读取一个块，就要等待一个块，磁盘划过不需要的块的时候并没有向用户输出有效的带宽，因此它实际上只输出了一半的效率。\n在 random 的 workload 下，RAID-1 的读取是完美的：Disk 2 和 Disk 4 作为 Disk 0 和 Disk 3 的副本也可以为用户提供带宽，因此聪明的选择当前空闲的磁盘可以使吞吐率达到 $N\\cdot R$。写入方面，因为要同时修改两个磁盘中的副本，所以吞吐率是 $\\frac{N\\cdot R}{2}$。\nThe RAID Consistent-Update Problem\nRAID-1 中涉及 mirroring，在写入操作时要同时更新两个副本，因此存在所谓的 consistent-update 问题：如果我们无脑地修改第一个部分再修改第二个副本，那么加入修改完第一个副本后系统掉电了，那么重启后整个磁盘将处于一个 inconsistent 的状态——两个副本的内容不一致。因此修改两个副本的操作应当是原子的。\n在文件系统中我们用 journaling 的方法来解决原子性的问题，在 RAID 中该方法同样适用。我们只要保存一个修改操作的 logging，意外掉电重启后就可以根据 logging 的内容来做恢复。值得一提的是，每次写入操作都在 disk 中做 logging 的代价太大无法忍受，因此 RAID 中一般会有一小块 non-volatile 的 RAM 用于写入 logging。\n38.6 RAID Level 4: Saving Space With Parity 镜像所需要的额外存储空间太多。事实上，我们可以使用校验码的思路来为数据保存副本，这就是 RAID-4。RAID-4 的一个例子如下：\nDisk 0 Disk 1 Disk 2 Disk 3 Disk 4 0 1 2 3 P0 4 5 6 7 P1 8 9 10 11 P2 12 13 14 15 P3 其中 Disk 4 上存储的都是前 4 个 disk 的校验码：$P0 = 0\\oplus 1\\oplus 2\\oplus 3$，依此类推。这样如果有任何一个磁盘损坏，将其他 4 个磁盘的数据异或起来就可以恢复该磁盘的数据。\nRAID-4 Analysis 从 capacity 的角度：它比 RAID-1 好很多：$\\frac{N-1}{N}$ 的空间都可以用来存储有效的信息。\n从 reliability 的角度：RAID-4 可以容忍一个磁盘的损坏。\n从 performance 的角度：\n首先考虑吞吐率：sequential 的情况是比较容易分析的：读取的时候，只有 $N-1$ 个磁盘中存储的是有效数据，所以带宽为 $(N-1)\\cdot S$。写入的时候，每一个 stripe ($N-1$ 个 block) 的数据可以由 $N$ 个磁盘并行写入，因此带宽也是 $(N-1)\\cdot S$。random 的读取也容易分析：只有 $N-1$ 个存储了有效数据的磁盘会工作，因此带宽为 $(N-1)\\cdot R$。\n困难的是 random 写入的分析。我们在修改一个 block 的时候同时也要修改它所在的 stripe 的校验 block。我们有两种思路来计算新的校验值：一是 addictive parity，即把该 stripe 中其他的 block 都读出来，然后计算新校验值并写入，该方法的问题是其代价随着 RAID 中磁盘的上升而上升 (要做很多异或)；二是 subtractive parity，即读出旧的校验值，异或掉旧的 block，再异或上新的 block 以获得新的校验值。写成公式就是 $P_{new}=P_{old}\\oplus(C_{old}\\oplus C_{new})$，该方法需要对校验 block 和数据 block 各做一次读和一次写。通常来说我们选择 subtractive parity，但该方法的关键问题在于不管我们修改哪个物理磁盘上的数据，都要读写校验磁盘，因此即使数据磁盘的修改可以并行，校验磁盘仍然会将整个过程变成串行，它成为了整个系统的瓶颈。这个问题被成为 small-write problem。RAID-4 在 random 写入下的带宽是 $(R/2)$，这非常糟糕，因为它不随着 RAID 规模的增大而提高。\n接着分析 latency：读一个 block 的延迟和一块物理磁盘上的延迟相同；写一个 block 的延迟则复杂一些：根据之前的 subtractive parity 的方法，我们要读一次写一次数据磁盘和校验磁盘，因此延迟大约是一块物理磁盘延迟的两倍。\n38.7 RAID Level 5: Rotating Parity RAID-5 针对 RAID-4 的 small-write problem 做出了改进，把校验 block 分散到了各个磁盘当中：\nDisk 0 Disk 1 Disk 2 Disk 3 Disk 4 0 1 2 3 P0 4 5 6 P1 7 8 9 P2 10 11 12 P3 13 14 15 P4 16 17 18 19 RAID-5 Analysis RAID-5 很多方面的参数和 RAID-4 是差不多的。这里主要关注 RAID-5 在 random workload 下的吞吐率：\n对于读取操作，由于现在 $N$ 个磁盘上都存储了数据，所以带宽可以达到 $N\\cdot R$。 对于写入操作，RAID-5 相比较于 RAID-4 有很大改善。我们可以认为在 random request 足够多的情况下，所有的物理磁盘都在满负荷运转，因此带宽可以达到 $\\frac{N\\cdot R}{4}$，这里要除以 4 是因为一个数据块的写入要涉及 4 次 I/O 操作。 在绝大多数场合下，RAID-5 已经完全取代了 RAID-4。除了某些特殊的场景，使用者确定不会出现大量的随机读写，这时使用 RAID-4 会使磁盘在结构上简单一些。\n38.8 RAID Comparison: A Summary RAID-0 RAID-1 RAID-4 RAID-5 Capacity $N\\cdot B$ $(N\\cdot B)/2$ $(N-1)\\cdot B$ $(N-1)\\cdot B$ Reliability $0$ $1$ (for sure)\n$N/2$ (if lucky) $1$ $1$ Throughput Sequential Read $N\\cdot S$ $(N\\cdot S)/2$ $(N-1)\\cdot S$ $(N-1)\\cdot S$ Sequential Write $N\\cdot S$ $(N\\cdot S)/2$ $(N-1)\\cdot S$ $(N-1)\\cdot S$ Random Read $N\\cdot R$ $N\\cdot R$ $(N-1)\\cdot R$ $N\\cdot R$ Random Write $N\\cdot R$ $(N\\cdot R)/2$ $R/2$ $(N\\cdot R)/4$ Latency Read $T$ $T$ $T$ $T$ Write $T$ $T$ $2T$ $2T$ 如果你想要极致的性能，不在乎数据的可靠性，那么就选 RAID-0；如果你在乎 random I/O 的效率且需要可靠性，那么就选 RAID-1 (代价是容量)；如果 reliability 和 capacity 你都在乎，那么就选 RAID-5 (代价是 small-write performance)。\n38.9 Other Interesting RAID Issues 关于 RAID 还有很多有意思的问题可以研究，比如在发生 failure 的时候系统会经历怎样的运作过程，这时候的性能会有什么变化等等。此外，我们也可以提出一些更贴合实际的 fault model，以考虑到 block corruption，latent sector error 等等。甚至有人将 RAID system 放到软件层面。\n38.10 Summary RAID 的核心思想是将许多块不太可靠的物理磁盘组合在一起形成一个又大又快又可靠的磁盘。RAID 的选择与使用场景的 workload 息息相关，并不是说 RAID-5 就一定比 RAID-1 来的好。因此选择合适的 RAID 模型并为其调整合适的参数 (比如 chunk size，物理磁盘个数等) 是一门艺术。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"a5c1380b7aa14a749aaf52d67284ecb4","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch38/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch38/","section":"notes","summary":"我们对磁盘有三个维度的需求：我们希望它读写速度快 (I/O 操作速度慢，因而成为整个系统的速度瓶颈)，我们希望它容量大，我们还希望它可靠 (如果发生磁盘损坏，仍然能恢复数据)。\n本章节主要介绍 Redundant Arrays of Inexpensive Disks (RAIDs) 技术，它的核心思想是用多块物理磁盘去构建一个大容量的，高速的，可靠性高的磁盘。对外来看，RAID 虚拟出了一块可读可写的磁盘；在其内部，RAID 由一个非常复杂的系统构成，包含了若干个物理磁盘和一个或多个用于控制的芯片，可以说 RAID 内部就是一个小型的计算机系统。\nRAID 的优点在于：它可以通过多块磁盘并行的读写来提供很好的 performance；通过叠加磁盘的数量来获得 capacity；通过存储一部分的冗余数据来保证数据的 reliability。更重要的是，RAID 可以透明地提供这些优势，这里透明的意思是对于其他硬件/OS来说，RAID 看上去就像是一整块普通的磁盘。整个系统的其他部分不需要做任何修改就可以兼容 RAID。这一点极大地提升了 RAID 的可部署性 (deployability)。用户可以放心地将自己现有的磁盘更换成 RAID，不需要担心兼容问题。\n38.1 Interface And RAID Internals 对于上层的文件系统来说，RAID deng |看上去就像一个磁盘。和其他单块磁盘的抽象一样，RAID 对外暴露成一个线性的 block array，每个块都可读可写。","tags":null,"title":"Chapter 38: Redundant Arrays of Inexpensive Disks (RAIDs)","type":"docs"},{"authors":null,"categories":null,"content":"文件系统是一个纯粹的软件，因此在本章节中我们不考虑加入任何的硬件 feature 使文件系统工作得更好 (当然我们还是会注意块设备本身的特性)。文件系统设计本身有很大的弹性，因此现存的文件系统很多，它们使用不同的数据结构，在各方面的表现也各有千秋。\n40.1 The Way To Think 设计文件系统我们通常考虑两件事情：\n数据结构：我们准备使用什么数据结构来组织磁盘上的数据和元数据？在简单的文件系统实现中我们通常使用简单的块链表，在一些比较精密的文件系统实现中也有使用树状结构的。 访问方式：进程使用的 open(), read(), write() 等函数该如何对应到文件系统的结构上？对于一个特定的系统调用，哪些数据需要被读写？每一步的效率如何？ 40.2 Overall Organization vsfs (very simple file system，一个 UNIX 文件系统的精简版本) 的结构如下：\n整个磁盘被划分成 64 个 block，每个 block 的大小是 4KB。\n后面的 56 个 block 是 data region，用来存储用户数据。 3~7 这 5 个 block 是 inode table 区，存储了一个 inode 数组，注意到一个 inode 通常没有一个 block 那么大——只有 128 或 256 字节，这里假设 256 字节，则 5 个 block 可以存储 80 个 inode，即我们的文件系统中最多可以有 80 个文件 (在更大的磁盘上，我们的 inode table 可以更大，从而可以存储更多的文件)。 block 1 是 inode bitmap，block 2 是 data bitmap，bitmap 存储了每个 inode/data block 处于空闲状态还是正在使用的状态。 block 0 是 superblock，存储了文件系统的元数据，比如 inode 的个数，磁盘的大小，inode table 的起始位置，文件系统的魔数等等。 40.3 File Organization: The Inode 几乎所有的文件系统都有类似于 inode 的结构：它保存了一个文件的元数据，比如大小、权限等等。inode 的全称是 index node，这是因为一般 inode 被整齐地存放在一个数组里面，因此给定一个下标，我们很容易索引到一个对应的 inode。以我们的 vsfs 为例，inode table 的起始地址 inodeStartAddr = 12KB，每个 inode 的大小是 256B，因此给定一个 inumber，我们有如下的计算公式：\nblk = (inumber * sizeof(inode_t)) / blockSize; sector = ((blk * blockSize) + inodeStartAddr) / sectorSize; (注：磁盘不是 byte addressable 的，所以我们只算出精确的地址没有用，而要算出它在哪个 sector 中，把整个 sector 读出来，再根据 offset 定位 inode。)\ninode 中有关于一个文件的所有信息：比如它的类型 (文件/文件夹/设备 etc.)，它的大小，它包含的 block 数目，它的访问权限，它的创建/修改日期等。这些信息通常被称为文件的元数据 (metadata) (通常文件系统中和用户数据无关的其他数据都被称为元数据)。下面展示了一个简化的 ext2 文件系统的 inode 中存储的元数据：\ninode 中最重要的部分就是指示 data block 位置的部分。一种简单的方法是在 inode 中存储若干个 direct pointers，每个指针保存一个 data block 的地址。这种方法的局限性在于无法保存大文件的所有 data block。\nThe Multi-Level Index 解决大文件存储的方法通常是所谓的 indirect pointer：我们从数据区分配一个 block，让 inode 中的 indirect pointer 指向这个 block，然后这个 block 里存放一堆 direct pointer。假设一个地址占 4B，那么一个 block 里可以存放 1024 个 direct pointer，这意味着只需要一个 indirect pointer 就可以记录一个 1024*4 KB 的文件的所有 data block 的位置。\n这个思想有点像页表。正如页表可以有多级，文件系统中我们也可以有 double indirect pointer 和 triple indirect pointer，这样我们用树状结构存下了很多 data block 的地址。值得一提的是，通常 inode 里会有 12 个左右的 direct pointer 和一个 indirect pointer，存放如此多的 direct pointer 是因为从统计规律上，大部分的文件都非常小，用 direct pointer 直接存地址可以略去遍历“页表”的过程，更加高效。\nLinked-Based Approaches\ninode 的另一种常见的设计方案是使用链表。在这种设计下我们不需要在 inode 中存储所有 data block 的地址，而只要存储第一个 data block 的地址。每个 data block 自己有一个 next 指针存储下一个 data block 的地址，这样也可以存储大文件。\n朴素的想法是将每个 data block 的 next 指针存储在 data block 内部。但这样文件系统在 random access 的 workload 下表现得会很坏：注意到磁盘是一个块设备，如果我们要访问一个文件尾部的内容，我们就必须顺着链表往后找，而每次我们要获得一个 next 指针都要把整个 data block 读出来，大量的磁盘读取会使得访问非常慢。\n一个优化是把所有的 next 指针放在一起做成一张表集中存储。这样我们只要将这个 next 指针表从磁盘读进内存，就可以定位一个大文件的任何一个 data block 的位置，再去磁盘中抓取对应的 data block 即可。\n这就是 FAT 的主要思想。\n40.4 Directory Organization 在很多文件系统中，目录文件的内容就是一系列的 (文件名, inode) 键值对。举一个例子，比如一个 inode 为 5 的目录文件 dir 中包含了文件 foo, bar 和 foobar_is_a_pretty_longname，那么 dir 文件的内容就大约长这样：\ninum reclen strlen name 5 12 2 . 2 12 3 .. 12 12 4 foo 13 12 4 bar 24 36 36 foobar_is_a_pretty_longname 这里的 strlen 表示文件名的实际长度 (包括末尾的 \\0)，reclen 则表示当前分配给这个目录项文件名的长度 (名字的长度和可能存在的若干空闲空间)。每个目录文件中都有两个文件：. 表示当前目录，.. 表示上一级目录。\n如果我们在一个目录下删去一个文件，那么它对应的目录项就会被挖空。通常我们会使用 inode 0 来表示该目录项是空闲的。删除也是我们留有 reclen 字段的原因：比如一个长名文件被删除后，一个短名文件被加进目录，那么新文件可以复用旧文件的目录项，包括之前分配的长文件名的空间，因此文件名后可能会有空格。\n目录文件也是一种文件，因此在文件系统中它也有对应的 inode，上面描述的这些键值对就存在该文件的 data block 中。值得一提的是并不是所有文件系统都使用这种顺序列表的方式存储键值对——数据结构有很多的选择空间，比如有的文件系统使用 B 树存储键值对，这样它们在搜索文件名时就可以避免穷举遍历。\n40.5 Free Space Management 在 vsfs 中，我们为 inode table 和 data region 各准备了一个 bitmap 来记录每个 inode/data block 是否处于空闲状态。分配的时候，我们遍历 bitmap 寻找空闲的 inode/data block 即可。\n分配中也有一些“花活”可以玩，比如 ext2/ext3 文件系统中，当一个新文件被创建且需要数据块时，文件系统会去寻找空闲的连续数据块 (8 个或更多)，这样文件在文件系统中存储的更加连续，有助于提升性能。\n40.6 Access Paths: Reading and Writing Reading A File From Disk 我们首先考虑这样一个系统调用：open(\u0026quot;/foo/bar\u0026quot;, O_RDONLY)。我们的目标是找到 bar 文件的 inode，但这是无法直接做到的，因此我们必须得通过文件名一层一层地去找。一个文件的 inode 编号存放在它的父目录的文件内容中，因此我们需要去读取 /foo 目录文件的内容，从而需要其 inode 编号，再向上我们需要 / 目录文件的内容，以及 / 的 inode 编号。\n根目录没有父目录，因此根目录文件的 inode 编号必须被显式或隐式地规定。在绝大多数的 UNIX 文件系统中，根目录文件的 inode 编号都是 2。因此整个过程如下：\n读取根目录的 inode 2，根据 inode 中的指针找到根目录文件内容，从目录项中找到 /foo 文件的 inode 号。 读取 /foo 的 inode，根据 inode 中的指针找到 /foo 文件内容，从目录项中找到 /foo/bar 的 inode 号。 读取 /foo/bar 的 inode，进行一系列权限检查，返回给当前进程一个指向 /foo/bar 的文件描述符。 打开文件后，程序就可以通过 read() 系统调用来读取文件内容。对于一次 read() 系统调用，文件系统首先要读取 inode，根据 read 的 offset 找到对应 data block 的地址，然后读取对应的 data block，最后还要修改文件的 inode，更新最近访问时间等字段。在文件系统之外，文件描述符的 offset 也要更新。\n在某个时刻，该文件会被关闭。关闭文件需要释放掉对应的文件描述符，不过这不是文件系统层面的动作，close() 的时候没有任何的 disk I/O 操作。\n下图展示了整个过程各部分数据的读写情况：\nWriting A File To Disk 写入的过程和读取的过程基本类似，但写入更麻烦的地方在于我们有时候要分配新的 inode/data block，因此还要读写 bitmap。通常来说在文件已经打开的情况下，一次 write 操作要对应 5 次磁盘 I/O 操作：一次读取数据区的 bitmap (寻找可用数据块)，一次写入数据区的 bitmap (更新使用情况)，读取和写入该文件的 inode，以及对数据块的写入。\n如果我们考虑文件的创建，涉及到的 disk I/O 次数则更多：创建文件时我们要为文件创建 inode，因此我们需要读写 inode 的 bitmap；我们要初始化新分配的 inode，因此需要写入新文件的 inode；我们需要更新该文件的父目录的键值对，因此我们要修改父目录的 data block，从而还要读写父目录文件的 inode。如果父目录文件的 data block 容量不足，我们还要为父目录文件分配新的 data block，这又要涉及数据区 bitmap 的读写……\n由此我们可以看出，文件系统 disk I/O 的次数非常多，负担很重，我们需要想办法让频繁的 I/O 更加高效。\n40.7 Caching and Buffering 为了缓解文件系统大量的磁盘 I/O 开销，大多数文件系统使用内存作为磁盘的 cache，在内存中保存一些常用的/重要的 block。早期的文件系统使用固定大小的 cache，通常是 DRAM 的 10%，这种静态分区的做法不太高效——当前空闲的文件系统 cache slot 无法作为其他东西使用。因此现代的文件系统采用 dynamic partitioning 的方法，把虚拟内存的页面和文件系统的页面放在一起统一管理。\nUnderstand Static VS. Dynamic Partitioning\n当我们将资源分成若干种不同用途的时候，我们通常有静态和动态两种方法。静态方法提前将资源划分成固定的比例，每种用途取一份；动态方法则根据当前的 workload 动态调整每种用途的使用量。静态实现简单，效率更稳定；而动态可以达到更好的资源利用率，但实现起来比较复杂。两者各有千秋。\n简单分析 caching 对于文件系统读写的好处：在读取方面，如果我们遍历一个目录下的所有文件，那么目录文件以及其 inode 就可以一直放在 cache 中供读取，节省了很多 I/O 操作；在写入方面，write buffering 带来的延迟写入可以将多次操作 batch 在一起，减少 I/O 次数 (比如创建文件再删除=什么都不用做)，系统还可以调度多次写入的顺序以获得更好的效率。\nDurability/Performance Trade-Off\n存储系统通常面临 durability/performance trade-off。如果用户希望写入的数据能立刻变得持久，那么文件系统就必须将新数据立刻落盘，但这样会很慢；如果用户可以忍受小量的数据丢失，那么文件系统就可以将数据在内存中放一会儿，每隔一段时间落盘一次，这样效率会有明显提升。至于如何在 trade-off 中选择，这与用户需求息息相关。\n一些应用 (比如数据库) 不喜欢这种 trade-off，因此它们会通过使用 fsync()，或者跳过文件系统层直接使用磁盘 I/O API 等方式来强制落盘。它们牺牲了效率但获得了稳定性。\n40.8 Summary 略。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"1cc8ca04bb0b1f758ba671289ccfae03","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/ch40/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/ch40/","section":"notes","summary":"文件系统是一个纯粹的软件，因此在本章节中我们不考虑加入任何的硬件 feature 使文件系统工作得更好 (当然我们还是会注意块设备本身的特性)。文件系统设计本身有很大的弹性，因此现存的文件系统很多，它们使用不同的数据结构，在各方面的表现也各有千秋。\n40.1 The Way To Think 设计文件系统我们通常考虑两件事情：\n数据结构：我们准备使用什么数据结构来组织磁盘上的数据和元数据？在简单的文件系统实现中我们通常使用简单的块链表，在一些比较精密的文件系统实现中也有使用树状结构的。 访问方式：进程使用的 open(), read(), write() 等函数该如何对应到文件系统的结构上？对于一个特定的系统调用，哪些数据需要被读写？每一步的效率如何？ 40.2 Overall Organization vsfs (very simple file system，一个 UNIX 文件系统的精简版本) 的结构如下：\n整个磁盘被划分成 64 个 block，每个 block 的大小是 4KB。","tags":null,"title":"Chapter 40: File System Implementation","type":"docs"},{"authors":null,"categories":null,"content":"Problem 1.1 解：(1) $A_1\\cap \\overline{A_2}\\cap \\overline{A_3}$。\n(2) $A_1\\cup A_2\\cup A_3$。\n(3) $(A_1\\cap \\overline{A_2}\\cap \\overline{A_3})\\cup (\\overline{A_1}\\cap A_2\\cap \\overline{A_3})\\cup (\\overline{A_1}\\cap \\overline{A_2}\\cap A_3)\\cup (\\overline{A_1}\\cap \\overline{A_2}\\cap \\overline{A_3})$。\n(4) $\\overline{A_1\\cap A_2\\cap A_3}$。\n(5) $(A_1\\cap A_2)\\cup(A_1\\cap A_3)\\cup (A_2\\cap A_3)$。\nProblem 1.3 解： $$ P=\\frac{\\binom{10}{4}\\binom{4}{3}\\binom{3}{2}}{\\binom{17}{9}}=\\frac{252}{2431}。 $$\nProblem 1.7 解： $$ P=\\frac{9^n-5^n-8^n+4^n}{9^n}=1-\\frac{5^n+ 8^n-4^n}{9^n} $$\nProblem 1.10 解：记第一天下雨为事件 $A$，第二天下雨为事件 $B$。\n(1) $P(至少有一天下雨)=P(A\\cup B)=P(A)+P(B)-P(A\\cap B)=0.6+0.3-0.1=0.8$。\n(2) $P(两天都不下雨)=P(\\overline{A}\\cap \\overline{B})=P(\\Omega)-P(A\\cup B)=1-0.8=0.2$。\n(3) $P(至少有一天不下雨)=P(\\overline{A}\\cup \\overline{B})=P(\\Omega)-P(A\\cap B)=1-0.1=0.9$。\n(4) $P(第一天下雨且第二天不下雨)=P(A\\cap \\overline{B})=P(A)-P(AB)=0.6-0.1=0.5$。\n(5) $P(恰好一天下雨)=P(A)+P(B)-2P(AB)=0.6+0.3-0.1-0.1=0.7$。\nProblem 1.13 解：容易发现三条折线能构成三角形 $\\Leftrightarrow$ 三条折线的长度均小于 $a$。\n设第一处折点距离线段左端点的距离为 $x$，第二处折点距离线段左端点的距离为 $y$，则上述约束可以被翻译为： $$ \\begin{cases} x\u0026lt;y\\\\ x\u0026lt;a\\\\ y-x\u0026lt;a\\\\ y\u0026gt;a \\end{cases} $$ 画图：\n容易看出，$P(能构成三角形)=0.25$。\nProblem 1.15 解：$P(AB)=P(A)P(B|A)=\\frac{1}{4}\\cdot \\frac{1}{3}=\\frac{1}{12}$，所以 $P(B)=\\frac{P(AB)}{P(A|B)}=\\frac{1}{6}$。\n$P(\\bar{A}\\bar{B})=P(\\Omega-A\\cup B)=1-(P(A)+P(B)-P(AB))=1-\\frac{1}{4}-\\frac{1}{6}+\\frac{1}{12}=\\frac{2}{3}$。\nProblem 1.18 解：记取了甲车间产品为事件 $A$，乙为事件 $B$，丙为事件 $C$，取到次品为事件 $D$。\n(1) $P(D)=P(AD)+P(BD)+P(CD)=0.25\\cdot 0.05+0.35\\cdot 0.04+0.4\\cdot 0.02=0.0345$。\n(2) $P(A|D)=\\frac{P(AD)}{P(D)}=\\frac{P(A)P(D|A)}{P(D)}=\\frac{0.25\\cdot 0.05}{0.0345}=\\frac{25}{69}$。\nProblem 1.21 解：一共有 3 个面是红色的，这三个红色的面中只有 1 个面背后是黄色的，所以 $P=\\frac{1}{3}$。\nProblem 1.24 解：因为 $A,B$ 相互独立，所以 $P(AB)=P(A)P(B)$。我们列出方程： $$ \\begin{cases} P(A)-P(A)P(B)\u0026amp;=\\frac{5}{9}\\\\ P(A)+P(B)-P(A)P(B)\u0026amp;=\\frac{8}{9}\\\\ 0\\leq P(A),P(B)\\leq 1 \\end{cases} $$ 解得 $$ \\begin{cases} P(A)=\\frac{5}{6}\\\\ P(B)=\\frac{1}{3} \\end{cases} $$ 综上，$P(A)=\\frac{5}{6}$。\nProblem 1.29 解：$P(A)=\\frac{3}{6}=\\frac{1}{2},P(B)=\\frac{3}{6}=\\frac{1}{2},P(C)=\\frac{18}{36}=\\frac{1}{2}$。\n显然 $P(ABC)=0\\neq P(A)P(B)P(C)$。\n但 $$ \\begin{align} P(AB)\u0026amp;=\\frac{3\\times 3}{6\\times 6}=\\frac{1}{4}=P(A)P(B)\\\\ P(AC)\u0026amp;=P(A\\cap \\overline{B})=\\frac{9}{36}=\\frac{1}{4}=P(A)P(C)\\\\ P(BC)\u0026amp;=P(B\\cap \\overline{A})=\\frac{9}{36}=\\frac{1}{4}=P(B)P(C) \\end{align} $$ 所以这三个事件两两独立，但不相互独立。\nProblem 1.32 解：记两人命中数一样为事件 $A$，两人都中 $i$ 球为事件 $B_i$，则 $$ \\begin{align} P(A)\u0026amp;=P(A|B_0)+P(A|B_1)+P(A|B_2)\\\\ \u0026amp;=\\left(\\frac{1}{3}\\right)^2\\left(\\frac{2}{3}\\right)^2+\\frac{4}{9}\\cdot \\frac{4}{9}+\\left(\\frac{2}{3}\\right)^2\\left(\\frac{1}{3}\\right)^2\\\\ \u0026amp;=\\frac{8}{27} \\end{align} $$\nProblem 1.34 解：记一个人蒙及格为事件 $A$。\n(1) $$ P(A)=\\sum_{k=3}^5\\binom{5}{k}\\left(\\frac{1}{4}\\right)^k\\left(\\frac{3}{4}\\right)^{5-k}=\\frac{53}{512} $$ (2) $$ \\begin{align} P(至少两人蒙及格)\u0026amp;=1-P(至多一人蒙及格)\\\\ \u0026amp;=1-\\sum_{k=0}^1\\binom{5}{k}P(A)^k(1-P(A))^{5-k}\\\\ \u0026amp;=0.0866 \\end{align} $$\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"2ffb0bdb9708704a9494543b65315b37","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/hw1/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/hw1/","section":"notes","summary":"Problem 1.1 解：(1) $A_1\\cap \\overline{A_2}\\cap \\overline{A_3}$。\n(2) $A_1\\cup A_2\\cup A_3$。\n(3) $(A_1\\cap \\overline{A_2}\\cap \\overline{A_3})\\cup (\\overline{A_1}\\cap A_2\\cap \\overline{A_3})\\cup (\\overline{A_1}\\cap \\overline{A_2}\\cap A_3)\\cup (\\overline{A_1}\\cap \\overline{A_2}\\cap \\overline{A_3})$。\n(4) $\\overline{A_1\\cap A_2\\cap A_3}$。\n(5) $(A_1\\cap A_2)\\cup(A_1\\cap A_3)\\cup (A_2\\cap A_3)$。","tags":null,"title":"Homework 1","type":"docs"},{"authors":null,"categories":null,"content":"Problem 2.1 解： $$ \\begin{align} P(X=1)\u0026amp;=\\frac{\\binom{4}{3}\\cdot 6}{4^3}=\\frac{3}{8}\\\\ P(X=2)\u0026amp;=\\frac{\\binom{3}{2}\\binom{4}{2}\\cdot 2}{4^3}=\\frac{9}{16}\\\\ P(X=3)\u0026amp;=\\frac{4}{4^3}=\\frac{1}{16} \\end{align} $$ 综上，$X$ 的分布列为\n$X$ $1$ $2$ $3$ $P(X)$ $\\frac{3}{8}$ $\\frac{9}{16}$ $\\frac{1}{16}$ Problem 2.4 解：各个常数的计算过程如下：\n$a=\\frac{3}{4}-P(X=-1)=\\frac{1}{2}$。\n$b=1-P(X=-1)-P(X=0)=\\frac{1}{4}$。\n$c=P(X\u0026lt;-1)=0$。\n$d=P(X\u0026lt;0)=P(X=-1)=\\frac{1}{4}$。\n$e=P(X=-1)+P(X=0)+P(X=1)=1$。\nProblem 2.8 解：(1) $$ \\begin{align} P(X\\leq 3)\u0026amp;=e^{-\\lambda}\\sum_{k=0}^3\\frac{\\lambda^k}{k!}\\approx 0.7576\\\\ P(转港)\u0026amp;=P(X\u0026gt;3)=1-P(X\\leq 3)=0.2424 \\end{align} $$ (2) 考察函数 $f(x)=\\frac{2.5^x}{x!},x\\in \\mathbb N$，显然当 $x=2$ 时 $f(x)$ 取得最大值。所以最大可能到达港口的油船数为 2，概率为 $\\frac{2.5^2}{2}e^{-2.5}\\approx 0.2565$。\n(3) 注意到 $$ \\begin{align} P(X\\leq 4)\u0026amp;=e^{-\\lambda}\\sum_{k=0}^4\\frac{\\lambda^k}{k!}=0.8912\u0026lt;0.9\\\\ P(X\\leq 5)\u0026amp;=e^{-\\lambda}\\sum_{k=0}^5\\frac{\\lambda^k}{k!}=0.9553\\geq 0.9 \\end{align} $$ 所以服务能力提高到 5 只油船才能使得到达游船以 $90%$ 的概率得到服务。\nProblem 2.12 解：(1) $$ \\int_{-\\infty}^{+\\infty}p(x)dx=\\int_0^1p(x)dx=A\\int_0^1x^3dx=\\left.\\frac{A}{4}x^4\\right|_0^1=\\frac{A}{4}=1 $$ 解得 $A=4$。\n(2) $$ F(x)=P(X\\leq x)=\\int_{-\\infty}^xp(u)du= \\begin{cases} 0\u0026amp;,x\\leq 1\\\\ x^4\u0026amp;,0\u0026lt;x\\leq 1\\\\ 1\u0026amp;,x\u0026gt;1 \\end{cases} $$ (3) 令 $F(x)=0.5$，解得 $x=(\\frac{1}{2})^{\\frac{1}{4}}$，所以 $B=\\left(\\frac{1}{2}\\right)^{\\frac{1}{4}}$。\nProblem 2.16 解：令 $Z=\\frac{X-\\mu}{4},W=\\frac{Y-\\mu}{5}$，则 $Z\\sim N(0,1),W\\sim N(0,1)$。 $$ \\begin{align} p_1\u0026amp;=P(X\\leq \\mu-4)=P(4Z+\\mu\\leq \\mu-4)=P(Z\\leq -1)=P(Z\\geq 1)\\\\ p_2\u0026amp;=P(Y\\geq \\mu+5)=P(5W+\\mu\\geq \\mu+5)=P(W\\geq 1) \\end{align} $$ 又 $Z,W$ 分布函数相同，所以 $p_1=p_2$。\nProblem 2.19 解：(1) $Y=2X$ 的分布律如下：\n$Y$ $-4$ $-1$ $0$ $1$ $8$ $P$ $\\frac{1}{8}$ $\\frac{1}{4}$ $\\frac{1}{8}$ $\\frac{1}{6}$ $\\frac{1}{3}$ (2) $Y=X^2$ 的分布律如下：\n$Y$ $0$ $\\frac{1}{4}$ $4$ $16$ $P$ $\\frac{1}{8}$ $\\frac{5}{12}$ $\\frac{1}{8}$ $\\frac{1}{3}$ (3) $Y=\\sin \\left(\\frac{\\pi}{2}X\\right)$ 的分布律如下：\n$Y$ $-\\frac{\\sqrt 2}{2}$ $0$ $\\frac{\\sqrt 2}{2}$ $P$ $\\frac{1}{4}$ $\\frac{7}{12}$ $\\frac{1}{6}$ Problem 2.26 证明：$X$ 服从参数为 2 的指数分布，即 $$ p_X(x)=\\begin{cases} 2e^{-2x}\u0026amp;,x\\geq 0\\\\ 0\u0026amp;,x\u0026lt;0 \\end{cases} $$ $Y=g(X)=1-e^{-2X}$，$g\u0026rsquo;(x)=-e^{-2x}\\cdot (-2)=2e^{-2x}\u0026gt;0$，所以 $g(x)$ 严格单调递增且处处可导。因此 $$ \\begin{align} p_Y(y)\u0026amp;=p_X(g^{-1}(y))\\cdot \\left|g^{-1}(y)\\right|\\\\ \u0026amp;=\\frac{1}{2(1-y)}p_X(-\\frac{1}{2}\\ln(1-y))\\\\ \u0026amp;= \\begin{cases} 1\u0026amp;,0\\leq x\\leq 1\\\\ 0\u0026amp;, otherwise \\end{cases} \\end{align} $$ 可以看到在 $[0,1]$ 中，$p_Y(y)=1=\\frac{1}{1-0}$，所以 $Y$ 在 $[0,1]$ 上服从均匀分布。$\\blacksquare$\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"438f7c5e77431f0a481c0bcf37d8f9f9","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/hw2/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/hw2/","section":"notes","summary":"Problem 2.1 解： $$ \\begin{align} P(X=1)\u0026amp;=\\frac{\\binom{4}{3}\\cdot 6}{4^3}=\\frac{3}{8}\\\\ P(X=2)\u0026amp;=\\frac{\\binom{3}{2}\\binom{4}{2}\\cdot 2}{4^3}=\\frac{9}{16}\\\\ P(X=3)\u0026amp;=\\frac{4}{4^3}=\\frac{1}{16} \\end{align} $$ 综上，$X$ 的分布列为\n$X$ $1$ $2$ $3$ $P(X)$ $\\frac{3}{8}$ $\\frac{9}{16}$ $\\frac{1}{16}$ Problem 2.4 解：各个常数的计算过程如下：\n$a=\\frac{3}{4}-P(X=-1)=\\frac{1}{2}$。\n$b=1-P(X=-1)-P(X=0)=\\frac{1}{4}$。\n$c=P(X\u0026lt;-1)=0$。\n$d=P(X\u0026lt;0)=P(X=-1)=\\frac{1}{4}$。\n$e=P(X=-1)+P(X=0)+P(X=1)=1$。","tags":null,"title":"Homework 2","type":"docs"},{"authors":null,"categories":null,"content":"Questions Let’s examine a simple program, “loop.s”. First, just read and understand it. Then, run it with these arguments (./x86.py -p loop.s -t 1 -i 100 -R dx) This specifies a single thread, an interrupt every 100 instructions, and tracing of register %dx. What will %dx be during the run? Use the -c flag to check your answers; the answers, on the left, show the value of the register (or memory value) after the instruction on the right has run. Same code, different flags: (./x86.py -p loop.s -t 2 -i 100 -a dx=3,dx=3 -R dx) This specifies two threads, and initializes each %dx to 3. What values will %dx see? Run with -c to check. Does the presence of multiple threads affect your calculations? Is there a race in this code? Run this: ./x86.py -p loop.s -t 2 -i 3 -r -a dx=3,dx=3 -R dx This makes the interrupt interval small/random; use different seeds (-s) to see different interleavings. Does the interrupt frequency change anything? Now, a different program, looping-race-nolock.s, which accesses a shared variable located at address 2000; we’ll call this variable value. Run it with a single thread to confirm your understanding: ./x86.py -p looping-race-nolock.s -t 1 -M 2000 What is value (i.e., at memory address 2000) throughout the run? Use -c to check. Run with multiple iterations/threads: ./x86.py -p looping-race-nolock.s -t 2 -a bx=3 -M 2000 Why does each thread loop three times? What is final value of value? Run with random interrupt intervals: ./x86.py -p looping-race-nolock.s -t 2 -M 2000 -i 4 -r -s 0 with different seeds (-s 1, -s 2, etc.) Can you tell by looking at the thread interleaving what the final value of value will be? Does the timing of the interrupt matter? Where can it safely occur? Where not? In other words, where is the critical section exactly? Now examine fixed interrupt intervals: ./x86.py -p looping-race-nolock.s -a bx=1 -t 2 -M 2000 -i 1 What will the final value of the shared variable value be? What about when you change -i 2, -i 3, etc.? For which interrupt intervals does the program give the “correct” answer? Run the same for more loops (e.g., set -a bx=100). What interrupt intervals (-i) lead to a correct outcome? Which intervals are surprising? One last program: wait-for-me.s. Run: ./x86.py -p wait-for-me.s -a ax=1,ax=0 -R ax -M 2000 This sets the %ax register to 1 for thread 0, and 0 for thread 1, and watches %ax and memory location 2000. How should the code behave? How is the value at location 2000 being used by the threads? What will its final value be? Now switch the inputs: ./x86.py -p wait-for-me.s -a ax=0,ax=1 -R ax -M 2000 How do the threads behave? What is thread 0 doing? How would changing the interrupt interval (e.g., -i 1000, or perhaps to use random intervals) change the trace outcome? Is the program efficiently using the CPU? Solutions %dx 寄存器初始值为 0，执行一次 sub 指令后变为 -1，随后跳出循环。\n%dx 从 3 开始每做一次循环 -1,直到变为负数后退出。两个线程的行为是完全一样的。多线程没有影响计算，这里没有出现竞争条件。\n中断的频率不会对线程行为产生任何影响。loop.s 中只有针对寄存器的行为，不同线程的寄存器之间是互相独立的。\n循环只做了一次，地址 2000 处最终数值为 1。\n%bx 寄存器的初始值为 3，所以每个线程做三次循环，最终地址 2000 处的值为 6。\n使用 0 和 2 做种子可以得到正确的结果 2，因为两个线程临界区域的代码没有交叉：\n# seed = 0 2000 bx Thread 0 Thread 1 0 0 0 0 1000 mov 2000, %ax 0 0 1001 add $1, %ax 1 0 1002 mov %ax, 2000 1 -1 1003 sub $1, %bx 1 0 ------ Interrupt ------ ------ Interrupt ------ 1 0 1000 mov 2000, %ax 1 0 1001 add $1, %ax 2 0 1002 mov %ax, 2000 2 -1 1003 sub $1, %bx 2 -1 ------ Interrupt ------ ------ Interrupt ------ 2 -1 1004 test $0, %bx 2 -1 1005 jgt .top 2 -1 ------ Interrupt ------ ------ Interrupt ------ 2 -1 1004 test $0, %bx 2 -1 1005 jgt .top 2 -1 ------ Interrupt ------ ------ Interrupt ------ 2 -1 1006 halt 2 -1 ----- Halt;Switch ----- ----- Halt;Switch ----- 2 -1 1006 halt 使用 1 做种子会得到错误的结果 1，因为两个线程的临界区域出现了交叉 (第一个线程做了第一条指令后切换到了第二个线程)。\n2000 bx Thread 0 Thread 1 0 0 0 0 1000 mov 2000, %ax 0 0 ------ Interrupt ------ ------ Interrupt ------ 0 0 1000 mov 2000, %ax 0 0 1001 add $1, %ax 1 0 1002 mov %ax, 2000 1 -1 1003 sub $1, %bx 1 0 ------ Interrupt ------ ------ Interrupt ------ 1 0 1001 add $1, %ax 1 0 1002 mov %ax, 2000 1 -1 1003 sub $1, %bx 1 -1 1004 test $0, %bx 1 -1 ------ Interrupt ------ ------ Interrupt ------ 1 -1 1004 test $0, %bx 1 -1 1005 jgt .top 1 -1 ------ Interrupt ------ ------ Interrupt ------ 1 -1 1005 jgt .top 1 -1 1006 halt 1 -1 ----- Halt;Switch ----- ----- Halt;Switch ----- 1 -1 ------ Interrupt ------ ------ Interrupt ------ 1 -1 1006 halt 只有两个线程在执行临界区域代码时保持原子性 (不被打断)，才能得到正确的结果。临界区域为：\n.main .top # \u0026lt;-- critical section begin --\u0026gt; mov 2000, %ax add $1, %ax mov %ax, 2000 # \u0026lt;-- critical section end --\u0026gt; sub $1, %bx test $0, %bx jgt .top halt 中断步长为 1 和 2 时无法获得正确的结果 (临界区域交织)。在只循环一次的情况下，中断步长大于等于 3 即可保证结果正确。\n保证执行结果正确有以下几种思路：\n只要设置 -i 参数足够大以使得两个线程串行地执行，就可以保证结果正确。 该汇编代码执行一个循环一共有 6 条语句，其中临界区域有 3 条语句。因此只要设置 -i 参数为 3 的倍数，就可以保证临界区域不会交叉。 对于那些不是 3 的倍数的参数，在参数较小时尚可预估 (比如如果设置 -i 1/2，则每个临界区域都会交织，最后答案为 N，-i 4 最后的结果会是 3N/2 上取整)，参数较大时得到的结果就难以理解了。\nwait-for-me.s 代码会根据 %ax 的值选择 waiter 或 signaller 身份。waiter 等待地址 2000 处值为 1结束，signaller 负责向 2000 处放一个 1。\n.main test $1, %ax # ax should be 1 (signaller) or 0 (waiter) je .signaller .waiter\tmov 2000, %cx test $1, %cx jne .waiter halt .signaller mov $1, 2000 halt 运行指令后会看到第一个线程放 1 结束，第二个线程看到有 1 结束。\n如果反过来，则会看到线程 1 在轮询地址 2000 处的值，直到发生线程切换，线程 2 向 2000 处填写了 1，线程 1 才得以退出。这是自旋锁的雏形。如果将 -i 调得很大，线程 1 将浪费 CPU cycle 进行大量轮询。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"2740481f457925b639784272ac936222","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/hw26/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/hw26/","section":"notes","summary":"Questions Let’s examine a simple program, “loop.s”. First, just read and understand it. Then, run it with these arguments (./x86.py -p loop.s -t 1 -i 100 -R dx) This specifies a single thread, an interrupt every 100 instructions, and tracing of register %dx.","tags":null,"title":"Homework 26","type":"docs"},{"authors":null,"categories":null,"content":"Questions First build main-race.c. Examine the code so you can see the (hopefully obvious) data race in the code. Now run helgrind (by typing valgrind \u0026ndash;tool=helgrind main-race) to see how it reports the race. Does it point to the right lines of code? What other information does it give to you? What happens when you remove one of the offending lines of code? Now add a lock around one of the updates to the shared variable, and then around both. What does helgrind report in each of these cases? Now let’s look at main-deadlock.c. Examine the code. This code has a problem known as deadlock (which we discuss in much more depth in a forthcoming chapter). Can you see what problem it might have? Now run helgrind on this code. What does helgrind report? Now run helgrind on main-deadlock-global.c. Examine the code; does it have the same problem that main-deadlock.c has? Should helgrind be reporting the same error? What does this tell you about tools like helgrind? Let’s next look at main-signal.c. This code uses a variable (done) to signal that the child is done and that the parent can now continue. Why is this code inefficient? (what does the parent end up spending its time doing, particularly if the child thread takes a long time to complete?) Now run helgrind on this program. What does it report? Is the code correct? Now look at a slightly modified version of the code, which is found in main-signal-cv.c. This version uses a condition variable to do the signaling (and associated lock). Why is this code preferred to the previous version? Is it correctness, or performance, or both? Once again run helgrind on main-signal-cv. Does it report any errors? Solutions helgrind 工具可以准确地报告出 main-race.c 的第 15 行和第 8 行的操作存在 data race。此外，helgrind 可以报告出产生数据竞争的地址 (0 bytes inside data symbol \u0026ldquo;balance\u0026rdquo;)，还可以报告线程创建的过程：\n---Thread-Announcement------------------------------------------ Thread #2 was created at 0x49A9D42: clone (clone.S:71) by 0x4878281: create_thread (createthread.c:103) by 0x4879C8B: pthread_create@@GLIBC_2.2.5 (pthread_create.c:821) by 0x484D627: ??? (in /usr/libexec/valgrind/vgpreload_helgrind-amd64-linux.so) by 0x109209: main (main-race.c:14) 如果删除掉任意一个对 balance 的操作，helgrind 就不会报告错误。如果只用锁保护一处操作，helgrind 仍然会报告 data race (且能报告处哪一处操作被锁保护了)。如果用锁将两处操作都保护了，helgrind 不会报告错误。\nmain-deadlock.c 存在发生死锁的风险：如果 p1 线程获得了锁 m1，然后 p2 线程获得了锁 m2，这时 p1 线程试图获得锁 m2，p2 线程试图获得锁 m1，它们都得不到需要的锁，也不会释放自己已经得到的锁，从而陷入死锁。\nhelgrind 会报告形如下面所示的错误：\nThread #3: lock order \u0026quot;0x10C040 before 0x10C080\u0026quot; violated Observed (incorrect) order is: acquisition of lock at 0x10C080 ... followed by a later acquisition of lock at 0x10C040 ... Required order was established by acquisition of lock at 0x10C040 ... followed by a later acquisition of lock at 0x10C080 ... Lock at 0x10C040 was first observed ... Address 0x10c040 is 0 bytes inside data symbol \u0026quot;m1\u0026quot; Lock at 0x10C080 was first observed ... Address 0x10c080 is 0 bytes inside data symbol \u0026quot;m2\u0026quot; 对于程序中的任意两个锁，所有获取锁的行为都一定要按照相同的顺序，否则就有可能引发死锁。helgrind 根据这个原理检测到了可能存在的死锁，并且给出了两次不同的顺序以及锁的名称。\n为什么我无法使死锁暴露出来？\n两个线程的创建是有时间差的，新创建的线程可以利用这个时间差把两个锁都得到，这样死锁就不会暴露出来。\n为了更好地观测死锁现象，我们可以在 worker() 函数的开头添加一句 usleep(1)，这会让线程在此处等待至少 1 微秒的时间。考虑到系统活动等因素，usleep(1) 其实会带来一段时长比较随机的 delay，这让两个线程被拉回“同一起跑线”的几率大大增加。此外，多次重复实验，即可比较容易地观察到死锁现象。\nmain-deadlock-global.c 中由于有一个外层的大锁保护，所以不会发生死锁。但使用 helgrind 检查仍然和会报告有非法的锁获得顺序问题。helgrind 只是记录访问锁的顺序并判断是否出现了环，并不能准确地判断死锁是否可能发生。\n主线程在子线程打印的时候会轮询 done 变量，让 CPU 空转，所以这个方法是不高效的。\nhelgrind 报告该程序存在数据竞争。两个线程对 done 的读写没有用锁保护起来，存在 race condition。\nmain-signal-cv.c 相较于前者有两个改进：一是两个进程对 done 变量的访问都用锁保护了起来，保证了不会发生 race condition；二是该程序使用了条件变量，如果主线程检查 done 结果为 0，会在条件变量上睡眠，睡眠的线程可以被 CPU 调度出去，从而不占据 CPU 时钟周期。等到子线程打印完了唤醒条件变量，主线程再来检查 done 变量并打印自己的内容。\nhelgrind 没有报告任何错误。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"eb0714df356e5364fe4e7ecd6a9c4630","permalink":"https://kristoff-starling.github.io/notes/booknotes/ostep/hw27/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/booknotes/ostep/hw27/","section":"notes","summary":"Questions First build main-race.c. Examine the code so you can see the (hopefully obvious) data race in the code. Now run helgrind (by typing valgrind \u0026ndash;tool=helgrind main-race) to see how it reports the race.","tags":null,"title":"Homework 27","type":"docs"},{"authors":null,"categories":null,"content":"A. 为世界所有美好而战 题面描述 yjher 是一名带学生，他有一个梦想，为世界所有美好而战。作为带学生，他首先要解决一个问题，就是选课问题。俗话说，选课一时爽，期末火葬场，为了避免这种情况，他决定根据期末最后的总复习时间 $m$ 来确定选课方案。(每门课只能选一次） 已知现在一共有 $n$ 门课，每门课有两个属性 $v_i$ 和 $t_i$，分别表示这门课修完能获得的学分和复习需要花的时间。 现在问你复习所花时间的和不超过 $m$ 的情况下，能获得的最高分数。 $n\\leq 1000,m\\leq 10^9,v_i\\leq 300,t\\leq 3e6$​​​。 题解 由于 $m$ 的范围过大，而学分 $v_i$​​ 的范围相对较小，因此考虑将学分作为背包dp的状态。\n令 $dp[i][j]$ 表示当前考虑到第 $i$ 门课，获得 $j$ 学分的情况下所需使用的最小时间，转移是简单的： $dp[i][j]=min{dp[i-1][j],dp[i-1][j-v[i]]+t[i]}$​​。\n时间复杂度 $O(n\\sum v_i)$，可以通过，但空间复杂度 $O(n\\sum v_i)$​​ 不能接受。\n背包dp有一种简单的空间优化的方式，考虑将dp状态压缩成一维 $dp[j]$，双重循环的第 $i$ 轮结束时表示获得 $j$ 学分所需的最小时间。我们只要在内循环中倒序循环，就能保证 $dp[j]$ 的更新来源都是上一层的数据，从而保证了正确性，这样空间复杂度压缩到 $O(\\sum v_i)$​。\nB. 数列 题面描述 给定一个 $n$ 个数的数列 $a[i]$，对于每个 $i$ ,在右边找到一个最靠右的位置 $k$（即 $k$ 尽可能大），满足 $a[k]\u0026lt;a[i]$，输出 $k-i-1$，如果一个都找不到，输出 $-1$。对于序列的每个元素都要输出。 $n\\leq 500000$​。 题解 考虑按照权值从小到大的顺序向空序列中依次添加这些数，这样做的好处是，某一次添加 $a[i]$​ 时，数列中已经存在的数一定是比当前数小的数，因此我们只需要一边加数，一边更新下标的最大值即可。（如果下标最大值小于当前数的下标，则答案为-1）。\n总时间复杂度 $O(nlogn)$​。\nC. 只有一种英雄主义 题面描述 这个世界上只有一种英雄主义，那就是在认清生活的真相后依然热爱它。yjher 面对着 $n$​​ 个生活的真相，这些生活的真相按序依次排好成为一个数列，yjher 对每个生活的真相都有 $m$​​ 种热爱等级可选（即可以理解为每个生活真相可以对应于一个 $1$​​ 到 $m$​​ 的热爱等级)。为了让生活看起来不要那么单调，要求相邻的生活真相有不同热爱等级（即如果你在第 $i$​​ 个生活真相中热爱等级是5，那么第 $i+1$​​ 个生活真相的热爱等级就不能是5），且 yjher 比较偏好数字 $k$​​，他希望所有生活真相总共使用的热爱等级数为恰好 $k$​​ 个。（就比如 $k=3,n=5,m=4$​​，那么 $1,2,3,2,1$​​ 和 $2,3,4,3,2$​​ 就是两个可行方案，但是 $1,2,3,4,3$​​​ 就不是，因为他用了超过3个不同的热爱等级）。\n现在问你所有可行的方案数。两个方案数认为是不同的，当前仅当两个方案的某个生活真相有不同的热爱等级（就比如 $1,2,3$ 和 $2,3,4$ 就是不同的方案），因为答案可能很大，令答案对 $1e9+7$取模。\n$n,m\\leq 10^9,k\\leq 10^6$​。\n题解 首先从 $m$ 个等级中选出 $k$ 个来进行安排，这一部分的方案数是 $\\binom{m}{k}$，之后的计算默认可选的等级为 1~k。\n恰好选满了 $k$​ 种等级较难控制，考虑容斥。令 $C(i)$​ 表示在 $k$​ 种等级的其中 $i$​ 种的范围中进行选择的方案数。为了保证相邻不相同的约束，第一个真相有 $i$​ 种选择，后面每一种都只有 $i-1$​ 种选择，因此 $C(i)=i\\cdot (i-1)^{n-1}$​。\n根据容斥原理，\n$$\\begin{align*}ans \u0026amp;= \\binom mk\\sum_{i=0}^{n-2}(-1)^i\\sum_{1\\leq a_1,a_2,\u0026hellip;,a_{k-i}\\leq k}C(a_1,a_2,\u0026hellip;,a_{k-i}) \\\\ \u0026amp;= \\binom mk \\sum_{i=0}^{n-2}(-1)^i\\binom kiC(i) \\\\ \u0026amp;= \\binom mk\\sum_{i=0}^{n-2}(-1)^i\\binom ki(k-i)(k-i-1)^{n-1} \\end{align*}$$$\\binom mk$ 可以通过下降幂的方式 $O(k)$ 地计算。预处理阶乘及其逆元之后，循环内部的组合数可以 $O(1)$ 计算， $(k-i-1)^{n-1}$ 需要使用快速幂，综上，总时间复杂度为 $O(klogn)$​。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"9b1b45fa4bbf1737fe6cf401e1e64696","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/ii-final/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/ii-final/","section":"notes","summary":"A. 为世界所有美好而战 题面描述 yjher 是一名带学生，他有一个梦想，为世界所有美好而战。作为带学生，他首先要解决一个问题，就是选课问题。俗话说，选课一时爽，期末火葬场，为了避免这种情况，他决定根据期末最后的总复习时间 $m$ 来确定选课方案。(每门课只能选一次） 已知现在一共有 $n$ 门课，每门课有两个属性 $v_i$ 和 $t_i$，分别表示这门课修完能获得的学分和复习需要花的时间。 现在问你复习所花时间的和不超过 $m$ 的情况下，能获得的最高分数。 $n\\leq 1000,m\\leq 10^9,v_i\\leq 300,t\\leq 3e6$​​​。 ","tags":null,"title":"问题求解 II - Final 题解","type":"docs"},{"authors":null,"categories":null,"content":"Overview 该实验的主要目的是在 abstract-machine 抽象的 bare-metal 上编写一个小游戏。笔者实现的小游戏是贪吃蛇。\nDesignation API 我们需要使用的比较重要的 AM 的接口有：\nputch() 及其封装版本 puts() ，负责向控制台输出字符和字符串。 AM_TIMER_UPTIME ，对该抽象寄存器进行读取可以获得系统启动以来运行时间的微秒数。 AM_INPUT_KEYBRD，对该抽象寄存器进行读取可以获得一个 AM_INPUT_KEYBRD_T 结构体，其中存储了当前是否有按键被按下，被按下的按键编码等。 AM_GPU_CONFIG，对该抽象寄存器进行读取可以获得 VGA 的基本信息，包括窗口宽高的像素数量。 AM_GPU_FBDRAW，对该抽象寄存器写入一个 AM_GPU_FBDRAW_T 结构体可以向 VGA 输出一个方格的颜色。 Game Logic 一个游戏的基本框架为：\nwhile (1) { while (uptime() \u0026lt; next_frame); while ((key = read_key() != AM_KEY_NONE) kbd_event(key); game_process(); screen_update(); next_frame += 1000 / FPS; } 对于贪吃蛇游戏：\n在 kbd_event() 中，我们需要处理 ESC 按键，令其调用 halt()，以及四个方向键用于控制贪吃蛇的行走方向。笔者还设置了按 R 键重新开始游戏的功能。\n在 game_process() 中\n我们需要维护贪吃蛇每一节身体的位置，并将头部按照当前方向移动一格，判断有没有出现撞墙或者吃了自己的情况，如果出现了，在游戏主循环中应该停止画面更新。 我们需要维护食物，如果食物和蛇头重合，则应该分数+1，并随机一个位置 (不能和蛇重合) 重新放置食物。 为了逐步增加游戏的难度，笔者维护 FPS = 5 + (score / 2)，即每多得两分，贪吃蛇的移动速度便会加快一级。 在 screen_update() 中，我们可以将背景涂成黑色，将边缘涂成橙色，将蛇身涂成绿色，蛇头涂成蓝色，食物涂成红色。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"de85713c9f7d3639a93d765d6cdcb140","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab00/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/labs/lab00/","section":"notes","summary":"Overview 该实验的主要目的是在 abstract-machine 抽象的 bare-metal 上编写一个小游戏。笔者实现的小游戏是贪吃蛇。\nDesignation API 我们需要使用的比较重要的 AM 的接口有：\nputch() 及其封装版本 puts() ，负责向控制台输出字符和字符串。 AM_TIMER_UPTIME ，对该抽象寄存器进行读取可以获得系统启动以来运行时间的微秒数。 AM_INPUT_KEYBRD，对该抽象寄存器进行读取可以获得一个 AM_INPUT_KEYBRD_T 结构体，其中存储了当前是否有按键被按下，被按下的按键编码等。 AM_GPU_CONFIG，对该抽象寄存器进行读取可以获得 VGA 的基本信息，包括窗口宽高的像素数量。 AM_GPU_FBDRAW，对该抽象寄存器写入一个 AM_GPU_FBDRAW_T 结构体可以向 VGA 输出一个方格的颜色。 Game Logic 一个游戏的基本框架为：","tags":null,"title":"Lab 00: AM Game","type":"docs"},{"authors":null,"categories":null,"content":"Overview 该实验的目标是实现一个 (内核使用的) 堆区的内存分配器。以下主要记录一些有趣的设计/性能调优经历。\nDesignation 维护堆区的数据结构应该放在堆区里，所以我们不应该开静态数组保存维护堆区的链表等，而应该将链表节点就存储在空闲的内存块上 (反正空闲的内存块当前也没有有效信息)。\n由于 kfree() 只传入了要释放内存块的起始地址，而没有传入 size，所以我们应当在 kalloc() 的时候记录每个释放出去的内存块的大小。笔者最初的实现是维护了一个分配出去的内存块的链表，kfree() 到来时，在链表里查找给定的地址是否存在以及对应的大小。但这样效率太低，于是笔者使用了在地址前打魔数的方法。笔者定义了一个如下的 header：\n#define ALLOC_MAGIC 0x1234567; typedef struct __header_t { size_t sz; union { uintptr_t magic; struct __header_t *next; }; }header_t; 每个内存块前都有一个这样的 header。这个 header 的好处是：未分配内存和已分配内存可以共用这个 header，当内存块处于未分配状态时，内存块被放在链表中，union 字段存放的是下一个链表节点的地址；当内存块处于已分配状态时，union 字段存放魔数。一个 kfree() 地址来临时，只要查看其前一个 uintptr_t 中是不是 ALLOC_MAGIC，就能确定这个地址合不合法，再往前看就能获得内存块的 size。\n(注：使用 header 的方法有一个弱点：原本在堆区中 1B 的内存加上 header 后变得很大。此外，由于对齐的原因，我们无法将多个大小相同的内存块“挨在一起”存放在堆区中，中间有很多“洞”。)\n由于 pmm 会被并发地执行，所以访问共享数据结构要上锁。\nDefensive Programming 笔者认为以下的防御性编程是有意义的：\n在 kalloc(), kfree() 中加入足够的对地址性质，空间大小分析的 panic(), panic_on() 等，这有助于提前发现 failure。 笔者实现的自旋锁中记录了当前拥有锁的 CPU 编号，这样在 acquire() 和 release() 前检查当前是否拥有锁，可以有效防御 AA-deadlock 和一些意料之外的情况。 kalloc()/kfree() 结束时应该将对应内存区间 memset 成奇怪数值，这样后续使用时如果忘了清零/地址溢出，读到垃圾数据可以加快 failure 出现的速度，减少排查 bug 的时间。 但以上防御性编程对效率有一定影响，因此笔者在提交 OJ 的版本中没有编译这些 (尤其是第三条) 防御性编程。\nPerformance Tuning 该实验对效率有一定的要求，笔者主要使用 Linux perf 工具对代码的运行时间/并行度进行观测。本地 Workload 的信息为：$60%$ 的 128K 以内内存分配，$30%$ 的 pagesize 内存分配，$10%$ 的大内存分配。释放的频率和分配相仿。每个核做 400,000 次分配和回收。\n笔者做过如下优化：\nFast Path 将整个堆区分成 cpu_count() 份，每个 CPU 核只在自己的那一份的链表中 alloc() 和 free() (free 时根据地址还到相应的资源区中)，因为一个核的 kalloc() 可能在另一个核中 kfree()，所以即使分成了多份，访问数据结构依旧要上锁。如果本地资源不足，则从别的资源区偷资源。该做法有一定效率提升，但不明显。\nslab。笔者对 1KB 以下内存分配的每种大小都开了一个单独的链表，对 pagesize (4KB) 也开了一个链表。slab 的核心做法是：没有资源时走 slow path，从全局资源中批发很多小块串成链表；有资源时直接从链表头取一个小块。这里每次走 slow path 批发多少个小块是一个需要调整的参数，不同的参数会对效率和失败率产生影响。\n这里的一个细节是：笔者希望每个核从自己的 slab 中获取资源，释放时将资源释放到自己的 slab 中，这样 fast path 不需要上锁。但提交 OJ 发现 smp=2 时就会出现 low memory usage，这很可能是因为 OJ 上两个核的任务不对称，如一个核专门 kalloc()，一个核专门 kfree()，导致资源全部堆积在第二个核的 slab 里无法利用。因此笔者不得不对 slab 的访问上锁，本地 slab 没有资源时去偷别人的 slab 的资源。\n为了减少 slab 上的锁拥堵，笔者尝试了以下两种“玄学”优化：\n每个核 kalloc() 时随机一个 slab 取资源，kfree() 时随机一个 slab 还资源 (其实两个都随机和只随机一个效果是一样的)。该策略只需要访问一个 slab，比之前的偷资源策略要高效一些，且打破了”不对称任务“约束，不会 low memory usage。该优化在本地 workload 中显著减少了锁的拥堵程度。 为了进一步减少锁的拥堵 (毕竟两个核随机到一个 slab 的概率还是不小的)，笔者给每个核选定一个 target slab (这是一个 permutation)，每个核向 target slab 索取资源，释放时归还到 target slab 中。为了避免“不对称任务”约束，每进行一定次数的分配后，shuffle 一下 target slab 的 permutation。该优化在本地的 workload 中相较前一种方法确实进一步减少了锁的拥堵程度，但没有看到明显的效率提升。 Slow Path 为了防止 (可以避免的) 过于破碎的内存，链表中应当有合并机制，即插入一个节点后，将其与左右邻居比较，若端点重合则合并节点。\nOSTEP 中提到过 best/first/next fit 等多种寻找可用节点的策略，如果使用 first fit，一段时间后堆区的前部就会出现较多破碎内存，后部相对完整，使搜索相对较慢。next fit 理论上会有更好的表现，但笔者没有在本地测试中观测到明显的效率提升。\n为了进一步减少破碎内存，笔者使用如下策略：一个内存块如果被分配完后剩余空间过少 (小于一个阈值)，则不选择切分这个内存块，而是将整块给当前分配。这样可以减少链表中容量很小的内存块个数。该优化在本地 workload 中体现出了效果。\n在一次 alloc() 失败后，记录这次的需求大小，在下一次 free() 来临之前，如果再出现大于之前失败最小值的 alloc()，可以不遍历链表直接返回 NULL。注意 free() 之后要将记录变量清空。该优化在失败率比较高的 workload 中体现出了效果。\n笔者发现完全抛弃链表，只用一个全局指针维护堆区，对于一个分配寻找全局指针最近的下一个对齐点 (结合 slab，kfree() 直接放到 slab 中) 的方法不会在 OJ 中报 low memory usage。这样复杂的链表操作被大幅简化。该优化在本地 workload 中体现出巨大效果。(注：如果很小的内存 alloc 和很大的内存 alloc 交替出现，该方法会浪费很多内存。该方法属于用失败率换效率的一个尝试。)\n即使笔者结合 Fast Path 和 Slow Path 中能想到的最优的实现，也无法通过旧版 OJ 上 smp=8 的测试用例。在本地 workload 下笔者的最优实现可以在 1.5s 到 2s 完成 8 核的所有任务。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"8dae62133b0683bfa4d827e0081132f8","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab01/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/labs/lab01/","section":"notes","summary":"Overview 该实验的目标是实现一个 (内核使用的) 堆区的内存分配器。以下主要记录一些有趣的设计/性能调优经历。\nDesignation 维护堆区的数据结构应该放在堆区里，所以我们不应该开静态数组保存维护堆区的链表等，而应该将链表节点就存储在空闲的内存块上 (反正空闲的内存块当前也没有有效信息)。\n由于 kfree() 只传入了要释放内存块的起始地址，而没有传入 size，所以我们应当在 kalloc() 的时候记录每个释放出去的内存块的大小。笔者最初的实现是维护了一个分配出去的内存块的链表，kfree() 到来时，在链表里查找给定的地址是否存在以及对应的大小。但这样效率太低，于是笔者使用了在地址前打魔数的方法。笔者定义了一个如下的 header：\n#define ALLOC_MAGIC 0x1234567; typedef struct __header_t { size_t sz; union { uintptr_t magic; struct __header_t *next; }; }header_t; 每个内存块前都有一个这样的 header。这个 header 的好处是：未分配内存和已分配内存可以共用这个 header，当内存块处于未分配状态时，内存块被放在链表中，union 字段存放的是下一个链表节点的地址；当内存块处于已分配状态时，union 字段存放魔数。一个 kfree() 地址来临时，只要查看其前一个 uintptr_t 中是不是 ALLOC_MAGIC，就能确定这个地址合不合法，再往前看就能获得内存块的 size。","tags":null,"title":"Lab 01: Physical Memory Manager","type":"docs"},{"authors":null,"categories":null,"content":"Overview 该实验的主要内容是实现内核线程的调度。本实验报告主要记录一些有趣的设计和测试方法。\nDesignation spinlock 在 L2 中我们需要实现一个相较于 L1 更加精细的自旋锁。在引入了中断机制后，我们在临界区内需要关闭中断，否则一旦持有锁的线程被调度下了 CPU 一整个时间片就会卡住。我们需要小心地维护中断的嵌套。我们需要一个 per-cpu 的变量来记录中断嵌套的层数，在第一层的时候关闭中断，并在最后一层被解开时打开中断。\nInline Assembly 笔者的初代实现使用了內联汇编进行栈切换 (模仿 xv6 的设计)，因而是架构相关的 (笔者针对 x86-64 和 x86 各写了一遍汇编)。在这种实现下，一次线程切换 (以时钟中断为例) 会经历如下历程：\n经过 AM 中的一些代码后，上下文保存在了栈上的 Context 结构体中，进入 os-\u0026gt;trap。\nos-\u0026gt;trap 根据中断原因，进入时钟中断的 handler。时钟中断要求当前线程主动让出 CPU。handler 会通过一个 swtch() 函数 (內联汇编) 跳转到 scheduler 线程，该函数原理类似 setjmp 和 longjmp，恢复寄存器现场并切换栈。scheduler 线程使用自己的独立的栈 (即不是线程的内核栈)，每个 CPU 核一个。\n调度器线程是一个死循环，它不断选择状态为 RUNNABLE 的线程并调用 swtch() 函数切换过去。\n目标线程返回自己的 Context 结构体。\n这种写法下，每个 os-\u0026gt;trap 最终返回的 Context 结构体就是传进来的那个，因此不需要对 Context 做额外的保存。这其中有一些细节需要注意：\nscheduler 线程必须打开中断，比如当前所有 input_task 线程都处于睡眠状态，我们只有让调度器线程响应键盘中断信号，才能唤醒这些 input_task 线程。 CPU 上锁之前的中断开关情况是一个 proc local 的状态，在调用 swtch() 切换前必须保存下来：比如在笔者的实现中，我们可能是在中断处理程序中 yield，这时 intena 是关中断状态；而信号量的 sleep() 中也会调用 swtch()，这时 intena 是开中断状态。 不使用 AM API 的最大坏处是：我们必须手动维护第一次进入一个线程的过程，因为我们之后切换到一个线程依赖的是它之前有一个 swtch() 到 scheduler 的现场，但一个进程刚被创建时没有现场。笔者的解决方法是：伪造一个寄存器现场完成栈切换，并通过一个內联汇编的 wrapper call 直接跳转到目标函数执行 (类似 M2)。 Semaphore 笔者为每个信号量准备了一把锁，这样可以用类似条件变量的方式实现信号量。sem_wait() 和 sem_post() 共用信号量的锁，sleep() 通过线程的锁来保证原子性。这其中的关键细节在于 sleep() 中先获取线程锁再释放信号量锁，这样对于 wait() 函数来说，sleep() 释放锁、线程睡眠 (修改线程的状态) 和线程切换这几个步骤就是原子的。\n有了信号量之后，我们可以使用 binary semaphore 作为一个睡眠锁，在长临界区的代码片段中睡眠锁可以提升效率。\nTesting Producer Consumer 在多核上多线程跑生产者消费者是一种比较好的暴露并发 bug 的好方法。在测试集的参数上笔者有如下心得：\n我们并不需要将括号打印在屏幕上肉眼检查，可以选择写一个 python 程序接收 oslab 的输出自动检查，或者在 oslab 的括号输出函数中直接修改一个全局计数器并执行检查。 创建较多的线程，将括号的嵌套层数调得浅一些 (比如 5 以内) 比较有利于测试并发正确性，因为嵌套层数浅时更容易触发错误，以及生产者/消费者的睡眠条件更容易满足，程序的并发行更高。 创建较小的线程可能有利于检查死锁错误。 dev Test Suite 一次完整的输入输出会经过如下步骤：\ntty_reader 线程向 tty 输出命令行提示符，然后调用 tty 的 read() 函数。tty 的 read() 函数要等待 tty_cook() 的信号，因此暂时挂起。\n每当用户按下一个键，硬件会生成一个中断，dev 测试集中的 input_notify() 函数负责处理这个中断，它会发送一个 kbdirq 信号，唤醒正在睡眠的 input_task 线程。input_task 线程从设备寄存器中读取按键的内容，更新当前的键盘按键状态，调用 push_event() 将按键事件放入 in-\u0026gt;events[] 队列中，并发送一个 event_sem 信号。此外，时钟中断也会发送 kbdirq 信号唤醒 input_task 线程，如果一段时间内没有任何按键，input_task 会 push 一个空的按键事件并发送 event_sem，向别的线程提供一个伪时钟。\ntty_task 线程会不断调用 input_read() 函数读取键盘输入，input_read() 会调用 pop_event() 从 in-\u0026gt;events[] 队列中取出一个按键事件返回，对于一个普通的按键事件，tty_task 会调用 tty_cook() 函数将字符加入一个和读取线程共享的队列 (保护该队列的锁是 tty-\u0026gt;lock)，并调用 ttydev-\u0026gt;ops-\u0026gt;write 将字符回显在 tty 上。\ntty_cook() 调用 tty_enqueue() 函数将字符放入队列 tty-\u0026gt;queue，如果遇到换行符 \\n，tty_cook() 会发送 cooked 信号来唤醒 tty_reader 线程。\ntty_read() 函数被唤醒后，会将队列里的字符拷贝到指定的地址。然后 tty_reader 线程打印相应的长度信息。\n注：tty_read() 打印信息和字符回显的先后无法保证。这里理应有的顺序是：在字符回显完成后 tty_reader 被唤醒并打印信息；tty_reader 打印出下一个命令行提示符之后再进行字符回显示。如果要获得更好的体验可能需要一些同步机制。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"7d83881d248fbc7ec98f7e99e83f5443","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab02/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/labs/lab02/","section":"notes","summary":"Overview 该实验的主要内容是实现内核线程的调度。本实验报告主要记录一些有趣的设计和测试方法。\nDesignation spinlock 在 L2 中我们需要实现一个相较于 L1 更加精细的自旋锁。在引入了中断机制后，我们在临界区内需要关闭中断，否则一旦持有锁的线程被调度下了 CPU 一整个时间片就会卡住。我们需要小心地维护中断的嵌套。我们需要一个 per-cpu 的变量来记录中断嵌套的层数，在第一层的时候关闭中断，并在最后一层被解开时打开中断。\nInline Assembly 笔者的初代实现使用了內联汇编进行栈切换 (模仿 xv6 的设计)，因而是架构相关的 (笔者针对 x86-64 和 x86 各写了一遍汇编)。在这种实现下，一次线程切换 (以时钟中断为例) 会经历如下历程：\n经过 AM 中的一些代码后，上下文保存在了栈上的 Context 结构体中，进入 os-\u0026gt;trap。","tags":null,"title":"Lab 02: Kernel Multi-Threads","type":"docs"},{"authors":null,"categories":null,"content":"Overview 该实验的主要内容是实现用户进程。用户进程可以理解为套上了虚拟内存的线程，因此我们需要引入 VME 系列的 API。本实验报告主要记录一些有趣的设计和遇到的 bug。\nDesignation ucontext() 由于笔者在 L2 中选择了通过汇编执行栈切换和执行流切换的操作，因此在 L3 的开始要做一些额外的改进。在 L2 中没有虚拟内存和页表切换的概念，因此第一次进入一个线程的时候我们可以很容易地通过一个內联汇编的 wrapper call 直接跳转到线程代码执行。但引入了用户进程后，初始上下文结构体的创建变得比较困难，返回用户态也需要做更多的事情 (比如页表切换，弹栈等)，因此笔者希望使用 AM 的 API。这就产生了一些矛盾。\n幸运的是，笔者发现 AM 中 trap64.S 中的汇编函数 __am_iret() 是有 label 的，这意味着笔者只需要抄写一些 AM 的头文件，就可以调用 __am_iret() 来完成用户态的返回。 笔者最终的代码是这样权衡的：\n因为调度器 swtch() 的原理是恢复内核线程执行的上下文，所以我们仍然需要一个类似于 xv6 中 forkret() 函数那样的东西作为一个进程第一次进入用户态的跳板。创建进程时，我们需要伪造一个内核线程的执行现场来让调度器跳转到一个函数 task_start()。 在 task_start() 中，我们需要完成 AM 中从 user_handler() 返回到调用 __am_iret() 之间做的事情，即切换用户页表和栈指针。然后调用 __am_iret() 完成最后的工作即可 (弹栈+iretq 返回用户态)。 Page Table Walk VME 对外的接口没有 page table walk，这让进程的复制变得困难：我们无法创建出一个和父进程页表一模一样的子进程页表。一种选择是在内核代码中对着 vme.c 中的 ptwalk() 写一个功能类似的函数，但笔者使用了比较简单的实现：在每个进程中额外维护了一个链表，记录了该进程拥有的所有虚拟页面以及其对应的物理地址和保护参数。链表这样扁平的结构会使得将来的查找效率变低，但比较容易写对且比较简单。\nwait()/exit() xv6 book 中花了大量篇幅讲解这两个 API，因为这里处理稍有不慎就可能导致 data race 或死锁。在 oslab 中该问题的难度大幅下降，因为我们不需要在 exit() 时将孤儿进程 reparent 给 init，但仍需要非常小心。\n笔者在书写代码时注意了锁的全局拓扑序问题：笔者规定任意一处代码如果要同时获得两个进程的锁，必须先获得父进程的锁再获得子进程的锁，这样一定程度上避免了死锁风险。\nCopy-on-write Fork 实现 cow fork 的基本思路为：在父进程 fork 时，将页面的写入权限去掉，并让父子进程的页表指向同一个物理页面。将来如果某个进程对该页面写入，则会触发 page fault，在 page fault handler 中我们新申请一个页面，将原页面的内容复制一份，修改当前进程的页表使其指向新页面，并重新赋予其写入权限。\ncow fork 会带来一些额外的细节，比如我们需要对每个页面维护一个 reference count 表示当前有多少个进程使用这个页面。在释放一个进程时我们不能直接释放它所有的物理页面，而是要修改其 reference count，只有一个页面的 reference count 变为 0 时才能释放。笔者的设计是将 reference count 的增加工作放在 fork() 和 pgmap() 中，将 reference count 的减少工作放在 kfree() 中，由 kfree() 判断当前减完 rfcnt 后是否需要执行真正的 free()，这样设计的好处在于之前写的涉及 free 的代码不需要修改。\n需要格外注意的是在引入 cow fork 后，一个页面就不只是一个进程的“资产”了，在处理页面 metadata 相关的信息时要记得上锁。\nmmap() 用户进程的虚拟地址空间理应以页为原子单位，因此笔者将 mmap() 参数中的 length 向 pgsize 上取整。分配时我们要确定一个地址 addr 是否满足 [addr, addr + length) 与当前地址空间没有冲突，由于无法直接访问页表，该检查笔者通过之前提到的链表完成，这一部分效率比较低下。\nmmap() 要注意 MAP_PRIVATE 和 MAP_SHARED 两种页面的性质差异。对于前者，fork 时要进行 copy-on-write 的处理，去掉写入权限并在 page fault handler 中进一步处理；对于后者，fork 时不需要做改动。父子进程对于 MAP_SHARED 的页面的读写的安全性由用户自己保证。\nInteresting Bugs dfs-fork() 笔者在移植 dfs-fork 时遇到了用户态指针跑飞的情况。经过检查发现跑飞的地址就是 dfs-fork.c 中 map[] 数组的地址。经过仔细检查，笔者发现 Makefile 中的命令\nx86_64-linux-gnu-ld -static --omagic --pic-executable --no-dynamic-linker --gc-sections -o _init -e _start trampoline.o ./printf.o ./init.o x86_64-linux-gnu-objcopy -S -j .text* -j.rodata* -j .data* -j .bss* --set-section-flags .bss=alloc,contents -O binary _init 前者并不能保证整个程序静态链接，map[] 的地址被放在了 GOT 中。在后续的 objcopy 中，只有代码节、数据节、.bss 节被保留了下来，从而 map[] 的地址丢失了。\n在 dfs-fork 的全局数组前加上 static 修饰就可以将数组放到数据节中，从而解决这个问题。\nPage Table Teardown 笔者在移植 dfs-fork 进行多核测试时曾经遇到神秘的 CPU reset。经过排查发现这涉及一个比较微妙的页表问题。假设一个核上父进程正在 wait()，另一个核上子进程在 exit()。根据笔者的设计，子进程 exit() 后会唤醒正在等待的父进程，然后跳转到调度器线程。但需要注意的是调度器线程现在使用的仍然是“子进程”的页表。父进程醒来后发现有僵尸子进程，于是回收资源，回收时调用 unprotect() 销毁子进程的页表，从而导致另一个核的调度器线程 crash。\n如果在 L2 中没有使用內联汇编做栈切换，我们应该会有一个“等待下一次进入 os_trap 再释放上一次进入 os_trap 的进程的锁” 的操作，这个操作在 L3 中同时可以确保页表不会被提前 teardown。但笔者的 L2 设计的特殊性导致了这里必须处理这样一个相似的问题。笔者的解决方法非常简单：用户进程在陷入内核后执行的都是内核代码，因此我们可以在 os_trap 的开头把页表切换成内核页表，这样就不会 crash 了。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"87fbeacf335707ab13c4b4de2567b40c","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/labs/lab03/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/labs/lab03/","section":"notes","summary":"Overview 该实验的主要内容是实现用户进程。用户进程可以理解为套上了虚拟内存的线程，因此我们需要引入 VME 系列的 API。本实验报告主要记录一些有趣的设计和遇到的 bug。\nDesignation ucontext() 由于笔者在 L2 中选择了通过汇编执行栈切换和执行流切换的操作，因此在 L3 的开始要做一些额外的改进。在 L2 中没有虚拟内存和页表切换的概念，因此第一次进入一个线程的时候我们可以很容易地通过一个內联汇编的 wrapper call 直接跳转到线程代码执行。但引入了用户进程后，初始上下文结构体的创建变得比较困难，返回用户态也需要做更多的事情 (比如页表切换，弹栈等)，因此笔者希望使用 AM 的 API。这就产生了一些矛盾。\n幸运的是，笔者发现 AM 中 trap64.S 中的汇编函数 __am_iret() 是有 label 的，这意味着笔者只需要抄写一些 AM 的头文件，就可以调用 __am_iret() 来完成用户态的返回。 笔者最终的代码是这样权衡的：","tags":null,"title":"Lab 03: User Level Processes","type":"docs"},{"authors":null,"categories":null,"content":"我们可以通过随机试验来研究随机现象。随机试验应当具有以下特点：\n相同条件下可重复； 试验结果不唯一，试验前未知，但所有可能的结果已知； 概率空间是一个三元组 $(\\Omega, \\mathscr F, P)$，其中 $\\Omega$ 为样本空间，$\\mathscr F$ 为可测事件集，$P$ 为概率测度。\nSample Space $\\fbox{Definition 1.1}$ 随机试验的所有可能结果的集合称为样本空间 (sample space)，记作 $\\Omega$。每个随机试验的可能结果称为样本点/基本事件 (sample point)，记作 $e$ 或 $\\omega$，$e\\in \\Omega$。\nMeasurable Event Set $\\fbox{Definition 1.2.1}$ 称 $\\mathscr{F}\\subseteq Pot(\\Omega)$ 是集合 $\\Omega$ 上的一个 $\\sigma$-域 ($\\sigma$-field)，当且仅当\n$\\Omega \\in \\mathscr{F}$； 若 $A\\in \\mathscr F$，则 $A^C\\in \\mathscr F$； 若 $A_1,\\cdots A_n\\cdots \\in \\mathscr F$，则 $\\bigcup_{i=1}^\\infty A_i\\in \\mathscr F$ (即可数个集合的并也是 $\\mathscr F$ 的元素)。 $\\fbox{Definition 1.2.2}$ 可测事件集 $\\mathscr F$ 是 $\\Omega$ 上的一个 $\\sigma$-域，若 $A\\subseteq \\Omega$，$A\\in \\mathscr F$，则称 $A$ 是一个事件 (event)。\nProbability Metric $\\fbox{Definition 1.3}$ 集合函数 $P:\\mathscr F\\rightarrow [0,1]$ 是 $(\\Omega, \\mathscr F)$ 上的一个概率测度 (probability metric)，当且仅当\n$P(\\Omega)=1$； 对于任意 $A\\in \\mathscr F$，$P(A)\\geq 0$； 满足可列可加性：对于互不相容的事件 $A_1,\\cdots,A_n\\cdots\\in \\mathscr F$，$P(\\bigcup_{n=1}^\\infty A_n)=\\sum_{n=1}^\\infty P(A_n)$。 以下是一系列有用的推论：\n$P(\\emptyset)=0$。\nProof: 取 $A_1=\\Omega, A_2=A_3=\\cdots =\\emptyset$，那么 $$ P(\\Omega)=P(\\bigcup_{n=1}^\\infty A_n)=\\sum_{n=1}^\\infty P(A_n)=P(\\Omega)+\\sum_{n=2}^\\infty P(\\emptyset) $$ 所以 $P(\\emptyset)=0$。$\\blacksquare$\n可列可加性可以推出有限可加性，即对于 $n\\in \\mathbb{N}$ ， $P(\\bigcup_{k=1}^nA_k)=\\sum_{k=1}^nP(A_k)$。\nProof: 取 $A_{n+1}=A_{n+2}=\\cdots =\\emptyset$，则有 $$ \\begin{align} P(\\bigcup_{k=1}^nA_k)\u0026amp;=P(\\bigcup_{k=1}^\\infty A_k)=\\sum_{k=1}^\\infty P(A_k)\\\\ \u0026amp;=\\sum_{k=1}^nP(A_k)+\\sum_{k=n+1}^\\infty P(\\emptyset)=\\sum_{k=1}^nP(A_k) \\end{align} $$ 有限可加性得证。$\\blacksquare$\n$P(A-B)=P(A)-P(A\\cap B)$。\nProof: 由 $A=(A-B)\\cup (A\\cap B)$ 和结论 2 易得。$\\blacksquare$\n$P(A\\cup B)=P(A)+P(B)-P(A\\cap B)$。更一般地， $$ P(\\bigcup_{k=1}^nA_k)=\\sum_{i=1}^n\\left((-1)^{i+1}\\sum_{1\\leq j_1\u0026lt;j_2\u0026lt;\\cdots\u0026lt;j_i\\leq n}P(\\bigcap_{k=1}^iA_{j_i})\\right) $$ (容斥原理的表达式)。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"5356e3eb94eab1acb963fdda80d2d534","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec01/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec01/","section":"notes","summary":"我们可以通过随机试验来研究随机现象。随机试验应当具有以下特点：\n相同条件下可重复； 试验结果不唯一，试验前未知，但所有可能的结果已知； 概率空间是一个三元组 $(\\Omega, \\mathscr F, P)$，其中 $\\Omega$ 为样本空间，$\\mathscr F$ 为可测事件集，$P$ 为概率测度。\nSample Space $\\fbox{Definition 1.1}$ 随机试验的所有可能结果的集合称为样本空间 (sample space)，记作 $\\Omega$。每个随机试验的可能结果称为样本点/基本事件 (sample point)，记作 $e$ 或 $\\omega$，$e\\in \\Omega$。\nMeasurable Event Set $\\fbox{Definition 1.","tags":null,"title":"Lecture 01: Probability Space","type":"docs"},{"authors":null,"categories":null,"content":"Classical Probability 古典概型的特点：\n$\\Omega={e_1,e_2,\\cdots,e_n},n\\in \\mathbb{N}$。 对于任意 $1\\leq i\\leq n$，$P({e_i})=\\frac{1}{n}$ (即每个样本点等可能)。 在此基础上，若 $A={e_{i_1},\\cdots e_{i_k}}$ ，则 $P(A)=\\frac{k}{n}$。\nPermutations and Combinations $n$ 个可分辨的球选 $r$ 个，可重复选，排列：$n^r$。\n$n$ 个可分辨的球选 $r$ 个，不可重复选，排列：$n^{\\underline r}=\\frac{n!}{(n-r)!}$。\n$n$ 个可分辨的球选 $r$ 个，不可重复选，组合：$\\binom{n}{r}$。\n$n$ 个可分辨的球选 $r$ 个，可重复选，组合：$\\binom{n+r-1}{r}$。\n考虑一个选择方案 $1\\leq x_1\\leq x_2\\leq \\cdots \\leq x_r\\leq n$，现设计另一个数列 $y$，满足 $y_1=x_1,y_2=x_2+1,y_3=x_3+2,\\cdots,y_r=x_r+r-1$。那么 $y$ 严格单调增，且 $1\\leq y_i\\leq n+r-1$。$x$ 序列和 $y$ 序列一一对应，因此 $x$ 序列个数 = $y$ 序列个数 = $\\binom{n+r-1}{r}$。\n【例】求 $(a+b+c)^n$ 合并同类项的展开式中有多少项。\n解：相当于求形如 $a^{n_1}b^{n_2}c^{n_3},n_1+n_2+n_3=n$ 的个数。可以将其理解为从 $3$ 个物品中选 $n$ 个，可重复选的组合方案数，因此答案为 $\\binom{n+2}{n}=\\frac{1}{2}(n+1)(n+2)$。\n有关组合数的一些性质：\n$(1+x)^n=\\sum_{k=0}^n\\binom{n}{k}x^k$，令 $x=1$ ，可得 $\\sum_{k=0}^n\\binom{n}{k}=2^n$。 $(1+x)^{a+b}=(1+x)^a(1+x)^b$，因此 $\\binom{a+b}{n}=\\sum_{k=0}^a\\binom{a}{k}\\binom{b}{n-k}$。若取 $a=b=n$，则可以得到 $\\binom{2n}{n}=\\sum_{k=0}^n\\binom{n}{k}\\binom{n}{n-k}=\\sum_{k=0}^n\\binom{n}{k}^2$。 Geometrical Probability $\\fbox{Definition 2.1}$ (几何概型) 若 $\\Omega$ 中的样本点与一个有界区域 $S$ 中的点一一对应，则事件 $A$ 对应于 $S$ 的一个子集 $D$。若 $A$ 的概率只和 $D$ 的测度有关，而与 $D$ 的形状，位置无关，那么 $P(A)=\\frac{D的测度}{S 的测度}$。\n【例】甲乙两人各在 1h 内随机一个时间点到达约会地点，先到的人最多等后到的人 15 分钟，求两人碰面的概率。\n解：用数对 $(x,y)$ 表示甲乙两人到达的时间，则两人可以碰面当且即当 $|x-y|\\leq 15$，画图：\n因此碰面概率为 $\\frac{60^2-45^2}{60^2}=\\frac{7}{16}$。\n【例】 (蒲丰投针) 两平行线间距 $a$，向其投掷长度为 $l$ $(l\u0026lt;a)$ 的针，使针的中点在两平行线之间，求针与两条平行线中任意一条相交的概率。\n解： $l\u0026lt;a$ 保证了针至多只会和一条线相交，根据对称性，我们只考虑针与下面的线相交的情况。\n设针的中点与线的距离为 $x$，针所在的直线与线的夹角为 $\\theta$，则针与线相交当且仅当 $x\\leq \\frac{l}{2}\\sin\\theta$。我们以 $x$ 和 $\\theta$ 为坐标轴画出样本空间和相交事件： $$ \\begin{align} \\Omega \u0026amp;= {(\\theta,x)|0\u0026lt;\\theta\u0026lt;\\pi,0\\leq x\\leq \\frac{a}{2}}\\\\ A \u0026amp;= {(\\theta,x)|0\\leq \\theta \\leq \\pi, 0\\leq x \\leq \\frac{l}{2}\\sin \\theta} \\end{align} $$ $A$ 的图像是一个正弦函数，要计算面积，只需要计算积分： $$ P(A)=\\frac{1}{\\pi\\cdot \\frac{a}{2}}\\int_{0}^\\pi\\frac{l}{2}\\sin \\theta d\\theta=\\left.-\\frac{l}{2}\\cos\\theta\\right|_{0}^\\pi=\\frac{2l}{a\\pi} $$ 这个方法可以用于估算 $\\pi$ 的值。通过大量重复试验用 $f_N(A)$ 来代替 $P(A)$ 后，$\\pi=\\frac{2l}{aP(A)}$。\n【例】 (贝特朗奇论) 在一个半径为 1 的圆中等概率地取一根弦，弦长 $l\u0026gt;\\sqrt 3$ 的概率是多少？\n由于这里的“等概率”没有被严格地定义，因此可能有多种对等概率的解读，它们都是对的且会算出不同的结果：\n在圆周上固定一个点，然后另一个点在圆周上随机选取：$P(A)=\\frac{1}{3}$。 让一条直线从上往下均匀地扫一遍，发现只有中点距离圆心小于 $\\frac{1}{2}$ 时弦长满足要求：$P(A)=\\frac{1}{2}$。 在圆内随机选取弦的中点，发现只有中点位于半径为 $\\frac{1}{2}$ 的小圆内是弦长满足要求：$P(A)=\\frac{1}{4}$。 …… ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"f29440c01199a69d27c54f764694fca1","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec02/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec02/","section":"notes","summary":"Classical Probability 古典概型的特点：\n$\\Omega={e_1,e_2,\\cdots,e_n},n\\in \\mathbb{N}$。 对于任意 $1\\leq i\\leq n$，$P({e_i})=\\frac{1}{n}$ (即每个样本点等可能)。 在此基础上，若 $A={e_{i_1},\\cdots e_{i_k}}$ ，则 $P(A)=\\frac{k}{n}$。\nPermutations and Combinations $n$ 个可分辨的球选 $r$ 个，可重复选，排列：$n^r$。\n$n$ 个可分辨的球选 $r$ 个，不可重复选，排列：$n^{\\underline r}=\\frac{n!}{(n-r)!}$。\n$n$ 个可分辨的球选 $r$ 个，不可重复选，组合：$\\binom{n}{r}$。","tags":null,"title":"Lecture 02: Classical Probability and Geometric Probability","type":"docs"},{"authors":null,"categories":null,"content":"Conditional Probability “事件 $A$ 和 $B$ 同时发生的概率”与“ $B$ 发生的条件下，$A$ 发生的概率”不一定相等！\n“事件 $A$ 和 $B$ 同时发生” 是在 $\\Omega$ 中 寻找 $A\\cap B$，$P(A\\cap B)=\\frac{|A\\cap B|}{|\\Omega|}$。 “ $B$ 发生的条件下，$A$ 发生”，样本空间退化为 $B$，$P(A|B)=\\frac{|A\\cap B|}{|B|}$。 $\\fbox{Definition 3.1}$ 设事件 $A,B$ 满足 $P(B)\u0026gt;0$，则称 $P(A|B)=\\frac{P(AB)}{P(B)}$ 为在事件 $B$ 发生的条件下事件 $A$ 发生的概率。\n注：若将 $B$ 视为一个样本空间 $\\Omega_B$，则可定义概率空间 $(\\Omega_B,\\mathscr{F}_B,P_B)$，其中 $\\mathscr{F}_B={A\\cap B| A\\in \\mathscr{F}}$，$P_B(A)=P(A|B)$。此时若直接取 $P$ 为 $\\Omega_B$ 的概率测度，即令 $P_B=P$，则 $P_B(B)\u0026lt;1$，违反了概率空间的定义 (出现了某种概率损失)，所以应该对其除掉 $P(B)$ 进行一个归一化：$P_B(A)=\\frac{P(AB)}{P(B)}$。\n事实上， $P_B$ 也是 $(\\Omega,\\mathscr{F})$ 上的一个概率\n$P_B(A)\\geq 0$，$P_B(\\Omega)=1$； 满足可列可加性。 因此，之前推导的关于交、并的概率公式在条件概率上仍然适用。$P_B$ 的特点是将所有发生的事件聚焦在 $B$ 以内，即对于任意 $A\\cap B=\\emptyset$，$P_B(A)=0$。\n乘法公式：当 $P(A_{n-1}\\cdots A_1)\u0026gt;0$ 时， $$ P(A_nA_{n-1}\\cdots A_1)=P(A_n|A_{n-1}A_{n-2}\\cdots A_1)P(A_{n-1}|A_{n-2}\\cdots A_1)\\cdots P(A_2|A_1)P(A_1) $$ 注：对于任意 $1\\leq m\\leq n-1$，$\\bigcap_{i=1}^{n-1}A_i\\subseteq \\bigcap_{i=1}^mA_i$，因此 $P(\\bigcap_{i=1}^{n-1}A_i)\u0026gt;0$ 的条件已经为之后所有的条件概率做好了假设。\n【例】$n$ 个人抽签，求放回/不放回的情况下，第 $k$ 个人抽中的概率。\n解：令 $A_k$ 表示事件“第 $k$ 个人抽中“，则要求 $P(A_k\\overline{A_{k-1}}\\cdots\\overline{A_1})$，根据乘法公式，$P(A_k\\overline{A_{k-1}}\\cdots\\overline{A_1})=P(A_k|\\overline{A_{k-1}}\\cdots\\overline{A_1})P(\\overline{A_{k-1}}|\\overline{A_{k-2}}\\cdots \\overline{A_1})\\cdots P(\\overline{A_2}|\\overline{A_1})P(\\overline{A_1})$。\n(a) 当 $k=1$ 时，$P(A_k)=\\frac{1}{n}$，当 $k\\geq 2$ 时，$P(\\overline{A_1})=\\frac{n-1}{n}$，对于任意 $2\\leq m\\leq k-1$，$P(\\overline{A_m}|\\overline{A_{m-1}}\\cdots\\overline{A_1})=\\frac{n-m}{n-m+1}$，$P(A_k|\\overline{A_{k-1}}\\cdots\\overline{A_1})=\\frac{1}{n-k+1}$，所以 $P=(\\prod_{m=1}^{k-1}\\frac{n-m}{n-m+1})\\frac{1}{n-k+1}=\\frac{1}{n}$\n(b) 当 $k=1$ 时，$P(A_k)=\\frac{1}{n}$，当 $k\\geq 2$ 时，$P(\\overline{A_1})=\\frac{n-1}{n}$，对于任意 $2\\leq m\\leq k-1$，$P(\\overline{A_m}|\\overline{A_{m-1}}\\cdots\\overline{A_1})=\\frac{n-1}{n}$，$P(A_k|\\overline{A_{k-1}}\\cdots\\overline{A_1})=\\frac{1}{n}$，所以 $P=\\left(\\frac{n-1}{n}\\right)^{k-1}\\frac{1}{n}$。\nTotal Probability Formula $\\fbox{Definition 3.2}$ 若事件 $A_1,A_2,\\cdots,A_n$ 满足\n对于任意 $1\\leq i\u0026lt;j\\leq n$，$A_i\\cap A_j=\\emptyset$； $\\bigcup_{i=1}^nA_i=\\Omega$。 则称 $A_1,\\cdots,A_n$ 为 $\\Omega$ 的一个划分/完备事件集。\n$\\fbox{Theorem 3.3}$ (全概率公式) 设 $A_1,\\cdots,A_n$ 为 $\\Omega$ 的一个划分，则 $$ P(B)=\\sum_{i=1}^nP(BA_i)=\\sum_{i=1}^nP(A_i)P(B|A_i)\\upharpoonleft {P(A_i)\u0026gt;0} $$ 其中最后的部分是示性函数 (indicator function)，表示略过 $P(A_i)=0$ 的那些部分的条件概率。\nProof：首先有 $B=B\\Omega=B(\\bigcup_{i=1}^nA_i)=\\bigcup_{i=1}^n(BA_i)$，且 $BA_i$ 彼此互不相容，所以 $$ P(B)=P\\left(\\bigcup_{i=1}^n(BA_i)\\right)\\overset{可列可加性}{=}\\sum_{i=1}^nP(BA_i) \\qquad\\qquad\\qquad \\blacksquare $$\n注：全概率公式对于无限可列的划分仍然成立。\n对于全概率公式的一个感性理解是：如果要计算事件A的概率，我们可以“分类讨论”A在各种情况下发生的概率，再全部加起来。\n对于一个条件概率 $P(B|C)$，我们可以考虑一个划分 $A_1,\\cdots,A_n$ 并将其写为 $P(B|C)=\\sum_{i=1}^nP(BA_i|C)$。若这仍不好算，仍然可以有以下变形： $$ \\sum_{i=1}^nP(BA_i|C)=\\sum_{i=1}^n\\frac{P(BA_iC)}{P(C)}=\\sum_{i=1}^n\\frac{P(A_iC)}{P(C)}P(B|A_iC)\\upharpoonleft {P(A_iC)\u0026gt;0} $$ 我们将条件 $C$ 加强到了条件 $A_iC$，从而可能更容易计算。\n【例】有两批灯泡各10支，第一批有一个次品，第二批有两个次品。运输过程中两批各打碎了一个。现从剩余灯泡中抽取一个，抽到次品的概率是多少？\n解：讨论打碎的两个灯泡的情况：$B_1=(好,好),B_2=(好,次),B_3=(次,好),B_4=(次,次)$。记 $A$ 为抽到次品这个事件 $$ \\begin{align} P(A)\u0026amp;=P(B_1)P(A|B_1)+P(B_2)P(A|B_2)+P(B_3)P(A|B_3)+P(B_4)P(A|B_4)\\\\ \u0026amp;=\\frac{9}{10}\\cdot \\frac{8}{10}\\cdot \\frac{3}{18}+\\frac{9}{10}\\cdot \\frac{2}{10}\\cdot \\frac{2}{18}+\\frac{1}{10}\\cdot \\frac{8}{10}\\cdot \\frac{2}{18}+\\frac{1}{10}\\cdot \\frac{2}{10}\\cdot \\frac{1}{18}\\\\ \u0026amp;=\\frac{3}{20} \\end{align} $$\nBayes Formula 在全概率公式 $P(B)=\\sum_{i=1}^nP(A_i)P(B|A_i)$ 中，$B$ 可以看作发生的结果，$A_i$ 可以看作 $B$ 发生的可能原因。$P(A_i)$ 被称为先验概率，$P(A_i|B)$ 衡量了 $B$ 已经发生的情况下原因发生的可能性，称为后验概率。\n$\\fbox{Theorem 3.4}$ (贝叶斯公式) 设 $A_1,\\cdots,A_n$ 为 $\\Omega$ 的一个划分，对于任意 $1\\leq k\\leq n$，$P(A_k)\u0026gt;0$。则对于 $B\\in \\mathscr F$，我们有 $$ P(A_k|B)=\\frac{P(A_kB)}{P(\\Omega B)}=\\frac{P(A_k)P(B|A_k)}{\\sum_{i=1}^nP(A_i)P(B|A_i)} $$ 【例】有一种罕见病，用某方法来检测时，如果该人患病，那么他被检测出有病的概率是 0.95，如果一个人没有患病，那么他被检测出没病的概率是 0.9，正常人中罕见病发病率为 0.0004。现有一个人检测出有病，他真正有病的概率是多少？\n解：令 $C={某人患罕见病},A={某人被检测出罕见病}$，则 $$ P(C|A)=\\frac{P(C)P(A|C)}{P(C)P(A|C)+P(\\overline{C})P(A|\\overline{C})}=\\frac{0.0004\\cdot 0.95}{0.0004\\cdot 0.95+0.9996\\cdot 0.1}\\approx 0.003 $$\n该概率实际上非常小的原因是：人群中不患病的很多，而不患病情况下的误诊率不够小，这导致有很大概率都是这种情况导致的检测结果异常。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"862c307bfbcb3278bbb2f0145ceb66b6","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec03/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec03/","section":"notes","summary":"Conditional Probability “事件 $A$ 和 $B$ 同时发生的概率”与“ $B$ 发生的条件下，$A$ 发生的概率”不一定相等！\n“事件 $A$ 和 $B$ 同时发生” 是在 $\\Omega$ 中 寻找 $A\\cap B$，$P(A\\cap B)=\\frac{|A\\cap B|}{|\\Omega|}$。 “ $B$ 发生的条件下，$A$ 发生”，样本空间退化为 $B$，$P(A|B)=\\frac{|A\\cap B|}{|B|}$。 $\\fbox{Definition 3.","tags":null,"title":"Lecture 03: Conditional Probability and Bayes Formula","type":"docs"},{"authors":null,"categories":null,"content":"Independence 【例】$a$ 个黑球，$b$ 个白球，分别在有放回、无放回的情况下计算：\n(1) 第一次摸到黑球 (A)，第二次摸到黑球的概率 (B)。\n(2) 第二次摸到黑球的概率。\n容易发现，有放回时，$P(B|A)=P(B)$ (放回后，第二次的实验条件与第一次的结果无关)，无放回时 $P(B|A)\\neq P(B)$。\n$\\fbox{Definition 4.1}$ 称事件 $A$ 和 $B$ 互相独立，若 $P(AB)=P(A)P(B)$ (或者说，$P(B)=P(B|A)$)。\n以下是一些推论：\n$\\emptyset,\\Omega$ 与任意事件独立。\n若 $A,B$ 独立，则 $\\overline{A},B$，$A,\\overline{B}$ ，$\\overline{A},\\overline{B}$ 也独立。\nProof: 第一条：$P(\\overline{A}B)=P(B-BA)=P(B)-P(BA)=P(B)-P(B)P(A)=P(B)(1-P(A))=P(B)P(\\overline{A})$\n容易推得第二，第三条也成立。$\\blacksquare$\n注：事件独立和韦恩图上两个事件没有交集没有任何关系！\n$\\fbox{Definition 4.2}$ (三个事件的独立性) $A,B,C$ 相互独立，若\n$A,B,C$ 两两互相独立。 $P(ABC)=P(A)P(B)P(C)$。 注：这两条并不能互相推出，以下是例子：\n(1) 推不出 (2)：一个正四面体，一面红色 (A)，一面绿色 (B)，一面蓝色 (C)，一面三个颜色都有，讨论向下面的颜色： $P(A)=P(B)=P(C)=2/4=1/2$，$P(AB)=1/4=P(A)P(B)$。 然而 $P(ABC)=1/4\\neq P(A)P(B)P(C)$。 (2) 推不出 (1)：一个正八面体，1,2,3,4面有红色，1,2,3,5面有绿色，1,6,7,8面有蓝色。 $P(A)=P(B)=P(C)=4/8=1/2$，$P(ABC)=1/8=P(A)P(B)P(C)$。 然而 $P(AB)=3/8\\neq P(A)P(B)$。 类似地可以定义 $n$ 个事件的独立性：对于事件 $A_1,\\cdots,A_n$，令 $I$ 为指标集，则它们独立当且仅当对于任意 $S\\subseteq I$，有 $P(\\bigcap_{\\alpha\\in S}A_\\alpha)=\\prod_{\\alpha\\in S}P(A_\\alpha)$。\n$\\fbox{Theorem 4.3}$ 若事件 $A_1,\\cdots, A_n$ 互相独立，那么考虑事件集的任意一个划分，每个组里的事件做任意运算的结果与别组的结果也互相独立。\n$\\fbox{Theorem 4.4}$ 若 $A_1,\\cdots, A_n$ 相互独立，则 $P(\\bigcup_{k=1}^nA_k)=1-\\prod_{k=1}^nP(\\overline{A_k})$。\n证明：$P(\\bigcup_{k=1}^nA_k)=1-P(\\overline{\\bigcup_{k=1}^nA_k})=1-P(\\bigcap_{k=1}^n\\overline{A_k})=1-\\prod_{k=1}^nP(\\overline{A_k})$。$\\blacksquare$\nBernoulli Experiments $\\fbox{Definition 4.5}$ 若一个独立重复试验满足\n每个事件只有两个结果：$A$ 和 $\\overline{A}$，$P(A)=p,P(\\overline(A))=1-p$。 试验可重复，每两次试验之间互相独立。 则 $n$ 次上述实验称为 $n$ 重伯努利试验 (Bernoulli Experiment)。\n$\\fbox{Theorem 4.6}$ 伯努利试验中，记 $P_n(k)$ 为 $A$ 发生 $k$ 次的概率，则 $P_n(k)=\\binom{n}{k}p^k(1-p)^{n-k}$。\n【例】 (简单随机游走 simple random walk) 一个粒子从0出发在整数数轴上运动，每次向右移动的概率为 $p$，求跳 $n$ 次后位于 $k$ 的概率。\n解：以下只讨论 $k\\geq 0$ 的情况： $$ P(n,k)= \\begin{cases} 0\u0026amp;, k\u0026gt;n\\\\ 0\u0026amp;, n与k奇偶性不同\\\\ \\binom{n}{(n+k)/2}p^{(n+k)/2}(1-p)^{(n-k)/2}\u0026amp;，otherwise \\end{cases} $$\n$\\fbox{Theorem 4.7}$ (泊松定理, Poisson) 若 $np_n=\\lambda$，则对于固定的 $k$， $$ \\lim_{n\\rightarrow \\infty} \\binom{n}{k}p_n^k(1-p_n)^{n-k}=\\frac{\\lambda^k}{k!}e^{-\\lambda} $$ 证明： $$ \\begin{align} \\lim_{n\\rightarrow \\infty}\\binom{n}{k}p_n^k(1-p_n)^{n-k}\u0026amp;=\\lim_{n\\rightarrow \\infty}\\frac{n(n-1)\\cdots (n-k+1)}{k!}(\\frac{\\lambda}{n})^k(1-\\frac{\\lambda}{n})^{n-k}\\\\ \u0026amp;=\\lim_{n\\rightarrow \\infty}\\frac{\\lambda^k}{k!}\\cdot 1(1-\\frac{1}{n})(1-\\frac{2}{n})\\cdots (1-\\frac{k-1}{n})(1-\\frac{\\lambda}{n})^n(1-\\frac{\\lambda}{n})^{-k}\\\\ \u0026amp;=\\lim_{n\\rightarrow \\infty}\\frac{\\lambda^k}{k!}(1-\\frac{\\lambda}{n})^n\\\\ \u0026amp;=\\frac{\\lambda^k}{k!}\\left[\\lim_{n\\rightarrow \\infty}(1+\\frac{-\\lambda}{n})^{\\frac{n}{-\\lambda}}\\right]^{-\\lambda}\\\\ \u0026amp;=\\frac{\\lambda^k}{k!}e^{-\\lambda} \\end{align} $$\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"5de02205838af2c574f2297e8ae89f81","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec04/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec04/","section":"notes","summary":"Independence 【例】$a$ 个黑球，$b$ 个白球，分别在有放回、无放回的情况下计算：\n(1) 第一次摸到黑球 (A)，第二次摸到黑球的概率 (B)。\n(2) 第二次摸到黑球的概率。\n容易发现，有放回时，$P(B|A)=P(B)$ (放回后，第二次的实验条件与第一次的结果无关)，无放回时 $P(B|A)\\neq P(B)$。\n$\\fbox{Definition 4.1}$ 称事件 $A$ 和 $B$ 互相独立，若 $P(AB)=P(A)P(B)$ (或者说，$P(B)=P(B|A)$)。\n以下是一些推论：\n$\\emptyset,\\Omega$ 与任意事件独立。\n若 $A,B$ 独立，则 $\\overline{A},B$，$A,\\overline{B}$ ，$\\overline{A},\\overline{B}$ 也独立。","tags":null,"title":"Lecture 04: Independence and Bernoulli Experiments","type":"docs"},{"authors":null,"categories":null,"content":"Definitions $\\fbox{Definition 5.1}$ 设 $X:\\Omega \\rightarrow \\mathbb{R}$，且对于任意 $\\mathbb{R}$ 中的 Borel 集 $B$，$\\{e|X(e)\\in B\\}\\in \\mathscr{F}$，则称 $X$ 是 $(\\Omega, \\mathscr F, P)$ 上的随机变量。\n注：1. Borel 集是由所有的 $\\{(a,b]|-\\infty\\leq a,b\\leq +\\infty\\}$ 经过可数次交或并得到的集合。\n​\t2. 在大部分场合，只需关注 $X$ 是从 $\\Omega$ 到 $\\mathbb{R}$ 上的映射即可。\n【例】示性随机变量 (indicator)，对于 $A\\in \\mathscr{F}$，定义 $X_A(e)=\\begin{cases}1,e\\in A\\\\0, e\\notin A\\end{cases}$。\n$\\fbox{Definition 5.2}$ 设 $X$ 是随机变量，则称 $F_X(x)\\triangleq P(X\\leq x)$ 为 $X$ 的分布函数。\n分布函数满足以下性质：\n单调不降。\n对于 $x_1\u0026lt;x_2$，$F(x_2)-F(x_1)=P(x_1\u0026lt;x\\leq x_2)\\geq 0$。\n$\\lim_{x\\rightarrow +\\infty}F(x)=1,\\lim_{x\\rightarrow -\\infty}F(x)=0$。\nLemma (单调收敛定理) 当被积函数单调递增时，积分和极限可以换序。\n${X\\leq x}\\overset{x\\rightarrow +\\infty}{\\longrightarrow}\\Omega$，$lim_{x\\rightarrow \\infty}P(X\\leq x)\\overset{lemma}{=}P(\\lim_{x\\rightarrow \\infty}{X\\leq x})=P(\\Omega)=1$。\n$F$ 右连续且存在左极限 (càdlàg, RCLL)，i.e. $\\lim_{x\\rightarrow x_0^+}F(x)=F(x_0)$，$F(x_0-0)$ 存在。\n$F(x)-F(x_0)=P(X\\leq x)-P(X\\leq x_0)=P(x_0\u0026lt;X\\leq x)\\overset{x\\rightarrow x_0^+}{\\longrightarrow}P(\\emptyset)=0$。\n$x\u0026lt;x_0$ 时，$F(x)\\leq F(x_0)$ 且 $F(x)$ 单增，所以左极限存在。\n注：左不一定连续的原因是：$F(x_0)-F(x)=P(x\u0026lt;X\\leq x_0)\\overset{x\\rightarrow x_0^-}{\\longrightarrow}P(X=x_0)$ 不一定为 0。\n$\\fbox{Theorem 5.3}$ 如果一个函数 $F$ 满足上述三条性质，那么它必然是某个随机变量 $X$ 的分布函数。\nDiscrete Random Variable $\\fbox{Definition 5.4}$ 若随机变量 $X$ 的取值为有限多个或无限可数个，则 $X$ 为离散随机变量。设 $X$ 的取值为 $x_1,x_2,\\cdots $，令 $P(x=x_k)=P_k$，称 ${P_k}$ 为 $X$ 的分布列/分布律。\n注：$F(x)=P(X\\leq x)=P(\\bigcup_{x_k\\leq x}P_k)=\\sum_{x_k\\leq x}P_k$。\nCommon Distributions 【例】 (0-1分布) 设 $A\\in \\mathscr{F}$，$P(A)=p\\in(0,1)$。令 $X_A$ 为 $A$ 的 indicator，则 $P(X_A=1)=P(A)=p,P(X_A=0)=1-p$。\n【例】 (二项分布) 设 $X$ 的分布律为 $p_k=P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k},p\\in (0,1)$，$p_k$ 即为 $n$ 重 Bernoulli 试验成功 $k$ 次的概率，$X$ 服从二项分布，记为 $X\\sim B(n,p)$。\n【例】 (泊松分布) 设 $X$ 的分布律为 $p_k=P(X=k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}$，则称 $X$ 服从泊松分布，记为 $X\\sim P(\\lambda)$。\n$$ \\sum_{k=0}^\\infty \\frac{\\lambda^k}{k!}e^{-\\lambda}=e^{-\\lambda}\\sum_{k=0}^\\infty \\frac{\\lambda^k}{k!}\\overset{Taylor\\space Series}{=}e^{-\\lambda}e^\\lambda=1 $$\n注：在 $\\lambda=np_n$ 固定的情况下，当 $n$ 很大时，$p_n$ 则很小。那么在 $k\u0026laquo;n$ 的情况下，二项分布可以近似为泊松分布。\n【例】 (几何分布) 独立重复试验，成功概率为 $p$，记第 $k$ 次试验首次成功的概率为 $p_k=P(X=k)=(1-p)^{k-1}p$，则 $X$ 服从几何分布，记为 $X\\sim g(p)$。\n$$ \\sum_{k=1}^\\infty (1-p)^{k-1}p=p\\sum_{k=0}^\\infty(1-p)^k=p\\cdot\\frac{1}{1-(1-p)}=p\\cdot \\frac{1}{p}=1 $$\n几何分布没有记忆性。假设前 $t$ 次试验均失败，则再试 $s$ 次成功的概率 $P(X=t+s|X\u0026gt;t)=P(X=s)$。或者：$P(X\\geq t+s|x\u0026gt;t)=\\sum_{k=s}^\\infty P(X=t+k|X\u0026gt;t)=\\sum_{k=s}^\\infty P(X=k)=P(X\\geq s)$。\n【例】 (巴斯卡分布) 独立重复试验，每次成功概率为 $p$，记做完第 $k$ 次试验后恰好取得了 $r$ 次成功 $(k\\geq r)$ 的概率为 $p_k$，有 $$ p_k=P(X=k)=\\binom{k-1}{r-1}p^r(1-p)^{k-r} $$ 我们称 $X$ 服从巴斯卡分布 ($r=1$ 时的巴斯卡分布就是几何分布)。\n$$ \\sum_{k=r}^\\infty p_k=\\sum_{k=r}^\\infty \\binom{k-1}{r-1}p^r(1-p)^{k-r}=p^r\\sum_{k=r}^\\infty \\binom{k-1}{r-1}(1-p)^{k-r} $$\n令 $q=1-p$，只要证 $\\sum_{k=r}^\\infty \\binom{k-1}{r-1}q^{k-r}=(1-q)^{-r}$。对 $f(x)=(1-x)^{-r}$ 泰勒展开， $$ \\begin{align} f(x)=(1-x)^{-r}\u0026amp;=\\sum_{k=0}^\\infty \\frac{f^{(k)}(0)}{k!}x^k\\\\ \u0026amp;=\\sum_{k=0}^\\infty\\frac{1}{k!}(-1)^k(-r)(-r-1)\\cdots (-r-k+1)x^k\\\\ \u0026amp;=\\sum_{k=0}^\\infty\\frac{1}{k!}r(r+1)\\cdots (r+k-1)x^k\\\\ \u0026amp;=\\sum_{k=0}^\\infty\\frac{(r+k-1)!}{k!(r-1)!}x^k\\\\ \u0026amp;=\\sum_{k=0}^\\infty\\binom{r+k-1}{k}x^k\\\\ \u0026amp;=\\sum_{k=r}^\\infty\\binom{k-1}{r-1}x^{k-r} \\end{align} $$\n【例】 (超几何分布) 对 $N$ 个产品无放回抽样 $n$ 次，其中有 $M$ 个次品，令抽到 $k$ 个次品的概率为 $p_k$，则 $$ p_k=P(X=k)=\\frac{\\binom{M}{k}\\binom{N-M}{n-k}}{\\binom{N}{n}} $$ 我们称 $X$ 服从超几何分布。\n$$ \\sum_{k=0}^\\infty p_k=\\frac{1}{\\binom{N}{n}}\\sum_{k=max(0,n-(N-M))}^{min(n,M)} \\binom{M}{k}\\binom{N-M}{n-k} $$\n右边的部分用“讲故事法”容易证明等于 $\\binom{N}{n}$。如果需要比较数学的方法，可以从 $(1+x)^N$ 和 $(1+x)^M(1+x)^{N-M}$ 两个角度去考察 $x^n$ 前的系数。\n注：当 $N,N-M\u0026raquo;n\\geq k$ 时，超几何分布可以近似地当作二项分布计算： $$ \\begin{align} \\frac{\\binom{M}{k}\\binom{N-M}{n-k}}{\\binom{N}{n}}\u0026amp;=\\frac{n!}{k!(n-k)!}\\frac{M(M-1)\\cdots (M-k+1)}{N(N-1)\\cdots (N-k+1)}\\frac{(N-M)\\cdots (N-M-(n-k)+1)}{(N-k)\\cdots (N-k-(n-k)+1)}\\\\ \u0026amp;\\approx \\binom{n}{k}\\left(\\frac{M}{N}\\right)^k\\left(\\frac{N-M}{N}\\right)^{n-k} \\end{align} $$\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"6de58b27325c3621f55ddda1917755c7","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec05/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec05/","section":"notes","summary":"Definitions $\\fbox{Definition 5.1}$ 设 $X:\\Omega \\rightarrow \\mathbb{R}$，且对于任意 $\\mathbb{R}$ 中的 Borel 集 $B$，$\\{e|X(e)\\in B\\}\\in \\mathscr{F}$，则称 $X$ 是 $(\\Omega, \\mathscr F, P)$ 上的随机变量。\n注：1. Borel 集是由所有的 $\\{(a,b]|-\\infty\\leq a,b\\leq +\\infty\\}$ 经过可数次交或并得到的集合。\n​\t2. 在大部分场合，只需关注 $X$ 是从 $\\Omega$ 到 $\\mathbb{R}$ 上的映射即可。","tags":null,"title":"Lecture 05: Random Variable and Distribution Function","type":"docs"},{"authors":null,"categories":null,"content":"$\\fbox{Definition 6.1}$ 设存在一个非负的可积函数 $p(x)$，若 $X$ 的分布函数 $F(x)=\\int_{-\\infty}^xp(u)du$，则称 $X$ 为连续型随机变量，$p(x)$ 为密度函数。\n根据定义，我们可以得到 $$ \\begin{align} P(X\\leq a)\u0026amp;=F(a)=\\int_{-\\infty}^ap(x)dx\\\\ P(a\u0026lt;X\\leq b)\u0026amp;=F(b)-F(a)=\\int_a^b p(x)dx \\end{align} $$ 一些注意点：\n$F(x)$ 连续。\n显然 $p(x)$ 有界，设 $p(x)\\leq M\u0026lt;+\\infty$，对于固定的 $x_0$， $$ |F(x)-F(x_0)|=\\left|\\int_{x_0}^xp(u)d(u)\\right|\\leq \\int_{x_0}^x |p(u)|du\\leq |x-x_0|M $$ $\\forall \\varepsilon\u0026gt;0$，当 $|x-x_0|\\leq \\frac{\\varepsilon}{M}$ 时，$|F(x)-F(x_0)|\\leq \\varepsilon$。\n$p(x)$ 并不能表示 $P(X=x)$。事实上对于任意 $x_0$，$P(X=x_0)=0$。$p(x)$ 只能理解为 $X$ 在 $x$ 的一个小邻域内的概率与该邻域的长度的近似比，即 $$ P(x\u0026lt;X\\leq x+ \\Delta x)=\\int_{x}^{x+\\Delta x}p(u)du\\approx p(x)\\Delta x $$ 关于 $P(X=x_0)=0$ 的说明： $$ 0\\leq P(X=x_0)\\leq P(x_0-\\Delta x\u0026lt;X\\leq x_0)=F(x_0)-F(x_0-\\Delta x)\\overset{\\Delta x\\rightarrow 0}{\\longrightarrow} 0 $$\n若 $p(x)$ 在 $x_0$ 连续，则 $F(x)$ 在 $x_0$ 处可导，且 $F\u0026rsquo;(x_0)=p(x_0)$。\n$$ \\begin{align} F(x)-F(x_0)\u0026amp;=\\int_{x_0}^x p(u)du\\\\ \u0026amp;=\\int_{x_0}^x(p(u)-p(x_0))du+\\int_{x_0}^xp(x_0)du\\\\ \u0026amp;=\\int_{x_0}^x(p(u)-p(x_0))du+p(x_0)(x-x_0) \\end{align} $$\n于是 $$ \\left|\\frac{F(x)-F(x_0)}{x-x_0}-p(x_0)\\right|\\leq \\frac{1}{|x-x_0|}\\int_{x_0}^x|p(u)-p(x_0)|du\\quad (*) $$ $\\forall \\varepsilon\u0026gt; 0,\\exists \\delta,|x-x_0|\u0026lt;\\delta \\Rightarrow |p(u)-p(x_0)|\u0026lt;\\varepsilon \\Rightarrow (*)\\leq \\frac{1}{|x-x_0|}\\cdot \\varepsilon |x-x_0|=\\varepsilon$。\n【例】 (均匀分布) $[a,b]$ 的均匀分布 $U[a,b]$ 中，$X$ 的密度函数和分布函数为 $$ \\begin{align} p(x)\u0026amp;=\\begin{cases}\\frac{1}{b-a}\u0026amp;,a\\leq x\\leq b\\\\0\u0026amp;, otherwise\\end{cases}\\\\ F(x)\u0026amp;=\\begin{cases}0\u0026amp;,x\u0026lt;a\\\\\\int_a^x\\frac{du}{b-a}=\\frac{x-a}{b-a}\u0026amp;,a\\leq x\\leq b\\\\1\u0026amp;,x\u0026gt;b\\end{cases} \\end{align} $$ 【例】 (正态分布) $X$ 服从正态分布，记为 $X\\sim N(\\mu, \\sigma^2)$ ，若 $$ p(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}，-\\infty\u0026lt;x\u0026lt;\\infty $$\n$$ \\begin{align} \\left(\\int_{-\\infty}^{+\\infty}p(x)dx\\right)^2\u0026amp;=\\left(\\int_{-\\infty}^{+\\infty}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}dx\\right)\\left(\\int_{-\\infty}^{+\\infty}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}}dy\\right)\\\\ \u0026amp;\\overset{u=\\frac{x-\\mu}{\\sigma},v=\\frac{y-\\mu}{\\sigma}}{=} \\frac{1}{2\\pi}\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}e^{-\\frac{u^2+v^2}{2}}dudv\\\\ \u0026amp;\\overset{u=r\\cos \\theta,v=r\\sin \\theta}{=} \\frac{1}{2\\pi}\\int_0^{2\\pi}\\int_{0}^{+\\infty}e^{-\\frac{r^2}{2}}rdrd\\theta\\\\ \u0026amp;=1 \\end{align} $$\n正态分布 $p(x)$ 的图像有以下性质：\n$p(x)$ 关于 $x=\\mu$ 轴对称。$F(\\mu-a)+F(\\mu+a)=1$。 $\\sigma^2$ 越大，$p(x)$ 的图像越平。(最大值变小，两头变高，方差 $\\uparrow$) 当 $\\mu=0,\\sigma=1$ 时，$X$ 称为标准正态分布： $$ \\begin{align} \\varphi(x)\u0026amp;=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}\\\\ \\Phi(x)\u0026amp;=\\int_{-\\infty}^x\\varphi(u)du \\end{align} $$ $\\fbox{Theorem 6.2}$ 设 $X\\sim N(\\mu, \\sigma^2)$，则 $Z=\\frac{X-\\mu}{\\sigma}\\sim N(0,1)$。\n$$ \\begin{align} F_Z(x)\u0026amp;=P(\\frac{X-\\mu}{\\sigma}\\leq x)=P(X\\leq \\sigma x+\\mu)\\\\ \u0026amp;=\\int_{-\\infty}^{\\sigma x+\\mu}\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(v-\\mu)^2}{2\\sigma^2}}dv\\\\ \u0026amp;\\overset{\\frac{v-\\mu}{\\sigma}=z}{=}\\int_{-\\infty}^x\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{z^2}{2}}d(\\sigma z+\\mu)\\\\ \u0026amp;=\\int_{-\\infty}^x\\varphi(u)du \\end{align} $$\n利用该定理，我们可以将所有的正态分布转换为标准正态分布的计算： $$ P(X\\leq a)=P\\left(\\frac{X-\\mu}{\\sigma}\\leq \\frac{a-\\mu}{\\sigma}\\right)=\\Phi\\left(\\frac{a-\\mu}{\\sigma}\\right)\\\\ P(a\u0026lt;X\\leq b)=\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right)-\\Phi\\left(\\frac{a-\\mu}{\\sigma}\\right) $$\n\u0026ldquo;3-$\\sigma$\u0026rdquo; 准则： $$ \\begin{align} P(|X-\\mu|\\leq \\sigma)\u0026amp;=\\Phi(1)-\\Phi(-1)\\approx 0.6826\\\\ P(|X-\\mu|\\leq 2\\sigma)\u0026amp;\\approx 0.9544\\\\ P(|X-\\mu|\\leq 3\\sigma)\u0026amp;\\approx 0.9974 \\end{align} $$\n当某个样本超过均值三个标准差以上时，可以怀疑它存在一些问题。\n$\\fbox{Theorem 6.3}$ $$ (\\frac{1}{x}-\\frac{1}{x^3})\\varphi(x)\\leq 1-\\Phi(x)\\leq \\frac{1}{x}\\varphi(x) $$ 且当 $x$ 充分大时，$1-\\Phi(x)\\approx \\frac{1}{x}\\varphi(x)$。\n【例】 (指数分布) 称 $X$ 服从参数为 $\\lambda(\\lambda \u0026gt; 0)$ 的指数分布，记为 $X\\sim E(\\lambda)$，若 $$ \\begin{align} p(x)\u0026amp;=\\begin{cases} \\lambda e^{-\\lambda x}\u0026amp;,x\\geq 0\\\\ 0\u0026amp;, x\u0026lt;0 \\end{cases}\\\\ F(x)\u0026amp;=\\begin{cases} \\int_0^x \\lambda e^{-\\lambda u}du=1-e^{-\\lambda x}\u0026amp;, x\u0026gt;0\\\\ 0\u0026amp;, x\u0026lt;0 \\end{cases} \\end{align} $$ 注：指数分布具有无记忆性，i.e. $P(X\u0026gt;s+t|x\u0026gt;t)=P(X\u0026gt;s)$。指数分布和几何分布是唯二具有无记忆性的分布。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"e51bbabbc6076ef72be701594e2ef10c","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec06/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec06/","section":"notes","summary":"$\\fbox{Definition 6.1}$ 设存在一个非负的可积函数 $p(x)$，若 $X$ 的分布函数 $F(x)=\\int_{-\\infty}^xp(u)du$，则称 $X$ 为连续型随机变量，$p(x)$ 为密度函数。\n根据定义，我们可以得到 $$ \\begin{align} P(X\\leq a)\u0026amp;=F(a)=\\int_{-\\infty}^ap(x)dx\\\\ P(a\u0026lt;X\\leq b)\u0026amp;=F(b)-F(a)=\\int_a^b p(x)dx \\end{align} $$ 一些注意点：\n$F(x)$ 连续。\n显然 $p(x)$ 有界，设 $p(x)\\leq M\u0026lt;+\\infty$，对于固定的 $x_0$， $$ |F(x)-F(x_0)|=\\left|\\int_{x_0}^xp(u)d(u)\\right|\\leq \\int_{x_0}^x |p(u)|du\\leq |x-x_0|M $$ $\\forall \\varepsilon\u0026gt;0$，当 $|x-x_0|\\leq \\frac{\\varepsilon}{M}$ 时，$|F(x)-F(x_0)|\\leq \\varepsilon$。","tags":null,"title":"Lecture 06: Continuous Random Variables","type":"docs"},{"authors":null,"categories":null,"content":"设 $X$ 是一个随机变量，函数 $g(x):\\mathbb R\\rightarrow \\mathbb{R}$。构造随机变量 $Y$，当 $X=x$ 时，$Y=g(x)$，称 $Y$ 是 $X$ 的函数，记为 $Y=g(X)$。在已知 $X$ 的分布时，我们希望求出 $Y$ 的分布。\nDiscrete Situation 设 $X$ 是一个离散型随机变量，其分布律为\n$x_1$ $x_2$ $\\cdots$ $x_k$ $\\cdots$ $p_1$ $p_2$ $\\cdots$ $p_k$ $\\cdots$ 那么 $Y\\in {g(x_k)}_{k=1}^n$，去重后可以写成 ${y_1,y_2,\\cdots,y_k,\\cdots}$，显然 $Y$ 也是离散型随机变量。\n考虑 $P(Y=y)=P(g(X)=y)=P(x\\in{x|g(x)=y})$，由可列可加性可知 $P(Y=y)=\\sum_{x:g(x)=y}P(X=x)$。\n【例】$X$ 是离散型随机变量，$P(X=0)=0$，对于任意 $k\\in \\mathbb{N}$，$P(X=k)=P(X=-k)=p^k$。求 $Y=X^2$ 的分布律。\n解：首先解出 $p$：$\\sum_{k=1}^\\infty P(X=\\pm k)=\\sum_{k=1}^\\infty 2P(X=k)=2\\sum_{k=1}^\\infty p^k=1$，解得 $p=\\frac{1}{3}$。\n显然 $Y$ 的取值只能是正整数。对于任意 $n\\in \\mathbb{N}$，有 $$ P(Y=n)=P(X^2=n)=P(X=\\pm \\sqrt{n})=\\begin{cases}2(\\frac{1}{3})^{\\sqrt{n}}\u0026amp;, \\sqrt n\\in \\mathbb{N}\\\\0\u0026amp;, otherwise\\end{cases} $$\n注：可以看出即使 $P(X=k)\\neq P(X=-k)$，只要 $P(X=\\pm k)=2p^k$，$Y$ 的分布就是上述结果。也就是说，随机变量的分布和随机变量函数的分布并不是一一映射。\nContinuous Situation 设 $X$ 为连续型随机变量，$y=g(x)$ 为连续函数，$Y=g(X)$，一般地，可如下求 $Y$ 的分布函数 $F_Y(y)$ 和密度函数 $P_Y(y)$： $$ F_Y(y)=P(Y\\leq y)=P(g(X)\\leq y)=P(x\\in {x|g(x)\\leq y})=\\int_{x:g(x)\\leq y} p_X(x)dx $$ 最后的积分式含参数 $y$，结果是关于 $y$ 的表达式。若 $F_Y(y)$ 可导，则 $p_Y(y)=F_Y\u0026rsquo;(y)$。\n【例】$X\\sim N(0,1)$，求 $Y=X^2$ 的分布。\n解：注意到 $Y\\geq 0$，所以对于任意 $y\u0026lt;0$，$F_y(y)=0$。\n对于 $y\\geq 0$，有 $$ F_Y(y)=P(Y\\leq y)=P(X^2\\leq y)=P(-\\sqrt{y}\\leq X\\leq \\sqrt{y})=F_X(\\sqrt{y})-F_X(-\\sqrt{y}) $$ 欲求 $p_Y(y)$，我们要对 $F_Y(y)$ 求导，注意使用链式法则： $$ \\begin{align} P_Y(y)\u0026amp;=F_Y\u0026rsquo;(y)=F_X\u0026rsquo;(\\sqrt{y})-F_X\u0026rsquo;(-\\sqrt{y})\\\\ \u0026amp;=p_X(\\sqrt{y})\\frac{1}{2\\sqrt{y}}-p_X(-\\sqrt{y})\\frac{-1}{2\\sqrt{y}}\\\\ \u0026amp;=\\frac{1}{\\sqrt{y}}p_X(\\sqrt{y})=\\frac{1}{\\sqrt{2\\pi y}}e^{-\\frac{y}{2}} \\end{align} $$ 综上， $$ p_Y(y)=\\begin{cases}\\frac{1}{\\sqrt{2\\pi y}}e^{-\\frac{y}{2}}\u0026amp;,y\\geq 0\\\\0\u0026amp;,y\u0026lt;0\\end{cases} $$\n注：$Y=X^2$ 称为服从一个自由度的 $\\chi^2$ 分布。$\\chi^2$ 分布是统计学中的一个重要分布。\n上述做法需要先计算 $F_Y(y)$ 再求导计算 $p_Y(y)$。若 $y=g(x)$ 严格单调，则对 $g(x)$ 加以一些可导条件，可以直接计算密度函数 $p_Y(y)$。\n$\\fbox{Theorem 7.1}$ 设 $X$ 为连续型随机变量，密度函数为 $p_X(x)$。设 $y=g(x)$ 严格单调处处可导且恒有 $g\u0026rsquo;(x)\u0026gt;0$ 或 $g\u0026rsquo;(x)\u0026lt;0$，则 $Y=g(X)$ 也为连续型随机变量，且 $$ p_Y(y)=\\begin{cases} p_X(g^{-1}(y))\\cdot \\left|(g^{-1}(y))\u0026rsquo;\\right|\u0026amp;,Y可取到y\\\\ 0\u0026amp;,Y取不到y \\end{cases} $$ 其中 $g^{-1}(y)$ 是 $g(x)$ 的反函数。\n注：当 $g(x)$ 单调且 $g\u0026rsquo;(x_0)$ 存在非零，可以证明 $g^{-1}(y)$ 在 $y_0=g(x_0)$ 处可导。但即使严格单调，$g\u0026rsquo;(x)$ 仍可能在某个 $x_0$ 取到 0 (如 $f(x)=x^3$ 的 $x=0$ 处)，此时 $g^{-1}(y)$ 在 $y_0=g(x_0)$ 处的可导性存在问题，故要求 $g\u0026rsquo;(x)$ 不能取 0。\n证明：这里仅证单调递增的情况，单调递减大同小异 (最终使结论添上绝对值)： $$ F_Y(y_0)=P(Y\\leq y_0)=P(g(X)\\leq y_0)=\\int_{-\\infty}^{g^{-1}(y_0)}p_X(x)dx $$ 作变量替换 $x=g^{-1}(y)$： $$ F_Y(y_0)=\\int_{-\\infty}^{y_0}p_X(g^{-1}(y))dg^{-1}(y)=\\int_{-\\infty}^{y_0}p_X(g^{-1}(y))(g^{-1}(y))\u0026lsquo;dy $$ 根据微积分基本定理， $$ p_Y(y_0)=F_Y\u0026rsquo;(y_0)=p_X(g^{-1}(y_0))(g^{-1}(y_0))\u0026rsquo; $$\n【例】$X\\sim N(\\mu, \\sigma^2)$，$Z=\\frac{X-\\mu}{\\sigma}$，即 $g(x)=\\frac{x-\\mu}{\\sigma}$，$Z=g(X)$。求 $Z$ 的分布。\n解：显然 $g(x)$ 单调递增，且 $g\u0026rsquo;(x)=\\frac{1}{\\sigma}\u0026gt;0$。$g^{-1}(z)=\\sigma z+\\mu$。 $$ \\begin{align} p_Z(z)\u0026amp;=p_X(g^{-1}(z))\\left|(g^{-1}(z))\u0026rsquo;\\right|=p_X(\\sigma z+\\mu)\\cdot \\sigma\\\\ \u0026amp;=\\sigma\\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(\\sigma z+\\mu-\\mu)^2}{2\\sigma^2}}\\\\ \u0026amp;=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}} \\end{align} $$ 即 $Z\\sim N(0,1)$。\n【例】若 $X$ 服从 $\\left(-\\frac{\\pi}{2},\\frac{\\pi}{2}\\right)$ 上的均匀分布，$Y=\\tan X$，求 $Y$ 的分布。\n解：$y=g(x)=\\tan x$，$x=g^{-1}(y)=\\arctan y$，$(\\arctan y)\u0026rsquo;=\\frac{1}{1+y^2}$。于是 $$ \\begin{align} p_Y(y)\u0026amp;=p_X(\\arctan y)\\cdot \\left|\\frac{1}{1+y^2}\\right|\\\\ \u0026amp;= \\frac{1}{\\pi}\\cdot \\frac{1}{1+y^2} \\end{align} $$\n注：$Y$ 的分布称为柯西分布。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"78e716fdb372f8383846ad165cd2dae0","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec07/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec07/","section":"notes","summary":"设 $X$ 是一个随机变量，函数 $g(x):\\mathbb R\\rightarrow \\mathbb{R}$。构造随机变量 $Y$，当 $X=x$ 时，$Y=g(x)$，称 $Y$ 是 $X$ 的函数，记为 $Y=g(X)$。在已知 $X$ 的分布时，我们希望求出 $Y$ 的分布。\nDiscrete Situation 设 $X$ 是一个离散型随机变量，其分布律为\n$x_1$ $x_2$ $\\cdots$ $x_k$ $\\cdots$ $p_1$ $p_2$ $\\cdots$ $p_k$ $\\cdots$ 那么 $Y\\in {g(x_k)}_{k=1}^n$，去重后可以写成 ${y_1,y_2,\\cdots,y_k,\\cdots}$，显然 $Y$ 也是离散型随机变量。","tags":null,"title":"Lecture 07: Distribution of Random Variable Function","type":"docs"},{"authors":null,"categories":null,"content":"Distribution Function of 2-Dimensional Random Variable $\\fbox{Definition 8.1}$ 设 $X,Y$ 是定义在 $(\\Omega, \\mathscr F, P)$ 上的随机变量，则称 $(X,Y)$ 为 $(\\Omega, \\mathscr F, P)$ 上的二维随机变量。对于任意 $x,y\\in \\mathbb R$，称 $$ F(x,y)=P({X\\leq x}\\cap {Y\\leq y})=P(X\\leq x,Y\\leq y) $$ 为 $(X,Y)$ 的 (联合) 分布函数。\n注：从图像上来看，$F(x_0,y_0)$ 即为落在点 $(x_0,y_0)$ 左下方无穷矩形的概率。\n$F(x,y)$ 的若干性质：\n固定 $x_0$，$F(x_0,y)$ 单调不减；固定 $y_0$，$F(x,y_0)$ 单调不减。\n(推论：$\\forall x_1\u0026gt;x_2,y_1\u0026gt;y_2,F(x_1,y_1)\\geq F(x_2,y_2)$。)\n固定 $x_0$，$\\lim_{y\\rightarrow -\\infty}F(x_0,y)=F(x_0,-\\infty)=0$，类似可得 $F(-\\infty,-\\infty)=0,F(+\\infty,+\\infty)=1$。\n固定 $x_0$，$F(x_0,y)$ 处处有左极限且右连续 (càdlàg)，固定 $y_0$ 时亦然。\n$\\forall x_1\u0026gt;x_2,y_1\u0026gt;y_2,F(x_1,y_1)-F(x_1,y_2)-F(x_2,y_1)+F(x_2,y_2)\\geq 0$。\n注：上述性质也是一个函数是某个 $(X,Y)$ 的分布函数的充分条件。\n$\\fbox{Definition 8.2}$ 给定 $(X,Y)$，$X$ 或 $Y$ 的分布函数称为边缘概率。\n在 $F(x,y)$ 已知的情况下，边缘概率可以直接求出： $$ F_X(x)=P(X\\leq x)=P(X\\leq x,Y\\in \\mathbb{R})=\\lim_{y\\rightarrow +\\infty}F(x,y) $$ $\\fbox{Definition 8.3}$ 设随机变量 $X,Y$ 满足对于任意 $x,y\\in \\mathbb{R}$，${X\\leq x}$ 与 ${Y\\leq y}$ 独立，即 $P(X\\leq x,Y\\leq y)=P(X\\leq x)P(Y\\leq y), F(x,y)=F_X(x)F_Y(y)$，则称 $X,Y$ 相互独立。\n注：虽然上述定义只对一部分事件的独立性进行了描述，但更复杂的事件的情形也是可以推出的：\n$$ \\begin{align} P(x_1\u0026lt;X\\leq x_2,y_1\u0026lt;Y\\leq y_2)\u0026amp;= F(x_2,y_2)-F(x_2,y_1)-F(x_1,y_2)+F(x_1,y_1)\\\\ \u0026amp;=F_X(x_2)F_Y(y_2)-F_X(x_2)F_Y(y_1)-F_X(x_1)F_Y(y_2)+F_x(x_1)F_Y(y_1)\\\\ \u0026amp;=(F_X(x_2)-F_X(x_1))(F_Y(y_2)-F_Y(y_1))\\\\ \u0026amp;=P(x_1\u0026lt;X\\leq x_2)P(y_1\u0026lt;Y\\leq Y_2) \\end{align} $$\n设 $I_n,J_m$ 是两列左开右闭区间，且 $\\forall n\\leq k,I_n\\cap I_k=\\emptyset,J_n\\cap J_k=\\emptyset$，那么 $$ \\begin{align} P(X\\in \\bigcup_{n=1}^\\infty I_n,Y\\in \\bigcup_{m=1}^\\infty J_m)\u0026amp;=P(\\bigcup_{n=1}^\\infty \\bigcup_{m=1}^\\infty {X\\in I_n, Y\\in J_m})\\\\ \u0026amp;\\overset{可列可加性}{=}\\sum_{n=1}^\\infty \\sum_{m=1}^\\infty P(X\\in I_n,Y\\in J_m)\\\\ \u0026amp;\\overset{上一条结论}{=}\\sum_{n=1}^\\infty \\sum_{m=1}^\\infty P(X\\in I_n)P(Y\\in J_m)\\\\ \u0026amp;= \\left(\\sum_{n=1}^\\infty P(X\\in I_n)\\right)\\left(\\sum_{m=1}^\\infty P(Y\\in J_m)\\right)\\\\ \u0026amp;=P(X\\in \\bigcup_{n=1}^\\infty I_n)P(Y\\in \\bigcup_{m=1}^\\infty J_m) \\end{align} $$\n$\\fbox{Theorem 8.4}$ 若 $X,Y$ 独立，$f(x),g(y)$ 为连续函数或分段连续函数，那么 $f(X)$ 和 $g(Y)$ 也相互独立。\nn-Dimensional Case 高维情况和二维情况的定义，性质基本相同。求解其 $k$ 维边缘概率时，将剩下的 $n-k$ 维都推到 $+\\infty$ 即可。\n$n$ 维随机变量的独立性要求：$\\forall (x_1,x_2,\\cdots x_n)\\in \\mathbb{R}^n, P(X_1\\leq x_1,\\cdots X_n\\leq x_n)=\\prod_{k=1}^nP(X_k\\leq x_k)$。联想 $n$ 个事件独立的定义，该条件似乎更弱：$n$ 个事件的独立性对所有子集都做了约束。但事实上上述条件也对所有子集做了约束：只要将某些维的 $x_i$ 推到 $+\\infty$ ，则是一个对子集的约束。\n2-Dimensional Discrete Random Variable $\\fbox{Definition 8.5}$ 若二维随机变量 $(X,Y)$ 的可能取值是有限多个或可列无限个，则称 $(X,Y)$ 为离散型二维随机变量，设 $(X,Y)$ 所有可能取值为 $(x_i,y_j), \\forall i,j=1,2,\\cdots$，则称 $P(X=x_i,Y=y_j),\\forall i,j=1,2,\\cdots$ 为 $(X,Y)$ 的联合分布律，可用表格表示为\nX/Y $y_1$ $\\cdots$ $y_k$ $\\cdots$ $x_1$ $p_{11}$ $\\cdots$ $p_{1k}$ $\\cdots$ $\\vdots$ $\\vdots$ $\\ddots$ $\\vdots$ $\\cdots$ $x_k$ $p_{k1}$ $\\cdots$ $p_{kk}$ $\\cdots$ $\\vdots$ $\\vdots$ $\\vdots$ $\\vdots$ $\\ddots$ $(X,Y)$ 联合分布律的性质：\n$\\forall i,j, p_{ij}\\geq 0$\n$\\sum_{i=1}^\\infty \\sum_{j=1}^\\infty p_{ij}=1$\n边缘分布的求法： $$ \\begin{align} P(X=x_i)\u0026amp;=P\\left(X=x_i,Y\\in \\bigcup_{j=1}^\\infty {y_j}\\right)=P\\left(\\bigcup_{j=1}^\\infty {X=x_i,Y=y_j}\\right)\\\\ \u0026amp;=\\sum_{j=1}^\\infty P(X=x_i,Y=y_j)=\\sum_{j=1}^\\infty p_{i,j}\\overset{def}{=} P_{i\\cdot} \\\\ P(Y=y_j)\u0026amp;=\\sum_{i=1}^\\infty P(X=x_i,Y=y_j)\\overset{def}{=}P_{\\cdot j} \\end{align} $$\n再考虑离散型二维随机变量的分布函数及其边缘分布函数： $$ F(x,y)=\\sum_{i:x_i\\leq x}\\sum_{j:y_j\\leq y}p_{i,j}\\\\ F_X(x)=\\sum_{i:x_i\\leq x}p_{i\\cdot}=\\sum_{i:x_i\\leq x}\\sum_{j=1}^\\infty p_{i,j} $$ 一般地，对于区域 $D\\subset \\mathbb{R}^2$，有 $$ P((x,y)\\in D)=\\sum_{i,j:(x_i,y_j)\\in D}p_{i,j} $$ 对于离散型随机变量的独立性，$X$ 和 $Y$ 独立当且仅当对于任意 $i,j$，$P(X=x_i,Y=y_j)=P(X=x_i)P(Y=y_j)$，或者写成 $p_{i,j}=p_{i\\cdot }p_{\\cdot j}$。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"6d31328016255aee4c17231ed93e802b","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec08/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec08/","section":"notes","summary":"Distribution Function of 2-Dimensional Random Variable $\\fbox{Definition 8.1}$ 设 $X,Y$ 是定义在 $(\\Omega, \\mathscr F, P)$ 上的随机变量，则称 $(X,Y)$ 为 $(\\Omega, \\mathscr F, P)$ 上的二维随机变量。对于任意 $x,y\\in \\mathbb R$，称 $$ F(x,y)=P({X\\leq x}\\cap {Y\\leq y})=P(X\\leq x,Y\\leq y) $$ 为 $(X,Y)$ 的 (联合) 分布函数。","tags":null,"title":"Lecture 08: Mult-dimensional Random Variable","type":"docs"},{"authors":null,"categories":null,"content":"Examples of Discrete 2-D Random Variable 【例】 (三项分布) 若二维离散型随机变量 $(X,Y)$ 的分布律为 $$ P(X=i,Y=j)=\\frac{n!}{i!j!(n-i-j)!}p_1^ip_2^j(1-p_1-p_2)^{n-i-j} $$ 其中 $i,j=0,1,\\cdots,n,i+j\\leq n,0\\leq p_1,p_2,p_1+p_2\\leq 1$，则称 $(X,Y)$ 服从参数 $n,p_1,p_2$ 的三项分布。\n概率背景：在 $n$ 重独立重复试验中，每次试验有三种可能的结果 $A_1,A_2,A_3$，$P(A_1)=p_1,P(A_2)=p_2$。令 $A_1$ 发生次数为 $X$，$A_2$ 发生次数为 $Y$，则 $(X,Y)$ 服从上述三项分布。\n三项分布的边缘分布是二项分布，因为在计算 $P(X=k)$ 时，我们不关心在没有命中 $A_1$ 时命中的是 $A_2$ 还是 $A_3$，相当于只剩下了两种事件。我们也可以从代数上进行验证： $$ \\begin{align} P(X=k)\u0026amp;=P(X=k,0\\leq Y\\leq n-k)=\\sum_{i=0}^{n-k}P(X=k,Y=i)\\\\ \u0026amp;=\\sum_{i=0}^{n-k}\\frac{n!}{k!i!(n-k-i)!}p_1^kp_2^i(1-p_1-p_2)^{n-k-i}\\\\ \u0026amp;=\\frac{n!}{k!(n-k)!}p_1^k\\sum_{i=0}^{n-k}\\frac{(n-k)!}{i!(n-k-i)!}p_2^i(1-p_1-p_2)^{n-k-i}\\\\ \u0026amp;=\\frac{n!}{k!(n-k)!}p_1^k(p_2+(1-p_1-p_2))^{n-k}\\\\ \u0026amp;=\\binom{n}{k}p_1^k(1-p_1)^{n-k} \\end{align} $$ 一般地，可以定义 $k$ 项分布。记 $P(A_1)=p_1,\\cdots, P(A_k)=p_k$，$0\\leq p_1,\\cdots, p_k,\\sum_{i=1}^kp_i\\leq 1$，记 $X_j$是 $n$ 次试验中 $A_j$ 发生的次数，则 $(X_1,\\cdots, X_k)$ 的分布律为 $$ P(X_1=j_1,\\cdots, X_k=j_k)=\\frac{n!}{j_1!\\cdots j_k!}p_1^{j_1}\\cdots p_k^{j_k} $$ 其中 $0\\leq j_1,\\cdots, j_k\\leq n,\\sum_{i=1}^kj_i=n$。\n【例】 (二维超几何分布) 若二维离散型随机变量 $(X,Y)$ 的分布律为 $$ P(X=n_1,Y=n_2)=\\frac{\\binom{N_1}{n_1}\\binom{N_2}{n_2}\\binom{N_3}{n_3}}{\\binom{N}{n}} $$ 其中 $0\\leq n_1\\leq N_1,0\\leq n_2\\leq N_2,0\\leq n_3\\leq N_4,n_1+n_2+n_3=n,N_1+N_2+N_3=N$，则称 $(X,Y)$ 服从二维超几何分布。\n概率背景：设 $N$ 个物品分为三类，各有 $N_1,N_2,N_3$ 个，不放回地挑 $n$ 个，第一类抽到 $X$ 个，第二类抽到 $Y$ 个，则 $(X,Y)$ 服从上述二维超几何分布。\n类似地，二维超几何分布的边缘分布是一维的超几何分布： $$ \\begin{align} P(X=n_1)\u0026amp;=P(X=n_1,0\\leq Y\\leq \\min{N_2,n-n_1})\\\\ \u0026amp;=\\sum_{k=0}^{\\min{N_2,n-n_1}}\\frac{\\binom{N_1}{n_1}\\binom{N_2}{k}\\binom{N_3}{n-n_1-k}}{\\binom{N}{n}}\\\\ \u0026amp;=\\frac{\\binom{N_1}{n_1}}{\\binom{N}{n}}\\left(\\sum_{k=0}^{\\min{N_2,n-n_1}}\\binom{N_2}{k}\\binom{N_3}{n-n_1-k}\\right)\\\\ \u0026amp;=\\frac{\\binom{N_1}{n_1}}{\\binom{N}{n}}\\binom{N_2+N_3}{n-n_1}\\\\ \u0026amp;=\\frac{\\binom{N_1}{n_1}\\binom{N-N_1}{n-n_1}}{\\binom{N}{n}}\\qquad (一维超几何分布) \\end{align} $$\n2-Dimensional Continuous Random Variable $\\fbox{Definition 9.1}$ 对于一个二维随机变量 $(X,Y)$ 的分布函数 $F(x,y)$，若存在非负可积函数 $p(x,y)$，使得对于任意 $(x,y)\\in \\mathbb{R}^2$，有 $$ F(x,y)=\\int_{-\\infty}^x\\int_{-\\infty}^yp(u,v)dudv $$ 则称 $(X,Y)$ 是二维连续型随机变量，称 $p(x,y)$ 是 $(X,Y)$ 的 (联合) 概率密度函数。\n$p(x,y)$ 的性质：\n$\\forall (x,y)\\in \\mathbb{R}^2,p(x,y)\\geq 0$\n$$ \\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}p(x,y)dxdy=F(+\\infty,+\\infty)=1 $$\n设 $D\\subseteq \\mathbb{R}^2$，则 $(X,Y)$ 落入 $D$ 中的概率为 $$ P((X,Y)\\in D)=\\iint_D p(x,y)dxdy $$\n若 $p(x,y)$ 在 $(x_0,y_0)$ 附近连续，则有 $$ \\left.\\frac{\\partial^2 F(x,y)}{\\partial x\\partial y}\\right|_{(x,y)=(x_0,y_0)}=p(x_0,y_0) $$ 注：和一维的情形类似，在二维连续型随机变量中，$p(x_0,y_0)$ 不能理解为 $x=x_0,y=y_0$ 的概率。事实上，$\\forall x_0,y_0\\in \\mathbb{R},P(X=x_0,Y=y_0)=0$。$p(x_0,y_0)$ 只能理解为 $(X,Y)$ 落入 $(x_0,y_0)$ 附近一小块面积的概率的近似值，即 $$ \\int_{x_0}^{x_0+\\Delta x}\\int_{y_0}^{y_0+\\Delta y}p(x,y)dxdy\\approx p(x_0,y_0)\\Delta x\\Delta y $$\n边缘分布和密度函数的求法：\n$X$ 的边缘分布函数为 $$ F_X(x)=F(X,+\\infty)=\\int_{-\\infty}^x\\left[\\int_{-\\infty}^{+\\infty}p(u,y)dy\\right]du $$ $X$ 的边缘密度函数为 $$ p_X(x)=\\frac{d}{dx}F_X(x)=\\int_{-\\infty}^{\\infty}p(x,y)dy $$ (直观地想，离散时边缘密度的求法是固定 $x$，对所有可能的 $y$ 求和，那么在连续型中将求和换作积分即可。)\n$Y$ 的边缘分布和密度函数求法类似。\n关于独立性：对于一般的二维随机变量，$X,Y$ 的独立性定义为 $$ \\forall (x,y)\\in \\mathbb{R}^2,F(x,y)=F_X(x)F_Y(y) $$ 在连续的情形中，即 $$ \\int_{-\\infty}^x\\int_{-\\infty}^yp(u,v)dudv=\\int_{-\\infty}^xp_X(u)du\\int_{-\\infty}^yp_Y(v)dv=\\int_{-\\infty}^x\\int_{-\\infty}^yp_X(u)p_Y(v)dudv $$ 因为上式对于任意 $x,y$ 均成立，所以独立性条件可以用密度函数直接表示为 $$ \\forall (x,y)\\in \\mathbb{R}^2,p(x,y)=p_X(x)p_Y(y) $$\nn-Dimensional Continuous Random Variable $\\fbox{Definition 9.2}$ 设 $n$ 维随机变量 $(X_1,\\cdots, X_n)$ 的分布函数为 $F(x_1,\\cdots, x_n)$，若存在非负可积函数 $p(x_1,\\cdots, x_n)$ 使得 $$ \\forall (x_1,\\cdots,x_n)\\in \\mathbb{R}^n,F(x_1,\\cdots, x_n)=\\int_{-\\infty}^{x_1}\\cdots \\int_{-\\infty}^{x_n} p(u_1,\\cdots, u_n)du_1\\cdots du_n $$ 则称 $(X_1,\\cdots, X_n)$ 为 $n$ 维连续型随机变量，$p(x_1,\\cdots, x_n)$ 为 (联合) 概率密度函数。\nExamples of 2-D Continuous Random Variable 【例】 (二维均匀分布) 设 $D\\subset \\mathbb{R}^2$ 为有界区域，面积为 $S_D$。若 $(X,Y)$ 的联合密度函数为 $$ p(x,y)=\\begin{cases} \\frac{1}{S_D}\u0026amp;, (X,Y)\\in D\\\\ 0\u0026amp;, (X,Y)\\in D \\end{cases} $$ 则称 $(X,Y)$ 服从区域 $D$ 上的二维均匀分布。\n(注：事实上该定义和一维情况相同，一维情况的测度是长度，二维情况的测度是面积。)\n该分布的均匀性体现在：对于任意 $A\\subseteq D$，若 $A$ 的面积为 $S_A$，则 $P((X,Y)\\in A)=\\frac{S_A}{S_D}$，与 $A$ 的形状、位置无关，只与 $A$ 的面积有关 (类比二维几何概型)。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"d3d8ec1e0310ef8d743f2840f609fea5","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec09/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec09/","section":"notes","summary":"Examples of Discrete 2-D Random Variable 【例】 (三项分布) 若二维离散型随机变量 $(X,Y)$ 的分布律为 $$ P(X=i,Y=j)=\\frac{n!}{i!j!(n-i-j)!}p_1^ip_2^j(1-p_1-p_2)^{n-i-j} $$ 其中 $i,j=0,1,\\cdots,n,i+j\\leq n,0\\leq p_1,p_2,p_1+p_2\\leq 1$，则称 $(X,Y)$ 服从参数 $n,p_1,p_2$ 的三项分布。\n概率背景：在 $n$ 重独立重复试验中，每次试验有三种可能的结果 $A_1,A_2,A_3$，$P(A_1)=p_1,P(A_2)=p_2$。令 $A_1$ 发生次数为 $X$，$A_2$ 发生次数为 $Y$，则 $(X,Y)$ 服从上述三项分布。","tags":null,"title":"Lecture 09: 2-Dimensional Continuous Random Variable","type":"docs"},{"authors":null,"categories":null,"content":"$\\fbox{Definition 10.1}$ 若二维随机变量 $(X,Y)$ 的联合密度为 $$ p(x,y)=\\frac{1}{2\\pi \\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}e^{-\\frac{1}{2(1-\\rho^2)}[(\\frac{x-\\mu_1}{\\sigma_1})^2-2\\rho(\\frac{x-\\mu_1}{\\sigma_1})(\\frac{y-\\mu_2}{\\sigma_2})+(\\frac{y-\\mu_2}{\\sigma_2})^2]} $$ 其中 $\\mu_1,\\mu_2\\in \\mathbb R$，$\\sigma_1,\\sigma_2\u0026gt;0$，$|\\rho|\u0026lt;1$，则称 $(X,Y)$ 服从二维正态分布。记为 $(X,Y)\\sim N(\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2,\\rho)$ (这里的每个参数都有具体含义)。\n$\\fbox{Theorem 10.2}$ 若 $(X,Y)\\sim N(\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2,\\rho)$，则其边缘分布为 $X\\sim N(\\mu_1,\\sigma_1^2)$，$Y\\sim N(\\mu_2,\\sigma_2^2)$。\n证明：根据对称性，我们仅需证明 $X$ 的边缘分布为正态分布。\n$$ \\begin{align} p_X(x)\u0026amp;=\\int_{-\\infty}^{+\\infty}p(x,y)dy\\\\ \u0026amp;=\\frac{1}{2\\pi \\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}e^{-\\frac{1}{2(1-\\rho^2)}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\left[\\left(\\frac{y-\\mu_2}{\\sigma_2\\sqrt {1-\\rho^2}}\\right)^2-\\frac{2\\rho}{1-\\rho^2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)\\left(\\frac{y-\\mu_2}{\\sigma_2}\\right)\\right]}dy\\\\ \u0026amp;\\overset{配方}{=} \\frac{1}{2\\pi \\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}e^{-\\frac{1}{2(1-\\rho^2)}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\left[\\left(\\frac{y-\\mu_2}{\\sigma_2\\sqrt {1-\\rho^2}}\\right)^2-\\frac{2\\rho}{1-\\rho^2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)\\left(\\frac{y-\\mu_2}{\\sigma_2}\\right)+\\left(\\frac{x-\\mu_1}{\\sigma_1\\sqrt{1-\\rho^2}}\\right)^2\\right]+\\frac{1}{2}\\frac{\\rho^2(x-\\mu_1)^2}{\\sigma_1^2(1-\\rho^2)}}dy\\\\ \u0026amp;=\\frac{1}{2\\pi \\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}e^{-\\frac{1}{2}(\\frac{x-\\mu_1}{\\sigma_1})^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\left(\\frac{y-\\mu_2}{\\sigma_2 \\sqrt{1-\\rho^2}}-\\frac{\\rho (x-\\mu_1)}{\\sigma_1 \\sqrt{1-\\rho^2}}\\right)^2}dy\\\\ \u0026amp;\\overset{u=\\frac{y-\\mu_2}{\\sigma_1\\sqrt{1-\\rho^2}}-\\frac{\\rho(x-\\mu_1)}{\\sigma_1\\sqrt{1-\\rho^2}}}{=}\\frac{1}{2\\pi \\sigma_1 \\sigma_2 \\sqrt{1-\\rho^2}}e^{\\frac{1}{2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}u^2}d(\\sigma_2\\sqrt{1-\\rho^2}u)\\\\ \u0026amp;=\\frac{1}{2\\pi \\sigma_1}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{u^2}{2}}du\\\\ \u0026amp;=\\frac{1}{\\sqrt{2\\pi}\\sigma_1}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2} \\end{align} $$\n因此 $X\\sim N(\\mu_1,\\sigma_1^2)$。$\\blacksquare$\n注：二维正态分布可以用矩阵描述成如下更简洁的形式：记 $\\Sigma=\\begin{bmatrix}\\sigma_1^2 \u0026amp; \\rho\\sigma_1\\sigma_2\\\\\\rho \\sigma_1\\sigma_2 \u0026amp; \\sigma_2^2 \\end{bmatrix}$，则 $$ p(x,y)=\\frac{1}{2\\pi\\sqrt{|\\Sigma|}}e^{-\\frac{1}{2}(x-\\mu_1,y-\\mu_2)\\Sigma^{-1}\\begin{pmatrix}x-\\mu_1\\\\y-\\mu_2\\end{pmatrix}} $$ 二维正态分布的边缘分布都是正态分布，那么两个边缘分布都是正态分布的二维分布是否一定是二维正态分布呢？答案是否定的。考虑如下分布：令 $\\varphi(x)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}$，$g(x)=\\begin{cases}\\cos x\u0026amp;, |x|\\leq \\pi\\\\ 0\u0026amp;,|x| \u0026gt; \\pi\\end{cases}$，可以看到 $\\varphi$ 就是一维标准正态分布的密度函数。令 $$ p(x,y)=\\varphi(x)\\varphi(y)+\\frac{1}{2\\pi} e^{-\\pi^2}g(x)g(y) $$ 这显然不是联合正态密度函数，但我们逐一验证二维分布的条件和边缘分布：\n$p(x,y)\\geq 0$：我们只需考虑 $|x|\\leq \\pi, |y|\\leq \\pi$ 的方形区域： $$ p(x,y)=\\frac{1}{2\\pi}\\left(e^{-\\frac{x^2+y^2}{2}}+e^{-\\pi^2}\\cos x\\cos y\\right)\\geq \\frac{1}{2\\pi}\\left(e^{-\\frac{x^2+y^2}{2}}-e^{-\\pi^2}\\right)\\geq 0 $$\n$$ \\begin{align} p_X(x)\u0026amp;=\\int_{-\\infty}^{+\\infty}\\varphi(x)\\varphi(y)dy+\\frac{1}{2\\pi}e^{-\\pi^2}\\int_{-\\infty}^{+\\infty}g(x)g(y)dy\\\\ \u0026amp;=\\varphi(x)+\\frac{1}{2\\pi}e^{-\\pi^2}g(x)\\int_{-\\pi}^{\\pi}\\cos y dy\\\\ \u0026amp;=\\varphi(x) \\end{align} $$\n$$ \\int_{-\\infty}^{+\\infty}\\left(\\int_{-\\infty}^{+\\infty}p(x,y)dy\\right)dx=\\int_{-\\infty}^{+\\infty}\\varphi(x)dx=1 $$\n$\\fbox{Theorem 10.3}$ 若 $(X,Y)\\sim N(\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2,\\rho)$ ，则 $X,Y$ 独立 $\\Leftrightarrow$ $\\rho =0$。\n证明：$\\Leftarrow$：当 $\\rho=0$ 时， $$ p(x,y)=\\frac{1}{2\\pi\\sigma_1\\sigma_2}e^{-\\frac{1}{2}\\left[\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2+\\left(\\frac{y-\\mu_2}{\\sigma_2}\\right)^2\\right]}=\\frac{1}{\\sqrt{2\\pi}\\sigma_1}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2}\\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma_2}e^{-\\frac{1}{2}\\left(\\frac{y-\\mu_2}{\\sigma_2}\\right)^2}=p_X(x)p_Y(y) $$ $\\Rightarrow$：当 $X,Y$ 独立时，取 $x=\\mu_1,y=\\mu_2$，则 $$ p(\\mu_1,\\mu_2)=\\frac{1}{2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}=p_X(x)p_Y(y)=\\frac{1}{2\\pi\\sigma_1\\sigma_2} $$ 所以 $\\sqrt{1-\\rho^2}=1$，$\\rho = 0$。$\\blacksquare$\n【习题3-5】二维随机变量 $(X,Y)$ 的联合密度函数为 $$ p(x,y)=\\begin{cases}xe^{-y}\u0026amp;,0\u0026lt;x\u0026lt;y\\\\0\u0026amp;,otherwise\\end{cases} $$ 求 $(X,Y)$ 的联合分布函数。\n(ATTENTION：$F(x,y)$ 的含义是落在 $(x,y)$ 左下方矩形的概率，切勿在 $p(x,y)$ 为零时直接推测 $F(x,y)$ 也为零！)\n解：当 $x\u0026lt;0$ 或 $y\u0026lt;0$ 时，$F(x,y)=0$。\n当 $0\u0026lt;x\\leq y$ 时，我们要积的是一个梯形区域， $$ \\begin{align} F(x,y)\u0026amp;=\\int_0^x\\left(\\int_{u}^{y}ue^{-v}dv\\right)du\\\\ \u0026amp;=\\int_{0}^xu(e^{-u}-e^{-y})du\\\\ \u0026amp;=\\left(\\int_0^xue^{-u}du\\right)-\\frac{1}{2}x^2e^{-y}\\\\ \u0026amp;=1-e^{-x}-xe^{-x}-\\frac{1}{2}x^2e^{-y} \\end{align} $$ 考虑到 $F$ 的连续性，当 $0\u0026lt;y\u0026lt;x$ 时，$F(x,y)=F(y,y)=1-e^{-y}-ye^{-y}-\\frac{1}{2}y^2e^{-y}$。\n2-Dimensional Random Variable Function 设 $(X,Y)$ 为二维随机变量，$z=g(x,y)$ 为二元实函数，定义 $(X,Y)$ 的函数 $Z=g(X,Y)$，即 $Z$ 在 $(X,Y)=(x,y)$ 时取值 $g(x,y)$，则 $Z$ 是一个随机变量。下面给出求 $Z$ 的分布的方法。 $$ F_Z(z)=P(Z\\leq z)=P(g(x,y)\\leq z) $$ 对于离散情形，记 $(X,Y)$ 的分布律为 $P(X=x_i,Y=y_j)=p_{ij},i,j=1,2,\\cdots$，则 $Z$ 也为离散型随机变量。记 $Z$ 的可能取值为 $z_k,k=1,2,\\cdots$，则 $$ \\begin{align} P(Z=z_k)\u0026amp;=P(g(X,Y)=z_k)=P((X,Y)\\in {(x,y)|g(x,y)=z_k})\\\\ \u0026amp;= \\sum_{i,j:g(x_i,y_j)=z_k}P(X=x_i,Y=y_j)=\\sum_{i,j:g(x_i,y_j)=z_k}p_{ij} \\end{align} $$ 对于连续情形，记 $(X,Y)$ 的密度函数为 $p(x,y)$，则 $$ \\begin{align} F_Z(z)\u0026amp;=P(g(X,Y)\\leq z)=P((X,Y)\\in {(x,y)|g(x,y)\\leq z})\\\\ \u0026amp;=\\iint_{{(x,y):g(x,y)\\leq z}}p(x,y)dxdy \\end{align} $$ 若 $F_Z(z)$ 可导，则 $p_Z(z)=F_Z\u0026rsquo;(z)$。\n对于混合情形，若 $X$ 为连续型随机变量，密度函数为 $p(x)$，$Y$ 为离散型随机变量，分布为 $P(Y=y_j)=q_j,j=1,2,\\cdots$。那么 $$ \\begin{align} F_Z(z)\u0026amp;=P(g(X,Y)\\leq z)=\\sum_{j=1}^\\infty P(g(X,Y)\\leq z,Y=y_j)\\\\ \u0026amp;=\\sum_{j=1}^\\infty P(g(X,y_j)\\leq z,Y=y_j)\\\\ \u0026amp;=\\sum_{j=1}^\\infty q_jP(g(X,y_j)\\leq z|Y=y_j)\\quad (条件概率) \\end{align} $$ 若 $X,Y$ 独立，则上式可化为 $$ \\sum_{j=1}^\\infty P(g(X,y_j)\\leq z)=\\sum_{j=1}^\\infty q_j\\int_{x:g(x,y_j)\\leq z}p(x)dx $$\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"0dbdc34078b5ff51258092a6b4b9df2a","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec10/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec10/","section":"notes","summary":"$\\fbox{Definition 10.1}$ 若二维随机变量 $(X,Y)$ 的联合密度为 $$ p(x,y)=\\frac{1}{2\\pi \\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}e^{-\\frac{1}{2(1-\\rho^2)}[(\\frac{x-\\mu_1}{\\sigma_1})^2-2\\rho(\\frac{x-\\mu_1}{\\sigma_1})(\\frac{y-\\mu_2}{\\sigma_2})+(\\frac{y-\\mu_2}{\\sigma_2})^2]} $$ 其中 $\\mu_1,\\mu_2\\in \\mathbb R$，$\\sigma_1,\\sigma_2\u0026gt;0$，$|\\rho|\u0026lt;1$，则称 $(X,Y)$ 服从二维正态分布。记为 $(X,Y)\\sim N(\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2,\\rho)$ (这里的每个参数都有具体含义)。\n$\\fbox{Theorem 10.2}$ 若 $(X,Y)\\sim N(\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2,\\rho)$，则其边缘分布为 $X\\sim N(\\mu_1,\\sigma_1^2)$，$Y\\sim N(\\mu_2,\\sigma_2^2)$。\n证明：根据对称性，我们仅需证明 $X$ 的边缘分布为正态分布。\n$$ \\begin{align} p_X(x)\u0026amp;=\\int_{-\\infty}^{+\\infty}p(x,y)dy\\\\ \u0026amp;=\\frac{1}{2\\pi \\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}e^{-\\frac{1}{2(1-\\rho^2)}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\left[\\left(\\frac{y-\\mu_2}{\\sigma_2\\sqrt {1-\\rho^2}}\\right)^2-\\frac{2\\rho}{1-\\rho^2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)\\left(\\frac{y-\\mu_2}{\\sigma_2}\\right)\\right]}dy\\\\ \u0026amp;\\overset{配方}{=} \\frac{1}{2\\pi \\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}e^{-\\frac{1}{2(1-\\rho^2)}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\left[\\left(\\frac{y-\\mu_2}{\\sigma_2\\sqrt {1-\\rho^2}}\\right)^2-\\frac{2\\rho}{1-\\rho^2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)\\left(\\frac{y-\\mu_2}{\\sigma_2}\\right)+\\left(\\frac{x-\\mu_1}{\\sigma_1\\sqrt{1-\\rho^2}}\\right)^2\\right]+\\frac{1}{2}\\frac{\\rho^2(x-\\mu_1)^2}{\\sigma_1^2(1-\\rho^2)}}dy\\\\ \u0026amp;=\\frac{1}{2\\pi \\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}e^{-\\frac{1}{2}(\\frac{x-\\mu_1}{\\sigma_1})^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\left(\\frac{y-\\mu_2}{\\sigma_2 \\sqrt{1-\\rho^2}}-\\frac{\\rho (x-\\mu_1)}{\\sigma_1 \\sqrt{1-\\rho^2}}\\right)^2}dy\\\\ \u0026amp;\\overset{u=\\frac{y-\\mu_2}{\\sigma_1\\sqrt{1-\\rho^2}}-\\frac{\\rho(x-\\mu_1)}{\\sigma_1\\sqrt{1-\\rho^2}}}{=}\\frac{1}{2\\pi \\sigma_1 \\sigma_2 \\sqrt{1-\\rho^2}}e^{\\frac{1}{2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}u^2}d(\\sigma_2\\sqrt{1-\\rho^2}u)\\\\ \u0026amp;=\\frac{1}{2\\pi \\sigma_1}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{u^2}{2}}du\\\\ \u0026amp;=\\frac{1}{\\sqrt{2\\pi}\\sigma_1}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2} \\end{align} $$","tags":null,"title":"Lecture 10: 2-Dimensional Normal Distribution and Random Variable Function","type":"docs"},{"authors":null,"categories":null,"content":"【例】 (顺序统计量, order statistics) 设 $X,Y$ 相互独立，分布函数分别为 $F_X(x)$ 和 $F_Y(y)$。令 $M=\\max \\{X,Y\\}$，$N=\\min \\{X,Y\\}$，现考虑 $M,N$ 的分布。 $$ \\begin{align} F_M(z)\u0026amp;=P(M\\leq z)=P(\\max {X,Y}\\leq z)=P(X\\leq z,Y\\leq z)\\overset{独立性}{=}P(X\\leq z)P(Y\\leq z)=F_X(z)F_Y(z)\\\\ F_N(z)\u0026amp;=P(N\\leq z)=P(\\min {X,Y}\\leq z)=1-P(X\u0026gt;z,Y\u0026gt;z)=1-(1-F_X(z))(1-F_Y(z)) \\end{align} $$ 注：(1) 设 $X,Y$ 只取整数，则 $P(M=n)=P(M\\leq n)-P(M\\leq n-1)=F_M(n)-F_M(n-1)$。\n(2) 上述结果可以推广到 $n$ 个独立随机变量 $X_1,\\cdots, X_n$ 的情形，此时有 $$ \\begin{align} F_M(z)\u0026amp;=\\prod_{k=1}^nF_{X_i}(z)\\\\ F_N(z)\u0026amp;=1-\\prod_{k=1}^n(1-F_{X_i}(z)) \\end{align} $$ 【例】 (和的分布) 令 $Z=X+Y$，考虑下列情形中 $Z$ 的分布：\n$X,Y$ 相互独立，且取值均为非负整数。此时 $X,Y$ 显然均为离散型随机变量，记 $P(X=k)=p_k$，$P(Y-k)=q_k$，$k=0,1,2,\\cdots$。 $(X,Y)$ 的密度函数为 $p(x,y)$。 对于离散情形： $$ P(Z=n)=P(X+Y=n)=\\sum_{k=0}^nP(X=k,Y=n-k)=\\sum_{k=0}^nP(X=k)P(Y=n-k)=\\sum_{k=0}^np_kq_{n-k} $$ 上式称为 (离散) 卷积 (convolution) 公式。\n对于连续情形： $$ \\begin{align} F_Z(z)\u0026amp;=P(X+Y\\leq z)=\\iint_{{(x,y):x+y\\leq z}}p(x,y)dxdy\\\\ \u0026amp;=\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{z-x}p(x,y)dydx\\\\ \u0026amp;\\overset{y=v-x}{=}\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^zp(x,v-x)dvdx\\\\ \u0026amp;\\overset{换序}{=}\\int_{-\\infty}^z\\left(\\int_{-\\infty}^{+\\infty}p(x,v-x)dx\\right)dv \\end{align} $$ 因为 $\\displaystyle{F_Z(z)=\\int_{-\\infty}^z p_Z(u)du}$，和上式对比，我们发现括号内的部分正好是 $Z$ 的密度函数。 $$ p_Z(v)=\\int_{-\\infty}^{+\\infty}p(x,v-x)dx $$ 上式称为 (连续) 卷积公式。\n进一步地，若 $X,Y$ 独立，则 $p(x,y)=p_X(x)p_Y(y)$，因此 $Z$ 的密度为 $$ p_Z(v)=\\int_{-\\infty}^{+\\infty}p_X(x)p_Y(v-x)dx $$\n【例题】 设 $X\\sim B(n_1,p),Y\\sim B(n_2,p)$，且 $X,Y$ 独立，求 $X+Y$ 的分布。\n解：$P(X=k)=\\binom{n_1}{k}p^k(1-p)^{n_1-k},k=0,\\cdots,n_1$，$P(Y=k)=\\binom{n_2}{k}p^k(1-p)^{n_2-k},k=0,\\cdots n_2$。\n令 $Z=X+Y$，则 $$ \\begin{align} P(Z=n)\u0026amp;=\\sum_{k=0}^nP(X=k,Y=n-k)=\\sum_{k=0}^nP(X=k)P(Y=n-k)\\\\ \u0026amp;=\\sum_{k=\\max \\{0,n-n_2\\}}^{\\min\\{n,n_1\\}}\\binom{n_1}{k}p^k(1-p)^{n_1-k}\\binom{n_2}{n-k}p^{n-k}(1-p)^{n_2-n+k}\\\\ \u0026amp;=p^n(1-p)^{n_1+n_2-n}\\sum_{k=\\max \\{0,n-n_2\\}}^{\\min \\{n,n_1\\}}\\binom{n_1}{k}\\binom{n_2}{n-k}\\\\ \u0026amp;=p^n(1-p)^{n_1+n_2-n}\\binom{n_1+n_2}{n} \\end{align} $$ 因此 $Z\\sim B(n_1+n_2,p)$。\n在多次实验 $p$ 相同的情况下，这个结论是容易理解的：先做 $n_1$ 次再做 $n_2$ 次和一共做 $n_1+n_2$ 次是一样的。\n注：上述结论可以推广到 $n$ 个变量的情形。且类似可证对于独立的泊松分布 $X_k\\sim P(\\lambda_k),k=1,\\cdots n$，有 $X=\\sum_{k=1}^nX_k\\sim P(\\sum_{k=1}^n\\lambda_k)$。\n【例题】设 $X\\sim N(\\mu_1,\\sigma_1^2),Y\\sim N(\\mu_2,\\sigma_2^2)$ 且 $X,Y$ 相互独立，求 $Z=X+Y$ 的分布。\n解：$p_X(x)=\\frac{1}{\\sqrt {2\\pi}\\sigma_1}e^{-\\frac{(x-\\mu_1)^2}{2\\sigma_1^2}},p_Y(y)=\\frac{1}{\\sqrt {2\\pi}\\sigma_2}e^{-\\frac{(y-\\mu_2)^2}{2\\sigma_2^2}}$。\n正态分布变量的取值均为 $\\mathbb R$ ，因此我们直接使用卷积公式： $$ \\begin{align} p_Z(z)=\\int_{-\\infty}^{+\\infty}p_X(x)p_Y(z-x)dx=\\frac{1}{2\\pi \\sigma_1 \\sigma_2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\left[\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2+\\left(\\frac{z-x-\\mu_2}{\\sigma_2}\\right)^2\\right]}dx \\end{align} $$ 遇到这种 e 上带指数，积分区域是 $\\mathbb R$ 的积分，常见的处理手法是将其凑成平方的形式，然后套用高斯积分。因此我们现在希望中括号中两个平方式的交叉项消掉。这里给出一个处理技巧：令 $x=y+a$，$a$ 为待定的系数，则 $$ \\begin{align} p_Z(z)=\\frac{1}{2\\pi \\sigma_1 \\sigma_2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\left[\\left(\\frac{y+a-\\mu_1}{\\sigma_1}\\right)^2+\\left(\\frac{y+a+\\mu_2-z}{\\sigma_2}\\right)^2\\right]}dy \\end{align} $$ 令交叉项为零，即 $$ \\frac{y}{\\sigma_1}\\cdot \\frac{a-\\mu_1}{\\sigma_1}+\\frac{y}{\\sigma_2}\\cdot \\frac{a+\\mu_2-z}{\\sigma_2}=0 $$ 解得 $$ a=\\frac{\\mu_1\\sigma_2^2-\\mu_2\\sigma_1^2+z\\sigma_1^2}{\\sigma_1^2+\\sigma_2^2} $$ 带回原式，有 $$ \\begin{align} p_Z(z)\u0026amp;=\\frac{1}{2\\pi \\sigma_1 \\sigma_2}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\left[\\left(\\frac{y}{\\sigma_1}\\right)^2+\\left(\\frac{y}{\\sigma_2}\\right)^2+\\frac{(z-\\mu_1-\\mu_2)^2}{\\sigma_1^2+\\sigma_2^2}\\right]}dy\\\\ \u0026amp;=\\frac{1}{2\\pi \\sigma_1 \\sigma_2}e^{-\\frac{(z-\\mu_1-\\mu_2)^2}{2\\left(\\sigma_1^2+\\sigma_2^2\\right)}}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}\\cdot \\frac{\\sigma_1^2+\\sigma_2^2}{\\sigma_1^2\\sigma_2^2}y^2}dy\\\\ \u0026amp;\\overset{v=\\sqrt{\\frac{\\sigma_1^2+\\sigma_2^2}{\\sigma_1^2\\sigma_2^2}}y}{=}\\frac{1}{2\\pi \\sigma_1 \\sigma_2}e^{-\\frac{(z-\\mu_1-\\mu_2)^2}{2\\left(\\sigma_1^2+\\sigma_2^2\\right)}}\\int_{-\\infty}^{+\\infty}e^{-\\frac{v^2}{2}}d\\left(\\sqrt{\\frac{\\sigma_1\\sigma_2}{\\sigma_1^2+\\sigma_2^2}}y\\right)\\\\ \u0026amp;=\\frac{1}{\\sqrt{2\\pi}\\cdot \\sqrt{\\sigma_1^2+\\sigma_2^2}}e^{-\\frac{(z-\\mu_1-\\mu_2)^2}{2\\left(\\sigma_1^2+\\sigma_2^2\\right)}} \\end{align} $$ 因此 $Z\\sim N(\\mu_1+\\mu_2,\\sigma_1^2+\\sigma_2^2)$。\n【例题】 (习题 3.25) 设 $X\\sim U[0,2],Y\\sim U[0,1]$ 且 $X,Y$ 独立，求 $Z=X+Y$ 的密度函数。\n解：该题随机变量取值不是 $\\mathbb R$，因此不能套用卷积公式，要从定义出法求解。\n$p_X(x)=\\begin{cases}\\frac{1}{2}\u0026amp;,0\\leq x\\leq 2\\\\0\u0026amp;,otherwise\\end{cases}$，$p_Y(y)=\\begin{cases}1\u0026amp;,0\\leq y\\leq 1\\\\0\u0026amp;,otherwise\\end{cases}$。$(X,Y)$ 的有效区域是一个长方形。 $$ F_Z(z)=P(X+Y\\leq z)=\\iint_{{(x,y):x+y\\leq z}}p(x,y)dxdy $$ 在有效区域内，有 $p(x,y)=p_X(x)p_Y(y)=\\frac{1}{2}$。考虑拿直线 $x+y\\leq z$ 滑过平面，看直线左侧。\n容易看出 $z\\leq 0$ 时 $F_Z(z)=0$；$z\\geq 3$ 时 $F_Z(z)=1$。剩下的几种情形需要仔细考虑：\n$0\u0026lt;z\u0026lt;1$，此时获得的是一个三角形，$F_Z(z)=\\frac{1}{2}\\cdot \\frac{z^2}{2}=\\frac{z^2}{4},p_Z(z)=F\u0026rsquo;_Z(z)=\\frac{z}{2}$。 $1\\leq z\u0026lt;2$，此时获得的是一个梯形，$F_Z(z)=\\frac{1}{2}\\cdot \\frac{z-1+z}{2}=\\frac{z}{2}-\\frac{1}{4}，p_Z(z)=\\frac{1}{2}$。 $2\\leq z\u0026lt;3$，此时获得的是矩形减去一个三角形，$F_Z(z)=\\frac{1}{2}\\cdot (2-\\frac{1}{2}(3-z)^2)=1-\\frac{1}{4}(3-z)^2$，$p_Z(z)=\\frac{1}{2}(3-z)$。 ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"3cf2a896ca4fe155a38d4529fd33b0bd","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec11/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec11/","section":"notes","summary":"【例】 (顺序统计量, order statistics) 设 $X,Y$ 相互独立，分布函数分别为 $F_X(x)$ 和 $F_Y(y)$。令 $M=\\max \\{X,Y\\}$，$N=\\min \\{X,Y\\}$，现考虑 $M,N$ 的分布。 $$ \\begin{align} F_M(z)\u0026amp;=P(M\\leq z)=P(\\max {X,Y}\\leq z)=P(X\\leq z,Y\\leq z)\\overset{独立性}{=}P(X\\leq z)P(Y\\leq z)=F_X(z)F_Y(z)\\\\ F_N(z)\u0026amp;=P(N\\leq z)=P(\\min {X,Y}\\leq z)=1-P(X\u0026gt;z,Y\u0026gt;z)=1-(1-F_X(z))(1-F_Y(z)) \\end{align} $$ 注：(1) 设 $X,Y$ 只取整数，则 $P(M=n)=P(M\\leq n)-P(M\\leq n-1)=F_M(n)-F_M(n-1)$。","tags":null,"title":"Lecture 11: Examples of 2-Dimensional Random Variable Function","type":"docs"},{"authors":null,"categories":null,"content":"【例】 (差的分布) 设 $(X,Y)$ 的密度为 $p(x,y)$，考虑 $Z=X-Y$ 的分布： $$ \\begin{align} F_Z(z)\u0026amp;=P(X-Y\\leq z)=\\iint_{{(x,y):x-y\\leq z}}p(x,y)dxdy\\\\ \u0026amp;=\\int_{-\\infty}^{+\\infty}\\left(\\int_{x-z}^{+\\infty}p(x,y)dy\\right)dx\\\\ \u0026amp;\\overset{y=x-v}{=}\\int_{-\\infty}^{+\\infty}\\int_z^{-\\infty}p(x,x-v)d(-v)dx\\\\ \u0026amp;=\\int_{-\\infty}^z\\left(\\int_{-\\infty}^{+\\infty}p(x,x-v)dx\\right)dv \\end{align} $$ 因此 $Z$ 的密度函数为 $$ p_Z(v)=\\int_{-\\infty}^{+\\infty}p(x,x-v)dx $$ 如果先积 x，可以类似地得到另一种表达式：$p_Z(u)=\\int_{-\\infty}^{+\\infty}p(y+u,y)dy$。\n【例题】 (习题 3.27) 设 $(X,Y)$ 的密度为 $p(x,y)=\\begin{cases}3x\u0026amp;,0\u0026lt;y\u0026lt;x\u0026lt;1\\\\0\u0026amp;,otherwise\\end{cases}$，求 $Z=X-Y$ 的密度。\n解：画图容易得出 $p(x,y)$ 的有效区域是一个三角形。 $$ F_Z(z)=P(X-Y\\leq z)=\\iint_{{(x,y):x-y\\leq z}}p(x,y)dxdy $$ 用直线 $x=y+z$ 滑过平面，关注直线的左侧。容易看出 $z\u0026lt;0$ 时 $F_Z(z)=0$，$z\\geq 1$ 时 $F_Z(z)=1$。这两中情况下 $p_Z(z)=0$。$0\\leq z\u0026lt;1$ 时，区域不太规则，要分成两个部分： $$ \\begin{align} F_Z(z)\u0026amp;=\\int_0^z\\int_0^x3xdydx+\\int_z^1\\int_{x-z}^x3xdydx\\\\ \u0026amp;=\\int_0^z3x^2dx+\\int_z^13zxdx\\\\ \u0026amp;=-\\frac{1}{2}z^3+\\frac{3}{2}z \\end{align} $$ 从而 $p_Z(z)=F_Z\u0026rsquo;(z)=-\\frac{3}{2}z^2+\\frac{3}{2}$。\n【例】 (积和商的分布) 设 $(X,Y)$ 的密度为 $p(x,y)$，考虑两者积和商的分布：\n$Z=XY$ $Z=\\frac{X}{Y}$。 对于积的分布， $$ F_Z(z)=P(XY\\leq z)=\\iint_{{(x,y):xy\\leq z}}p(x,y)dxdy $$ 我们要小心 $x$ 的符号对积分上下限的影响，因此要分类讨论 $x\u0026lt;0$ 和 $x\u0026gt;0$ 的情况： $$ \\begin{align} F_Z(z)\u0026amp;=\\int_{-\\infty}^0\\left(\\int_{z/x}^{+\\infty} p(x,y)dy\\right)dx+\\int_0^{+\\infty}\\left(\\int_{-\\infty}^{z/x}p(x,y)dy\\right)dx\\\\ \u0026amp;\\overset{y=\\frac{v}{x}}{=}\\int_{-\\infty}^0\\left(\\int_z^{-\\infty}p(x,\\frac{v}{x})d\\frac{v}{x}\\right) dx+\\int_0^{+\\infty}\\left(\\int_{-\\infty}^zp(x,\\frac{v}{x})d\\frac{v}{x}\\right)dx\\\\ \u0026amp;=\\int_{-\\infty}^z\\int_{-\\infty}^0-p(x,\\frac{v}{x})\\frac{1}{x}dxdv+\\int_{-\\infty}^z\\int_0^{+\\infty}p(x,\\frac{v}{x})\\frac{1}{x}dxdv\\\\ \u0026amp;=\\int_{-\\infty}^z\\left(\\int_{-\\infty}^{+\\infty}p(x,\\frac{v}{x})\\frac{1}{|x|}dx\\right)dv \\end{align} $$ 因此密度函数 $$ p_Z(z)=\\int_{-\\infty}^{+\\infty}p(x,\\frac{v}{x})\\frac{1}{|x|}dx $$ 当然，如果先积 $y$ 再积 $x$，我们可以得到对称的形式：$p_Z(u)=\\int_{-\\infty}^{+\\infty}p(\\frac{u}{y},y)\\frac{1}{|y|}dy$。\n对于商的分布， $$ F_Z(z)=P(X/Y\\leq z)=\\iint_{{(x,y):\\frac{x}{y}\\leq z}}p(x,y)dxdy $$ 类似地，考虑 $y\u0026lt;0$ 和 $y\u0026gt;0$， $$ \\begin{align} F_Z(z)\u0026amp;=\\int_{-\\infty}^0\\left(\\int_{yz}^{+\\infty}p(x,y)dx\\right)dy+\\int_0^{+\\infty}\\left(\\int_{-\\infty}^{yz}p(x,y)dx\\right)dy\\\\ \u0026amp;\\overset{x=yu}{=}\\int_{-\\infty}^0\\left(\\int_z^{-\\infty}p(yu,y)d(yu)\\right)dy+\\int_0^{+\\infty}\\left(\\int_{-\\infty}^zp(yu,y)d(yu)\\right)dy\\\\ \u0026amp;=\\int_{-\\infty}^z\\left(\\int_{-\\infty}^0p(yu,y)(-y)dy\\right)du+\\int_{-\\infty}^z\\left(\\int_0^{+\\infty}p(yu,y)ydy\\right)du\\\\ \u0026amp;=\\int_{-\\infty}^z\\left(\\int_{-\\infty}^{+\\infty}p(yu,y)|y|dy\\right)du \\end{align} $$ 因此密度函数 $$ p_Z(u)=\\int_{-\\infty}^{+\\infty}p(yu,y)|y|dy $$ 【例题】 (习题 3.28) $(X,Y)$ 的密度为 $p(x,y)=\\begin{cases}\\frac{1}{2}\u0026amp;,0\\leq x\\leq 2,0\\leq y\\leq 1\\\\0\u0026amp;,otherwise\\end{cases}$，求 $Z=XY$ 的密度。\n解：用反比例函数曲线 $z=xy$ 滑过平面，考虑曲线下方的部分。显然当 $z\u0026lt;0$ 时 $F_Z(z)=0$，$z\\geq 2$ 时 $F_Z(z)=1$。下面考虑 $0\\leq z\u0026lt;2$ 的部分： $$ F_Z(z)=\\int_0^z\\int_0^1\\frac{1}{2}dydx+\\int_z^2\\int_0^{\\frac{z}{x}}\\frac{1}{2}dydx=\\frac{z}{2}(\\ln 2+1-\\ln z) $$ 从而 $p_Z(z)=F_Z\u0026rsquo;(z)=\\frac{1}{2}(\\ln 2-\\ln z)$。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"975f9e13dc3952850abc64dc6bafa889","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec12/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec12/","section":"notes","summary":"【例】 (差的分布) 设 $(X,Y)$ 的密度为 $p(x,y)$，考虑 $Z=X-Y$ 的分布： $$ \\begin{align} F_Z(z)\u0026amp;=P(X-Y\\leq z)=\\iint_{{(x,y):x-y\\leq z}}p(x,y)dxdy\\\\ \u0026amp;=\\int_{-\\infty}^{+\\infty}\\left(\\int_{x-z}^{+\\infty}p(x,y)dy\\right)dx\\\\ \u0026amp;\\overset{y=x-v}{=}\\int_{-\\infty}^{+\\infty}\\int_z^{-\\infty}p(x,x-v)d(-v)dx\\\\ \u0026amp;=\\int_{-\\infty}^z\\left(\\int_{-\\infty}^{+\\infty}p(x,x-v)dx\\right)dv \\end{align} $$ 因此 $Z$ 的密度函数为 $$ p_Z(v)=\\int_{-\\infty}^{+\\infty}p(x,x-v)dx $$ 如果先积 x，可以类似地得到另一种表达式：$p_Z(u)=\\int_{-\\infty}^{+\\infty}p(y+u,y)dy$。\n【例题】 (习题 3.27) 设 $(X,Y)$ 的密度为 $p(x,y)=\\begin{cases}3x\u0026amp;,0\u0026lt;y\u0026lt;x\u0026lt;1\\\\0\u0026amp;,otherwise\\end{cases}$，求 $Z=X-Y$ 的密度。","tags":null,"title":" Lecture 12: More Examples of 2-Dimensional Random Variable Function","type":"docs"},{"authors":null,"categories":null,"content":"Expectation of Discrete Random Variables 离散型随机变量的数学期望类似于“加权平均数”，但我们要将频率换成严格的概率。\n$\\fbox{Definition 13.1}$ 设离散型随机变量 $X$ 的分布律为 $P(X=x_i)=p_i,i=1,2,\\cdots$。若级数 $\\sum_{i=1}^\\infty |x_i|p_i$ 收敛，则称 $$ E[x]\\triangleq \\sum_{i=1}^\\infty x_ip_i $$ 为 $X$ 的数学期望，简称均值或期望。\n注：(1) 分布唯一决定了期望。\n(2) 在定义中，我们要求级数 $\\sum_{i=1}^\\infty x_ip_i$ 绝对收敛，这是为了保证重排 $x_ip_i$ 的顺序不影响期望的值 (采样顺序不应影响均值)。\n(3) 当 $\\sum_{i=1}^\\infty |x_i|p_i$ 不收敛时，称 $X$ 的期望不存在。\n【例】考虑泊松分布 $P(\\lambda)$ 的期望。泊松分布的分布律为 $$ P(X=k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}\\qquad k=0,1,\\cdots $$ 因此 $$ \\begin{align} E[x]\u0026amp;=\\sum_{k=1}^\\infty kP(X=k)=\\sum_{k=1}^\\infty k\\frac{\\lambda^k}{k!}e^{-\\lambda}=e^{-\\lambda}\\sum_{k=1}^\\infty \\frac{\\lambda^k}{(k-1)!}\\\\ \u0026amp;=e^{-\\lambda}\\lambda\\cdot \\sum_{n=0}^{\\infty} \\frac{\\lambda^n}{n!}=e^{-\\lambda}\\cdot \\lambda\\cdot e^{\\lambda}\\\\ \u0026amp;=\\lambda \\end{align} $$ 【例】考虑二项分布 $X\\sim B(n,p)$ 的期望。二项分布的分布律为 $$ P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}\\qquad k=0,1,\\cdots, n $$ 因此 $$ \\begin{align} E[x]\u0026amp;=\\sum_{k=1}^\\infty kP(X=k)=\\sum_{k=1}^n k\\binom{n}{k}p^k(1-p)^{n-k}\\\\ \u0026amp;=\\sum_{k=1}^n \\frac{n!}{(k-1)!(n-k)!}p^k(1-p)^{n-k}\\\\ \u0026amp;=np\\sum_{k=1}^n\\frac{(n-1)!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k}\\\\ \u0026amp;=np\\sum_{k\u0026rsquo;=0}^{n-1}\\binom{n-1}{k\u0026rsquo;}p^{k\u0026rsquo;}(1-p)^{n-1-k\u0026rsquo;}\\\\ \u0026amp;=np\\cdot [p+(1-p)]^{n-1}\\\\ \u0026amp;=np \\end{align} $$ 【例】考虑几何分布 $X\\sim g(p)$ 的期望。几何分布的分布律为 $$ P(X=k)=(1-p)^{k-1}p\\qquad k=1,2,\\cdots $$ 因此 $$ \\begin{align} E[x]\u0026amp;=\\sum_{k=1}^\\infty kP(X=k)=\\sum_{k=1}^\\infty k(1-p)^{k-1}p=p\\sum_{k=1}^\\infty k(1-p)^{k-1} \\end{align} $$ 令 $$ F(p)=\\sum_{k=1}^\\infty (1-p)^k=\\frac{1-p}{p} $$ (注：$1-p\\in [0,1]$ 在收敛半径内，因此等式成立，后续的求导和求和可以交换。)\n则 $$ \\frac{d}{dp}F(p)=-\\sum_{k=1}^\\infty k(1-p)^{k-1} $$ 所以 $$ E[x]=-pF\u0026rsquo;(p)=-p\\cdot \\left(\\frac{1-p}{p}\\right)\u0026rsquo;=-p\\cdot -\\frac{1}{p^2}=\\frac{1}{p} $$ 【例】 (圣彼得堡悖论) 连续扔一枚均匀硬币，当出现反面时停止。若此前出现的正面次数为 $k$ 次，则收益为 $2^k$，求该游戏收益的期望。\n解：设收益为 $X$，则 $P(X=2^k)=\\frac{1}{2^{k+1}},k=0,1,\\cdots$ $$ E[x]=\\sum_{k=0}^\\infty x_kP(X=x_k)=\\sum_{k=0}^\\infty 2^k\\frac{1}{2^{k+1}}=\\sum_{k=0}^\\infty \\frac{1}{2}=+\\infty $$ 因此期望不存在。\n这是一个期望不存在的例子。有其他角度可以研究如何定价可以使该游戏公平。一个合理的定价是支付 $n\\log_2 n$ 玩 $n$ 次。\nExpectation of Continuous Random Variables $\\fbox{Definition 13.2}$ 设连续型随机变量 $X$ 的密度为 $p(x)$，若积分 $\\int_{-\\infty}^{+\\infty}|x|p(x)dx\u0026lt;+\\infty$，则称 $$ E[x]\\triangleq \\int_{-\\infty}^{+\\infty}xp(x)dx $$ 为 $X$ 的期望。\n注：若对 $\\mathbb R$ 取很密的划分 $$ \\begin{align} \u0026amp;0=x_0\u0026lt;x_1\u0026lt;\\cdots \u0026lt;x_n\u0026lt;\\cdots\u0026lt;+\\infty\\\\ \u0026amp;0=y_0\u0026gt;y_1\u0026gt;\\cdots \u0026gt;y_n\u0026gt;\\cdots\u0026gt;-\\infty \\end{align} $$ 把 $X$ 近似看成”随机变量“ $\\tilde{X}$，满足 $$ \\begin{align} \\tilde P(\\tilde X=x_k)\u0026amp;=p(x_k)(x_{k+1}-x_k),k\\geq 0\\\\ \\tilde P(\\tilde X=y_k)\u0026amp;=p(y_k)(y_{k-1}-y_k),k\\geq 1 \\end{align} $$ 则 $$ \\tilde E[\\tilde X]=\\sum_{k=0}^\\infty x_kp(x_k)(x_{k+1}-x_k)+\\sum_{k=1}^\\infty y_kp(y_k)(y_{k-1}-y_k) $$ 为 $E[x]$ 的渐进和式。\n【例】考虑指数分布 $X\\sim E(\\lambda)$ 的期望。指数分布的密度为 $$ p(x)=\\begin{cases}\\lambda e^{-\\lambda x}\u0026amp;,x\\geq 0\\\\0\u0026amp;,x\u0026lt;0\\end{cases} $$ 因此\n$$ \\begin{align} E[x]\u0026amp;=\\int_{-\\infty}^{+\\infty}xp(x)dx=\\int_0^{+\\infty}x\\cdot \\lambda e^{-\\lambda x}dx=-\\int_0^{+\\infty}xe^{-\\lambda x}d(-\\lambda x)=-\\int_{0}^{+\\infty}xd(e^{-\\lambda x})\\\\ \u0026amp;=\\left .-xe^{-\\lambda x}\\right|_{0}^{\\infty}+\\int_0^{+\\infty}e^{-\\lambda x}dx=-\\frac{1}{\\lambda}\\int_0^{+\\infty}e^{-\\lambda x}d(-\\lambda x)=\\left.-\\frac{e^{-\\lambda x}}{\\lambda}\\right|_0^{+\\infty}\\\\ \u0026amp;=\\frac{1}{\\lambda} \\end{align} $$\n【例】考虑正态分布 $X\\sim N(\\mu,\\sigma^2)$ 的期望。正态分布的密度为 $$ p(x)-\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} $$ 因此 $$ \\begin{align} E[x]\u0026amp;=\\int_{-\\infty}^{+\\infty}xp(x)dx=\\int_{-\\infty}^{+\\infty}x\\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}dx\\\\ \u0026amp;\\overset{y=x-\\mu}{=}\\int_{-\\infty}^{+\\infty}(y+\\mu)\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{y^2}{2\\sigma^2}}dy\\\\ \u0026amp;=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{+\\infty}ye^{-\\frac{y^2}{2\\sigma^2}}dy+\\mu\\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{+\\infty}e^{-\\frac{y^2}{2\\sigma^2}}dy \\end{align} $$ 第一项是奇函数在对称区域上的积分，为 0。第二项除了 $\\mu$ 后面的部分正好是正态分布全区域上的 $p(x$) 的积分，为 1，因此 $E[x]=\\mu$。\n【例】 连续型随机变量的期望也可能不存在。考虑柯西分布 $X$，$p(x)=\\frac{1}{\\pi(1+x^2)}$，求其期望。\n解： $$ \\begin{align} \\int_{-\\infty}^{+\\infty}|x|p(x)dx\u0026amp;=\\int_{-\\infty}^{+\\infty}\\frac{|x|dx}{\\pi(1+x^2)}=2\\int_0^{+\\infty}\\frac{xdx}{\\pi(1+x^2)}\\\\ \u0026amp;=\\frac{1}{\\pi}\\int_0^{+\\infty}\\frac{d(1+x^2)}{1+x^2}=\\left.\\frac{1}{\\pi}\\ln (1+x^2)\\right|_{0}^{+\\infty}=+\\infty \\end{align} $$ 因此期望不存在。\n注：微妙的一点是：柯西分布的密度函数是关于 $y$ 轴对称的，但这并不能说明期望存在且等于 0。\nExpectation of Random Variable Functions 设 $X$ 的分布已知，$Y=g(X)$，可通过下面的定理求 $E[Y]$ 而不必先求出 $Y$ 的分布再求期望：\n$\\fbox{Theorem 13.3}$ 若 $X$ 为离散随机变量，分布律为 $P(X=x_k)=p_k,k=1,2,\\cdots$，若 $\\sum_{k=1}^\\infty |g(x_k)|p_k\u0026lt;+\\infty$，则 $$ E[Y]=E[g(x)]=\\sum_{k=1}^{\\infty} g(x_k)p_k $$ 若 $X$ 为连续型随机变量，密度为 $p(x)$，且期望存在，则 $$ E[Y]=E[g(X)]=\\int_{-\\infty}^{+\\infty}g(x)p(x)dx $$\n证明：这里仅讨论离散情形的证明。设 $Y=g(X)$ 的取值为 $y_1,y_2,\\cdots$，$Y$ 显然也是离散型随机变量。记 $A_n={X的取值}\\cap {x|g(x)=y_n}={x_n^1,x_n^2,\\cdots}$，则 $A$ 构成了全空间 $\\Omega$ 的一个划分。 $$ \\begin{align} E[Y]\u0026amp;=\\sum_{n=1}^\\infty y_nP(X\\in A_n)=\\sum_{n=1}^\\infty y_n\\sum_{m=1}^\\infty P(X=x_n^m)\\\\ \u0026amp;=\\sum_{n=1}^\\infty \\sum_{m=1}^\\infty y_nP(X=x_n^m)=\\sum_{n=1}^\\infty\\sum_{m=1}^\\infty g(x_n^m)P(X=x_n^m)\\\\ \u0026amp;=\\sum_{n=1}^\\infty \\sum_{x\\in A_n}g(x)P(X=x)\\\\ \u0026amp;=\\sum_{k=1}^\\infty g(x_k)P(X=x_k)\\qquad \\blacksquare \\end{align} $$\n对于二维随机变量函数我们也有类似的结论：\n$\\fbox{Theorem 13.4}$ 设 $(X,Y)$ 为二维随机变量，$Z=g(X,Y)$。\n(1) 离散情形：$(X,Y)$ 有分布律 $P(X=x_i,Y=y_j)=p_{i,j}$。若期望存在，那么 $$ E[Z]=E[g(X,Y)]=\\sum_{i=1}^\\infty\\sum_{j=1}^\\infty g(x_i,y_j)p_{i,j} $$ (2) 连续情形：$(X,Y)$ 的密度函数为 $p(x,y)$，若期望存在，则 $$ E[Z]=E[g(X,Y)]=\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}g(x,y)p(x,y)dxdy $$ 【例题】 (习题 4.5) 商品出口需求 $X\\sim U[2000,4000]$，售出 1 单位商品可以获得 3 万元收益，不能售出要倒贴 1 万元。问应出口多少吨才能得到最大收益。\n解：设出口量为 $y$，显然有 $2000\\leq y\\leq 4000$。令收益为 $Z$： $$ Z=g(X)=\\begin{cases}3y\u0026amp;,X\u0026gt;y\\\\3X-(y-X)\u0026amp;,X\\leq y\\end{cases} $$ 考虑 $Z$ 的期望： $$ \\begin{align} E[Z]\u0026amp;=E[g(X)]=\\int_{-\\infty}^{+\\infty}g(x)p(x)dx=\\int_{2000}^{4000}g(x)\\frac{1}{2000}dx\\\\ \u0026amp;=\\frac{1}{2000}\\left(\\int_{2000}^y(4x-y)dx+\\int_y^{4000}3ydx\\right)\\\\ \u0026amp;=\\frac{1}{1000}(-y^2+7000y-4\\cdot 10^6) \\end{align} $$ 当 $y=3500$ 时期望收益最大。\nProperties of Expectation 若随机变量 $X\\equiv a$，则 $E[x]=a$。\n对于任意常数 $a,b$，有 $E[aX+bY]=aE[X]+bE[Y]$。\n证明：这里的证明考虑 $X,Y$ 是离散型随机变量的情况：\n设 $X,Y$ 的分布律为 $P(X=x_i,Y=y_j)=p_{ij}$，那么 $$ \\begin{align} E[aX+bY]\u0026amp;=\\sum_{i=1}^\\infty\\sum_{j=1}^\\infty(ax_i+by_j)p_{ij}\\\\ \u0026amp;=a\\sum_{i=1}^\\infty x_i\\sum_{j=1}^\\infty p_{ij}+b\\sum_{j=1}^\\infty y_j\\sum_{i=1}^\\infty p_{ij}\\\\ \u0026amp;=a\\sum_{i=1}^\\infty x_ip_{i\\cdot}+b\\sum_{j=1}^\\infty y_jp_{\\cdot j}\\\\ \u0026amp;=aE[X]+bE[Y] \\end{align} $$\n若 $X,Y$ 独立，则 $E[XY]=E[X]E[Y]$。\n证明：这里的证明考虑 $X,Y$ 是离散型随机变量的情况：\n设 $X,Y$ 的分布律为 $P(X=x_i,Y=y_j)=p_{ij}$，因为 $X,Y$ 相互独立，所以 $p_{ij}=p_{i\\cdot}\\cdot p_{\\cdot j}$。那么 $$ \\begin{align} E(XY)\u0026amp;=\\sum_{i=1}^\\infty\\sum_{j=1}^\\infty x_iy_jp_{ij}\\\\ \u0026amp;=\\sum_{i=1}^\\infty\\sum_{j=1}^\\infty x_iy_jp_{i\\cdot }p_{\\cdot j}\\\\ \u0026amp;=\\left(\\sum_{i=1}^\\infty x_ip_{i\\cdot }\\right)\\left(\\sum_{j=1}^\\infty y_jp_{\\cdot j}\\right)\\\\ \u0026amp;=E[X]E[Y] \\end{align} $$\n利用期望的线性性，我们可以很方便地解决一些问题，比如考虑 $X\\sim B(n,p)$ 的期望，令 $x_i$ 表示第 $i$ 次实验是否成功的示性随机变量 i.e. $x_i=\\begin{cases}1\u0026amp;,第i次实验成功\\\\0\u0026amp;,otherwise\\end{cases}$，容易发现 $E(x_i)=P(x_i=1)=p$。那么 $$ E[X]=E\\left[\\sum_{i=1}^nx_i\\right]=\\sum_{i=1}^nE[x_i]=\\sum_{i=1}^nP(x_i=1)=np. $$ 再举一例，设 $X$ 服从超几何分布，考虑 $X$ 的期望。类似地，我们令示性随机变量 $x_i$ 刻画第 $i$ 个次品被抽中的情况，显然有 $P(x_i=1)=\\frac{\\binom{N-1}{n-1}}{\\binom{N}{n}}=\\frac{n}{N}$ (分子的意义是：保证该次品被抽中，剩下的 $n-1$ 个物品随便抽)，那么 $$ E[x]=E\\left[\\sum_{i=1}^Mx_i\\right]=\\sum_{i=1}^ME[x_i]=\\sum_{i=1}^M\\frac{n}{N}=\\frac{nM}{N}. $$ 【例题】 (习题 4.8) $n$ 个人无放回拿 $n$ 个帽子，求拿到自己的帽子的人数的期望。\n解：令 $x_i$ 是刻画第 $i$ 个人是否拿到帽子的示性随机变量，那么 $$ E[X]=E\\left[\\sum_{i=1}^nx_i\\right]=\\sum_{i=1}^nE[x_i]=\\sum_{i=1}^n\\frac{(n-1)!}{n!}=1. $$\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"03e661b54a38ecaf3b015fc4e4532cb7","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec13/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec13/","section":"notes","summary":"Expectation of Discrete Random Variables 离散型随机变量的数学期望类似于“加权平均数”，但我们要将频率换成严格的概率。\n$\\fbox{Definition 13.1}$ 设离散型随机变量 $X$ 的分布律为 $P(X=x_i)=p_i,i=1,2,\\cdots$。若级数 $\\sum_{i=1}^\\infty |x_i|p_i$ 收敛，则称 $$ E[x]\\triangleq \\sum_{i=1}^\\infty x_ip_i $$ 为 $X$ 的数学期望，简称均值或期望。\n注：(1) 分布唯一决定了期望。\n(2) 在定义中，我们要求级数 $\\sum_{i=1}^\\infty x_ip_i$ 绝对收敛，这是为了保证重排 $x_ip_i$ 的顺序不影响期望的值 (采样顺序不应影响均值)。","tags":null,"title":"Lecture 13: Mathematical Expectation","type":"docs"},{"authors":null,"categories":null,"content":"我们希望衡量一个随机变量每个取值和平均值的差异，并且希望这个值是正数。因此我们引入方差的概念。\n$\\fbox{Definition 14.1}$ 设 $X$ 是一个随机变量。若 $E[|X|^2]$ 存在，则称 $$ D(X)\\triangleq E[(X-E[x])^2] $$ 为 $X$ 的方差，同时称 $\\sigma(X)\\triangleq \\sqrt{D(X)}$ 为 $X$ 的均方差/标准差。\n注：(1) $(X-E[X])^2$ 的数学性质好于 $|X-E[X]|$，比如可导性，以及代数运算时的方便性。\n(2) $E[X^2]\u0026lt;+\\infty$ 可以推出 $E[X]\u0026lt;+\\infty$ (反过来不成立)。\n(3) 对于离散型随机变量，设 $P(X=x_i)=p_i$，则 $$ D(X)=\\sum_{k=1}^\\infty(x_k-E[X])^2p_k $$ 对于连续型随机变量，设密度函数为 $p(x)$，则 $$ D(X)=\\int_{-\\infty}^{+\\infty}(x-E[X])^2p(x)dx $$ (4) 方差公式还有另外一种形式： $$ \\begin{align} D(X)\u0026amp;=E[(X-E[X])^2]\\\\ \u0026amp;=E[X^2-2E[X]X+E[X]^2]\\\\ \u0026amp;=E[X^2]-E[2E[X]X]+E[E[X]^2]\\\\ \u0026amp;=E[X^2]-2E[X]^2+E[X]^2\\\\ \u0026amp;=E[X^2]-E[X]^2 \\end{align} $$ 从这个公式中我们可以看出：$D(X)\\leq E[X^2]$。\n【例】考虑 $X\\sim B(n,p)$ 的方差。$X$ 的分布律为 $P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}$。我们已知 $E[X]=np$，因此只需要求 $E[X^2]$。 $$ \\begin{align} E[X^2]\u0026amp;=\\sum_{k=1}^nk^2\\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\\\\ \u0026amp;=\\sum_{k=1}^nk\\frac{n!}{(k-1)!(n-k)!}p^k(1-p)^{n-k}\\\\ \u0026amp;=\\sum_{k=1}^n(k-1)\\frac{n!}{(k-1)!(n-k!)}p^k(1-p)^{n-k}+\\sum_{k=1}^n\\frac{n!}{(k-1)!(n-k)!}p^k(1-p)^{n-k}\\\\ \u0026amp;=n(n-1)p^2\\sum_{k=2}^n\\frac{(n-2)!}{(k-2)!(n-k)!}p^{k-2}(1-p)^{n-k}+np\\sum_{k=1}^n\\frac{(n-1)!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k}\\\\ \u0026amp;=n(n-1)p^2[1+(1-p)]^{n-2}+np[1+(1-p)]^{n-1}\\\\ \u0026amp;=n(n-1)p^2+np \\end{align} $$ 因此 $D(X)=E[X^2]-E[X]^2=np-np^2=np(1-p)$。\n【例】考虑 $X\\sim p(\\lambda)$ 的泊松分布的方差。$X$ 的分布律为 $P(X=k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}$，我们已知 $E[X]=\\lambda$，因此只需要求 $E[X^2]$。 $$ \\begin{align} E[X^2]\u0026amp;=\\sum_{k=1}^\\infty k^2\\frac{\\lambda^k}{k!}e^{-\\lambda}=\\sum_{k=1}^\\infty k\\frac{\\lambda^k}{(k-1)!}e^{-\\lambda}\\\\ \u0026amp;=\\sum_{k=1}^\\infty(k-1)\\frac{\\lambda^k}{(k-1)!}e^{-\\lambda}+\\sum_{k=1}^\\infty\\frac{\\lambda^k}{(k-1)!}e^{-\\lambda}\\\\ \u0026amp;=\\lambda^2\\sum_{k=2}^\\infty\\frac{\\lambda^{k-2}}{(k-2)!}e^{-\\lambda}+\\lambda\\sum_{k=1}^\\infty\\frac{\\lambda^{k-1}}{(k-1)!}e^{-\\lambda}\\\\ \u0026amp;=\\lambda^2+\\lambda \\end{align} $$ 因此 $D(X)=E[X^2]-E[X]^2=\\lambda$。\n【例】 考虑指数分布 $X\\sim E(\\lambda)$ 的方差。$X$ 的密度函数为 $p(x)=\\begin{cases}\\lambda e^{-\\lambda x}\u0026amp;,x\u0026gt;0\\\\0\u0026amp;,x\\leq 0\\end{cases}$。我们已知 $E[X]=\\frac{1}{\\lambda}$，因此只需要求 $E[X^2]$。 $$ \\begin{align} E[X^2]\u0026amp;=\\int_{-\\infty}^{+\\infty}x^2p(x)dx=\\int_0^{+\\infty}x^2\\lambda e^{-\\lambda x}dx=-\\int_0^{+\\infty}x^2e^{-\\lambda x}d(-\\lambda x)\\\\ \u0026amp;=-\\int_0^{+\\infty}x^2d(e^{-\\lambda x})=\\left.x^2e^{-\\lambda x}\\right|_0^{+\\infty}+2\\int_0^{+\\infty}xe^{-\\lambda x}dx\\\\ \u0026amp;=\\frac{2}{\\lambda}\\int_0^{+\\infty}x\\lambda e^{-\\lambda x}dx\\\\ \u0026amp;=\\frac{2}{\\lambda}E[X]=\\frac{2}{\\lambda^2} \\end{align} $$ 因此 $D(X)=E[X^2]-E[X]^2=\\frac{1}{\\lambda^2}$。\n【例】考虑正态分布 $X\\sim N(\\mu, \\sigma^2)$ 的方差。$X$ 的密度函数为 $p(x)=\\frac{1}{\\sqrt {2\\pi }\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$。我们容易发现这里直接方差的原始定义式计算会更加方便： $$ \\begin{align} D(X)\u0026amp;=E[(X-E[X])^2]=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{+\\infty}(x-\\mu)^2e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}dx\\\\ \u0026amp;\\overset{y=\\frac{x-\\mu}{\\sigma}}{=}\\frac{\\sigma^2}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}y^2e^{-\\frac{y^2}{2}}dy\\\\ \u0026amp;=-\\frac{\\sigma^2}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}yd\\left(e^{-\\frac{y^2}{2}}\\right)\\\\ \u0026amp;=\\left.-\\frac{\\sigma^2}{\\sqrt{2\\pi}}ye^{-\\frac{y^2}{2}}\\right|_{-\\infty}^{+\\infty}+\\sigma^2\\cdot \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}e^{-\\frac{y^2}{2}}dy\\\\ \u0026amp;=0+\\sigma^2\\cdot (标准正态分布在 \\mathbb R 上的密度函数积分)\\\\ \u0026amp;=\\sigma^2 \\end{align} $$ 方差的性质：\n若 $X\\equiv a$，则 $D(X)=E[(X-a)^2]=0$ 。\n若 $D(X)$ 存在，对于任意 $a,b\\in \\mathbb R$，$D(aX+b)=a^2D(X)$。\n证明： $$ \\begin{align} D(aX+b)\u0026amp;=E[(aX+b-E[aX+b])^2]\\\\ \u0026amp;=E[(aX+b-aE[X]-b)^2]\\\\ \u0026amp;=E[(a(X-E[X]))^2]\\\\ \u0026amp;=a^2D(X) \\end{align} $$\n直观来看这个公式也容易理解：全局加上 $b$ 不影响对期望的偏离；全局乘 $a$ 在 L2 偏差下最终反映为 $a^2$。\n在该性质的支撑下，对于随机变量 $X$，若 $D(X)$ 存在，考虑 $Z=\\frac{X-E[X]}{\\sqrt{D(X)}}$，则 $E[Z]=0$，$D(Z)=\\left(\\frac{1}{\\sqrt{D(X)}}\\right)^2D(X)=1$，因此称 $Z$ 为 $X$ 的标准化。(标准正态分布和正态分布之间的转化是该公式的一个特例)。\n设 $X,Y$ 为随机变量，则 $D(X\\pm Y)=D(X)+D(Y)\\pm 2E[(X-E )(Y-E(Y))]$。\n证明：这里只证 + 的情况，- 的情况同理。 $$ \\begin{align} D(X+Y)\u0026amp;=E[(X+Y-E[X+Y])^2]=E[((X-E[X])+(Y-E[Y]))^2]\\\\ \u0026amp;=E[(X-E[X])^2]+E[(Y-E[Y])^2]+2E[(X-E[X])(Y-E[Y])]\\\\ \u0026amp;=D(X)+D(Y)+2E[(X-E[X])(Y-E[Y])] \\end{align} $$\n特别地，若 $X,Y$ 独立，则 $X-E[X], Y-E[Y]$ 也独立，则 $$ E[(X-E[X])(Y-E[Y])]=E[X-E[X]]E[Y-E[Y]]=0 $$ 从而 $D(X\\pm Y)=D(X)+D(Y)$ (注意符号！)。\n上述结论可以推广到 $n$ 个随机变量的情形： $$ D\\left(\\sum_{i=1}^nx_i\\right)=\\sum_{i=1}^nD(x_i)-\\sum_{1\\leq i\u0026lt;j\\leq n}E[(x_i-E[x_i])(x_j-E[x_j])] $$ 若这些变量两两独立 (注意，该条件比 $n$ 个变量的独立性弱！)，则 $$ D\\left(\\sum_{i=1}^nx_i\\right)=\\sum_{i=1}^nD(x_i) $$\n对于任意 $c\\in \\mathbb R$，$D(X)\\leq E[(X-c)^2]$。\n证明： $$ \\begin{align} D(X)\u0026amp;=E[(X-E[X])^2]=E[(X-c+c-E[X])^2]\\\\ \u0026amp;=E[(X-c)^2]+2E[(X-c)(c-E[X])]+E[(c-E[X])^2]\\\\ \u0026amp;=E[(X-c)^2]+2(c-E[X])(E[X]-c)+(c-E[X])^2\\\\ \u0026amp;=E[(X-c)^2]-(c-E[X])^2\\\\ \u0026amp;\\leq E[(X-c)^2] \\end{align} $$\n利用期望的可拆分性 (性质 3) 有时能大幅简化计算过程，这里以二项分布 $X\\sim B(n,p)$ 为例。令 $x_i$ 为描述第 $i$ 次实验是否成功的示性随机变量，显然 $x_1,\\cdots, x_n$ 两两独立。那么 $$ \\begin{align} D(X)\u0026amp;=D\\left(\\sum_{i=1}^nx_i\\right)=\\sum_{i=1}^nD(x_i)=nD(x_1)\\\\ \u0026amp;=nE[(x_1-E[x_1])^2]=n((1-p)^2p+(0-p)^2(1-p))\\\\ \u0026amp;=np(1-p) \\end{align} $$\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"699d77816fd43bef3682cbbd9c6eaabc","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec14/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec14/","section":"notes","summary":"我们希望衡量一个随机变量每个取值和平均值的差异，并且希望这个值是正数。因此我们引入方差的概念。\n$\\fbox{Definition 14.1}$ 设 $X$ 是一个随机变量。若 $E[|X|^2]$ 存在，则称 $$ D(X)\\triangleq E[(X-E[x])^2] $$ 为 $X$ 的方差，同时称 $\\sigma(X)\\triangleq \\sqrt{D(X)}$ 为 $X$ 的均方差/标准差。\n注：(1) $(X-E[X])^2$ 的数学性质好于 $|X-E[X]|$，比如可导性，以及代数运算时的方便性。\n(2) $E[X^2]\u0026lt;+\\infty$ 可以推出 $E[X]\u0026lt;+\\infty$ (反过来不成立)。\n(3) 对于离散型随机变量，设 $P(X=x_i)=p_i$，则 $$ D(X)=\\sum_{k=1}^\\infty(x_k-E[X])^2p_k $$ 对于连续型随机变量，设密度函数为 $p(x)$，则 $$ D(X)=\\int_{-\\infty}^{+\\infty}(x-E[X])^2p(x)dx $$ (4) 方差公式还有另外一种形式： $$ \\begin{align} D(X)\u0026amp;=E[(X-E[X])^2]\\\\ \u0026amp;=E[X^2-2E[X]X+E[X]^2]\\\\ \u0026amp;=E[X^2]-E[2E[X]X]+E[E[X]^2]\\\\ \u0026amp;=E[X^2]-2E[X]^2+E[X]^2\\\\ \u0026amp;=E[X^2]-E[X]^2 \\end{align} $$ 从这个公式中我们可以看出：$D(X)\\leq E[X^2]$。","tags":null,"title":"Lecture 14: Variance","type":"docs"},{"authors":null,"categories":null,"content":"$\\fbox{Theorem 15.1}$ (Chebyshev) 设随机变量 $X$ 的方差存在，则有 $$ \\forall \\varepsilon\u0026gt;0,P(|X-E[X]|\u0026gt;\\varepsilon)\\leq \\frac{D(X)}{\\varepsilon^2} $$ 证明：设 $X$ 存在密度函数 $p(x)$，则 $$ \\begin{align} P(|X-E[X]|\u0026gt;\\varepsilon)\u0026amp;=\\int_{{x:|X-E[X]|\u0026gt;\\varepsilon}}p(x)dx\\\\ \u0026amp;\\leq \\int_{{x:|X-E[X]|\u0026gt;\\varepsilon}}\\frac{|X-E[x]|^2}{\\varepsilon^2}p(x)dx\\\\ \u0026amp;\\leq \\frac{1}{\\varepsilon^2}\\int_{-\\infty}^{+\\infty}|X-E[X]|^2p(x)dx\\\\ \u0026amp;=\\frac{D(X)}{\\varepsilon^2}\\qquad \\blacksquare \\end{align} $$ 我们的证明过程中使用了两次看上去很“松”的放缩，但下面的例子可以说明，在对 $X$ 没有任何额外限制的情况下，Chebyshev 的结果已经是最紧的了：\n例：设 $X$ 的分布律为 $P(X=1)=P(X=-1)=\\frac{1}{2k^2}$，$P(X=0)=1-\\frac{1}{k^2}$，显然有 $E[X]=0$。那么 $$ P(|X-E[x]|\\geq 1)=P(X=\\pm 1)=\\frac{1}{k^2}\\leq \\frac{D(X)}{\\varepsilon^2}=\\frac{1/k^2}{1^2}=\\frac{1}{k^2} $$ 【例题】用 Chebyshev 不等式证明：如果随机变量 $X$ 满足 $D(X)=0$，则 $P(X=E[X])=1$。\n证明：令 $A={w:|X(w)-E[X]|\u0026gt;0}$，我们要证明的目标是 $P(A)=0$。\n令 $A_n={w:|X(w)-E[X]|\u0026gt;\\frac{1}{n}}$，那么显然有 $A=\\bigcup_{n=1}^\\infty A_n$，从而 $$ P(A)=P(\\bigcup_{n=1}^\\infty A_n)\\leq \\sum_{n=1}^\\infty P(A_n)=\\sum_{n=1}^\\infty P(X-E[X]\u0026gt;\\frac{1}{n})\\leq \\sum_{n=1}^\\infty \\frac{1}{n^2}D(X)=0 $$ 又 $P(A)\\geq 0$，所以 $P(A)=0$。\n（注：第一个不等号是 union bound。注意 $A_n$ 之间不是互不相交的，所以不能用“可列可加性”。）\nCovariance $\\fbox{Definition 15.2}$ $X,Y$ 为随机变量，$E[X],E[Y],E[XY]$ 均存在，则 $$ cov(X,Y)\\triangleq E[(X-E[X])(Y-E[Y])] $$ 为 $X$ 和 $Y$ 的协方差。\n注：(1) $cov(X,X)=D(X)$。\n(2) $D(X\\pm Y)=D(X)+D(Y)\\pm 2cov(X,Y)$。\n一般地， $$ D(\\sum_{k=1}^nX_k)=\\sum_{k=1}^nD(X_k)+2\\sum_{1\\leq i\u0026lt;j\\leq n}cov(X_i,X_j). $$ (3) $cov(X,Y)=E[XY-XE[Y]-YE[X]+E[X]E[Y]]=E[XY]-E[X]E[Y]$。\n(4) $cov(X,Y)\u0026gt;0$ 说明 $X$ 和 $Y$ 有很大倾向同时大于或小于各自的期望；$cov(X,Y)\u0026lt;0$ 说明 $X$ 和 $Y$ 有很大倾向一个大于自身期望，一个小于自身期望。\n(5) $cov(X,Y)$ 依赖于单位。比如如果将两者的单位本来是米，将它们改成毫米，协方差的数值将会变大很多。因此协方差不是一个很好的衡量相关性的客观数值。\n协方差的性质：\n$cov(X,Y)=cov(Y,X)$。\n对于任意 $a,b,c,d\\in \\mathbb R$，$cov(aX+c,bY+d)=abcov(X,Y)$。\n证明： $$ \\begin{align} cov(aX+c,bY+d)\u0026amp;=E[(aX+c)(bY+d)]-E[aX+c]E[bY+d]\\\\ \u0026amp;=E[abXY+adX+bcY+cd]-(aE[X]+c)(bE[Y]+d)\\\\ \u0026amp;=abE[XY]-abE[X]E[Y]\\\\ \u0026amp;=abcov(X,Y) \\end{align} $$\n$cov(X_1+X_2,Y)=cov(X_1,Y)+cov(X_2,Y)$。\n证明： $$ \\begin{align} cov(X_1+X_2,Y)\u0026amp;=E[(X_1+X_2)Y]-E[X_1+X_2]E[Y]\\\\ \u0026amp;=E[X_1Y]+E[X_2Y]-E[X_1]E[Y]-E[X_2]E[Y]\\\\ \u0026amp;=cov(X_1,Y)+cov(X_2,Y) \\end{align} $$\n若 $X,Y$ 独立，则 $cov(X,Y)=0$。\n证明：$cov(X,Y)=E[XY]-E[X]E[Y]=E[X]E[Y]-E[X]E[Y]=0$。\n下面展示一个比较精巧的计算协方差的例子：\n【例】设 $(X,Y)$ 服从参数为 $n,p_1,p_2$ 的三项分布，即对于任意 $i,j$，$i+j\\leq n$， $$ P(X=i,Y=j)=\\frac{n!}{i!j!(n-i-j)!}p_1^ip_2^j(1-p_1-p_2)^{n-i-j} $$ 考虑计算 $cov(X,Y)$。我们发现利用定义计算非常麻烦，但考虑公式 $$ D(X+Y)=D(X)+D(Y)+2cov(X,Y) $$ 这三个方差都很容易求：因为 $X\\sim B(n,p_1),Y\\sim B(n,p_2),X+Y\\sim B(n,p_1+p_2)$，所以 $$ \\begin{align} cov(X,Y)\u0026amp;=\\frac{1}{2}(D(X+Y)-D(X)-D(Y))\\\\ \u0026amp;=\\frac{1}{2}(n(p_1+p_2)(1-p_1-p_2)-np_1(1-p_2)-np_2(1-p_2))\\\\ \u0026amp;=-np_1p_2 \\end{align} $$ $\\fbox{Theorem 15.3}$ (Cauchy-Schwarz) 设随机变量 $X,Y$ 的方差都存在，则 $$ (cov(X,Y))^2\\leq D(X)D(Y) $$ 其中等号取到当且仅当存在不全为 0 的常数 $a,b$，使得 $P(Y=aX+b)=1$。\n证明：对于任意 $t\\in \\mathbb R$，令 $$ u(t)=E[(t(X-E[X])-(Y-E[Y]))^2]\\geq 0 $$ 那么 $$ \\begin{align} u(t)\u0026amp;=t^2E[(X-E[X])^2]-2tE[(X-E[X])(Y-E[Y])]+E[(Y-E[Y])^2]\\\\ \u0026amp;=t^2D(X)-2tcov(X,Y)+D(Y) \\end{align} $$ 因为 $u(t)\\geq 0$，所以二次函数判别式小于等于 0，即 $(cov(X,Y))^2\\leq D(X)D(Y)$。\n下面考虑等号成立的条件：\n$\\Rightarrow:$ 若 $(cov(X,Y))^2=D(X)D(Y)$，那么存在 $t_0\\in \\mathbb R$，$u(t_0)=0$。令 $Z=t_0(X-E[X])-(Y-E[Y])$，则 $$ 0=u(t_0)=E[Z^2]\\geq D(Z)\\geq 0 $$ 所以 $D(Z)=0$，$P(Z=E[Z])=P(Z=0)=1$。\n$\\Leftarrow:$ 若存在不全为 0 的 $a,b\\in \\mathbb R$ 满足 $P(Y=aX+b)=1$，那么 $$ \\begin{align} cov(X,Y)\u0026amp;=E[XY]-E[X]E[Y]\\\\ \u0026amp;=E[X(aX+b)]-E[X]E[aX+b]\\\\ \u0026amp;=aE[X^2]+bE[X]-a(E[X])^2-bE[X]\\\\ \u0026amp;=aD(X)=\\pm \\sqrt{a^2D(X)^2} \\end{align} $$ 注意到 $D(Y)=D(aX+b)=a^2D(X)$，所以 $cov(X,Y)=\\pm \\sqrt{D(X)D(Y)}$。$\\blacksquare$\nCorrelation Coefficient 由 Cauchy-Schwarz 不等式可知，$D(X),D(Y)\u0026gt;0$ 时，$\\left|\\frac{cov(X,Y)}{\\sqrt{D(X)D(Y)}}\\right|\\leq 1$，我们在此基础上定义相关系数。\n$\\fbox{Definition 15.4}$ 设随机变量 $X,Y$ 方差均存在，$D(X)\u0026gt;0,D(Y)\u0026gt;0$，则令 $$ \\rho_{XY}\\triangleq \\frac{cov(X,Y)}{\\sqrt{D(X)D(Y)}} $$ 为 $X,Y$ 的相关系数，也可记作 $corr(X,Y)$。若 $\\rho_{XY}\u0026gt;0$，则称 $X,Y$ 正相关；若 $\\rho_{XY}\u0026lt;0$，则称 $X,Y$ 负相关。\n注：(1) 考虑 $X,Y$ 的标准化随机变量 $X^*=\\frac{X-E[X]}{\\sqrt{D(X)}},Y^*=\\frac{Y-E[Y]}{\\sqrt{D(Y)}}$，那么 $$ cov(X^*,Y^*)=E[(X^*-E[X^*])(Y^*-E[Y^*])]=E\\left[\\frac{X-E[X]}{\\sqrt{D(X)}}\\cdot \\frac{Y-E[Y]}{\\sqrt{D(Y)}}\\right]=\\frac{cov(X,Y)}{\\sqrt{D(X)D(Y)}}=\\rho_{XY} $$ 即标准化后的随机变量的协方差等于其原变量的相关系数。\n(2) $\\rho_{XY}$ 不依赖 $X,Y$ 数量级的选取。\n(3) 根据 Cauchy-Schwarz 的取等条件，$|\\rho_{XY}=1|$ 当且仅当 $|cov(X,Y)|=\\sqrt{D(X)D(Y)}$，即存在不全为 0 的常数 $a,b$，$P(Y=aX+b)=1$。$\\rho_{XY}$ 刻画了 $X,Y$ 之间线性相关的程度，$|\\rho_{XY}|$ 越大，$X,Y$ 的线性关系就越密切。\n$\\fbox{Definition 15.5}$ 若 $X,Y$ 满足 $\\rho_{XY}=0$，则称 $X,Y$ 线性无关或不相关。\n$\\fbox{Proposition 15.6}$ 在 $X,Y$ 方差存在的情况下，下述 4 条等价：\n$\\rho_{XY}=0$。 $cov(X,Y)=0$。 $E[XY]=E[X]E[Y]$。 $D(X\\pm Y)=D(X)+D(Y)$。 根据上述命题，我们容易发现如果 $X,Y$ 相互独立，那么 $\\rho_{XY}=0$，但反之不成立，即不相关是比相互独立弱的条件，下面是一个例子：\n【例】设 $\\theta$ 服从 $[0,2\\pi]$ 上的均匀分布，令 $X=\\cos \\theta,Y=\\cos (\\theta+a)$，其中 $a$ 为给定常数，考虑 $\\rho_{XY}$。 $$ \\begin{align} E[X]\u0026amp;=\\int_0^{2\\pi}xp(x)dx=\\frac{1}{2\\pi}\\int_0^{2\\pi}\\cos xdx=0\\\\ E[Y]\u0026amp;=\\frac{1}{2\\pi}\\int_0^{2\\pi}\\cos(x+a)dx=0\\\\ D(X)\u0026amp;=E[(X-0)^2]=\\frac{1}{2\\pi}\\int_0^{2\\pi}\\cos ^2xdx=\\frac{1}{4\\pi}\\int_0^{2\\pi}(1+\\cos 2x)dx=\\frac{1}{2}\\\\ D(Y)\u0026amp;=E[(Y-0)^2]=\\frac{1}{2\\pi}\\int_0^{2\\pi}\\cos ^2(x+a)dx=\\frac{1}{4\\pi}\\int_0^{2\\pi}(1+\\cos 2(x+a))dx=\\frac{1}{2}\\\\ E[XY]\u0026amp;=E[\\cos \\theta \\cos (\\theta +a)]=\\frac{1}{2\\pi}\\int_0^{2\\pi}\\cos x\\cos (x+a)dx\\\\ \u0026amp;\\overset{和差化积}{=}\\frac{1}{4\\pi}(\\int_0^{2\\pi}\\cos(2x+a)+\\cos a)dx=\\frac{1}{2}\\cos a\\\\ \\rho_{XY}\u0026amp;=\\frac{cov(X,Y)}{\\sqrt{D(X)D(Y)}}=\\frac{\\frac{1}{2}cos a}{\\sqrt{\\frac{1}{2}\\cdot \\frac{1}{2}}}=\\cos a \\end{align} $$ 当 $a=\\frac{3\\pi}{2}$ 时，$\\rho_{XY}=0$，$X,Y$ 不相关。此时 $X=\\cos \\theta,Y=\\cos (\\theta+a)=\\sin \\theta$，有 $X^2+Y^2=1$。\n考虑如下事件的概率：$P(|X|\\leq \\frac{1}{2},|Y|\\leq \\frac{1}{2})$，因为 $X^2+Y^2=1$，所以该概率为 0。但 $P(|X|\\leq \\frac{1}{2})\u0026gt;0$，$P(|Y|\\leq \\frac{1}{2})\u0026gt;0$，从而 $P(|X|\\leq \\frac{1}{2},|Y|\\leq \\frac{1}{2})\\neq P(|X|\\leq \\frac{1}{2})\\cdot P(|Y|\\leq \\frac{1}{2})$，所以 $X,Y$ 不相互独立。\n【例题】设 $(X,Y)\\sim N(\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2,\\rho)$，求 $cov(X,Y)$ 和 $\\rho_{XY}$。\n解： $$ p(x,y)=\\frac{1}{2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}e^{-\\frac{1}{2(1-\\rho^2)}\\left[\\left(\\frac{x-\\mu_1}{\\sigma_1}\\right)^2-2\\rho \\left(\\frac{x-\\mu_1}{\\sigma_1}\\cdot \\frac{y-\\mu_2}{\\sigma_2}\\right)+\\left(\\frac{y-\\mu_2}{\\sigma_2}\\right)^2\\right]} $$ 我们已知 $E[X]=\\mu_1,E[Y]=\\mu_2,D(X)=\\sigma_1^2,D(Y)=\\sigma_2^2$。 $$ \\begin{align} cov(X,Y)\u0026amp;=E[(X-E[X])(Y-E[Y])]=\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}(x-\\mu_1)(y-\\mu_2)p(x,y)dxdy\\\\ \u0026amp;\\overset{u=\\frac{x-\\mu_1}{\\sigma_1},v=\\frac{y-\\mu_2}{\\sigma_2}}{=}\\frac{1}{2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}\\sigma_1u\\cdot \\sigma_2ve^{-\\frac{1}{2(1-\\rho^2)}(u^2-2\\rho uv+v^2)}d(\\sigma_1u)d(\\sigma_2v)\\\\ \u0026amp;=\\frac{\\sigma_1\\sigma_2}{2\\pi\\sqrt{1-\\rho^2}}\\int_{-\\infty}^{+\\infty}v\\int_{-\\infty}^{+\\infty}ue^{-\\frac{1}{2(1-\\rho^2)}(u^2-2\\rho vu+\\rho^2v^2-\\rho^2v^2+v^2)}dudv\\\\ \u0026amp;=\\frac{\\sigma_1\\sigma_2}{2\\pi\\sqrt{1-\\rho^2}}\\int_{-\\infty}^{+\\infty}ve^{-\\frac{v^2}{2}}\\int_{-\\infty}^{+\\infty}ue^{-\\frac{1}{2(1-\\rho^2)}(u-\\rho v)^2}dudv \\end{align} $$ 注意到 $$ \\frac{1}{\\sqrt{2\\pi}\\sqrt{1-\\rho^2}}\\int_{-\\infty}^{+\\infty}ue^{-\\frac{1}{2(1-\\rho^2)}(u-\\rho v)^2}du $$ 是正态分布 $N(\\rho v, 1-\\rho^2)$ 的期望 (自变量为 $u$)，所以 $$ \\begin{align} cov(X,Y)=\\frac{\\sigma_1\\sigma_2}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}ve^{-\\frac{v^2}{2}}\\rho vdv=\\sigma_1\\sigma_2\\rho\\cdot \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}v^2e^{-\\frac{v^2}{2}}dv \\end{align} $$ 注意到 $$ \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}v^2e^{-\\frac{v^2}{2}}dv=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}(v-0)^2e^{-\\frac{v^2}{2}}dv $$ 是标准正态分布 $N(0,1)$ 的方差，所以该式为 1，所以 $cov(X,Y)=\\sigma_1\\sigma_2\\rho$。相关系数 $\\rho_{XY}=\\rho$。\n$\\fbox{Theorem 15.7}$ 设 $(X,Y)\\sim N(\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2,\\rho)$，则 $X,Y$ 相互独立当且仅当 $X,Y$ 不相关。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"de807efff34d5cd14919e533e3baa01f","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec15/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec15/","section":"notes","summary":"$\\fbox{Theorem 15.1}$ (Chebyshev) 设随机变量 $X$ 的方差存在，则有 $$ \\forall \\varepsilon\u0026gt;0,P(|X-E[X]|\u0026gt;\\varepsilon)\\leq \\frac{D(X)}{\\varepsilon^2} $$ 证明：设 $X$ 存在密度函数 $p(x)$，则 $$ \\begin{align} P(|X-E[X]|\u0026gt;\\varepsilon)\u0026amp;=\\int_{{x:|X-E[X]|\u0026gt;\\varepsilon}}p(x)dx\\\\ \u0026amp;\\leq \\int_{{x:|X-E[X]|\u0026gt;\\varepsilon}}\\frac{|X-E[x]|^2}{\\varepsilon^2}p(x)dx\\\\ \u0026amp;\\leq \\frac{1}{\\varepsilon^2}\\int_{-\\infty}^{+\\infty}|X-E[X]|^2p(x)dx\\\\ \u0026amp;=\\frac{D(X)}{\\varepsilon^2}\\qquad \\blacksquare \\end{align} $$ 我们的证明过程中使用了两次看上去很“松”的放缩，但下面的例子可以说明，在对 $X$ 没有任何额外限制的情况下，Chebyshev 的结果已经是最紧的了：","tags":null,"title":"Lecture 15: Covariance and Correlation Coefficient","type":"docs"},{"authors":null,"categories":null,"content":"Origin Moment and Central Moment $\\fbox{Definition 16.1}$ 设 $X$ 是随机变量，对正整数 $k$，若 $E[|X|^k]\u0026lt;+\\infty$，则称 $E[X^k]$ 为 $X$ 的 $k$ 阶原点矩或 $k$ 阶矩；若 $E[|X-E[X]|^k]\u0026lt;+\\infty$，则称 $E[(X-E[X])^k]$ 为 $X$ 的 $k$ 阶中心矩。\n注：(1) 矩是对期望、方差的推广，1 阶原点矩就是期望，2 阶中心矩就是方差。\n(2) 一般情形下，两个随机变量的任意阶原点矩/中心矩相同不能推出两个随机变量的分布相同。\n【例】考虑正态分布 $X\\sim N(\\mu,\\sigma^2)$ 的 $k$ 阶中心矩。首先写出 $X$ 的密度函数： $$ p(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} $$ 所以 $$ \\begin{align} E[(X-E[X])^k]\u0026amp;=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{+\\infty}(x-\\mu)^ke^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}dx\\\\ \u0026amp;\\overset{t=\\frac{x-\\mu}{\\sigma}}{=}\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{+\\infty}\\sigma^kt^ke^{-\\frac{t^2}{2}}d(\\sigma t)\\\\ \u0026amp;=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}t^ke^{-\\frac{t^2}{2}}dt \\end{align} $$ $k$ 是奇数时，被积函数是奇函数，原式为 0。$k$ 是偶数时，我们考虑归纳地使用分部积分： $$ \\begin{align} \\int_{-\\infty}^{+\\infty}t^ke^{-\\frac{t^2}{2}}dt\u0026amp;=\\int_{-\\infty}^{+\\infty}t^{k-1}e^{-\\frac{t^2}{2}}d\\frac{t^2}{2}=-\\int_{-\\infty}^{+\\infty}t^{k-1}de^{-\\frac{t^2}{2}}\\\\ \u0026amp;=-\\left.t^{k-1}e^{-\\frac{t^2}{2}}\\right|_{-\\infty}^{+\\infty}+\\int_{-\\infty}^{+\\infty}e^{-\\frac{t^2}{2}}d(t^{k-1})\\\\ \u0026amp;=(k-1)\\int_{-\\infty}^{+\\infty}t^{k-2}e^{-\\frac{t^2}{2}}dt \\end{align} $$ 最后剩下的东西是高斯积分，为 $\\sqrt{2\\pi}$，因此 $$ E[(X-E[X])^k]=\\begin{cases}0\u0026amp;,k是偶数\\\\\\sigma^k(k-1)!!\u0026amp;,k是奇数\\end{cases}. $$ 注：标准化随机变量 (此时期望为 0，中心矩和原点矩相同) 的三阶矩称为偏度。偏度为负意味着分布的左尾更长，但大多数取值比期望大 (即有一些概率取到很小的负数，但更大概率取到大于期望的数)；偏度为 0 意味着数值相对均匀地分布在期望的两侧 (但未必完全对称)。\n四阶矩称为峰度。峰度高意味着存在远大于或远小于期望的取值且取到的概率不太小。\n对于中心矩，我们有如下的切比雪夫不等式的推广：\n$\\fbox{Theorem 16.2}$ 设 $E[|X-E[X]|^k]\u0026lt;+\\infty$，则对于任意 $\\varepsilon\u0026gt;0$， $$ P(|X-E[X||\u0026gt;\\varepsilon)\\leq \\frac{E[|X-E[X]|^k]}{\\varepsilon^k} $$ 该不等式在远端可以给出比切比雪夫不等式更好的估计。\nCovariance Matrix $\\fbox{Definition 16.3}$ 设 $X=(X_1,\\cdots, X_n)^T$ 是一个 $n$ 维随机变量，则 $$ E[X]\\triangleq(E[X_1],E[X_2],\\cdots, E[X_n])^T $$ 为 $X$ 的期望。记 $C_{ij}=cov(X_i,X_j)$，称矩阵 $$ \\Sigma=\\begin{bmatrix}C_{11} \u0026amp; C_{12}\u0026amp;\\cdots \u0026amp;C_{1n}\\\\ C_{21}\u0026amp;C_{22}\u0026amp;\\cdots\u0026amp;C_{2n}\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ C_{n1}\u0026amp;C_{n2}\u0026amp;\\cdots\u0026amp;C_{nn}\\end{bmatrix} $$ 为 $X$ 的协方差阵。\n【例】考虑 $(X_1,X_2)\\sim N(\\mu_1,\\mu_2,\\sigma_1^2,\\sigma_2^2,\\rho)$，记 $\\Sigma=\\begin{bmatrix}\\sigma_1^2\u0026amp; \\sigma_1\\sigma_2\\rho\\\\\\sigma_1\\sigma_2\\rho\u0026amp;\\sigma_2^2\\end{bmatrix}$，$\\mu=(\\mu_1,\\mu_2)^T,X=(X_1,X_2)^T$，则 $$ p(x_1,x_2)=p(x)=\\frac{1}{2\\pi\\sqrt{\\det \\Sigma}}e^{-\\frac{1}{2}(X-\\mu)^T\\Sigma^{-1}(X-\\mu)} $$ $\\fbox{Theorem 16.4}$ 协方差矩阵是半正定的，即对于任意 $X\\in \\mathbb R^n$，$X^T\\Sigma X\\geq 0$。\n证明：对于任意 $T=(t_1,\\cdots, t_n)^T\\in \\mathbb R^n$，考虑如下随机变量的期望： $$ E\\left[\\left(\\sum_{i=1}^nt_i(X_i-E[X_i])\\right)^2\\right]\\geq 0 $$ 我们下面证明这个期望就是协方差矩阵的二次型： $$ \\begin{align} E\\left[\\left(\\sum_{i=1}^nt_i(X_i-E[X_i])\\right)^2\\right]\u0026amp;=E\\left[\\sum_{i=1}^n\\sum_{j=1}^nt_it_j(X_i-E[X_i])(X_j-E[X_j])\\right]\\\\ \u0026amp;=\\sum_{i=1}^n\\sum_{j=1}^nt_it_jE[(X_i-E[X_i])(X_j-E[X_j])]\\\\ \u0026amp;=\\sum_{i=1}^n\\sum_{j=1}^nt_it_jC_{ij}\\\\ \u0026amp;=\\sum_{j=1}^n\\left(\\sum_{i=1}^nt_iC_{ij}\\right)t_j\\\\ \u0026amp;= \\begin{pmatrix} \\sum_{i=1}^nt_iC_{i1}\u0026amp;\\sum_{i=1}^nt_iC_{i2}\u0026amp;\\cdots\u0026amp;\\sum_{i=1}^nt_iC_{in} \\end{pmatrix} \\begin{pmatrix} t_1\\\\t_2\\\\\\vdots\\\\t_n \\end{pmatrix}\\\\ \u0026amp;=\\begin{pmatrix} \\begin{pmatrix} t_1\u0026amp;\\cdots\u0026amp;t_n \\end{pmatrix} \\begin{pmatrix} C_{11}\\\\\\vdots \\\\C_{1n} \\end{pmatrix} \u0026amp; \\cdots \u0026amp; \\begin{pmatrix} t_1\u0026amp;\\cdots\u0026amp;t_n \\end{pmatrix} \\begin{pmatrix} C_{n1}\\\\\\vdots \\\\C_{nn} \\end{pmatrix} \\end{pmatrix} \\begin{pmatrix} t_1\\\\\\vdots \\\\t_n \\end{pmatrix}\\\\ \u0026amp;= \\begin{pmatrix} t_1\u0026amp;\\cdots \u0026amp;t_n \\end{pmatrix} \\begin{bmatrix}C_{11} \u0026amp; C_{12}\u0026amp;\\cdots \u0026amp;C_{1n}\\\\ C_{21}\u0026amp;C_{22}\u0026amp;\\cdots\u0026amp;C_{2n}\\\\ \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\\\ C_{n1}\u0026amp;C_{n2}\u0026amp;\\cdots\u0026amp;C_{nn}\\end{bmatrix} \\begin{pmatrix} t_1\\\\\\vdots \\\\t_n \\end{pmatrix}\\\\ \u0026amp;=T^T\\Sigma T \\end{align} $$ 所以 $\\Sigma$ 半正定。 $\\blacksquare$\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"ff2f8af92cce5eef1ab8e7eada09afd9","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec16/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec16/","section":"notes","summary":"Origin Moment and Central Moment $\\fbox{Definition 16.1}$ 设 $X$ 是随机变量，对正整数 $k$，若 $E[|X|^k]\u0026lt;+\\infty$，则称 $E[X^k]$ 为 $X$ 的 $k$ 阶原点矩或 $k$ 阶矩；若 $E[|X-E[X]|^k]\u0026lt;+\\infty$，则称 $E[(X-E[X])^k]$ 为 $X$ 的 $k$ 阶中心矩。\n注：(1) 矩是对期望、方差的推广，1 阶原点矩就是期望，2 阶中心矩就是方差。","tags":null,"title":" Lecture 16: Moment and Covariance Matrix","type":"docs"},{"authors":null,"categories":null,"content":"$\\fbox{Definition 21.1}$ 设 $\\theta$ 是总体 $X$ 的未知参数，$X_1,\\cdots, X_n$ 是来自 $X$ 的样本，若对于给定的 $0\u0026lt;\\alpha\u0026lt;1$，存在两个统计量 $\\hat\\theta_1(X_1,\\cdots, X_n)$ 和 $\\hat\\theta_2(X_1,\\cdots, X_n)$，使得 $$ P(\\hat\\theta_1\u0026lt;\\theta\u0026lt;\\hat\\theta_2)=1-\\alpha $$ 则称 $(\\hat\\theta_1,\\hat\\theta_2)$ 是 $\\theta$ 的置信度为 $1-\\alpha$ 的置信区间，$\\theta_1,\\theta_2$ 称为置信下限和置信上限，$1-\\alpha$ 称为置信度或置信系数。\n注：(1) 上面数学表达式的含义为：在进行了 $m$ 轮 (每轮 $n$ 次) 采样后，我们会得到 $m$ 个区间 $(\\hat\\theta_{1,1},\\hat\\theta_{2,1})$ …… $(\\hat\\theta_{1,m},\\hat\\theta_{2,m})$。这其中大约有 $(1-\\alpha)m$ 个区间包含了 $\\theta$。对于一组具体的估计值 $\\hat\\theta_1(x_1,\\cdots,x_n)$ 和 $\\hat\\theta_2(x_1,\\cdots, x_n)$，我们不能说 $\\theta$ 有 $1-\\alpha$ 的概率落在区间中，因为这时区间的上下界已经是确定的数了，不再具有随机性。\n(2) $\\hat\\theta_2-\\hat\\theta_1$ 越大，置信度越高，但精度也会越差。\n有时我们也会只关心未知参数的上限或下限 (如保质期)，因此我们类似地有单侧置信区间和单侧置信上限/下限的概念。\nPivot Method 枢轴变量法的主要思想如下：\n构造一个样本函数 $U(X_1,\\cdots, X_n;\\theta)$，我们要求 $U$ 是有且仅有未知参数 $\\theta$ 的函数，且 $U$ 的分布已知。我们称 $U$ 为枢轴变量。 因为 $U$ 的分布已知，所以对于给定的置信区间 $1-\\alpha$，我们可以确定区间 $[a,b]$，使得 $P(a\\leq U\\leq b)=1-\\alpha$ (如果要求单边置信区间，则只需要一个方向的约束)。 根据 $a\\leq U\\leq b$ 反推出 $\\theta$ 的范围 (范围表达式中仅包含 $X_1,\\cdots, X_n$)，这个范围就是我们要求的 $\\hat\\theta_1$ 和 $\\hat\\theta_2$。 Confidence Interval of $\\mu$ in Normal Population 【例】给定置信度 $1-\\alpha$，样本 $X_1,\\cdots, X_n$ 来自总体 $X\\sim N(\\mu,\\sigma^2)$。考虑用枢轴变量法求均值 $\\mu$ 的置信区间：因为 $X\\sim N(\\mu,\\sigma^2)$，所以 $\\overline{X}\\sim N(\\mu,\\frac{\\sigma^2}{n})$ 我们构造 $U=\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt n}$，则 $U\\sim N(0,1)$。\n记 $u_{\\alpha}$ 是 $N(0,1)$ 的上 $\\alpha$ 分为数 (即 $P(u\u0026gt;u_\\alpha)=\\alpha$)，那么 $$ 1-\\alpha=P(u_{1-\\alpha/2}\u0026lt;U\u0026lt;u_{\\alpha/2})=P(-u_{\\alpha/2}\u0026lt;U\u0026lt;u_{\\alpha/2}) $$ 因此 $$ -u_{\\frac{\\alpha}{2}}\u0026lt;\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt n}\u0026lt;u_{\\frac{\\alpha}{2}}\\quad \\Rightarrow\\quad \\overline{X}-\\frac{\\sigma u_{\\frac{\\alpha}{2}}}{\\sqrt n}\u0026lt;\\mu\u0026lt;\\overline{X}+\\frac{\\sigma \\mu_{\\frac{\\alpha}{2}}}{\\sqrt n} $$ 因此置信区间为 $\\left(\\overline{X}-\\frac{\\sigma u_{\\frac{\\alpha}{2}}}{\\sqrt n},\\overline{X}+\\frac{\\sigma \\mu_{\\frac{\\alpha}{2}}}{\\sqrt n}\\right)$。\n如果我们不知道 $\\sigma^2$，我们也可以给出一个置信区间。根据正态总体章节的知识，我们有 $$ T=\\frac{\\sqrt n(\\overline{X}-\\mu)}{S}\\sim t(n-1) $$ 因此记 $t_{\\alpha}(n-1)$ 为 $T$ 的上 $\\alpha$ 分为数，有 $$ 1-\\alpha=P(t_{1-\\alpha/2}(n-1)\u0026lt;T\u0026lt;t_{\\alpha/2}(n-1))=P(-t_{\\alpha/2}(n-1)\u0026lt;T\u0026lt;t_{\\alpha/2}(n-1)) $$ 因此 $$ -t_{\\frac{\\alpha}{2}}(n-1)\u0026lt;\\frac{\\sqrt n(\\overline{X}-\\mu)}{S}\u0026lt;t_{\\frac{\\alpha}{2}}(n-1)\\quad \\Rightarrow \\quad 置信区间\\left(\\overline{X}-\\frac{St_{\\frac{\\alpha}{2}}(n-1)}{\\sqrt n},\\overline{X}+\\frac{St_{\\frac{\\alpha}{2}}(n-1)}{\\sqrt n}\\right) $$ $T$ 分布的尾部比正态分布要重 (正态分布是指数衰减的，T 分布是多项式衰减的)，因此上述置信区间会比知道 $\\sigma^2$ 时的置信区间要宽一些。考虑到我们是在知道更少的信息的情况下求出的该区间，这一点是容易理解的。\nConfidence Interval of $\\sigma^2$ in Normal Population 【例】给定置信度 $1-\\alpha$，样本 $X_1,\\cdots, X_n$ 来自总体 $X\\sim N(\\mu,\\sigma^2)$。考虑用枢轴变量法求方差 $\\sigma^2$ 的置信区间：在 $\\mu$ 未知的情况下，我们可以这样给出枢轴变量：$\\frac{(n-1)S^2}{\\sigma^2}\\sim \\chi^2(n-1)$。从而 $$ 1-\\alpha=P\\left(\\chi^2_{1-\\frac{\\alpha}{2}}(n-1)\u0026lt;\\frac{(n-1)S^2}{\\sigma^2}\u0026lt;\\chi^2_{\\frac{\\alpha}{2}}(n-1)\\right) $$ 解得置信区间为 $$ \\left(\\frac{(n-1)S^2}{\\chi^2_{\\frac{\\alpha}{2}}(n-1)},\\frac{(n-1)S^2}{\\chi^2_{1-\\frac{\\alpha}{2}}(n-1)}\\right) $$ 注：(1) 尽管 $\\chi^2$ 分布和 $F$ 分布非对称，但通常仍然沿用 $\\alpha/2$ 和 $1-\\alpha/2$ 这两个分位点。这样求得的置信区间可能并非最短。\n(2) 若 $\\mu$ 已知，我们可以将其运用起来精确化我们的置信区间：取 $U=\\left(\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt n}\\right)^2$，则 $U\\sim \\chi^2(1)$。\nConfidence Interval of $\\mu_1-\\mu_2$ in Normal Population 【例】给定置信度 $1-\\alpha$，样本 $X_1,\\cdots, X_{n_1}$ 来自总体 $X\\sim N(\\mu_1,\\sigma_1^2)$，$Y_1,\\cdots, Y_{n_2}$ 来自总体 $Y\\sim N(\\mu_2,\\sigma_2^2)$，考虑它们的均值差 $\\mu_1-\\mu_2$ 的置信区间。如果 $\\sigma_1^2$ 和 $\\sigma_2^2$ 均已知，那么 $\\overline{X}\\sim N(\\mu_1,\\frac{\\sigma_1^2}{n_1})$，$\\overline{Y}\\sim N(\\mu_2,\\frac{\\sigma_2^2}{n_2})$，$\\overline{X}-\\overline{Y}\\sim N(\\mu_1-\\mu_2,\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2})$。因此取 $$ U=\\frac{\\overline{X}-\\overline{Y}-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}}\\sim N(0,1) $$ 从而 $$ -u_{\\frac{\\alpha}{2}}\u0026lt;\\frac{\\overline{X}-\\overline{Y}-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}}\u0026lt;u_{\\frac{\\alpha}{2}}\\Rightarrow置信区间\\left(\\overline{X}-\\overline{Y}-\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}u_{\\frac{\\alpha}{2}},\\overline{X}-\\overline{Y}+\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}u_{\\frac{\\alpha}{2}}\\right) $$ 若不知道 $\\sigma_1^2$ 和 $\\sigma_2^2$，但知道 $\\sigma_1^2=\\sigma_2^2=\\sigma^2$，那么考虑如下公式： $$ T=\\sqrt{\\frac{n_1n_2(n_1+n_2-2)}{n_1+n_2}}\\frac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{\\sqrt{(n_1-1)S_X^2+(n_2-1)S_Y^2}}\\sim t(n_1+n_2-2) $$ 于是有 $$ 1-\\alpha=P(-t_{\\alpha/2}(n_1+n_2-2)\u0026lt;T\u0026lt;t_{\\alpha/2}(n_1+n_2-2)) $$ 令 $C_{n_1,n_2}=\\sqrt{\\frac{n_1n_2(n_1+n_2-2)}{n_1+n_2}}\\frac{1}{\\sqrt{(n_1-1)S_X^2+(n_2-1)S_Y^2}}$，则 $$ -t_{\\frac{\\alpha}{2}}(n_1+n_2-2)\u0026lt;C_{n_1,n_2}[(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)]\u0026lt;t_{\\frac{\\alpha}{2}}(n_1+n_2-2) $$ 解得置信区间为 $$ \\left(\\overline{X}-\\overline{Y}-\\frac{t_{\\frac{\\alpha}{2}}(n_1+n_2-2)}{C_{n_1,n_2}},\\overline{X}-\\overline{Y}+\\frac{t_{\\frac{\\alpha}{2}}(n_1+n_2-2)}{C_{n_1,n_2}}\\right) $$\nConfidence Interval of $\\frac{\\sigma_1^2}{\\sigma_2^2}$ in Normal Population 【例】给定置信度 $1-\\alpha$，样本 $X_1,\\cdots, X_{n_1}$ 来自总体 $X\\sim N(\\mu_1,\\sigma_1^2)$，$Y_1,\\cdots, Y_{n_2}$ 来自总体 $Y\\sim N(\\mu_2,\\sigma_2^2)$，考虑它们的方差比 $\\frac{\\sigma_1^2}{\\sigma_2^2}$ 的置信区间。若 $\\mu_1,\\mu_2$ 未知，我们考虑枢轴变量 $$ F=\\frac{S_X^2\\sigma_2^2}{S_Y^2\\sigma_1^2}\\sim F(n_1-1,n_2-2) $$ 从而 $$ 1-\\alpha=P(F_{1-\\frac{\\alpha}{2}}(n_1-1,n_2-1)\u0026lt;F\u0026lt;F_{\\frac{\\alpha}{2}}(n_1-1,n_2-1)) $$ 解得置信区间为 $$ \\left(\\frac{S_X^2}{S_Y^2}\\frac{1}{F_\\frac{\\alpha}{2}(n_1-1,n_2-1)},\\frac{S_X^2}{S_Y^2}\\frac{1}{F_{1-\\frac{\\alpha}{2}}(n_1-1,n_2-1)}\\right) $$ 如果我们知道更多信息，则可以给出更好的估计，比如：\n若 $\\mu_1$ 已知，$\\mu_2$ 未知，那么 $\\frac{\\overline X-\\mu_1}{\\sigma_1/\\sqrt{n_1}}\\sim N(0,1)$，$\\frac{(n_2-1)S_Y^2}{\\sigma_2^2}\\sim \\chi^2(n_2-1)$，则 $$ U=\\frac{\\left(\\frac{\\overline X-\\mu_1}{\\sigma_1/\\sqrt{n_1}}\\right)^2}{S_Y^2/\\sigma_2^2}\\sim F(1,n_2-1) $$ (注：分子正态分布的平方，即一个自由度的 $\\chi^2$ 分布。)\n若 $\\mu_1,\\mu_2$ 均已知，则 $$ U=\\frac{\\left(\\frac{\\overline X-\\mu_1}{\\sigma_1/\\sqrt{n_1}}\\right)^2}{\\left(\\frac{\\overline Y-\\mu_2}{\\sigma_2/\\sqrt{n_2}}\\right)^2}\\sim F(1,1) $$\nInterval Estimation of Unknown Population 非正态总体均值的区间估计通常采用所为的大样本法：\n设 $X_1,\\cdots, X_n$ 来自总体 $X$，且 $E[X]=\\mu,D(X)=\\sigma$，考虑计算 $\\mu$ 的置信度为 $1-\\alpha$ 的置信区间。由中心极限定理，有 $$ \\frac{\\sum_{k=1}^nX_k-n\\mu}{\\sqrt n\\sigma}\\to N(0,1) $$ 从而考虑 $U=\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt n}\\approx N(0,1)$，于是 $1-\\alpha\\approx P(-u_{\\frac{\\alpha}{2}}\u0026lt;U\u0026lt;u_{\\frac{\\alpha}{2}})$。\n当 $\\sigma^2$ 已知时，置信区间为 $(\\overline X-\\frac{u_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt n},\\overline X+\\frac{u_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt n})$。\n当 $\\sigma^2$ 未知时，用 $S$ 来代替 $\\sigma$。\n【例题】设总体服从 0-1 分布，$X_1,\\cdots, X_n$ 为样本，求总体期望 $p$ 的置信度为 $1-\\alpha$ 的置信区间。\n解法一：该题设符合方差未知的情形，所以使用第二个结论，所求区间为 $$ \\left(\\overline X-\\frac{u_{\\frac{\\alpha}{2}}S}{\\sqrt n},\\overline X+\\frac{u_{\\frac{\\alpha}{2}}S}{\\sqrt n}\\right) $$ 这里的 $S$ 是一个二阶的统计量，利用 0-1 分布的性质，我们可以进一步化简它： $$ \\begin{align} S^2\u0026amp;=\\frac{1}{n-1}\\sum_{k=1}^n(X_k-\\overline{X})^2=\\frac{1}{n-1}\\left(\\sum_{k=1}^nX_k^2-n\\overline{X}^2\\right)\\\\ \u0026amp;\\overset{\\text{0-1分布}}{=}\\frac{1}{n-1}\\left(\\sum_{k=1}^nX_k-n\\overline{X}^2\\right)\\\\ \u0026amp;=\\frac{n}{n-1}\\overline{X}(1-\\overline{X}) \\end{align} $$ 代入原式得置信区间： $$ \\left(\\overline{X}-u_{\\frac{\\alpha}{2}}\\sqrt{\\frac{\\overline{X}(1-\\overline X)}{n-1}},\\overline{X}+u_{\\frac{\\alpha}{2}}\\sqrt{\\frac{\\overline{X}(1-\\overline X)}{n-1}}\\right) $$ 这样置信区间中只有一阶的统计量，更加准确。\n解法二：因为 $\\sum_{k=1}^nX_k\\sim B(n,p)$，伯努利试验中方差 $\\sigma=\\sqrt{p(1-p)}$。根据中心极限定理， $$ \\frac{\\sum_{k=1}^nX_k-np}{\\sqrt{n}\\sqrt{p(1-p)}}\\to N(0,1) $$ 因此可以得到近似的置信区间 $$ \\left(\\overline{X}-u_{\\frac{\\alpha}{2}}\\sqrt{\\frac{p(1-p)}{n}},\\overline{X}+u_{\\frac{\\alpha}{2}}\\sqrt{\\frac{p(1-p)}{n}}\\right) $$ $\\overline{X}$ 是对 $p$ 的一个较好的估计，因此用 $\\overline{X}$ 代替 $p$，即得到 $$ \\left(\\overline{X}-u_{\\frac{\\alpha}{2}}\\sqrt{\\frac{\\overline{X}(1-\\overline{X})}{n}},\\overline{X}+u_{\\frac{\\alpha}{2}}\\sqrt{\\frac{\\overline{X}(1-\\overline{X})}{n}}\\right) $$ 该做法更好地利用了 0-1 分布 (伯努利试验)，因此给出的区间更加精确一些。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"f20c941cf151c3086388b7c8c58ac2b8","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec21/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec21/","section":"notes","summary":"$\\fbox{Definition 21.1}$ 设 $\\theta$ 是总体 $X$ 的未知参数，$X_1,\\cdots, X_n$ 是来自 $X$ 的样本，若对于给定的 $0\u0026lt;\\alpha\u0026lt;1$，存在两个统计量 $\\hat\\theta_1(X_1,\\cdots, X_n)$ 和 $\\hat\\theta_2(X_1,\\cdots, X_n)$，使得 $$ P(\\hat\\theta_1\u0026lt;\\theta\u0026lt;\\hat\\theta_2)=1-\\alpha $$ 则称 $(\\hat\\theta_1,\\hat\\theta_2)$ 是 $\\theta$ 的置信度为 $1-\\alpha$ 的置信区间，$\\theta_1,\\theta_2$ 称为置信下限和置信上限，$1-\\alpha$ 称为置信度或置信系数。\n注：(1) 上面数学表达式的含义为：在进行了 $m$ 轮 (每轮 $n$ 次) 采样后，我们会得到 $m$ 个区间 $(\\hat\\theta_{1,1},\\hat\\theta_{2,1})$ …… $(\\hat\\theta_{1,m},\\hat\\theta_{2,m})$。这其中大约有 $(1-\\alpha)m$ 个区间包含了 $\\theta$。对于一组具体的估计值 $\\hat\\theta_1(x_1,\\cdots,x_n)$ 和 $\\hat\\theta_2(x_1,\\cdots, x_n)$，我们不能说 $\\theta$ 有 $1-\\alpha$ 的概率落在区间中，因为这时区间的上下界已经是确定的数了，不再具有随机性。","tags":null,"title":"Lecture 21: Interval Estimation","type":"docs"},{"authors":null,"categories":null,"content":"设总体 $X\\sim N(\\mu,\\sigma^2)$，欲判断 $\\mu$ 是否为某个给定的常数 $\\mu_0$，我们将 $\\mu=\\mu_0$ ，记为 $H_0:\\mu=\\mu_0$，称为原假设或零假设。对应的，$H_1:\\mu\\neq \\mu_0$ 称为备择假设或对立假设。 $$ H_0:\\mu=\\mu_0\\qquad H_1:\\mu\\neq \\mu_0 $$ 我们也可以考虑判断 $\\mu\\leq \\mu_0$ 是否成立，这时的原假设和对立假设为 $$ H_0:\\mu\\leq \\mu_0\\qquad H_1:\\mu\u0026gt;\\mu_0 $$ 第一种假设称为双边检验 (对立假设居于原假设两边)，第二种则是单边检验。上述两种假设只涉及已知总体的未知参数，称为参数假设检验 (像 $H_0:X服从正态分布$ 就是非参数假设检验)。\n以第一种假设为例介绍假设检验的一般方法：$\\overline{X}$ 是 $\\mu$ 的一个比较好的估计，因此 $|\\overline{X}-\\mu_0|$ 应该不太大。我们希望找到一个阈值 $k$，当 $|\\overline{X}-\\mu_0|\u0026lt; k$ 时，我们认为假设成立。问题的关键在于如何选取 $k$。在 $H_0$ 成立的情况下，$\\overline{X}\\sim N(\\mu_0,\\frac{\\sigma^2}{n})$。考虑 $\\sigma^2$ 已知的情形，则 $U=\\frac{\\overline{X}-\\mu_0}{\\sigma/\\sqrt n}\\sim N(0,1)$。$|\\overline{X}-\\mu_0|\\geq k$ 意味着 $|U|\\geq \\frac{k}{\\sigma/\\sqrt n}$，故 $k$ 的选取应当使得 $P\\left(|U|\\geq \\frac{k}{\\sigma/\\sqrt n}\\right)$ 足够小。给定一个小概率 $\\alpha$ (常用值：0.1, 0.05, 0.01)，令 $P(|U|\\geq \\frac{k}{\\sigma/\\sqrt n})=\\alpha$，即可确定 $\\frac{k}{\\sigma/\\sqrt n}=u_{\\frac{\\alpha}{2}}$。\n我们把 $U$ 称为检验统计量，$\\alpha$ 称为显著性水平，$u_{\\frac{\\alpha}{2}}=\\frac{k}{\\sigma/\\sqrt n}$ 称为临界值。$W={|U|\\geq u_{\\frac{\\alpha}{2}}}$ 称为拒绝域，$\\overline{W}$ 称为接受域。\n基本步骤：\n根据问题提出 $H_0$ 和 $H_1$。 构造一个合适的统计量，在 $H_0$ 成立的条件下求该统计量的分布。 给出小概率 $\\alpha$，确定临界值和拒绝域 $W$。 由样本算出观察值，若其落入 $W$，则拒绝 $H_0$，否则接受 $H_0$。 假设检验的两类错误：\n弃真错误：$H_0$ 正确却拒绝了 $H_0$。$P(拒绝H_0|H_0为真)=P(U\\in W|H_0为真)=\\alpha$。 存伪错误：$H_0$ 错误却接受了 $H_0$。$P(接受H_0|H_1为真)=P(U\\notin W|H_1为真)=\\beta$。 通常来说 $\\beta$ 不容易求得。$\\alpha$ 和 $\\beta$ 不能同时减小，我们通常在控制 $\\alpha$ 足够小的情况下尽可能减小 $\\beta$ (Neyman-Pearson 原则)，即拒绝 $H_0$ 需要更充分的理由，$H_0$ 地位高于 $H_1$。\n【例题】设 $X\\sim N(\\mu,1)$，$X_1,\\cdots, X_n$ 为样本。在给定显著性水平 $\\alpha$ 的情况下求 $H_0:\\mu=\\mu_0$，$H_1:\\mu=\\mu_1$ 的第二类错误概率 $\\beta$。\n解：在 $H_0$ 下，我们会构造 $U=\\frac{\\overline X-\\mu_0}{1/\\sqrt n}=\\sqrt n(\\overline X-\\mu_0)\\sim N(0,1)$。但现在 $H_1$ 成立，因此 $U$ 实际服从的分布为 $$ U=\\sqrt n(\\overline X-\\mu_0)=\\sqrt n(\\overline X-\\mu_1)+\\sqrt n(\\mu_1-\\mu_0)\\sim N(\\sqrt n(\\mu_1-\\mu_0),1) $$ 根据 $\\beta$ 的定义， $$ \\begin{align} \\beta\u0026amp;=P(U\\notin W|H_1为真)=P(|U|\u0026lt;u_{\\frac{\\alpha}{2}}|\\mu=\\mu_1)\\\\ \u0026amp;=P(-u_{\\frac{\\alpha}{2}}-\\sqrt n(\\mu_1-\\mu_0)\u0026lt;\\sqrt n(\\overline{X}-\\mu_1)\u0026lt;u_{\\frac{\\alpha}{2}}-\\sqrt n(\\mu_1-\\mu_0)|\\mu=\\mu_1)\\\\ \u0026amp;=\\Phi(u_{\\frac{\\alpha}{2}}-\\sqrt n(\\mu_1-\\mu_0))-\\Phi(-u_{\\frac{\\alpha}{2}}-\\sqrt n(\\mu_1-\\mu_0)) \\end{align} $$\nMean Value Test of Normal Population 总体 $X\\sim N(\\mu,\\sigma^2)$，$X_1,\\cdots,X_n$ 为样本，给定 $\\alpha$。\n$u$ Test 在 $\\sigma^2$ 已知的情况下，$H_0:\\mu=\\mu_0,H_1:\\mu\\neq \\mu_0$。考虑 $U=\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1)$。容易得出临界值 $P(|U|\u0026gt;u_{\\frac{\\alpha}{2}})=\\alpha$，拒绝域 $W=\\left\\{\\left|\\frac{\\overline{X}-\\mu_0}{\\sigma/\\sqrt n}\\right|\u0026gt;u_{\\frac{\\alpha}{2}}\\right\\}$。\n如果做单边检验：$H_0:\\mu=\\mu_0,H_1:\\mu\u0026gt;\\mu_0$，则临界值为 $u_\\alpha$，拒绝域：$W=\\left\\{\\frac{\\overline{X}-\\mu_0}{\\sigma/\\sqrt n}\u0026gt;u_\\alpha\\right\\}$。\n若假设为 $H_0:\\mu\\leq \\mu_0,H_1:\\mu\u0026gt;\\mu_0$。我们的拒绝域 $W$ 应该满足 $P(U\\in W|H_0)\\leq \\alpha$。我们发现 $\\mu_0$ 是 $\\mu$ 的上界，因此 $$ P\\left(\\left.\\frac{\\overline{X}-\\mu_0}{\\sigma/\\sqrt n}\u0026gt;\\lambda_\\alpha\\right|\\mu\\leq \\mu_0\\right)\\leq P\\left(\\left.\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt n}\u0026gt;\\lambda_\\alpha\\right|\\mu\\leq \\mu_0\\right) $$ 令右式等于 $\\alpha$，因为 $\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1)$，所以解得 $\\lambda_\\alpha=u_\\alpha$。拒绝域：$W=\\left\\{\\frac{\\overline{X}-\\mu_0}{\\sigma/\\sqrt n}\u0026gt;u_\\alpha\\right\\}$。\n$t$ Test 在 $\\sigma^2$ 未知的情况下，$H_0:\\mu=\\mu_0,H_1:\\mu\\neq \\mu_0$，取 $$ T=\\frac{\\sqrt n(\\overline{X}-\\mu_0)}{S}\\sim t(n-1) $$ 可解出拒绝域 $W=\\left\\{|T|\u0026gt;t_{\\frac{\\alpha}{2}}(n-1)\\right\\}$。\nTest of the Difference of Mean Values of Two Normal Populations 总体 $X\\sim N(\\mu_1,\\sigma_1^2),Y\\sim N(\\mu_2,\\sigma_2^2)$。假设 $H_0:\\mu_1=\\mu_2,H_1:\\mu_1\\neq \\mu_2$。考虑以下几种情况：\n(1) $\\sigma_1^2,\\sigma_2^2$ 已知，取 $$ U=\\frac{\\overline X-\\overline Y-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}}\\overset{在H_0下}{=}\\frac{\\overline X-\\overline Y}{\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}}\\sim N(0,1) $$ 因此拒绝域 $$ W=\\left\\{\\left|\\frac{\\overline X-\\overline Y}{\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}}\\right|\u0026gt;u_{\\frac{\\alpha}{2}}\\right\\} $$ (2) $\\sigma_1^2=\\sigma_2^2=\\sigma^2$ 但未知，取 $$ T=\\sqrt{\\frac{n_1n_2(n_1+n_2-2)}{n_1+n_2}}\\frac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{\\sqrt{(n_1-1)S_X^2+(n_2-1)S_Y^2}}\\sim t(n_1+n_2-2) $$ (类似地，在 $H_0$ 下，$\\mu_1-\\mu_2$ 可以消去)\n因此拒绝域 $$ W=\\left\\{|T|\u0026gt;t_{\\frac{\\alpha}{2}}(n_1+n_2-2)\\right\\} $$\nPairwise $t$ Test 另外一种情况是，$X,Y$ 分布未知且相关，但 $Z=X-Y\\sim N(\\mu,\\sigma^2)$。我们想要检验这两个分布是否接近。假设 $H_0:\\mu=0,H_1:\\mu\\neq 0$。那么取 $$ T=\\frac{\\sqrt n(\\overline{Z}-\\mu)}{S_Z}\\overset{在H_0下}{=}\\frac{\\sqrt n\\overline{Z}}{S_Z}\\sim t(n-1) $$ 拒绝域 $$ W=\\left\\{|T|\u0026gt;t_{\\frac{\\alpha}{2}}(n-1)\\right\\} $$\nVariance Test of Normal Population 设 $X\\sim N(\\mu,\\sigma^2)$，$X_1,\\cdots, X_n$ 来自总体 $X$，$\\alpha$ 为显著水平。若 $\\mu$ 未知，假设 $H_0:\\sigma^2=\\sigma_0^2,H_1:\\sigma^2\\neq \\sigma_0^2$，考虑变量 $$ \\chi^2=\\frac{(n-1)S^2}{\\sigma_0^2}\\sim \\chi^2(n-1) $$ 因此拒绝域 $$ W={\\chi^2\u0026lt;\\chi_{1-\\frac{\\alpha}{2}}^2(n-1)}\\cup{\\chi^2\u0026gt;\\chi^2_{\\frac{\\alpha}{2}}(n-1)} $$ 两正态总体方差比值的检验：设 $X\\sim N(\\mu,\\sigma^2)$，$X_1,\\cdots, X_n$ 来自总体 $X$，$\\alpha$ 为显著水平。这次利用 F 分布 $$ F=\\frac{S_1^2\\sigma_2^2}{S_2^2\\sigma_1^2}\\sim F(n_1-1,n_2-2) $$ 因此拒绝域 $$ W={F\u0026lt;F_{1-\\frac{\\alpha}{2}}(n_1-1,n_2-1)}\\cup {F\u0026gt;F_{\\frac{\\alpha}{2}}(n_1-1,n_2-1)} $$\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"a553e3b6607870f0024eeb18d8a0e42f","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/lec22/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/lec22/","section":"notes","summary":"设总体 $X\\sim N(\\mu,\\sigma^2)$，欲判断 $\\mu$ 是否为某个给定的常数 $\\mu_0$，我们将 $\\mu=\\mu_0$ ，记为 $H_0:\\mu=\\mu_0$，称为原假设或零假设。对应的，$H_1:\\mu\\neq \\mu_0$ 称为备择假设或对立假设。 $$ H_0:\\mu=\\mu_0\\qquad H_1:\\mu\\neq \\mu_0 $$ 我们也可以考虑判断 $\\mu\\leq \\mu_0$ 是否成立，这时的原假设和对立假设为 $$ H_0:\\mu\\leq \\mu_0\\qquad H_1:\\mu\u0026gt;\\mu_0 $$ 第一种假设称为双边检验 (对立假设居于原假设两边)，第二种则是单边检验。上述两种假设只涉及已知总体的未知参数，称为参数假设检验 (像 $H_0:X服从正态分布$ 就是非参数假设检验)。","tags":null,"title":"Lecture 22: Hypothesis Test","type":"docs"},{"authors":null,"categories":null,"content":"矩母函数是快速求解高阶矩的利器。\nDefinitions and Properties $\\fbox{Definition 1}$ ($k$ 阶矩) 设 $X$ 是一个概率密度为 $f$ 的随机变量。若 $X$ 是离散的，则它的 $k$ 阶矩 (记作 $\\mu_k$) 定义为 $$ \\mu_k\\triangleq \\sum_{m=0}^{\\infty}x_m^kf(x_m) $$ 若 $X$ 是连续的，则它的 $k$ 阶矩定义为 $$ \\mu_k\\triangleq \\int_{-\\infty}^{+\\infty}x^kf(x)\\text{d}x $$ $\\fbox{Definition 2}$ (矩母函数) 设 $X$ 是一个概率密度为 $f$ 的随机变量，则其矩母函数 $M_X(t)$ 定义为 $\\mathbb E[e^{tX}]$。具体地说，若 $X$ 是离散的，则 $$ M_X(t)\\triangleq \\sum_{m=0}^\\infty e^{tx_m}f(x_m) $$ 若 $X$ 是连续的，则 $$ M_X(t)\\triangleq \\int_{-\\infty}^{+\\infty}e^{tx}f(x)\\text{d}x $$ 矩母函数有如下重要性质：\n$$ M_X(t)=\\sum_{k=0}^\\infty\\mu_k\\frac{t^k}{k!} $$\n证明：此处仅证明连续情形。考虑将矩母函数中的 $e^{tx}$ 泰勒展开，则有 $$ \\begin{align} M_X(t)\u0026amp;=\\int_{-\\infty}^{+\\infty}e^{tx}f(x)\\text{d}x\\\\ \u0026amp;=\\int_{-\\infty}^{+\\infty}\\left(\\sum_{k=0}^\\infty\\frac{(tx)^k}{k!}\\right)f(x)\\text{d}x\\\\ \u0026amp;=\\sum_{k=0}^\\infty\\frac{t^k}{k!}\\int_{-\\infty}^{+\\infty}x^kf(x)\\text{d}x\\\\ \u0026amp;=\\sum_{k=0}^\\infty\\frac{t^k}{k!}\\mu_k\\qquad \\blacksquare \\end{align} $$\n因此我们可以通过对矩母函数求导的方式来快速获得一个随机变量的各个 $k$ 阶矩： $$ \\mu_k=\\left.\\frac{\\text{d}^kM_X(t)}{\\text{d}x^k}\\right|_{t=0} $$\n设 $\\alpha$ 和 $\\beta$ 为常数，那么 $$ M_{\\alpha X+\\beta}(t)=e^{\\beta t}M_X(\\alpha t) $$\n证明： $$ \\begin{align} M_{\\alpha X+\\beta}(t)=\\mathbb E[e^{t(\\alpha X+\\beta)}]=e^{\\beta t}\\mathbb E[e^{\\alpha t\\cdot X}]=e^{\\beta t}M_X(\\alpha t)\\qquad \\blacksquare \\end{align} $$\n设 $X_1$ 和 $X_2$ 为互相独立的两个随机变量，且 $|t|\u0026lt;\\delta$ 时 $M_{X_1}(t)$ 和 $M_{X_2}(t)$ 均收敛，那么 $$ M_{X_1+X_2}(t)=M_{X_1}(t)\\cdot M_{X_2}(t) $$\n证明： $$ \\begin{align} M_{X_1+X_2}(t)=\\mathbb E[e^{t(X_1+X_2)}]=\\mathbb E[e^{tX_1}\\cdot e^{tX_2}]=\\mathbb E[e^{tX_1}]\\cdot \\mathbb E[e^{tX_2}]=M_{X_1}(t)\\cdot M_{X_2}(t)\\qquad \\blacksquare \\end{align} $$\nMGF of Common Distribution Bernoulli Distribution 设 $X\\sim B(n,p)$，即 $P(X=k)=f(k)=\\binom{n}{k}p^k(1-p)^{n-k}$，那么 $$ \\begin{align} M_X(t)\u0026amp;=\\sum_{k=0}^\\infty e^{tk}f(k)\\\\ \u0026amp;=\\sum_{k=0}^n e^{tk}\\binom{n}{k}p^k(1-p)^{n-k}\\\\ \u0026amp;=\\sum_{k=0}^n\\binom{n}{k}(e^tp)^k(1-p)^{n-k}\\\\ \u0026amp;=(e^tp+1-p)^n \\end{align} $$\nPoisson Distribution 设 $X\\sim p(\\lambda)$，即 $P(X=k)=f(k)=\\frac{\\lambda^ke^{-\\lambda}}{k!}$，那么 $$ \\begin{align} M_X(t)\u0026amp;=\\sum_{k=0}^\\infty e^{tk}f(k)\\\\ \u0026amp;=\\sum_{k=0}^\\infty e^{tk}\\cdot \\frac{\\lambda^ke^{-\\lambda}}{k!}\\\\ \u0026amp;=e^{-\\lambda}\\sum_{k=0}^\\infty\\frac{(\\lambda e^t)^k}{k!}\\\\ \u0026amp;=e^{-\\lambda}\\cdot e^{\\lambda e^t}=e^{\\lambda(e^t-1)} \\end{align} $$\nNormal Distribution 我们首先考虑标准正态分布：设 $Y\\sim N(0,1)$，那么 $Y$ 的密度函数 $f(y)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{y^2}{2}}$，从而 $$ \\begin{align} M_Y(t)\u0026amp;=\\mathbb E[e^{tY}]=\\int_{-\\infty}^{+\\infty}e^{ty}f(y)\\text{d}y\\\\ \u0026amp;=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}e^{-\\frac{y^2}{2}+ty}\\text{d}y\\\\ \u0026amp;=e^{\\frac{1}{2}t^2}\\cdot \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}e^{-\\frac{1}{2}(y-t)^2}\\text{d}y \\end{align} $$ 注意到后半部分恰好是 $N(t,1)$ 的概率密度函数在 $\\mathbb R$ 上的积分，因此后半部分为 1，从而 $M_Y(t)=e^{\\frac{1}{2}t^2}$。\n对于一般的正态分布 $X\\sim N(\\mu,\\sigma^2)$，注意到 $\\frac{X-\\mu}{\\sigma}=Y$，即 $X=\\sigma Y+\\mu$，因此根据矩母函数的性质， $$ M_X(t)=M_{\\sigma Y+\\mu}(t)=e^{\\mu t}M_Y(\\sigma t)=e^{\\mu t+\\frac{1}{2}\\sigma^2t^2} $$ 正态分布的矩母函数恰好就是对数正态分布的 $k$ 阶矩，推导过程如下：假设 $X$ 服从对数正态分布，那么 $\\ln X\\sim N(\\mu,\\sigma)$，从而 $$ \\mathbb E[X^k]=\\mathbb E[(e^{\\ln X})^k]=\\mathbb E[e^{k\\ln X}]=M_{\\ln X}(k)=e^{\\mu k+\\frac{1}{2}\\sigma^2k^2} $$ 注：对数正态分布没有矩母函数。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"99d0bcf0b387e7bc896ab072df6dc887","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-probability/mgf/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-probability/mgf/","section":"notes","summary":"矩母函数是快速求解高阶矩的利器。\nDefinitions and Properties $\\fbox{Definition 1}$ ($k$ 阶矩) 设 $X$ 是一个概率密度为 $f$ 的随机变量。若 $X$ 是离散的，则它的 $k$ 阶矩 (记作 $\\mu_k$) 定义为 $$ \\mu_k\\triangleq \\sum_{m=0}^{\\infty}x_m^kf(x_m) $$ 若 $X$ 是连续的，则它的 $k$ 阶矩定义为 $$ \\mu_k\\triangleq \\int_{-\\infty}^{+\\infty}x^kf(x)\\text{d}x $$ $\\fbox{Definition 2}$ (矩母函数) 设 $X$ 是一个概率密度为 $f$ 的随机变量，则其矩母函数 $M_X(t)$ 定义为 $\\mathbb E[e^{tX}]$。具体地说，若 $X$ 是离散的，则 $$ M_X(t)\\triangleq \\sum_{m=0}^\\infty e^{tx_m}f(x_m) $$ 若 $X$ 是连续的，则 $$ M_X(t)\\triangleq \\int_{-\\infty}^{+\\infty}e^{tx}f(x)\\text{d}x $$ 矩母函数有如下重要性质：","tags":null,"title":"Moment Generating Function","type":"docs"},{"authors":null,"categories":null,"content":"该实验主要目的是实现一个精简版的 Linux pstree 命令行工具，以较为优美的方式打印当前系统中的进程树。\nParse args 首先对输入的选项列表进行分析。笔者使用了 C 库函数 getopt_long()，它不仅可以帮助我们快速解析选项，还可以同时识别一个选项的长短版本 (使用 C 库提供的 option 结构体可以定义每种选项的长短版本以及是否需要参数等)，识别多个选吸纳更合并给出的格式 etc.。\n定义好表格后，仅需一句话即可完成选项解析：\nconst struct option table[] = { {\u0026quot;numeric-sort\u0026quot;, no_argument, NULL, 'n'}, {\u0026quot;show-pids\u0026quot; , no_argument, NULL, 'p'}, {\u0026quot;version\u0026quot; , no_argument, NULL, 'V'}, {0 , 0 , NULL, 0 }, }; getopt_long(argc, argv, \u0026quot;-npV\u0026quot;, table, NULL) 关于版本信息\nLinux 的 pstree 工具会将版本信息输出到标准错误流，为了模拟这一特性，我们可以使用 fprintf 语句将版本信息输出到 stderr 文件。\nFetch Process Information Linux 提供 procfs，我们可以用读写文件的 API 来获取操作系统中的进程状态。procfs 的根目录是 /proc，该目录中所有是数字的文件夹都存储了一个进程相关的信息，文件夹的数字名就是进程编号。配合使用 C 库函数 opendir() 和 readdir() 就可以遍历 /proc 下的所有内容并筛选出那些是数字的文件夹名。\n每个进程文件夹下的 /proc/[pid]/stat 文件中存储了我们打印进程树所需要的状态信息，包括但不限于进程的名字，进程的状态，进程号，父进程号等。我们可以利用这些信息把进程树构建出来。\n关于进程名的格式\n根据 man proc 的提示，所有的进程名都是用一对小括号包裹着的。笔者起初使用了 scanf(\u0026quot;%[^)]\u0026quot;) 的方法，读到右括号停止，但发现进程中有一些进程的进程名本身就带括号。因此只能一个字节一个字节读并同步维护一个括号的栈来确定什么时候停止。\n我们可以在 /proc/sys/kernel/pid_max 文件中查看进程号的最大值，在 64 位系统中，这个最大值为 $2^{22}$。为了代码编写的方便和效率，笔者开了一个这么大的数组 proc_pos[] 用于维护每个进程号对应到进程信息结构体数组 proc[] 的哪个位置。 proc 结构体中维护了一个当前进程的所有孩子的链表，孩子数量，进程名等信息。由于系统中真正在运行的进程个数远小于 $2^{22}$，这个做法可以省很多内存。\n事实上，Linux 的 pstree 工具还会将一个进程下的所有线程打印出来。我们可以在 /proc/[pid]/task 下看到所有的线程文件夹，/proc/[pid]/task/[tid]/stat 中也有各个线程的状态，不过本实验不要求打印线程。\nPrint tree 打印进程树可以用对进程树的一次 dfs 来实现 —— 根节点是 1 号进程 systemd。这里需要注意的是遍历顺序的问题：在默认情况下，pstree 各个子树会按照进程名的字典序排序，如果有 -n 选项，则要按照进程号从小到大排序。在笔者的实现中，单向链表不方便进行高级的排序，但我们可以直接交换两个链表内部的内容，使用朴素的冒泡排序来完成工作。\n更优美的显示\n打印树结构的最简单的方法是使用缩进：我们只需要记录当前递归到第几层，并打印相应个数的 TAB 即可。为了实现像 Linux pstree 工具那样精美的树结构，我们需要以下观察：\n每个进程的第一个子进程不换行。仔细思考以下，我们会发现这个规则等价于我们只会在那些叶子进程处换行。 每个进程名之前有一个树的节点符号，这个节点符号遵循的规则如下： 如果某进程有且仅有一个子进程，则节点符号为 -； 如果某进程有大于一个子进程，则第一个孩子的节点符号是 +，最后一个孩子的节点符号是 ` ，中间孩子的节点符号是 |。 当我们在打印内层进程内容时，外层进程树会有 | 延伸下来，我们可以用一个栈记录所有需要打印 | 的位置。但需要注意的是：每个进程的最后一个子进程如果还有子进程，子进程的子进程是不会被子进程的父进程的 | 包裹住的，具体操作上，每个进程的最后一个子进程负责将父进程从栈中弹出。 ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"3c4bb3635b50e9e2e50931d8b102a4d3","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/minilabs/minilab01/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/minilabs/minilab01/","section":"notes","summary":"该实验主要目的是实现一个精简版的 Linux pstree 命令行工具，以较为优美的方式打印当前系统中的进程树。\nParse args 首先对输入的选项列表进行分析。笔者使用了 C 库函数 getopt_long()，它不仅可以帮助我们快速解析选项，还可以同时识别一个选项的长短版本 (使用 C 库提供的 option 结构体可以定义每种选项的长短版本以及是否需要参数等)，识别多个选吸纳更合并给出的格式 etc.。\n定义好表格后，仅需一句话即可完成选项解析：\nconst struct option table[] = { {\u0026quot;numeric-sort\u0026quot;, no_argument, NULL, 'n'}, {\u0026quot;show-pids\u0026quot; , no_argument, NULL, 'p'}, {\u0026quot;version\u0026quot; , no_argument, NULL, 'V'}, {0 , 0 , NULL, 0 }, }; getopt_long(argc, argv, \u0026quot;-npV\u0026quot;, table, NULL) 关于版本信息","tags":null,"title":"MiniLab 01: Process Tree","type":"docs"},{"authors":null,"categories":null,"content":"本实验的主要目标是实现协程库 (lib coroutines)。很大程度上协程和线程非常相似，一个主要的区别是：线程可以响应中断，然后通过内核的调度器进行切换，而协程如果不主动 yield 则不会切换。\nCoroutine Struct 协程之间共享内存，但各自有独立的运行时栈。笔者定义的协程结构体大致如下：\nstruct co { const char *name; void (*func)(void *); void *arg; enum co_status status; struct co *waiter; jmp_buf context; uint8_t stack[STACK_SIZE]; }coroutine[CO_SIZE]; name 字段主要用于 debug。func 和 arg 是目标函数的地址和调用时的参数。waiter 存储了指向调用 co_wait() 等待当前协程的“父协程”的指针，当本协程结束时，应该唤醒 (可能存在的) 睡眠的父协程。context 存储了切换时的寄存器上下文，在本实验中，我们使用 setjmp() 和 longjmp() 来完成跳转。\nco_new() co_new() 要做的事情很简单：将所有的协程相关的信息保存到一个结构体变量中即可。我们主要需要思考的是如何开始执行一个新的协程。对于那些调用 co_yield() 中断的协程，我们只需要一个 longjmp() 就可以跳回去，但新的协程的运行时环境的创建要我们自己来操心：\n我们需要自己完成栈切换并让 PC 指向目标函数的地址。 协程对应的函数结束后，我们要指定好返回地址。 笔者最初的实现用內联汇编包办了上面的所有事情：将协程栈地址赋给 %esp/%rsp，用 jmp 指令直接跳转，并在栈上提前存储了一个指向 co_exit() 函数地址的“返回地址”来引导协程结束的去向。但后发现其实用 C 语言做一个 wrapper 完成函数跳转更方便：\nvoid wrapper(void *sp, void *entry, uintptr_t arg) { // stack switching, in assembly ((void(*)(uintptr_t))entry)(arg); // coroutine goes here after entry(arg) } C 编译器会将我们的跳转语句翻译成 call，帮我们填写好返回地址 (不需要额外创建一个 co_exit() 函数了)。我们在內联汇编中需要做的就是将 wrapper() 的栈环境复刻一份到协程的栈上 ( x86_64 甚至只需要改一下 %rsp，因为参数是放在寄存器里的；x86 需要把栈上的参数也搬一份)。\n协程结束后，我们应该将其状态设置成 ZOMBIE (等待父协程回收)，并跳转到调度函数。\nStack Alignment 笔者曾经在 x86_64 中遇到过神秘的段错误，使用 GDB 定位后发现错误语句出现在 printf() 库函数形如\nmovaps %xmm0,0x50(%rsp) movaps %xmm1,0x60(%rsp) 的 SSE 指令。x86_64 对栈有 16 字节的对齐要求 (每个单元是 8 个字节)，这是因为 x86_64 中的一部分寄存器是 16 字节的。出现该错误的根本原因是笔者没有按照 System V ABI 的要求设置好 %rsp：System V ABI (x86-64) 对堆栈对齐的要求是：call 指令执行之前要按 16B 对齐，call 指令执行之后就不按照 16B 对齐了。这其中的原理如下：\ncall 指令执行之前，堆栈按 16B 对齐；\ncall 指令的语义是：将下一条指令的地址 push 到栈上，然后根据操作数让 PC 跳转到对应的地址执行新的函数。我们向堆栈 push 了一个 8B 的东西 (返回地址)，所以刚执行完 call 指令时堆栈是不对齐的。\n刚进入一个新函数时，(一般情况下) 编译器生成的头两条指令会是\npush %rbp mov %rsp, %rbp 这时我们又向栈上 push 了一个 8B 的东西 (旧 %rbp 值)，因此在正式开始执行函数体时，堆栈又是对齐的了。\n在这套流程下，返回地址总是被保存在一个 16B 不对齐的地址上。笔者最初的实现用 jmp 指令直接跳转，且 %rsp 设置成了 16B 对齐，在 16B 对齐的位置手动放了一个返回地址，这样进入新函数 push %rbp 之后，堆栈就不对齐了，从而导致错误。\nco_yield() co_yield() 的代码非常简单：\nvoid co_yield() { int val = setjmp(current-\u0026gt;context); if (val == 0) sched(); } 利用 setjmp() 和 longjmp()，我们可以轻松地完成寄存器现场的封存和恢复。setjmp() 在保存寄存器现场时的返回值是 0，longjmp() 跳转回来时可以指定返回值为非零数，这样保存完现场会跳转到调度函数，跳转回来时就可以直接返回协程继续执行。\nco_wait() co_wait() 要分两种情况：一是子协程已经是僵尸协程，这时候直接释放子协程的资源；二是子协程还不是僵尸协程，这时候要将当前协程睡眠 (状态设置成 WAITING)，子协程结束时会负责唤醒它 (将状态改成 RUNNING)。\nco_init() 我们需要对协程库做一些必要的初始化：比如 main() 函数本身也是一个协程，我们要将 main() 函数作为一个 RUNNING 的协程存储好。初始化函数应当在 main() 函数开始执行之前执行，因此我们需要\n__attribute__((constructor)) void co_init() { // code } 来修饰 co_init()。\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"5847fa78360e623c3b605d28db3bfd92","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/minilabs/minilab02/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/minilabs/minilab02/","section":"notes","summary":"本实验的主要目标是实现协程库 (lib coroutines)。很大程度上协程和线程非常相似，一个主要的区别是：线程可以响应中断，然后通过内核的调度器进行切换，而协程如果不主动 yield 则不会切换。\nCoroutine Struct 协程之间共享内存，但各自有独立的运行时栈。笔者定义的协程结构体大致如下：\nstruct co { const char *name; void (*func)(void *); void *arg; enum co_status status; struct co *waiter; jmp_buf context; uint8_t stack[STACK_SIZE]; }coroutine[CO_SIZE]; name 字段主要用于 debug。func 和 arg 是目标函数的地址和调用时的参数。waiter 存储了指向调用 co_wait() 等待当前协程的“父协程”的指针，当本协程结束时，应该唤醒 (可能存在的) 睡眠的父协程。context 存储了切换时的寄存器上下文，在本实验中，我们使用 setjmp() 和 longjmp() 来完成跳转。","tags":null,"title":"MiniLab 02: Coroutine Library","type":"docs"},{"authors":null,"categories":null,"content":"该实验的主要目标是利用 strace 系统调用实现一个性能监测器，实时输出当前进程运行耗时排名前 5 的系统调用。\nOverview 该实验的大体思路为：我们需要 fork 出一个子进程，让子进程用 strace 运行目标程序，并把 strace 的结果通过管道输送给父进程。本实验只允许使用 execve() 函数，不允许使用带有 p 的库函数，这意味着我们必须手动解析环境变量，将所有的路径一一加在 strace 的前面并调用 execve()，直到找到 strace 的确切位置为止 (如果成功执行，函数不会返回)。父进程负责不断从管道中读取 strace 的输出，解析出系统调用名和消耗的时间并添加到数据结构中，每隔一段时间输出一次。\n以下主要记录实验中遇到的一些有趣的细节。\ndup() vs dup2() 创建管道以后，我们会有将子进程的标准输出和父进程的标准输入连接到管道的写口/读口的需求。我们可能会写出这样的代码：\nclose(0); // close stdin dup(pipefd[0]); dup() 总是会挑选当前最小的未使用文件描述符，因此关闭了 stdin 后，dup() 会将 0 号文件描述符复制为管道写口的文件描述符。但这其实是一个 bad practice：在多线程的程序中，如果 close() 和 dup() 之间被插入了其他执行流，我们不能保证 dup() 执行时最小的未使用文件描述符仍然是 0。因此我们应该使用函数 dup2()：\ndup2(pipefd[0], 0); dup2() 系统调用的声明为\nint dup2(int oldfd, int newfd); 它和 dup() 的含义基本相同，不同之处在于我们可以指定将 oldfd 复制到 newfd 上而不是“最小的未使用文件描述符”。如果 newfd 对应的文件处于打开状态，dup2() 会将其先关闭再使用该描述符。dup2() 的好处在于关闭文件和使用 newfd 的过程是原子的 (手册保证了这一点)。\nTime Information Matching 笔者尝试使用了正则表达式来匹配 strace 输出信息中和运行时间相关的有效内容。regex.h 库中提供了和正则表达式相关的库函数。一些比较有用的函数罗列如下：\nint regcomp(regex_t *preg, const char *regex, int cflags); 该函数负责将一个正则表达式编译成一个 regex_t 类型的东西。\nint regexec(const regex_t *preg, const char *string, size_t nmatch, regmatch_t pmatch[], int eflags); regexec() 负责匹配。preg 是编译好的正则表达式，string 是匹配的串。nmatch 是匹配次数。pmatch[] 数组会存储 nmatch 个匹配结果，其中每个结果是一个 regmatch_t 类型的东西：\ntypedef struct { regoff_t rm_so; regoff_t rm_eo; } regmatch_t; 两个变量存储了匹配结果首尾相对于 string 首地址的偏移量。\nNoise Filtering 我们希望过滤掉目标程序的噪音输出以保证父进程可以获得纯净的 strace 信息。我们有两个方向：\n重定向目标程序的标准错误 (因为 strace 默认输出到标准错误)，但笔者并没有在 strace 的手册中查看到只重定向目标程序的选项。 重定向 strace 的输出：我们可以利用 strace 的 -o 选项来将 strace 的信息输出到一个指定的文件。事实上，我们创建的管道也是一个文件：虽然 pipe() 创建的管道是匿名的，但我们仍然可以通过 procfs 找到它：对于进程号 pid 下文件描述符 id，/proc/pid/fd/id 就是该文件的文件名。因此我们可以利用 -o 直接将 strace 的输出直接定向到管道 (甚至省掉了 dup2() 的过程)。 ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"8e3f4173daa95862959692f8fb3086ed","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-operating-system/minilabs/minilab03/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/notes/coursenotes/nju-operating-system/minilabs/minilab03/","section":"notes","summary":"该实验的主要目标是利用 strace 系统调用实现一个性能监测器，实时输出当前进程运行耗时排名前 5 的系统调用。\nOverview 该实验的大体思路为：我们需要 fork 出一个子进程，让子进程用 strace 运行目标程序，并把 strace 的结果通过管道输送给父进程。本实验只允许使用 execve() 函数，不允许使用带有 p 的库函数，这意味着我们必须手动解析环境变量，将所有的路径一一加在 strace 的前面并调用 execve()，直到找到 strace 的确切位置为止 (如果成功执行，函数不会返回)。父进程负责不断从管道中读取 strace 的输出，解析出系统调用名和消耗的时间并添加到数据结构中，每隔一段时间输出一次。\n以下主要记录实验中遇到的一些有趣的细节。\ndup() vs dup2() 创建管道以后，我们会有将子进程的标准输出和父进程的标准输入连接到管道的写口/读口的需求。我们可能会写出这样的代码：","tags":null,"title":"MiniLab 03: Syscall Profiler","type":"docs"},{"authors":[],"categories":[],"content":"DL Library Fuzzing Bug Report Source: release notes of latest versions, Github PRs Version: TensorFlow 2.8\u0026amp;2.9, PyTorch 1.12 Amount: 40 Multi-API triggered bugs: 8 (all in PyTorch) Typical Bugs PyTorch, GitHub #73187\nError: unexpected RuntimeError\nimport torch grad_output = torch.full((1, 1, 1, 4, 4,), 1, dtype=torch.float64, requires_grad=True) input = torch.full((5, 5, 5, 5, 5,), 3.5e+35, dtype=torch.float64, requires_grad=True) grid = torch.full((1, 1, 1, 4, 4,), 1, dtype=torch.float64, requires_grad=True) interpolation_mode = 0 padding_mode = 0 align_corners = True res = torch.grid_sampler_3d(input, grid, interpolation_mode, padding_mode, align_corners) grad_out = torch.zeros_like(res) torch.autograd.backward(res, grad_tensors=grad_out) grid_sampler_3d() + backward()\nTypical Bugs PyTorch, GitHub #75781\nError: unexpected warning\nimport torch if __name__ == \u0026quot;__main__\u0026quot;: n = 8 x = torch.zeros(n).normal_() x.requires_grad = True z = torch.fft.irfft(x).sum() z.backward() fft() + irfft() + sum() + backward()\nTypical Bugs PyTorch, GitHub #77245\nError: unexpected RuntimeError\nimport torch def fn(input): offset = 0 fn_res = torch.diagonal(input, offset=offset, ) return fn_res input = torch.rand([0, 1], dtype=torch.complex128, requires_grad=True) torch.autograd.gradcheck(fn, (input), check_forward_ad=True, check_backward_ad=False) gradcheck() + diagonal() + function parameter\nTypical Bugs PyTorch, GitHub #77526\nError: man-made assertion error\na = torch.randn((2, 2), dtype=torch.cfloat).transpose(0, 1) result = torch.abs(a) assert a.stride() == b.stride() transpose() + abs() + stride()\nSummary Linux kernel(system) v.s. DL libraries(tool kit) Common bug types Integer overflow, division by zero Out of memory(OOM), Out of bound(OOB) missing validation Documentation Documentation Semantics Learning-based semantics \u0026lsquo;understanding\u0026rsquo; seems inevitable. $\\Rightarrow$ NLP work\nAn interesting bug: PyTorch, GitHub #70657\nimport torch assert torch.ones(10)[::2].ravel().is_contiguous() == True The assertion comes from the document: \"ravel() returns a contiguous flattened tensor\".\nDocumentation Structure The \u0026ldquo;Python API\u0026rdquo; module is divided into 54 sections, including torch, torch.nn, torch.cuda etc.\nThe torch.nn section is divided into 20 subsections, including \u0026ldquo;Convolutional layers\u0026rdquo;, \u0026ldquo;Pooling layers\u0026rdquo;, \u0026ldquo;Padding layers\u0026rdquo; etc. The section contains 186 APIs in total.\nSubsection \u0026ldquo;Convolutional layers\u0026rdquo; includes 14 APIs, offering rich relational information.\nDocumentation Structure Drawback: scalability (e.g. TensorFlow's doc only has coarse categories and lots of APIs are sorted in chronological order.)\nFuzzing Fuzzing perspectives Model-level fuzzing: CRADLE, LEMON Sub-Model? API-level fuzzing: FreeFuzz, DeepREL, DocTer Sub-API? Sub-Model Fuzzing Model-level: precison loss, hard for mutation\u0026hellip; API-level: complicated situations uncovered Sub-model level fuzzing serves as an auxiliary approach to cover more cases. The scale of sub-models/combinations of APIs should be small. Example: PyTorch, GitHub #74404 import torch from torch import nn class MyModule(nn.Module): def __init__(self): super().__init__() self.module_list = nn.ModuleList([nn.Linear(1,1) for _ in range(10)]) self.parameter_list = nn.ParameterList([nn.Parameter(torch.zeros(1)) for _ in range(10)]) def forward(self, x): for m in self.module_list: x = m(x) return x if __name__ == '__main__': model = MyModule() optimize = True with torch.jit.optimized_execution(optimize): a = torch.jit.script(model, 2) Sub-API Fuzzing Under Python APIs: C++ codes\nIdea:\nMost bugs come from missing validations/boundary argument values. The propagation chain of a bug: fault $\\to$ error $\\to$ failure #error \u0026gt; #failure Open the state machine\nExample: assertion injections TensorFlow: CVE-2022-21725 (division by 0)\nint64_t GetOutputSize(const int64_t input, const int64_t filter, const int64_t stride, const Padding\u0026amp; padding) { + assert(stride != 0); if (padding == Padding::VALID) { return (input - filter + stride) / stride; // what if stride = 0 ? } else { // SAME. return (input + stride - 1) / stride; } } Example: assertion injections TensorFlow: CVE-2022-21728 (heap OOB)\nstatic DimensionHandle DimKnownRank(ShapeHandle s, int64_t idx) { + assert(-s-\u0026gt;dims_.size() \u0026lt;= idx \u0026amp;\u0026amp; idx \u0026lt; s-\u0026gt;dims_.size()); CHECK_NE(s-\u0026gt;rank_, kUnknownRank); if (idx \u0026lt; 0) { return s-\u0026gt;dims_[s-\u0026gt;dims_.size() + idx]; } return s-\u0026gt;dims_[idx]; } Example: assertion injections TensorFlow: CVE-2022-23589 (null pointer dereference)\nNodeDef* mul_left_child = node_map_-\u0026gt;GetNode(node-\u0026gt;input(0)); NodeDef* mul_right_child = node_map_-\u0026gt;GetNode(node-\u0026gt;input(1)); + assert(mul_left_child != NULL \u0026amp;\u0026amp; mul_right_child != NULL); const bool left_child_is_constant = IsReallyConstant(*mul_left_child); const bool right_child_is_constant = IsReallyConstant(*mul_right_child); ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"32289cc6e2d5280519de71d4379386a1","permalink":"https://kristoff-starling.github.io/slides/20220727/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/20220727/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":[],"content":"Atheris Automation Methodology Use FreeFuzz\u0026rsquo;s tests as templates Substitute concrete values with appropriate functions arg_1 = 56 --\u0026gt; arg_1 = fh.get_int() arg_1 = [-1.0, 6.0] --\u0026gt; arg_1 = fh.get_float_list() padding = 'VALID' --\u0026gt; padding = fh.get_string(type=padding) An Example: def TestOneInput(data): fh = FuzzingHelper(data) arg_0_tensor = fh.get_random_tensor( shape=None, dtype_set=[tf.float16, tf.float32, tf.float64, tf.int32, tf.int64], min_size=1, max_size=8) arg_0 = tf.identity(arg_0_tensor) dtype = tf.float16 _ = tf.cast(arg_0,dtype=dtype,) Issue: lots of APIs contains hidden specifications.\nExample: tf.nn.conv2d()\nSpecification: The input tensor may have rank 4 or higher. padding should be in {'VALID', 'SAME'} A dummy test such as arg_0 = fh.get_random_tensor() arg_1 = fh.get_random_tensor() strides = fh.get_int() padding = fh.get_string() _ = tf.nn.conv2d(arg_0,arg_1,strides=strides,padding=padding,) will fail. Solution: use FreeFuzz to find specifications through trials and errors.\nExample:\nGoal: Identify whether the API accepts negative inputs. Steps: Obtain a valid FreeFuzz test. Substitute the argument with \u0026ldquo;-1\u0026rdquo;. Execute the modified tests and try to catch exceptions. int/float: value range int/float list: length, negative value string: special names (reduction/padding/activation/channel) Tensor: dtype, shape(length, value range) Sometimes, two lists/tensors are required to have the same length/dimension. In this situation, we analyze the structure of an invocation and try to add restrictions on arguments on the same level. Results Success Rate (Here success means that the test terminates without \"InvalidArgument\" errors.)\nBefore specification learning: \u0026lt;50% After specification learning: 478/533, 89.6% Coverage 5 untrivial APIs were selected for coverage test:\ntf.random.stateless_parameterized_truncated_normal tf.optimizers.schedules.ExponentialDecay tf.keras.layers.SpatialDropout3D tf.keras.layers.Convolution3DTranspose tf.keras.initializers.LecunNormal 150 tests were generated for each API\nCoverage The dummy test\nimport tensorflow as tf covers 70005 lines. Besides that,\nFreeFuzz\u0026rsquo;s tests cover 1151 lines. Atheris\u0026rsquo;s tests cover 1040 lines. 1038 of which are common. Current Problems We cannot learn complicated specifications through simple experiments. FreeFuzz itself is not very stable: some tests rely on random seeds to run normally. We haven\u0026rsquo;t found bugs through these tests. Some OOM bugs have been caught but it seems that they are false positive bugs due to my local machine limitations. ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"3dc8db85422fdd097f5b7eb557a8c0b7","permalink":"https://kristoff-starling.github.io/slides/20220907/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/20220907/","section":"slides","summary":"Atheris Automation Methodology Use FreeFuzz\u0026rsquo;s tests as templates Substitute concrete values with appropriate functions arg_1 = 56 --\u0026gt; arg_1 = fh.get_int() arg_1 = [-1.0, 6.0] --\u0026gt; arg_1 = fh.get_float_list() padding = 'VALID' --\u0026gt; padding = fh.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":[],"content":"C/C++ Coverage Methods We found that running programs with Atheris will not produce coverage information, i.e. \".gcda\" files. Jiawei has created an issue in Atheris's GitHub repository. We manage to walk around this issue by tracing the bytes generated by Atheris and replay the tests natively. Results 5 APIs, 100 tests under FreeFuzz \u0026 Atheris\nHow many lines are covered. How many lines are covered only by FreeFuzz/Atheris. How many lines are executed more. tf.keras.initializers.LecunNormal\nOverall:\nUnique More execution Total FreeFuzz 211 2390 6447 Atheris 105 1468 6342 TensorFlow:\nUnique More execution Total FreeFuzz 109 1080 3735 Atheris 33 884 3659 tf.keras.layers.Convolution3DTranspose\nAll:\nUnique More Execution Total FreeFuzz 192 5884 16423 Atheris 163 1457 16394 TensorFlow:\nUnique More Execution Total FreeFuzz 80 2907 5649 Atheris 11 461 5580 tf.optimizers.schedules.ExponentialDecay\nAll:\nUnique More Execution Total FreeFuzz 194 2307 6511 Atheris 117 2383 6434 TensorFlow:\nUnique More Execution Total FreeFuzz 166 1340 3872 Atheris 15 1311 3720 tf.losses.CategoricalHinge\nAll:\nUnique More Execution Total FreeFuzz 34 181 7045 Atheris 52 3136 7064 TensorFlow:\nUnique More execution Total FreeFuzz 20 25 4171 Atheris 1 1871 4153 tf.math.reduce_sum\nAll:\nUnique More Execution Total FreeFuzz 589 2955 7247 Atheris 178 1992 6838 TensorFlow:\nUnique More Execution Total FreeFuzz 350 1805 4257 Atheris 57 994 3965 ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"e76eb6a52708786ebb499e1735bbde8b","permalink":"https://kristoff-starling.github.io/slides/20220923/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/20220923/","section":"slides","summary":"C/C++ Coverage Methods We found that running programs with Atheris will not produce coverage information, i.e. \".gcda\" files. Jiawei has created an issue in Atheris's GitHub repository. We manage to walk around this issue by tracing the bytes generated by Atheris and replay the tests natively.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":[],"content":"Scalability Setup 1000 times for each API (FreeFuzz\u0026rsquo;s standard) Including invalid inputs Total coverage (including C++\u0026rsquo;s libraries) Coverage 209 APIs were tested. Approximately 150 new lines per API. 4158 new lines are covered, 567 of which are \u0026ldquo;completely new\u0026rdquo;. Speed Approximately 5 min per API (with coverage test) :( Several seconds per API (generate tests only) Optimization Three strategies:\nSuccessful-execution path: Leverage FreeFuzz\u0026rsquo;s mutation strategies. (working) Non-aggresive argument generation (with learned specifications) Error-handling path: Aggresive argument generation (no specification) Atheris Test Framework Example: tf.tile\ndef TestOneInput(data): fh = FuzzingHelper(data) aggresive = False if fh.random_dice(0.3) else True follow_freefuzz = False if fh.random_dice(0.6) else True arg_0_tensor = get_argument_arg_0_tensor( name='arg_0_tensor', fh, aggresive=aggresive, follow_freefuzz=follow_freefuzz) arg_0 = tf.identity(arg_0_tensor) arg_1 = get_argument_arg_1( name='arg_1', fh, aggresive=aggresive, follow_freefuzz=follow_freefuzz) _ = tf.tile(arg_0, arg_1,) Atheris Test Framework (cont\u0026rsquo;d) def get_argument_arg_0_tensor(name, fh, aggresive=False, follow_freefuzz=False): global argument_dict if name not in argument_dict: follow_freefuzz = False if follow_freefuzz is True: res = fh.mutate(argument_dict[name]) elif not aggresive: res = fh.get_random_tensor(shape=None, dtype_set=[tf.float16, tf.float32, tf.float64, tf.int32, tf.int64], min_size=3, max_size=3) else: res = fh.get_random_tensor() argument_dict[name] = res return res ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"fd772302ba339b112e45985d1982341f","permalink":"https://kristoff-starling.github.io/slides/20220930/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/20220930/","section":"slides","summary":"Scalability Setup 1000 times for each API (FreeFuzz\u0026rsquo;s standard) Including invalid inputs Total coverage (including C++\u0026rsquo;s libraries) Coverage 209 APIs were tested. Approximately 150 new lines per API. 4158 new lines are covered, 567 of which are \u0026ldquo;completely new\u0026rdquo;.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment \u0026quot;weight\u0026quot;=1%}} One {{% /fragment %}} {{% fragment \u0026quot;weight\u0026quot;=1%}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://kristoff-starling.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://kristoff-starling.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://kristoff-starling.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":null,"categories":null,"content":" Introduction Data and Functions Enumerated Types Days of the Week Booleans Types New Types from Old Module Tuples Numbers Proof by Simplification Proof by Rewriting Proof by Case Analysis Fixpoints and Structural Recursion (Optional) Exercises Exercise: 1 star, standard (nandb) Exercise: 1 star, standard (andb3) Exercise: 1 star, standard (factorial) Exercise: 1 star, standard (ltb) Exercise: 1 star, standard (plus_id_exercise) Exercise: 1 star, standard (mult_n_1) Exercise: 2 stars, standard (andb_true_elim2) Exercise: 1 star, standard (zero_nbeq_plus_1) Exercise: 2 stars, standard, optional (decreasing) Exercise: 1 star, standard (identity_fn_applied_twice) Exercise: 1 star, standard (negation_fn_applied_twice) Exercise: 3 stars, standard, optional (andb_eq_orb) Exercise: 3 stars, standard (binary) Introduction 函数式编程 (functional programming) 的思想来自于：如果一个过程或方法没有副作用，那么我们只关心它如何将输入映射到输出，即这个过程/方法是一个数学函数的具体实现。函数式编程的另一个想法是：所有的函数都应当被当作 first-classs value：函数可以作为参数，可以作为返回值，就像普通的数据一样。\nData and Functions Enumerated Types Coq 的一个显著特点在于：它的内置 features 非常的少。例如除了一些最基本的类型 (如 boolean, integer, strings)，其他的类型都可以由用户自己通过基本类型来定义。\nDays of the Week Inductive day : Type := | monday | tuesday | wednesday | thursday | friday | saturday | sunday. 这段代码定义了一个叫 day 的数据类型，它的成员有 7 个。基于这个类型，我们可以书写一些函数：\nDefinition next_weekday (d : day) : day := match d with | monday =\u0026gt; tuesday | tuesday =\u0026gt; wednesday | wednesday =\u0026gt; thursday | thursday =\u0026gt; friday | friday =\u0026gt; monday | saturday =\u0026gt; monday | sunday =\u0026gt; monday end. 这段代码显式地给出了函数参数和返回值的类型。事实上 Coq 支持 type inference，但为了阅读方便这里还是写上了。\n定义了函数之后，我们可以利用 Compute 命令来计算一些使用了这个函数的表达式，例如：\nCompute (next_weekday friday). (* ==\u0026gt; monday: day *) 我们还可以通过 Coq Example 来给出一个 assertion：\nExample test_next_weekday: (next_weekday (next_weekday saturday)) = tuesday. 这样的一个 Example 是需要证明的。一个合法的证明如下 (tactic 的意义见后文)：\nProof. simpl. reflexivity. Qed. Booleans 类似地我们可以定义 bool 类型，以及 negation, and, or 三个运算函数：\nInductive bool : Type := | true | false. Definition negb (b : bool) : bool := match b with | true =\u0026gt; false | false =\u0026gt; true end. Definition andb (b1 : bool) (b2 : bool) : bool := match b1 with | true =\u0026gt; b2 | false =\u0026gt; false end. Definition orb (b1 : bool) (b2 : bool) : bool := match b1 with | true =\u0026gt; true | false =\u0026gt; b2 end. 我们可以使用 Notation 命令来通过已有的 definitions 定义新符号：\nNotation \u0026quot;x \u0026amp;\u0026amp; y\u0026quot; := (andb x y). Notation \u0026quot;x || y\u0026quot; := (orb x y). 在 Coq 中我们也可以使用条件分支语句，下面是用条件分支语句描述 and, or, neg 的例子 ( if-then-else 的折行是比较随意的)：\nDefinition negb' (b : bool) : bool := if b then false else true. Definition andb' (b1 : bool) (b2 : bool) : bool := if b1 then b2 else false. Definition orb' (b1 : bool) (b2 : bool) : bool := if b1 then true else b2. Coq 的条件分支语句比一般编程语言的语句的功能更 general 一些：对于只有两个 constructor 的类型，if X 可以表示如果 X 等于第一个 constructor，这里只是因为 bool 类型的第一个 constructor 正好是 true 所以看上去和一般编程语言没有区别。\nTypes Coq 中的每个表达式都有类型，我们可以使用 Check 命令来打印一个表达式的类型：\nCheck true. (* ==\u0026gt; true: bool *) Check (negb true) : bool. 第二种写法相当于一个 assertion，如果类型正确 Coq 不会有反应，如果错误 Coq 会报错。\n在 Coq 中，函数也是有类型的：\nCheck negb : bool -\u0026gt; bool. New Types from Old 我们之前定义的类型都是 enumerated types，即这些定义显式地列举了一个有穷的元素集合，这些元素被称为 constructor。下面的一个更复杂的例子中出现了 constructor 带有参数的用法：\nInductive rgb : Type := | red | blue | green. Inductive color : Type := | black | white | primary (p : rgb). 这里我们引出 constructor expression 的概念：constructor expression 指的是以符合定义的方式将一个 constructor apply 到零个或多个 constructor expression 上。这里的 red, blue, black, white, primary red 等都是 constructor expression。\n这里 color 类型描述了属于 color 这个集合的 constructor expression 的三种形式：\nblack white 如果 p 是一个属于 rgb 的 constructor expression，那么 primary p 就是属于 color 的 constructor expression。 我们仍然可以用 pattern matching 的方式来定义函数：\nDefinition isred (c : color) : bool := match c with | black =\u0026gt; false | white =\u0026gt; false | pattern red =\u0026gt; true | pattern _ =\u0026gt; false end. 这里出现了一个新用法：wildcard pattern _ 是通配符，在这里可以匹配所有不是 red 的其他情形。\nModule Coq 提供一套 module system：如果我们将一个定义 foo 包含在了 Module X 和 End X 之间，那么在模块外我们想要使用 foo 时就要写成 X.foo 而不是直接 foo。module system 让我们可以不用太担心名字重复的问题。\nTuples 一个拥有多个参数的 constructor 可以用来表示 tuple，下面的例子展示了一个 nybble (half byte) 类型：\nInductive bit : Type := | B0 | B1 Inductive nybble: Type := | bits (b0, b1, b2, b3 : bit). 同样地我们可以使用 pattern matching 的方式书写函数：\nDefinition all_zero (nb : nybble) : bool :=\tmatch nb with: | (bits B0 B0 B0 B0) =\u0026gt; true | (bits _ _ _ _\t) =\u0026gt; false end. Compute (all_zero(bits B1 B0 B1 B0)) (* ===\u0026gt; false : bool *) Compute (all_zero(bits B0 B0 B0 B0)) (* ===\u0026gt; true : bool *) Numbers 之前我们定义的 type 都是有穷集合，而自然数集是一个无穷集合，因此我们在这里使用归纳的方法，根据自然数在朴素集合论中的定义方式给出自然数的定义：\nInductive nat : Type := | O | S (n : nat). 该定义的意思是：\nO 是一个属于 nat 集合的 constructor expression。 如果 n 是一个属于 nat 集合的 constructor expression，那么 S n 也属于 nat 集合。 除了以上两条，没有别的 constructor expression 在 nat 集合中。 值得注意的是：这里的 O 和 S 没有任何实际的含义，我们可以用任意别的字符/单词来替换它们。\n下面展示两个函数：pred 和 minustwo，值得学习的是其中 pattern matching 的方法：\nDefinition pred (n : nat) : nat := match n with: | O =\u0026gt; O | S n' =\u0026gt; n' end. Definition minustwo (n : nat) : nat := match n with: | O =\u0026gt; O | S O =\u0026gt; O | S (S n') =\u0026gt; n' end. 由于自然数是一种非常普遍的数据类型，所以 Coq 内置了一些解析和打印自然数的小魔法：O 会被输出为 0，S O 会被输出为 1，依次类推。此外我们给函数传递参数的时候也可以直接使用阿拉伯数字而不是形式化的 S ... S O：\nCompute (minustwo 4). (* ===\u0026gt; 2 : nat *) Check (S (S (S (S O)))). (* ===\u0026gt; 4 : nat *) 我们在定义自然数时使用的 constructor S 和函数 pred minustwo 在类型上是一样的，\nCheck S : nat -\u0026gt; nat. Check pred : nat -\u0026gt; nat. Check minustwo : nat -\u0026gt; nat. 但 S 和其他两者有着本质的区别：pred 和 minustwo 是通过计算规则的方式定义的，例如 pred 4 和 3 没有本质区别；但 S 只是一个表示数的方式，正如十进制用 0~9 这 10 个字符表示数字一样，在我们的归纳系统中我们使用 S 和 O 这两个字符表示数字，S 本身不包含任何的计算功能。\n接下来我们考虑一些更加复杂的关于 number 的函数。例如判断一个数是否是偶数：对于这个问题我们无法通过 pattern matching 的方法直接给出答案，因为偶数有无穷多个。我们只能使用递归的方式：首先规定 O 是偶数，然后对于整数 n 不断 -2 来判断奇偶性。这类需要使用递归的函数应当使用 Fixpoint 而不是 Definition：\nFixpoint even (n : nat) : bool := match n with | O =\u0026gt; true | S O =\u0026gt; false | S (S n') =\u0026gt; even n' end. 下面我们来定义加法，这是一个多参数的函数：\nFixpoint plus (n : nat) (m : nat) : nat := match n with | O =\u0026gt; m | S n' =\u0026gt; S (plus n' m) end. 加法的归纳思路十分巧妙，将第一个加数的 S 施加到结果上，直到第一个加数为 0。下面是 Coq 计算 plus 2 3 的化简流程：\n(* [plus 3 2] i.e. [plus (S (S (S O))) (S (S O))] ==\u0026gt; [S (plus (S (S O)) (S (S O)))] by the second clause of the [match] ==\u0026gt; [S (S (plus (S O) (S (S O))))] by the second clause of the [match] ==\u0026gt; [S (S (S (plus O (S (S O)))))] by the second clause of the [match] ==\u0026gt; [S (S (S (S (S O))))] by the first clause of the [match] i.e. [5] *) 函数的多个参数如果类型一样也可以合并了写，例如下面的这个减法的例子\nFixpoint minus (n m : nat) : nat := match n, m with | O , _ =\u0026gt; O | _ , O =\u0026gt; n | S n', S m' =\u0026gt; minus n', m' end. 这个减法的思路也十分巧妙：不断将被减数和减数同时减少，直到有一个是 0 为止。\n我们可以为加法、减法、乘法 (代码省略) 添加符号：\nNotation \u0026quot;x + y\u0026quot; := (plus x y) (at level 50, left associativity) : nat_scope. Notation \u0026quot;x - y\u0026quot; := (minus x y) (at level 50, left associativity) : nat_scope. Notation \u0026quot;x * y\u0026quot; := (mult x y) (at level 40, left associativity) : nat_scope. More about Notations\n这里出现了三个新的内容：\nlevel 后面可以跟一个 0~100 的数值，这个数值规定了该运算的优先级，数字越小优先级越大。上面的例子中 + 和 - 优先级相同，乘法优先级更高，因此 a + b * c 等价于 a + (b * c)。\nassociativity 有 left, right, no 三种，描述了该符号的结合性。例如 + 是左结合的意味着 a + b + c 等价于 (a + b) + c。\n每个符号有其 notation scope。Coq 的解释器会根据上下文自动分析符号的作用域。比如在 S(0x0) 中 x 会被认定为 nat_scope，而在 bool x bool 中 x 就会被认定为 type_scope。有些情况下我们需要显式地帮助 Coq 解释器确定 scope，我们可以使用 % 语法：例如 (x+y)%nat。\n除了符号有 notation scope，数字也可以指定 scope，例如 0%nat 和 0%Z 一个是自然数 0，一个是整数 0，它们来自不同的标准库。\n接下来再展示一个给两个数比大小的函数 (在 Coq 中，一切都得自己定义)：\nFixpoint leb (n m : nat) : bool := match n with | O =\u0026gt; true | S n' =\u0026gt; match m with | O =\u0026gt; false | S m' =\u0026gt; leb n' m' end end. 当然，我们也可以用像减法那样的语法，这里主要想展示的是 match 的嵌套使用。\nNotation \u0026quot;x =? y\u0026quot; := (eqb x y) (at level 70) : nat_scope. Notation \u0026quot;x \u0026lt;=? y\u0026quot; := (leb x y) (at level 70) : nat_scope. 这里区分一下 = 和 =? ：x = y 是一个命题 (proposition)，给出这样一个 claim 是需要证明的；而 x =? y 是一个表达式，可以直接计算出 true/false。\nProof by Simplification 我们已经有了一系列定义和函数，接下来我们可以证明一些定理。\nTheorem plus_O_n: forall n : nat, 0 + n = n. Proof. intros n. simpl. reflexivity. Qed. 我们对定理和证明中的一些元素做一点说明：\n在 Coq 中，Example Theorem Lemma Fact Remark 没有本质区别。 在定理中我们使用了全称量词 forall。联想人类在证明的时候，我们对于这类定理通常会写下“对于任意自然数n\u0026hellip;” 从而在接下来的证明中把 n 当作一个“具体”的数使用。在 Coq 中我们可以通过 intros 来完成这一步骤。值得注意的是这里 intros 后面其实可以使用任意符号，不一定要和命题中的 n 保持一致。 在本证明以及上面的所有证明中，用于化简的 simpl 其实都是不需要的，因为 reflexivity 自带了化简功能，这里有意显式地写出 simpl 是为了能更好地看到证明化简的中间过程。值得一提的是 reflexivity 的化简功能比 simpl 更强大：它还可以将复杂定义展开。 这里的关键词 intros simpl reflexivity 都是 tactic。tactic 指的是证明过程中用于推进证明过程，检验结果正确的一些命令。\nProof by Rewriting 下面的这个定理比之前的要更加复杂和有趣一些：\nTheorem plus_id_example : forall n m : nat, n = m -\u0026gt; n + n = m + m 这个定理中出现了蕴含关系符。由于 n 和 m 都是任意整数，我们无法直接通过简单的化简来证明最后的等式。但我们注意到在 n = m 的假设下我们可以将等式中的 n 都用 m 来代替。在 Coq 中 rewrite 这个 tactic 负责进行这种替换。\nProof. intros n m. intros H. rewrite -\u0026gt; H. reflexivity. Qed. 第二行的 intros H 表示我们将 n = m 这条假设加入到上下文中，并给其命名为 H。第三条语句表示利用假设 H 将目标中的等式左侧的内容替换成等式右侧的内容。rewrite 中的 -\u0026gt; 表示用 RHS 替换 LHS，如果写成 \u0026lt;- 则是用 LHS 替换 RHS。\nCheck 命令不仅可以检查类型，还可以打印一个定理的内容。下面两个定理是在标准库中证明过的：\nCheck mult_n_O. (* ===\u0026gt; forall n : nat, 0 = n * 0 *) Check mult_n_Sm. (* ===\u0026gt; forall n m : nat, n * m + n = n * S m *) rewrite tactic 除了可以利用命题中的假设等式进行替换，还可以利用已经证明的定理进行替换，例如：\nTheorem mult_n_0_m_0 : forall p q : nat, (p * 0) + (q * 0) = 0. Proof. intros p q. rewrite \u0026lt;- mult_n_O. rewrite \u0026lt;- mult_n_O. reflexivity. Qed. 证明中连续两次利用 mult_n_O 定理进行替换，每次执行替换时 Coq 的解释器会自动在目标等式中寻找定理的 instance。\nProof by Case Analysis 有的时候我们不得不分情况讨论。这里首先给出一个分情况讨论的证明过程的例子：\nTheorem negb_involutive : forall b : bool, negb (negb b) = b. Proof. intros b. destruct b eqn:E - reflexivity. - reflexivity. Qed. 命题中的 b 由于是一个不确定的变量，无法直接化简，我们需要分情况讨论 b = true 和 b = false。\ndestruct 这个 tactic 用于分类讨论，它可以针对所有 inductively 定义的数据类型使用。使用 destruct 相当于分别将 b 看作它定义中的第一，第二……个 constructor，作出 assumption 并创建若干个 subgoal。这里对于 bool 类型相当于分别假设 b = true 和 b = false。作出假设后，destruct 会顺手把假设的内容 \u0026ldquo;rewrite\u0026rdquo; 进去。 eqn:E 负责给做出的假设命名，之后可以通过 E 来使用这个假设。这一步不是必要的，但这是一个好的习惯。 - 称为 bullet，负责划分各个 subgoal 的证明过程。bullet 不是必要的，如果省略，Coq 会将你的按照 subgoal 的顺序将你的证明过程一一代入。但使用 bullet 会使你的证明过程结构更清晰、更可读。 下面是一个稍复杂的例子：\nTheorem plus_1_neq_0_firsttry : forall n : nat, (n + 1) =? 0 = false. Proof. intros n. simpl. (* does nothing! *) Abort. 我们直接使用 simpl 无法化简这个式子。这里值的注意的一点是：如果我们要证明的命题是 (1 + n) =? 0 = false，那么 simpl 就管用了，因为 1 + n 会被计算成 S n，S n =? 0 可以直接判定为 false。这里无法计算是因为我们定义的加法是针对第一个参数进行递归的，而第一个参数是一个无法确定具体值的 n，所以 simpl 无法化简。\n我们分类讨论的策略是看 n 是 O 还是 S n'。这里给出证明过程：\nTheorem plus_1_neg_0 : forall n : nat, (n + 1) ?= 0 = false. Proof. intros n. destruct n as [| n'] eqn:E. - reflexivity. - reflexivity. Qed. 这里新出现了 [| n']。和上一个例子不同，自然数的定义的第二个 constructor 是带参数的，因此我们要用一对中括号 [] 给出每一个 constructor 的参数列表，不同 constructor 的参数列表之间用 | 隔开 (自然数的第一个 constructor 是 O 没有参数，因此 | 左边留空)。如果没有用 [] 显式地说明参数的名称，Coq 会自动分配参数名，但自动分配的参数名可能会很奇怪，从而影响后续的证明。\n分类讨论可以嵌套进行，例如下面的证明 and 运算满足交换律的过程：\nTheorem andb_commutative: forall b c : bool, andb b c = andb c b. Proof. intros b c. destruct b eqn Eb. - destruct c eqn:Ec. + reflexivity. + reflexivity. - destruct c eqn:Ec. + reflexivity. + reflexivity. Qed. 不同层级必须使用不同的 bullet。可以使用的 bullet 有 - + * 以及它们的重复版本 (如 -- *** 等)。除了 bullet 我们还可以使用大括号来框出证明的层次，大括号是可以嵌套的，例如\n{ destruct c eqn:Ec. { reflexivity. } { reflexivity. } } 大括号和 bullet 还可以混合使用：\n{ destruct c eqn:Ec. - reflexivity. - reflexivity. } 很多时候我们使用完 intros 后立刻就要开始分情况讨论，Coq 为我们准备了更加紧凑方便的语法。下面是两个例子：\nTheorem plus_1_neq_0' : forall n : nat, (n + 1) =? 0 = false. Proof. intros [|n]. - reflexivity. - refiexivity. Qed. Theorem andb_commutative'': forall b c : nat, andb b c = andb c b. Proof. intros [] []. - reflexivity. - reflexivity. - reflexivity. - reflexivity. Qed. 这种简洁语法的缺点在于我们无法给分情况讨论时做出的假设等式命名 (即 eqn:E 的部分)。\nFixpoints and Structural Recursion (Optional) 回想加法的定义，我们对第一个加数不断 -1 递归。这样的结构递归保证了我们的参数会越来越小，因此不论输入什么参数计算都一定可以终止。\nCoq 要求所有 Fixpoint 类型的函数的参数都要不断变小，从而保证函数一定可以终止。事实上，有的时候存在一些可以终止的合法函数不满足这个性质 (比如如果我们以 5 和 6 为基准定义偶数，那么 0, 1, 2, 3, 4 就得往上加，从而 Coq 报错)。\nExercises Exercise: 1 star, standard (nandb) Definition nandb (b1:bool) (b2:bool) : bool := match b1, b2 with | true, true =\u0026gt; false | true, false =\u0026gt; true | false, true =\u0026gt; true | false, false =\u0026gt; true end. Example test_nandb1: (nandb true false) = true. Proof. simpl. reflexivity. Qed. Example test_nandb2: (nandb false false) = true. Proof. simpl. reflexivity. Qed. Example test_nandb3: (nandb false true) = true. Proof. simpl. reflexivity. Qed. Example test_nandb4: (nandb true true) = false. Proof. simpl. reflexivity. Qed. Exercise: 1 star, standard (andb3) Definition andb3 (b1:bool) (b2:bool) (b3:bool) : bool := (b1 \u0026amp;\u0026amp; b2) \u0026amp;\u0026amp; b3. Example test_andb31: (andb3 true true true) = true. Proof. reflexivity. Qed. Example test_andb32: (andb3 false true true) = false. Proof. reflexivity. Qed. Example test_andb33: (andb3 true false true) = false. Proof. reflexivity. Qed. Example test_andb34: (andb3 true true false) = false. Proof. reflexivity. Qed. 注：如果 definition 中没有使用 match 语法，则证明过程中使用 simpl. 并不能简化证明过程，这时直接使用 reflexivity. 即可。\nExercise: 1 star, standard (factorial) Fixpoint factorial (n : nat) : nat := match n with | O =\u0026gt; S O | S n' =\u0026gt; mult n (factorial n') end. Example test_factorial1: (factorial 3) = 6. Proof. simpl. reflexivity. Qed. Example test_factorial2: (factorial 5) = (mult 10 12). Proof. simpl. reflexivity. Qed. Exercise: 1 star, standard (ltb) Definition ltb (n m : nat) : bool := negb (m \u0026lt;=? n). Notation \u0026quot;x \u0026lt;? y\u0026quot; := (ltb x y) (at level 70) : nat_scope. Example test_ltb1: (ltb 2 2) = false. Proof. reflexivity. Qed. Example test_ltb2: (ltb 2 4) = true. Proof. reflexivity. Qed. Example test_ltb3: (ltb 4 2) = false. Proof. reflexivity. Qed. Exercise: 1 star, standard (plus_id_exercise) Theorem plus_id_exercise : forall n m o : nat, n = m -\u0026gt; m = o -\u0026gt; n + m = m + o. Proof. intros n m o. intros H1. intros H2. rewrite -\u0026gt; H1. rewrite -\u0026gt; H2. reflexivity. Qed. 这里需要注意第一条假设使用时的替换方向：如果反过来把等式中的 m 用 n 代替，由于没有 n 和 o 的直接关系，证明就被卡住了。\nExercise: 1 star, standard (mult_n_1) Theorem mult_n_1 : forall p : nat, p * 1 = p. Proof. intros p. rewrite \u0026lt;- mult_n_Sm. rewrite \u0026lt;- mult_n_O. reflexivity. Qed. Exercise: 2 stars, standard (andb_true_elim2) Theorem andb_true_elim2 : forall b c : bool, andb b c = true -\u0026gt; c = true. Proof. intros b c. destruct c eqn:Ec. - reflexivity. - destruct b eqn:Eb. + intros H. rewrite \u0026lt;- H. reflexivity. + intros H. rewrite \u0026lt;- H. reflexivity. Qed. 本题的一个有意思的点在于如何处理 contradiction：我们对 c 分情况讨论的时候会发现如果 c = false 那么假设条件不可能成立，会导出 false = true。对于人类来说这就已经结束了，但在 Coq 中我们需要利用这条规则继续做 rewrite (false = true 的情况下天地大同了)，直到导出等式两边相等。\nExercise: 1 star, standard (zero_nbeq_plus_1) Theorem zero_nbeq_plus_1 : forall n : nat, 0 =? (n + 1) = false. Proof. intros [|n']. - reflexivity. - reflexivity. Qed. 这里值得一提的是为何在 n = S n' 时 reflexivity 可以直接算出结果。此时我们的 subgoal 是证明 0 =? (S n' + 1) = false。根据加法的第二条规则，我们有 S n' + 1 = S (n' + 1)。根据 =? 的规则又有第一个参数为 0 第二个参数满足 S n 形式时可以直接判定为 false。因此 false = false 就证出来了。\nExercise: 2 stars, standard, optional (decreasing) Fixpoint error_func (n : nat) : nat := match n with | O =\u0026gt; error_func (S n) | S O =\u0026gt; S O | S n' =\u0026gt; S (error_func n') end. Exercise: 1 star, standard (identity_fn_applied_twice) Theorem identity_fn_applied_twice : forall (f : bool -\u0026gt; bool), (forall (x : bool), f x = x) -\u0026gt; forall (b : bool), f (f b) = b. Proof. intros f. intros H. intros b. rewrite -\u0026gt; H. rewrite -\u0026gt; H. reflexivity. Qed. Exercise: 1 star, standard (negation_fn_applied_twice) Theorem negation_fn_applied_twice : forall (f : bool -\u0026gt; bool), (forall (x : bool), f x = negb x) -\u0026gt; forall (b : bool), f (f b) = b. Proof. intros f H b. rewrite -\u0026gt; H. rewrite -\u0026gt; H. destruct b eqn:E. - reflexivity. - reflexivity. Qed. Exercise: 3 stars, standard, optional (andb_eq_orb) Theorem andb_eq_orb : forall (b c : bool), (andb b c = orb b c) -\u0026gt; b = c. Proof. intros []. - simpl. intros c H. rewrite -\u0026gt; H. reflexivity. - simpl. intros c H. rewrite \u0026lt;- H. reflexivity. Qed. 本题最暴力的做法就是对 b, c 的四种情况分类讨论。但这样不是很聪明，根据 andb 和 orb 的定义，一旦 b 的值确定，表达式的结果是可以用 true, false, c 来表示的，因此我们只要对 b 讨论就可以直接得出 c 的值，这样做简洁很多。\nExercise: 3 stars, standard (binary) Fixpoint incr (m:bin) : bin := match m with | Z =\u0026gt; B1 Z | B0 m' =\u0026gt; B1 m' | B1 m' =\u0026gt; B0 (incr m') end. Fixpoint bin_to_nat (m : bin) : nat := match m with | Z =\u0026gt; O | B0 m' =\u0026gt; (bin_to_nat m') * 2 | B1 m' =\u0026gt; (bin_to_nat m') * 2 + 1 end. Example test_bin_incr1 : (incr (B1 Z)) = B0 (B1 Z). Proof. reflexivity. Qed. Example test_bin_incr2 : (incr (B0 (B1 Z))) = B1 (B1 Z). Proof. reflexivity. Qed. Example test_bin_incr3 : (incr (B1 (B1 Z))) = B0 (B0 (B1 Z)). Proof. reflexivity. Qed. Example test_bin_incr4 : bin_to_nat (B0 (B1 Z)) = 2. Proof. reflexivity. Qed. Example test_bin_incr5 : bin_to_nat (incr (B1 Z)) = 1 + bin_to_nat (B1 Z). Proof. reflexivity. Qed. Example test_bin_incr6 : bin_to_nat (incr (incr (B1 Z))) = 2 + bin_to_nat (B1 Z). Proof. reflexivity. Qed. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7418dec0eee29c1e5eb111ee8f0bf168","permalink":"https://kristoff-starling.github.io/notes/booknotes/softwarefoundations/lf/basics/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/booknotes/softwarefoundations/lf/basics/","section":"notes","summary":"Introduction Data and Functions Enumerated Types Days of the Week Booleans Types New Types from Old Module Tuples Numbers Proof by Simplification Proof by Rewriting Proof by Case Analysis Fixpoints and Structural Recursion (Optional) Exercises Exercise: 1 star, standard (nandb) Exercise: 1 star, standard (andb3) Exercise: 1 star, standard (factorial) Exercise: 1 star, standard (ltb) Exercise: 1 star, standard (plus_id_exercise) Exercise: 1 star, standard (mult_n_1) Exercise: 2 stars, standard (andb_true_elim2) Exercise: 1 star, standard (zero_nbeq_plus_1) Exercise: 2 stars, standard, optional (decreasing) Exercise: 1 star, standard (identity_fn_applied_twice) Exercise: 1 star, standard (negation_fn_applied_twice) Exercise: 3 stars, standard, optional (andb_eq_orb) Exercise: 3 stars, standard (binary) Introduction 函数式编程 (functional programming) 的思想来自于：如果一个过程或方法没有副作用，那么我们只关心它如何将输入映射到输出，即这个过程/方法是一个数学函数的具体实现。函数式编程的另一个想法是：所有的函数都应当被当作 first-classs value：函数可以作为参数，可以作为返回值，就像普通的数据一样。","tags":null,"title":"Functional Programming in Coq","type":"docs"},{"authors":null,"categories":null,"content":"值得一提的是下面两道题\nQ5: If Function Refactor 函数调用会先将所有的参数的值算出来再调用，因此会发生 ZeroDivisionError。\n题目要求 invert_short() 和 change_short() 使用同一套 limited() 的接口，且不能添加额外的判断语句。因此最好的实现方法就是修改 limited() 的语义，参数 z 不再是除法的结果而是分子，除 0 的判断放到 limited() 里面做。\nQ7: Quine 下面提供一种 Python 的 Quine 代码：\n_='_=%r;print (_%%_)';print (_%_) 写入到 hw01.py 中要注意对 ' 进行转义，以及最后需要额外添加一个换行符。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a88e09f3be2b0a5ecaf9fd6c11b59cb6","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/homework/hw01/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/homework/hw01/","section":"notes","summary":"值得一提的是下面两道题\nQ5: If Function Refactor 函数调用会先将所有的参数的值算出来再调用，因此会发生 ZeroDivisionError。\n题目要求 invert_short() 和 change_short() 使用同一套 limited() 的接口，且不能添加额外的判断语句。因此最好的实现方法就是修改 limited() 的语义，参数 z 不再是除法的结果而是分子，除 0 的判断放到 limited() 里面做。\nQ7: Quine 下面提供一种 Python 的 Quine 代码：\n_='_=%r;print (_%%_)';print (_%_) 写入到 hw01.","tags":null,"title":"UCB-CS61A Homework 01: Control","type":"docs"},{"authors":null,"categories":null,"content":"Phase 1: Simulator Problem 1 模拟扔骰子计算得分。唯一需要注意的是即使中间摇出了 1 也要将传入的摇骰子次数做完。因为摇骰子的 index 是一个全局变量，这次的不摇完会影响下一次的结果。\nProblem 2 模拟 picky_piggy，本题代码中不允许使用 string 和 list，因此要使用分离数位的方法获得结果 (或者用大 if)。\nProblem 3 完成 take_turn()，调用 problem 1, 2 中写的两个函数即可。\nProblem 4 模拟 hog_pile，判断两人得分是否相同即可。\nProblem 5 模拟两个人完整的游戏流程。每轮先调用对应的 strategy 获得摇骰子的次数，然后调用 take_turn() 获得分数，再调用 hog_pile() 获得附加得分，最后切换玩家。\nPhase 2: Commentary Commentary Examples say 函数是一类返回值为函数的高阶函数。调用 say 函数会打印出一些信息，并返回一个 say 函数用于下一次调用。最简单的 say 函数是每次逻辑不变的函数：\ndef say(score0, score1): print(score0, score1) return say 稍复杂一些的 say 函数每次返回的函数行为可以不同，比如下面的例子在两人分数领先情况发生变化时会打印信息：\ndef annouce_leader_change(last_leader=None): def say(score0, score1): if score0 \u0026gt; score1: leader = 0 elif: score1 \u0026gt; score0: leader = 1 else: leader = None if leader != None and leader != last_leader: print('Player', leader, 'take the lead by', abs(score0 - score1)) return annouce_leader_change(leader) return say announce_leader_change() 返回的 say() 函数被定义在 announce_leader_change()函数体内，变量 last_leader 会影响 say() 的逻辑。\n下面展示比较有意思的 both() 函数，它会依次执行两个 say 函数：\ndef both(f, g): def say(score0, score1): return both(f(score0, score1), g(score0, score1)) return say Problem 6 在 play() 的最后每次调用 say 函数，并令 say 等于新的 say 函数即可。\nProblem 7 自己书写一个稍复杂的 say 函数 announce_highest()。该问题中需要注意的是：如果没有声明 non local，我们不能在子函数中直接修改父函数中的变量，我们可以选择通过参数传递的方式把新的 last_score 和 running_high 传给父函数。\nPhase 3: Strategy Problem 8 计算若干次运行摇骰子函数的结果的平均值。除了编写高阶函数外，该 problem 的一个知识点在于：我们可以用 *arg 来将某个函数接收的所有参数灌给另一个要执行的函数。例如：\ndef printed(f): def print_and_return(*args): result = f(*args) print('Result:', result) return result return print_and_return 随着调用 printed() 时的函数 f 的不同，我们后续执行 print_and_return() 时可以使用各种数量的参数。\nProblem 9 通过平均值选取当前最优的摇骰子次数。将摇骰子的函数 roll_dice() 喂给之前编写的 make_averaged() 即可。此外，为了通过 ok 的测试，循环必须按照从 1 到 10 的顺序写。\nProblem 10 调用 problem 2 中编写的 picky_piggy() 计算摇 0 的收益并和 cutoff 比较即可。\nProblem 11 和 problem 10 几乎没有差别，额外判断一下会不会触发 hog_pile 规则即可。\nProblem 12 可以参考的一些策略有：\npicky_piggy_strategy() 和 hog_pile_strategy()。 如果能够确保胜利，则应该选择小的摇骰子次数规避风险。 …… ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ab913ea1f4816291afa4d10836b4c106","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/projects/hog/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/projects/hog/","section":"notes","summary":"Phase 1: Simulator Problem 1 模拟扔骰子计算得分。唯一需要注意的是即使中间摇出了 1 也要将传入的摇骰子次数做完。因为摇骰子的 index 是一个全局变量，这次的不摇完会影响下一次的结果。\nProblem 2 模拟 picky_piggy，本题代码中不允许使用 string 和 list，因此要使用分离数位的方法获得结果 (或者用大 if)。\nProblem 3 完成 take_turn()，调用 problem 1, 2 中写的两个函数即可。\nProblem 4 模拟 hog_pile，判断两人得分是否相同即可。","tags":null,"title":"UCB-CS61A Project 01: Hog","type":"docs"},{"authors":null,"categories":null,"content":"Purposes of O/S Abstraction of hardware. Higher level interfaces and abstractions that applications can use can enhance convenience and portability (e.g. processes and file systems) Multiplexing. Different applications can execute at the same time. Isolation and sharing. Security. Restrictions on resources applications have access to. (Help applications to get) performance. Range of different uses. O/S Organization User: VIM, CC, SHELL etc. Kernel: File system etc.\nProcesses, Memory allocations, Access control \u0026hellip; Hardware: CPU, RAM, DISK, NET etc. API-Kernel Applications use API-kernel provided by Kernel to jump into Kernel. For example:\nfd = open(\u0026quot;out\u0026quot;, 1);\t// fd is the file descriptor write(fd, \u0026quot;hello\\n\u0026quot;, 6); pid = fork();\t// fork() API returns the descriptor of the newly created process Do high-level programming language like Python directly use system calls?\nSome high-level programming languages focus on portability - its code should be executable on different operating systems so usually they call library functions instead of directly using system calls to ensure its portability. Of course, theses languages provide methods for programmers to directly use system calls.\nHow is jumping to kernel different from ordinary function calls?\nKernel codes have direct access to sensitive information such as disks, so the privilege level should be carefully maintained during kernel jumping to ensure the safety of data.\nWhy hard/interesting? unforgiving environment: different from applications whose environment is provided by O/S, O/S is built directly on the hardware, which is harder.\n(In this course, QEMU is used to simulate CPU and corresponding hardwares.)\nTensions: there are some trade-offs. For example\nwe want high efficiency so O/S should be close to the H/W, but to support applications we need a correct high-level abstraction. We want powerful O/S services, but applications want simple interfaces. We want flexible API, but for security reasons we need to have restraints. Interactions. For example,\nfd = open(); pid = fork(); The semantic of fork() is to create a copy of the current process. The file descriptor fd we acquire at the first line should be accessible by the child process, so interactions between processes are needed.\nApplications using system calls: Examples read() write() This is copy.c, we execute it on xv6:\n// copy.c: copy input to output. #include \u0026quot;kernel/types.h\u0026quot; #include \u0026quot;user/user.h\u0026quot; int main () { char buf[64]; while (1) { int n = read(0, buf, sizeof(buf)); if (n \u0026lt;= 0) break; write(1, buf, n); } exit(0); } copy.c \u0026rsquo;s function is that it prints on the screen whatever you input on the screen. Here 0/1 are the file descriptors of stdin/stdout (pervasive UNIX convention), which, in default, connect to the console input/output. Shell ensures that stdin/stdout have been opened when copy.c is being executed.\nHere copy.c doesn\u0026rsquo;t check the return values of system calls for error (e.g. line 16). We should be more careful when coding.\nWhat if we replace sizeof(buf) by 65?\nO/S will happily read at most 65 bytes from console input, but it may cause unexpected memory error. It\u0026rsquo;s a bug.\nopen() stdin and stdout are automatically opened, but we need a method to open files by ourselves, here\u0026rsquo;s another example program open.c:\n// open.c: create a file, write to it. #include \u0026quot;kernel/types.h\u0026quot; #include \u0026quot;user/user.h\u0026quot; #include \u0026quot;kernel/fcntl.h\u0026quot; int main () { int fd = open(\u0026quot;output.txt\u0026quot;, O_WRONLY | O_CREATE); write(fd, \u0026quot;ooo\\n\u0026quot;, 4); exit(0); } After running open, we use cat output.txt to see the contents and we\u0026rsquo;ll get ooo\\n. Here fd is the file descriptor indexing into a table inside the kernel. The kernel maintains a table for every running process and the table tells the kernel which file each file descriptor refers to. (NOTE: same file descriptor may refer to different files in different processes because the \u0026ldquo;table\u0026rdquo; is different.)\nfork() This is fork.c:\n// fork.c: create a new process #include \u0026quot;kernel/types.h\u0026quot; #include \u0026quot;user/user.h\u0026quot; int main () { int pid; pid = fork(); printf(\u0026quot;fork() returned %d\\n\u0026quot;, pid); if (pid == 0) printf(\u0026quot;child\\n\u0026quot;); else printf(\u0026quot;parent\\n\u0026quot;); exit(0); } fork() returns in both processes. In the original process, fork() returns a value greater than zero representing the pid of the child process. In the new process, fork() returns zero. Even if the two processes have the same memory, we can discriminate the parent from the child according to the return value of fork().\nThe printed message is\nffoorrkk(()) rreettuurrnende d 0 1c9h ilpda rent It seems like messy code, but actually the two processes run at the same time and QEMU simulates a multi-core processor for us, so the two processes alternatively print information on the console.\nexec() When a command is typed into the shell, the shell forks a child process and use exec() system call to run the application in the child process. exec() loads the instructions in the file you specify over the current process, discards its current memory and starts executing those instructions.\nfork() and exec() are always used together to run an application, here is forkexec.c:\n// forkexec.c: fork then exec int main () { int pid, status; pid = fork(); if (pid == 0) { char *argv[] = { \u0026quot;echo\u0026quot;, \u0026quot;THIS\u0026quot;, \u0026quot;IS\u0026quot;, \u0026quot;ECHO\u0026quot;, 0 }; // Note: there should be a null pointer NULL/0 at the end of the array exec(\u0026quot;echo\u0026quot;, argv); printf(\u0026quot;exec failed!\\n\u0026quot;); exit(1); } else { printf(\u0026quot;parent waiting\\n\u0026quot;); wait(\u0026amp;status); // the exit status of the child process will be recorded in variable status printf(\u0026quot;the child exited with status %d\\n\u0026quot;, status); } exit(0); } If echo is executed successfully, it will print the arguments and use exit(0) to exit. If echo returns, which means something goes wrong, the child process will exit by exit(1) to tell the parent process about the error.\nIn lots of cases, fork() and exec() are used together. It seems that a lot of memory space is wasted because after fork() copies the memory of the parent process, exec() immediately discards it. But with the aid of virtual memory, we can use the tricky \u0026ldquo;copy on write\u0026rdquo; technique to solve the issue.\nIs there any way for the child process to wait for the parent process?\nNo.\nWill \u0026ldquo;parent waiting\\n\u0026rdquo; always be printed first?\nNot necessary. The parent process and the child process execute concurrently so there outputs may interweave. However, because it takes a lot of machine instructions to discard the memory, load the memory and start echo, \u0026ldquo;parent waiting\\n\u0026rdquo;, in most cases, will be printed first.\nHow should we use wait() if there are more than one child processes?\nIf there are 2 child processes, the parent process should use 2 wait() to wait for both of them to exit.\nIO Redirection IO redirection can be achieved if we do something sophisticated between fork() and exec(). Here is redirect.c:\n// redirect.c: run a command with output redirected int main() { int pid; pid = fork(); if(pid == 0){ close(1); open(\u0026quot;output.txt\u0026quot;, O_WRONLY|O_CREATE); char *argv[] = { \u0026quot;echo\u0026quot;, \u0026quot;this\u0026quot;, \u0026quot;is\u0026quot;, \u0026quot;redirected\u0026quot;, \u0026quot;echo\u0026quot;, 0 }; exec(\u0026quot;echo\u0026quot;, argv); printf(\u0026quot;exec failed!\\n\u0026quot;); exit(1); } else { wait((int *) 0); } exit(0); } In the child process, we firstly close file descriptor 1 and then open \u0026ldquo;output.txt\u0026rdquo;, the semantic of open() is to allocate the least file descriptor that is not being used to the file. Since 0 is still allocated to the console input, file descriptor 1 is allocated to output.txt and echo will output things into file 1, i.e. output.txt. It should be noticed that only the child process\u0026rsquo;s IO is redirected, the parent process, i.e. the shell process, stays the same.\nThe magical thing is that the application echo doesn\u0026rsquo;t need to know about the redirection - the only thing it knows is that it should output to file descriptor 1. This is abstraction.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8010e29128eaf6cd51e1db5db7fc8841","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec01/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec01/","section":"notes","summary":"Purposes of O/S Abstraction of hardware. Higher level interfaces and abstractions that applications can use can enhance convenience and portability (e.g. processes and file systems) Multiplexing. Different applications can execute at the same time.","tags":null,"title":"MIT-6.S081 Lecture 01: Introduction and Examples","type":"docs"},{"authors":null,"categories":null,"content":"Phase 1: Typing Problem 1 寻找第 k 个满足条件的字符串，注意这里的 k 是 0-base 的。\nProblem 2 充分利用 utils.py 中提供的 split() remove_punctuation() 和 lower() 函数可以大幅简化代码的难度。\nProblem 3 注意单独处理几种列表长度为 0 的边界情况。 返回值 0/100 会被当作一个整数，想要返回一个浮点数应当写 0.0/100.0。 Problem 4 简单数学计算。\nPhase 2: Autocorrect Problem 5 本题比较漂亮的写法是充分运用 min() 函数的 key：直接把 diff_function() 的内容用 lambda 表达式套起来喂给 key，可以省去书写 for 循环。\nProblem 6 本题的难点在于不能使用循环只能用递归，此外还要保证答案超过 limit 的时候运行效率尽可能与长度无关。笔者实现的方法是将答案作为参数随着递归传下去，这样一旦答案超出 limit 递归就提前返回。\nProblem 7 这题颇具难度，其思路类似于动态规划。一个比较简单的做法是：我们每次考虑如何让两个单词的第一个字母匹配上。如果已经一样就跳过看下一个字母，否则就从加字母 (肯定会加匹配的字母)，删字母 (删字母后并不保证第一个字母能匹配上)，换字母中选一种操作。\nPhase 3: Multiplayer Problem 8 本题可以关注字典的初始化方法：在 {} 中用 'key': value 的方式包括若干 key-value pairs。\nProblem 9 本题没有太大的难度，运用 list comprehension 可以将代码写得简短漂亮。\nProblem 10 该题本身没有太大难度，但应当注意实现时最好使用框架代码提供的几个和 match 互动的 API，将 match 当作一个 abstract data structure 而不是直接去定位嵌套列表中的元素。所谓的 abstract data structure 就是只关注 API 提供的数据结构对外的交互功能而忽略数据结构内部的实现方法。\nUtils utils.py 提供了一些辅助函数。其中值得注意的 API 用法有：\ndef remove_punctuation(s): punctuation_remover = str.maketrans('', '', string.punctuation) return s.strip().translate(punctuation_remover) str.maketrans() 为 translate() 提供字符转换的规则：\n如果 maketrans() 接收一个参数，那么这个参数必须是一个字典。字典的映射就是转换的源和目标。 如果 maketrans() 接收两个参数，那么这两个参数必须是长度相同的字符串，对应的字符构成转换规则。 如果 maketrans() 接收三个参数，那么第三个参数的字符串的内容会被映射到 None，前两个同 (2)。 这里主要利用了三个参数的规则将所有的标点符号映射到了 None。\nstrip(c=' ') 方法用于去除字符串首尾的字符 c，如果没有传入参数则默认去除空格。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1ed1ac1846441940df154aa68c4143df","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/projects/cat/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/projects/cat/","section":"notes","summary":"Phase 1: Typing Problem 1 寻找第 k 个满足条件的字符串，注意这里的 k 是 0-base 的。\nProblem 2 充分利用 utils.py 中提供的 split() remove_punctuation() 和 lower() 函数可以大幅简化代码的难度。\nProblem 3 注意单独处理几种列表长度为 0 的边界情况。 返回值 0/100 会被当作一个整数，想要返回一个浮点数应当写 0.","tags":null,"title":"UCB-CS61A Project 02: Cat","type":"docs"},{"authors":null,"categories":null,"content":" Separate Compilation Proof by Induction Proofs Within Proofs Formal vs. Informal Proof Exercises Exercise: 2 stars, standard, especially useful (basic_induction) Exercise: 2 stars, standard (double_plus) Exercise: 2 stars, standard (eqb_refl) Exercise: 2 stars, standard, optional (even_S) Exercise: 3 stars, standard, especially useful (mul_comm) Exercise: 2 stars, standard, optional (plus_leb_compat_l) Exercise: 3 stars, standard, optional (more_exercises) Exercise: 2 stars, standard, optional (add_shuffle3\u0026rsquo;) Exercise: 3 stars, standard, especially useful (binary_commute) Exercise: 3 stars, standard (nat_bin_nat) Exercise: 2 stars, advanced (double_bin) Exercise: 4 stars, advanced (bin_nat_bin) Separate Compilation 如果想在新的 .v 文件中使用别的文件中的所有定义和定理 (比如 Basics.v)，可以使用如下语句：\nFrom LF Require Export Basics. 使用这条语句的前置条件是 Coq 可以在有 \u0026ldquo;LF\u0026rdquo; 前缀的目录下找到编译过的 Basics.vo。.vo 文件之于 .v 文件就好比 .o 文件之于 .c 文件。我们应当在当前的工作目录下建立 _CoqProject 文件，在其中写上\n-Q . LF 这会将当前目录绑定到 \u0026ldquo;LF\u0026rdquo; 前缀上。之后我们可以用\ncoq_makefile -f _CoqProject *.v -o Makefile 来自动生成用于编译工作目录下所有源文件的 Makefile，并通过\nmake Basics.vo 来编译生成 .vo 文件。\nProof by Induction 我们之前证明了 0 是 \u0026ldquo;+\u0026rdquo; 的 neutral element，但我们只证明了 0 在左侧的情况，即 forall n : nat, 0 + n = n.。如果我们要证明 n + 0 = n，事情便变得复杂起来：因为我们的加法是通过对第一个加数的递归定义的，未知大小的整数 n 无法递归。在这里我们必须使用归纳法 (induction)。\n我们先直接给出归纳法证明 n + 0 = n 的步骤：\nTheorem add_0_r: forall n : nat, n + 0 = n. Proof. intros n. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite -\u0026gt; IHn'. reflexivity. Qed. induction 和 destruct 这个 tactic 一样，也可以在后面跟一个 as。第一种情况是令 n = 0，这种情况没有参数，所以 | 左侧没有东西；第二种情况是令 n = S n'，基于的假设是 n' + 0 = n' ，我们给这个假设命名为 IHn'。\nProofs Within Proofs 我们进行大的证明的过程中时常需要一些小的结论。我们可以在证明大定理之前把小结论先证明好，然后在大定理中 rewrite。但有时候有一些杂项的、trivial 的结论单独拎出来给证明会使证明过程变得很繁杂，所以 Coq 提供了在证明内部证明另一个命题的语法。下面是一个例子：\nTheorem mult_0_plus' forall n m : nat, (n + 0 + 0) * m = n * m. Proof. intros n m. assert (H: n + 0 + 0 = n). { rewrite add_comm. simpl. rewrite add_comm. reflexivity. } rewrite -\u0026gt; H. reflexivity. Qed. assert 这个 tactic 会引入两个 subgoal：\n第一个 subgoal 是括号内写出的命题。上述的写法给这个命题命名为 H。我们也可以使用 assert (n + 0 + 0 = n) as H. 的语法来书写这一行。这个命题的证明用一对 {} 框起来。 第二个 subgoal 和 assert 之前的一刻的 goal 相同，但多了 assert 证明的结论作为一条假设。 下面展示另一个需要使用 assert 的有趣的场景：\nTheorem plus_rearrange: forall n m p q : nat, (n + m) + (p + q) = (m + n) + (p + q). Proof. intros n m p q. assert (H: n + m = m + n) { rewrite add_comm. reflexivity. } rewrite H. reflexivity. Qed. 可以看到要证明的命题中只有第一个括号内两个加数的顺序不同。但可惜的是我们不能直接利用加法的交换律来 rewrite，因为 Coq 根据加法交换律在 goal 中寻找实例时会优先找到外层括号的实例，即会把两个括号的内容整体调换。在这里我们不利用加法交换律 rewrite，而是先证明 n + m = m + n 然后直接 rewrite。\nFormal vs. Informal Proof Formal proof 指的是写给 Coq 等证明工具看的证明过程；Informal proof 指的是用自然语言写给人看的证明过程。一个好的 formal proof 应当通过适当的注释和缩进来使其对人类也比较友好。通常来说，formal proof 在细节处会写得比 informal proof 更详细 (例如 reflexivity)，informal proof 会通过一些语言让读者更好地了解当前地证明状态 (这些信息只有使用 Coq 执行代码时才会显示出来)。\nExercises Exercise: 2 stars, standard, especially useful (basic_induction) Theorem mul_0_r : forall n:nat, n * 0 = 0. Proof. intros n. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite -\u0026gt; IHn'. reflexivity. Qed. Theorem plus_n_Sm : forall n m : nat, S (n + m) = n + (S m). Proof. intros n m. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite -\u0026gt; IHn'. reflexivity. Qed. Theorem add_comm : forall n m : nat, n + m = m + n. Proof. intros n m. induction n as [| n' IHn']. - rewrite -\u0026gt; add_0_r. reflexivity. - rewrite \u0026lt;- plus_n_Sm. rewrite \u0026lt;- IHn'. reflexivity. Qed. 这个证明稍微复杂一些，归纳基础和归纳步骤都需要使用之前证明过的定理。\nTheorem add_assoc : forall n m p : nat, n + (m + p) = (n + m) + p. Proof. intros n m p. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite -\u0026gt; IHn'. reflexivity. Qed. Exercise: 2 stars, standard (double_plus) Lemma double_plus : forall n, double n = n + n . Proof. intros n. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite -\u0026gt; IHn'. rewrite \u0026lt;- plus_n_Sm. reflexivity. Qed. Exercise: 2 stars, standard (eqb_refl) Theorem eqb_refl : forall n : nat, (n =? n) = true. Proof. intros n. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite -\u0026gt; IHn'. reflexivity. Qed. Exercise: 2 stars, standard, optional (even_S) Theorem even_S : forall n : nat, even (S n) = negb (even n). Proof. intros n. induction n as [| n' IHn']. - reflexivity. - rewrite -\u0026gt; IHn'. simpl. rewrite -\u0026gt; negb_involutive. reflexivity. Qed. 本题需要注意的点是：归纳步骤中如果直接上 simpl 化简，会将等式右侧的 even n' 的定义展开，所以这里笔者先 rewrite 再 simpl。\nExercise: 3 stars, standard, especially useful (mul_comm) Theorem add_shuffle3 : forall n m p : nat, n + (m + p) = m + (n + p). Proof. intros n m p. rewrite add_assoc. rewrite add_assoc. assert (H: n + m = m + n). { rewrite add_comm. reflexivity. } rewrite H. reflexivity. Qed. Lemma mult_n_0: forall n : nat, n * 0 = 0. Proof. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite IHn'. reflexivity. Qed. Lemma mult_n_Sm: forall n m : nat, n * (1 + m) = n + n * m. Proof. intros n m. induction n as [| n' IHn']. - reflexivity. - assert (H1: S n' * (1 + m) = S m + n' * (1 + m)). { reflexivity. } rewrite H1. rewrite IHn'. assert (H2: S n' * m = m + n' * m). { reflexivity. } rewrite H2. simpl. rewrite add_shuffle3. reflexivity. Qed. Theorem mul_comm : forall m n : nat, m * n = n * m. Proof. intros n m. induction n as [| n' IHn']. - rewrite mult_n_0. reflexivity. - simpl. rewrite mult_n_Sm. rewrite IHn'. reflexivity. Qed. 这题相当有难度，需要先证明 n * S m = n + n * m 这个引理，中间反复的在局部使用乘法定义/加法交换律结合律比较搞心态。\nExercise: 2 stars, standard, optional (plus_leb_compat_l) Theorem plus_leb_compat_l : forall n m p : nat, n \u0026lt;=? m = true -\u0026gt; (p + n) \u0026lt;=? (p + m) = true. Proof. intros n m p H. induction p as [| p' IHp']. - simpl. rewrite H. reflexivity. - simpl. rewrite IHp'. reflexivity. Qed. Exercise: 3 stars, standard, optional (more_exercises) Theorem leb_refl : forall n:nat, (n \u0026lt;=? n) = true. Proof. intros n. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite IHn'. reflexivity. Qed. Theorem zero_neqb_S : forall n:nat, 0 =? (S n) = false. Proof. intros n. reflexivity. Qed. Theorem andb_false_r : forall b : bool, andb b false = false. Proof. intros b. rewrite andb_commutative. reflexivity. Qed Theorem S_neqb_0 : forall n:nat, (S n) =? 0 = false. Proof. intros n. reflexivity. Qed. Theorem mult_1_l : forall n:nat, 1 * n = n. Proof. intros n. simpl. rewrite add_comm. reflexivity. Qed. Theorem all3_spec : forall b c : bool, orb (andb b c) (orb (negb b) (negb c)) = true. Proof. intros [] []. - reflexivity. - reflexivity. - reflexivity. - reflexivity. Qed. Theorem mult_plus_distr_r : forall n m p : nat, (n + m) * p = (n * p) + (m * p). Proof. intros. rewrite mul_comm. induction p as [| p' IHp']. - rewrite mult_n_0. rewrite mult_n_0. reflexivity. - simpl. rewrite mult_n_Sm. rewrite mult_n_Sm. rewrite IHp'. rewrite add_assoc. rewrite add_assoc. assert (H1: n + m + n * p' = n + (m + n * p')). { rewrite add_assoc. reflexivity. } rewrite H1. assert (H2: m + n * p' = n * p' + m). { rewrite add_comm. reflexivity. } rewrite H2. rewrite add_assoc. reflexivity. Qed. Theorem mult_assoc : forall n m p : nat, n * (m * p) = (n * m) * p. Proof. intros. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite IHn'. rewrite mult_plus_distr_r. reflexivity. Qed. 注：乘法分配律的证明由于涉及过多繁琐的加法交换律/结合律，不能保证过程的简洁性。\nExercise: 2 stars, standard, optional (add_shuffle3') Theorem add_shuffle3' : forall n m p : nat, n + (m + p) = m + (n + p). Proof. intros. rewrite add_assoc. rewrite add_assoc. replace (n + m) with (m + n). - reflexivity. - rewrite add_comm. reflexivity. Qed. 使用 replace 这个 tactic 可以避免每次 assert 之后再 rewrite 新假设的繁琐过程。\nExercise: 3 stars, standard, especially useful (binary_commute) Theorem bin_to_nat_pres_incr : forall b : bin, bin_to_nat (incr b) = 1 + bin_to_nat b. Proof. intros b. induction b as [| b' | b' IHb']. - reflexivity. - simpl. rewrite add_comm. reflexivity. - simpl. rewrite IHb'. simpl. rewrite add_comm. reflexivity. Qed. 这里值得一提的是：Coq 中只有基于结构的归纳法，只要变量类型是以 inductive 的形式定义的，我们都可以使用归纳法进行证明。之前的归纳法都针对自然数，这是因为自然数也是归纳定义的。这里的 bin 有三个归纳分支，写起来和自然数大同小异。\nExercise: 3 stars, standard (nat_bin_nat) Fixpoint nat_to_bin (n:nat) : bin := match n with | O =\u0026gt; Z | S n' =\u0026gt; incr(nat_to_bin(n')) end. Theorem nat_bin_nat : forall n, bin_to_nat (nat_to_bin n) = n. Proof. intros. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite bin_to_nat_pres_incr. rewrite IHn'. reflexivity. Qed. Exercise: 2 stars, advanced (double_bin) Lemma double_incr : forall n : nat, double (S n) = S (S (double n)). Proof. reflexivity. Qed. Definition double_bin (b:bin) : bin := match b with | Z =\u0026gt; Z | _ =\u0026gt; B0 b end. Example double_bin_zero : double_bin Z = Z. Proof. reflexivity. Qed. Lemma double_incr_bin : forall b, double_bin (incr b) = incr (incr (double_bin b)). Proof. intros b. induction b as [| b' | b' IHb']. - reflexivity. - reflexivity. - reflexivity. Qed. Exercise: 4 stars, advanced (bin_nat_bin) Fixpoint normalize (b:bin) : bin := match b with | Z =\u0026gt; Z | B0 b' =\u0026gt; match bin_to_nat b' with | 0 =\u0026gt; Z | S n' =\u0026gt; B0 (normalize b') end | B1 b' =\u0026gt; B1 (normalize b') end. Example normalize_example : normalize (B1 (B0 Z)) = B1 Z. Proof. reflexivity. Qed. 书中提到的 \u0026ldquo;equivalent\u0026rdquo; bin 实质上指的就是前导 0 的问题，normalize 的主要任务是去除掉 B0 (B0 ... Z) 的情况，因此对 B0 b' 的情况进行特殊判断。\n这里利用了 bin_to_nat b' 的结果判断是否是 0 而没有直接用 normalize b' 的结果，是为了下面证明的方便。下面的证明中对 bin_to_nat b' 的结果进行了分类讨论，这样定义可以让 simpl 直接拆解定义。\nLemma mult_2_plus_1_bin : forall n : nat, nat_to_bin(n * 2 + 1) = B1 (nat_to_bin n). Proof. intros n. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite IHn'. reflexivity. Qed. Lemma mult_2_eq_double : forall n : nat, nat_to_bin (n * 2) = double_bin (nat_to_bin n). Proof. intros n. induction n as [| n' IHn']. - reflexivity. - simpl. rewrite IHn'. rewrite double_incr_bin. reflexivity. Qed. Lemma double_bin_eq_B0 : forall b : bin, double_bin (incr b) = B0 (incr b). Proof. intros b. destruct b as [| b' | b'] eqn:B. - reflexivity. - reflexivity. - reflexivity. Qed. Lemma mult_2_bin : forall n : nat, nat_to_bin (S n * 2) = B0 (nat_to_bin (S n)). Proof. intros n. simpl. rewrite mult_2_eq_double. rewrite \u0026lt;- double_incr_bin. rewrite double_bin_eq_B0. reflexivity. Qed. Theorem bin_nat_bin : forall b, nat_to_bin (bin_to_nat b) = normalize b. Proof. intros b. induction b as [| b' | b' IHb']. - reflexivity. - destruct (bin_to_nat b') as [| n'] eqn:N. + simpl. rewrite N. reflexivity. + simpl. rewrite N. rewrite \u0026lt;- IHb'. rewrite mult_2_bin. reflexivity. - simpl. rewrite \u0026lt;- IHb'. rewrite mult_2_plus_1_bin. reflexivity. Qed. 为了证明最终的定理，笔者先证明了 3 个引理，主要围绕着 *2/*2+1 和在 bin前面添加 B0/B1 的一致性讨论。最终定理的证明中比较精妙的部分是关于 bin_to_nat b' 的讨论。在归纳步骤中等式右边是 normalize (B0 b')，如果我们不能确定 b' 不是 Z，那么括号里的 B0 就提不出来，可如果对着 b\u0026rsquo; 的结构直接进行讨论，又容易陷入循环论证 (如果 b'= B0 b''，仍然说明不了问题)，因此在这里选择对 b\u0026rsquo; 转化成自然数后的结果进行讨论。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f7805daf6bd7ae729437592b78c7bc5c","permalink":"https://kristoff-starling.github.io/notes/booknotes/softwarefoundations/lf/induction/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/booknotes/softwarefoundations/lf/induction/","section":"notes","summary":"Separate Compilation Proof by Induction Proofs Within Proofs Formal vs. Informal Proof Exercises Exercise: 2 stars, standard, especially useful (basic_induction) Exercise: 2 stars, standard (double_plus) Exercise: 2 stars, standard (eqb_refl) Exercise: 2 stars, standard, optional (even_S) Exercise: 3 stars, standard, especially useful (mul_comm) Exercise: 2 stars, standard, optional (plus_leb_compat_l) Exercise: 3 stars, standard, optional (more_exercises) Exercise: 2 stars, standard, optional (add_shuffle3\u0026rsquo;) Exercise: 3 stars, standard, especially useful (binary_commute) Exercise: 3 stars, standard (nat_bin_nat) Exercise: 2 stars, advanced (double_bin) Exercise: 4 stars, advanced (bin_nat_bin) Separate Compilation 如果想在新的 .","tags":null,"title":"Proof by Indution","type":"docs"},{"authors":null,"categories":null,"content":"值得一提的是附加的思考题，对理解 lambda 表达式和函数的本质很有帮助：\nQ3: Church Numerals def zero(f): return lambda x: x def successor(n): return lambda f: lambda x: f(n(f)(x)) 在 successor() 和 zero() 的基础上我们可以用函数定义出所有的自然数：zero, one, two\u0026hellip; 这些东西本质上是函数，它们首先接受一个参数 f，f 可以是一个任意的函数。接收完 f 之后 zero(f) one(f) \u0026hellip; 这些东西还是函数，它们可以接收一个“自变量\u0026quot; x 并返回结果 (可以理解为 _(_) 前面填函数名，后面填自变量)。\n这里举一例说明 successor() 的作用：考虑 successor(zero)，传入 f 和 x 后，zero(f) 就是 lambda x: x 这个功能上是 identity 的匿名函数，从而 zero(f)(x) 的结果是 x，因此 one 的返回值是 f(x)，因此\ndef one(f): return lambda f: lambda x: f(x) def two(f): return lambda f: lambda x: f(f(x)) 容易用归纳法证明 n(f)(x) 就是 $f(f(\u0026hellip;f(x)))$，或者理解为对着 x 这个东西将操作 f 做 n 次后的结果，后一种理解更为好用。\n接下来考虑 church_to_int(n)，n 这个东西是一个嵌套了很多层的函数，我们需要知道它嵌套了多少层，直接去解构显然是不行的。最好的办法就是精心设计传给 n 的参数 f 和 x。我们发现：如果令 f 为函数“将一个数+1\u0026quot;，令 x 为 0，那么 n(f)(x) 就是\u0026quot;对着 0 将 +1 操作做 n 次后的结果\u0026quot;，这正好是我们需要的答案。因此\ndef church_to_int(n): return n(increment)(0) 再然后是加法。一种比较朴素的写法是先解析出 m 和 n 的具体数值，利用数值相加，再循环调用 successor 获得函数：\ndef add_church(m, n): s = church_to_int(m) + church_to_int(n) ans = zero for _ in range(s): ans = successor(ans) return ans 但这种做法违背了这道题完全摆脱自然数体系的美感，我们可以从更抽象的角度看待这个问题：m(f) 和 n(f) 分别表示 “做 m 次 f” 和 “做 n 次 f”，因此 m(f)n(f)(x) 就是先对 x 做 n 次 f 再做 m 次 f，也就是做了 $m+n$ 次 f。\ndef add_church(m, n): return m(f)n(f)(x) 乘法：考虑到 m(f) 是 “做 m 次 f\u0026quot;，那么 n(m(f)) 就是“把做m次f这件事情做n次“，也就是做了 $m\\times n$ 次 f。\ndef mul_church(m, n): return n(m(f))(x) 乘方更具有挑战性，我们直接解读 n(m)(f)(x) 的意思： 首先 n(m) 相当于把 m 重复了 n 次，它的结构类似于 m(m(m(...m(_))))，也就是每一个 m 返回的函数作为下一层 m 的参数。n(m)(f) 相当于把函数 f 填到了之前的下划线中，因此展开后，第一个 m 的函数参数是一个 f，第二个 m 的函数参数就是 m 个 f，第三个 m 的函数参数就是 $m^2$ 个 f，依次类推，全部展开就是 $m^n$ 个 f。\ndef pow_church(m, n): return n(m)(f)(x) 乘法和乘方写法的细微差别是很值得玩味的。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ce27b8a25adf114349b069dc5a217245","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/homework/hw02/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/homework/hw02/","section":"notes","summary":"值得一提的是附加的思考题，对理解 lambda 表达式和函数的本质很有帮助：\nQ3: Church Numerals def zero(f): return lambda x: x def successor(n): return lambda f: lambda x: f(n(f)(x)) 在 successor() 和 zero() 的基础上我们可以用函数定义出所有的自然数：zero, one, two\u0026hellip; 这些东西本质上是函数，它们首先接受一个参数 f，f 可以是一个任意的函数。接收完 f 之后 zero(f) one(f) \u0026hellip; 这些东西还是函数，它们可以接收一个“自变量\u0026quot; x 并返回结果 (可以理解为 _(_) 前面填函数名，后面填自变量)。","tags":null,"title":"UCB-CS61A Homework 02: Higher-Order Functions","type":"docs"},{"authors":null,"categories":null,"content":"Side Effects 一个函数如果没有显式地返回内容，那么它的返回值默认为 None。比如下面的程序会报 TypeError：\ndef square(x): x * x result = square(4) # result = 'None' print(result + 1) 一个函数有 side-effect 指的是它除了返回内容还做了一些可见的事情，最常见的有 side-effect 的函数就是 print()。\n一个有趣的问题：print(print(1), print(2)) 的结果？\n首先，里面的 print(1) 会 Display \u0026ldquo;1\u0026rdquo;，print(2) 会 Display \u0026ldquo;2\u0026rdquo;。两个 print 函数没有显式地返回，所以外层的 print 会 Display \u0026ldquo;None None\u0026rdquo;。整个语句的返回值是 None。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8e69fc5aa11e2e32e1fea3c17c3ae405","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec03/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec03/","section":"notes","summary":"Side Effects 一个函数如果没有显式地返回内容，那么它的返回值默认为 None。比如下面的程序会报 TypeError：\ndef square(x): x * x result = square(4) # result = 'None' print(result + 1) 一个函数有 side-effect 指的是它除了返回内容还做了一些可见的事情，最常见的有 side-effect 的函数就是 print()。\n一个有趣的问题：print(print(1), print(2)) 的结果？\n首先，里面的 print(1) 会 Display \u0026ldquo;1\u0026rdquo;，print(2) 会 Display \u0026ldquo;2\u0026rdquo;。两个 print 函数没有显式地返回，所以外层的 print 会 Display \u0026ldquo;None None\u0026rdquo;。整个语句的返回值是 None。","tags":null,"title":"UCB-CS61A Lecture 03: Control","type":"docs"},{"authors":null,"categories":null,"content":" Pairs of Numbers Lists of Numbers Repeat Length Append Head ant Tail Bags via Lists Reasoning About Lists Induction on Lists Reversing a List Search Options Partial Maps Exercises Exercise: 1 star, standard (snd_fst_is_swap) Exercise: 1 star, standard, optional (fst_swap_is_snd) Exercise: 2 stars, standard, especially useful (list_funs) Exercise: 3 stars, advanced (alternate) Exercise: 3 stars, standard, especially useful (bag_functions) Exercise: 3 stars, standard, optional (bag_more_functions) Exercise: 2 stars, standard, especially useful (add_inc_count) Exercise: 3 stars, standard (list_exercises) Exercise: 2 stars, standard (eqblist) Exercise: 1 star, standard (count_member_nonzero) Exercise: 3 stars, advanced (remove_does_not_increase_count) Exercise: 3 stars, standard, optional (bag_count_sum) Exercise: 3 stars, advanced (involution_injective) Exercise: 2 stars, advanced (rev_injective) Exercise: 2 stars, standard (hd_error) Exercise: 1 star, standard, optional (option_elim_hd) Exercise: 1 star, standard (eqb_id_refl) Exercise: 1 star, standard (update_eq) Exercise: 1 star, standard (update_neq) Pairs of Numbers 我们可以定义一个 pair 类型：\nInductive natprod : Type := | pair (n1 n2 : nat). Notation \u0026quot;( x, y )\u0026quot; := (pair x y). 以及一些辅助函数：\nDefinition fst (p : natprod) : nat := match p with | (x, y) =\u0026gt; x end. Definition snd (p : natprod) : nat := match p with | (x, y) =\u0026gt; y end. Definition swap_pair(p : natprod) : nat := match p with | (x, y) =\u0026gt; (y, x) end. 这里值得注意的是在 pattern matching 中的 (x, y) 和 x, y 是不一样的：前者匹配的是一个 pair 类型，而后者匹配了两个东西。\n下面看一个有意思的证明题：\nTheorem surjective_pairing : forall p : natprod, p = (fst p, snd p). 我们无法通过 simpl 直接证明该题，因为 p 的具体内容不知道，fst p snd p 无法化简。一个好的方法是使用 destruct：\nProof. intros p. destruct p as [n m]. simpl. reflexivity. Qed. 这里的 destruct 不是用来分类讨论，而是其字面意思：给 p 一个形式，从而解构它。\nLists of Numbers 我们定义一个链表类型：\nInductive natlist : Type := | nil | cons (n : nat) (l : natlist). 简单来说，每一个 natlist 类型的变量要么是 nil，要么是一个自然数和另一个 natlist。下面的一些 notation 让表示链表变得简单：\nNotation \u0026quot;x :: l\u0026quot; := (cons x l) (at level 60, right associativity). Notation \u0026quot;[ ]\u0026quot; := nil. Notation \u0026quot;[ x ; .. ; y]\u0026quot; := (cons x .. (cons y nil) ..). 这里值得注意两点：\n:: 应当是右结合的，即 1 :: 2 :: 3 等价于 1 :: (2 :: 3)。 :: 的优先级低于加减法，即 1 + 2 :: 3 等价于 (1 + 2) :: 3。 Repeat repeat 函数接收两个参数 n 和 count，返回一个长度为 count，每个节点都是 n 的链表：\nFixpoint repeat (n count : nat) -\u0026gt; natlist := match count with | O =\u0026gt; nil | S count' =\u0026gt; n :: (repeat n count') end. Length length 函数接收一个参数 l，返回链表 l 的长度。\nFixpoint length (l : natlist) -\u0026gt; nat := match l with | nil =\u0026gt; 0 | h :: t =\u0026gt; 1 + (length t) end. Append app 函数用于把两个链表连接起来。\nFixpoint app (l1 l2 : natlist) -\u0026gt; natlist := match l1 with | nil =\u0026gt; l2 | h :: t =\u0026gt; h :: (app t l2) end. Notation \u0026quot;x ++ y\u0026quot; := (app x y) (right associativity, at level 60). Head ant Tail hd 函数返回链表的第一个元素，tl 函数返回链条除了第一个元素以外的后面的部分。\nDefinition hd (default : nat) (l : natlist) -\u0026gt; nat := match hd with | nil =\u0026gt; default | h :: t =\u0026gt; h end. Definition tl (l : natlist) -\u0026gt; natlist := match tl with | nil =\u0026gt; nil | h :: t =\u0026gt; t end. Bags via Lists 这里的 bag 指的是 multiset。我们可以用链表模拟 multiset。\nReasoning About Lists List 的 match 定义让我们可以对于很多比较简单的命题直接使用 reflexivity 或者分类讨论解决。但稍复杂的问题还是要借助归纳法。\nInduction on Lists 对于链表的归纳法和对于自然数的归纳法没有本质区别。只要使用 Inductive 的方式定义的类型都可以使用归纳法进行证明。下面是 ++ 具有结合律的一段证明：\nTheorem app_assoc : forall l1 l2 l3 : natlist, (l1 ++ l2) ++ l3 = l1 ++ (l2 ++ l3). Proof. intros l1 l2 l3. induction l1 as [| n l1' IHl']. - (* l1 = nil *) reflexivity. - (* l1 = cons n l1' *) simpl. rewrite IHl'. reflexivity. Qed. Reversing a List 考虑如下的翻转链表的函数：\nFixpoint rev (l : natlist) : natlist := match l with | nil =\u0026gt; nil | h :: t =\u0026gt; (rev t) ++ [h] end. 下面我们尝试证明链表翻转后长度不变：\nTheorem rev_length : forall l : natlist, length (rev l) = length l. 如果直接使用数学归纳法证明，在 successor case 中，我们会被 length(rev l' ++ [n]) = S (length (rev l')) 这个结论卡住。因此我们需要先证明一个引理：链表结合后的长度等于结合前两个链表的长度之和。\nTheorem app_length : forall l1 l2 : natlist, length (l1 ++ l2) = (length l1) + (length l2). Proof. intros l1 l2. induction l1 as [| n l1' IHl1']. - reflexivity. - simpl. rewrite IHl1'. reflexivity. Qed. Theorem rev_length : forall l : natlist, length (rev l) = length l. Proof. intros l. induction l as [| n l' IHl']. - reflexivity. - simpl. rewrite app_length. simpl. rewrite IHl'. rewrite add_comm. reflexivity. Qed. Search 我们在证明的时候时常要使用之前证明过的引理，但使用这些引理需要知道它们的名字，如果现场不记得名字，可以使用 Search name 的方式来查找，Coq 会输出所有名字中带有 name 的引理。\nSearch tactic 还支持更加丰富的查找功能，例如\nSearch (_ + _ = _ + _) inside Induction. 会在 Induction 模块中寻找符合上述形式的定理。\nSearch (?x + ?y = ?y + ?x). 几乎可以直接锁定到加法交换律。这里变量前加一个 ? 表示这是搜索时使用的 pattern，而不是在当前环境中要求存在的变量。\nOptions 这一章节讲述了 error handling 的重要性。假设我们要写一个函数返回链表的第 n 个元素，我们必须要考虑如果链表的长度小于 n 应当返回什么，如果我们这样写代码：\nFixpoint nth_bad (l : natlist) (n : nat) : nat := match l with | nil =\u0026gt; 42 | a :: l' =\u0026gt; match n with | 0 ⇒ a | S n' ⇒ nth_bad l' n' end end. 那么如果函数返回了 42，我们必须再检查一遍链表才能确定究竟是链表太短了还是第 n 个元素正好是 42。一个好的方法是重新定义返回类型，在 error 时返回一个特殊的东西：\nInductive natoption : Type := | Some (n : nat) | None. Fixpoint nth_error (l : natlist) (n : nat) : natoption := match l with | nil =\u0026gt; None | a :: l' =\u0026gt; match n with | O ⇒ Some a | S n' ⇒ nth_error l' n' end end. 之后我们还可以根据具体的情境来选择不同的不可能出现的值作为返回值：\nDefinition option_elim (d : nat) (o : natoption) : nat := match o with | Some n' =\u0026gt; n' | None =\u0026gt; d end. Partial Maps 这一章介绍了用 Coq 定义 map 这一数据结构。map 本质上就是 key-value pair 的集合。这里我们先为 key 定义一个单独的类型 (没有什么特殊的作用，只是为了封装一下好看)：\nInductive id : Type := | Id (n : nat) 接下来我们定义 partial map:\nInductive partial_map : Type := | empty | record (i : id) (v : nat) (m : partial_map) 该定义的意思是：partial map 要么是 empty (空集)，要么是一个 key-value pair 接上另一个 partial map。\n下面的 update 函数可以完成向 partial map 中添加一个 key-value pair 的功能：\nDefinition update (d : partial_map) (x : id) (value : nat) -\u0026gt; partial_map := record x value d. find 函数可以查询 partial map 中是否存在某个 id，并返回对应的 value：\nFixpoint find (x : id) (d : partial_map) : natoption := match d with | empty =\u0026gt; None. | y v d' =\u0026gt; if eqb_id x y then Some v else find x d' end.s Exercises Exercise: 1 star, standard (snd_fst_is_swap) Theorem snd_fst_is_swap : forall (p : natprod), (snd p, fst p) = swap_pair p. Proof. intros p. destruct p as [n m]. reflexivity. Qed. Exercise: 1 star, standard, optional (fst_swap_is_snd) Theorem fst_swap_is_snd : forall (p : natprod), fst (swap_pair p) = snd p. Proof. intros p. destruct p as [n m]. reflexivity. Qed. Exercise: 2 stars, standard, especially useful (list_funs) Fixpoint nonzeros (l:natlist) : natlist := match l with | nil =\u0026gt; nil | O :: t =\u0026gt; nonzeros t | S n :: t =\u0026gt; S n :: (nonzeros t) end. Example test_nonzeros: nonzeros [0;1;0;2;3;0;0] = [1;2;3]. Proof. reflexivity. Qed. Fixpoint oddmembers (l:natlist) : natlist := match l with | nil =\u0026gt; nil | h :: t =\u0026gt; if (even h) then (oddmembers t) else (h :: (oddmembers t)) end. Example test_oddmembers: oddmembers [0;1;0;2;3;0;0] = [1;3]. Proof. reflexivity. Qed. Definition countoddmembers (l:natlist) : nat := length (oddmembers l). Example test_countoddmembers1: countoddmembers [1;0;3;1;4;5] = 4. Proof. reflexivity. Qed. Example test_countoddmembers2: countoddmembers [0;2;4] = 0. Proof. reflexivity. Qed. Example test_countoddmembers3: countoddmembers nil = 0. Proof. reflexivity. Qed. Exercise: 3 stars, advanced (alternate) Fixpoint alternate (l1 l2 : natlist) : natlist := match l1, l2 with | nil, nil =\u0026gt; nil | nil, _ =\u0026gt; l2 | _, nil =\u0026gt; l1 | h1 :: t1, h2 :: t2 =\u0026gt; h1 :: h2 :: (alternate t1 t2) end. Example test_alternate1: alternate [1;2;3] [4;5;6] = [1;4;2;5;3;6]. Proof. reflexivity. Qed. Example test_alternate2: alternate [1] [4;5;6] = [1;4;5;6]. Proof. reflexivity. Qed. Example test_alternate3: alternate [1;2;3] [4] = [1;4;2;3]. Proof. reflexivity. Qed. Example test_alternate4: alternate [] [20;30] = [20;30]. Proof. reflexivity. Qed. Exercise: 3 stars, standard, especially useful (bag_functions) Fixpoint count (v : nat) (s : bag) : nat := match s with | nil =\u0026gt; 0 | h :: t =\u0026gt; if (v =? h) then 1 + (count v t) else (count v t) end. Example test_count1: count 1 [1;2;3;1;4;1] = 3. Proof. reflexivity. Qed. Example test_count2: count 6 [1;2;3;1;4;1] = 0. Proof. reflexivity. Qed. Definition sum : bag -\u0026gt; bag -\u0026gt; bag := app. Example test_sum1: count 1 (sum [1;2;3] [1;4;1]) = 3. Proof. reflexivity. Qed. 这里可以注意一下不显式给出参数名称的定义函数的方法。在这种情况下，我们只能把一个参数类型和返回值类型相同的函数赋给当前函数。\nDefinition add (v : nat) (s : bag) : bag := v :: s. Example test_add1: count 1 (add 1 [1;4;1]) = 3. Proof. reflexivity. Qed. Example test_add2: count 5 (add 1 [1;4;1]) = 0. Proof. reflexivity. Qed. Fixpoint member (v : nat) (s : bag) : bool := match s with | nil =\u0026gt; false | h :: t =\u0026gt; if (v =? h) then true else (member v t) end. Example test_member1: member 1 [1;4;1] = true. Proof. reflexivity. Qed. Example test_member2: member 2 [1;4;1] = false. Proof. reflexivity. Qed. Exercise: 3 stars, standard, optional (bag_more_functions) Fixpoint remove_one (v : nat) (s : bag) : bag := match s with | nil =\u0026gt; nil | h :: t =\u0026gt; if (h =? v) then t else (h :: (remove_one v t)) end. Example test_remove_one1: count 5 (remove_one 5 [2;1;5;4;1]) = 0. Proof. reflexivity. Qed. Example test_remove_one2: count 5 (remove_one 5 [2;1;4;1]) = 0. Proof. reflexivity. Qed. Example test_remove_one3: count 4 (remove_one 5 [2;1;4;5;1;4]) = 2. Proof. reflexivity. Qed. Example test_remove_one4: count 5 (remove_one 5 [2;1;5;4;5;1;4]) = 1. Proof. reflexivity. Qed. Fixpoint remove_all (v:nat) (s:bag) : bag := match s with | nil =\u0026gt; nil | h :: t =\u0026gt; if (h =? v) then (remove_all v t) else (h :: (remove_all v t)) end. Example test_remove_all1: count 5 (remove_all 5 [2;1;5;4;1]) = 0. Proof. reflexivity. Qed. Example test_remove_all2: count 5 (remove_all 5 [2;1;4;1]) = 0. Proof. reflexivity. Qed. Example test_remove_all3: count 4 (remove_all 5 [2;1;4;5;1;4]) = 2. Proof. reflexivity. Qed. Example test_remove_all4: count 5 (remove_all 5 [2;1;5;4;5;1;4;5;1;4]) = 0. Proof. reflexivity. Qed. Fixpoint included (s1 : bag) (s2 : bag) : bool := match s1 with | nil =\u0026gt; true | h :: t =\u0026gt; if ((count h s2) =? 0) then false else included t (remove_one h s2) end. Example test_included1: included [1;2] [2;1;4;1] = true. Proof. reflexivity. Qed. Example test_included2: included [1;2;2] [2;1;4;1] = false. Proof. reflexivity. Qed. Exercise: 2 stars, standard, especially useful (add_inc_count) Theorem add_inc_count : forall (v : nat) (s : bag), count v (add v s) = 1 + count v s. Proof. intros. simpl. rewrite eqb_refl. (* n =? n = true *) reflexivity. Qed. Exercise: 3 stars, standard (list_exercises) Theorem app_nil_r : forall l : natlist, l ++ [] = l. Proof. intros l. induction l as [| n l' IHl']. - reflexivity. - simpl. rewrite IHl'. reflexivity. Qed. Theorem rev_app_distr: forall l1 l2 : natlist, rev (l1 ++ l2) = rev l2 ++ rev l1. Proof. intros l1 l2. induction l1 as [|n l1' IHl1']. - rewrite app_nil_r. reflexivity. - simpl. rewrite IHl1'. rewrite app_assoc. reflexivity. Qed. Theorem rev_involutive : forall l : natlist, rev (rev l) = l. Proof. intros l. induction l as [| n l' IHl']. - reflexivity. - simpl. rewrite rev_app_distr. rewrite IHl'. reflexivity. Qed. Theorem app_assoc4 : forall l1 l2 l3 l4 : natlist, l1 ++ (l2 ++ (l3 ++ l4)) = ((l1 ++ l2) ++ l3) ++ l4. Proof. intros l1 l2 l3 l4. rewrite app_assoc. rewrite app_assoc. reflexivity. Qed. Lemma nonzeros_app : forall l1 l2 : natlist, nonzeros (l1 ++ l2) = (nonzeros l1) ++ (nonzeros l2). Proof. intros l1 l2. induction l1 as [| n l1' IHl1']. - reflexivity. - destruct n as [| n'] eqn:N. + simpl. rewrite IHl1'. reflexivity. + simpl. rewrite IHl1'. reflexivity. Qed. Exercise: 2 stars, standard (eqblist) Fixpoint eqblist (l1 l2 : natlist) : bool := match l1, l2 with | nil, nil =\u0026gt; true | nil, _ =\u0026gt; false | _, nil =\u0026gt; false | h1 :: t1, h2 :: t2 =\u0026gt; if (h1 =? h2) then (eqblist t1 t2) else false end. Example test_eqblist1 : (eqblist nil nil = true). Proof. reflexivity. Qed. Example test_eqblist2 : eqblist [1;2;3] [1;2;3] = true. Proof. reflexivity. Qed. Example test_eqblist3 : eqblist [1;2;3] [1;2;4] = false. Proof. reflexivity. Qed. Theorem eqblist_refl : forall l:natlist, true = eqblist l l. Proof. intros l. induction l as [| n l' IHl']. - (* l = nil *) reflexivity. - (* l = con n l' *) simpl. rewrite eqb_refl. (* n =? n = true *) rewrite IHl'. reflexivity. Qed. Exercise: 1 star, standard (count_member_nonzero) Theorem count_member_nonzero : forall (s : bag), 1 \u0026lt;=? (count 1 (1 :: s)) = true. Proof. intros s. reflexivity. Qed. Exercise: 3 stars, advanced (remove_does_not_increase_count) Theorem remove_does_not_increase_count: forall (s : bag), (count 0 (remove_one 0 s)) \u0026lt;=? (count 0 s) = true. Proof. intros s. induction s as [| n s' IHs']. - reflexivity. - destruct n as [| n'] eqn:N. + simpl. rewrite leb_n_Sn. reflexivity. + simpl. rewrite IHs'. reflexivity. Qed. Exercise: 3 stars, standard, optional (bag_count_sum) Theorem count_sum : forall (v : nat) (l1 l2 : bag), count v l1 + count v l2 = count v (sum l1 l2). Proof. intros v l1 l2. induction l1 as [| n l1' IHl1']. - reflexivity. - simpl. destruct (v =? n) as []. + simpl. rewrite IHl1'. reflexivity. + rewrite IHl1'. reflexivity. Qed. 这题一个值得注意的细节是：我们不方便利用 destruct 直接去讨论 n 是否等于 v，但我们可以通过讨论 v =? n 是 true 还是 false 来实现这一需求。\nExercise: 3 stars, advanced (involution_injective) Theorem involution_injective : forall (f : nat -\u0026gt; nat), (forall n : nat, n = f (f n)) -\u0026gt; (forall n1 n2 : nat, f n1 = f n2 -\u0026gt; n1 = n2). Proof. intros f H1 n1 n2 H2. rewrite H1. rewrite \u0026lt;- H2. rewrite \u0026lt;- H1. reflexivity. Qed. Exercise: 2 stars, advanced (rev_injective) Theorem rev_injective : forall (l1 l2 : natlist), rev l1 = rev l2 -\u0026gt; l1 = l2. Proof. intros l1 l2 H. rewrite \u0026lt;- rev_involutive. rewrite \u0026lt;- H. rewrite rev_involutive. reflexivity. Qed. 该定理的证明具有一定的技巧性。如果直接对某个链表使用归纳法会比较繁琐。这里利用 involutive 定理 l = rev (rev l)先把 l2 换成 rev (rev l2)，再利用条件把 rev l2 换成 rev l1，最后换一个方向利用 involutive 完成证明。\nExercise: 2 stars, standard (hd_error) Definition hd_error (l : natlist) : natoption := match l with | nil =\u0026gt; None | h :: t =\u0026gt; (Some h) end. Example test_hd_error1 : hd_error [] = None. Proof. reflexivity. Qed. Example test_hd_error2 : hd_error [1] = Some 1. Proof. reflexivity. Qed. Example test_hd_error3 : hd_error [5;6] = Some 5. Proof. reflexivity. Qed. Exercise: 1 star, standard, optional (option_elim_hd) Theorem option_elim_hd : forall (l:natlist) (default:nat), hd default l = option_elim default (hd_error l). Proof. intros l d. destruct l as [| h l'] eqn:L. - reflexivity. - reflexivity. Qed. Exercise: 1 star, standard (eqb_id_refl) Theorem eqb_id_refl : forall x, eqb_id x x = true. Proof. intros x. destruct x as [n]. simpl. rewrite eqb_refl. reflexivity. Qed. Exercise: 1 star, standard (update_eq) Theorem update_eq : forall (d : partial_map) (x : id) (v: nat), find x (update d x v) = Some v. Proof. intros d x v. simpl. destruct x as [x']. simpl. rewrite eqb_refl. reflexivity. Qed. Exercise: 1 star, standard (update_neq) Theorem update_neq : forall (d : partial_map) (x y : id) (o: nat), eqb_id x y = false -\u0026gt; find x (update d y o) = find x d. Proof. intros d x y o H. simpl. rewrite H. reflexivity. Qed. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cc2099b0681a6a05ff595c593a982b4e","permalink":"https://kristoff-starling.github.io/notes/booknotes/softwarefoundations/lf/lists/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/booknotes/softwarefoundations/lf/lists/","section":"notes","summary":"Pairs of Numbers Lists of Numbers Repeat Length Append Head ant Tail Bags via Lists Reasoning About Lists Induction on Lists Reversing a List Search Options Partial Maps Exercises Exercise: 1 star, standard (snd_fst_is_swap) Exercise: 1 star, standard, optional (fst_swap_is_snd) Exercise: 2 stars, standard, especially useful (list_funs) Exercise: 3 stars, advanced (alternate) Exercise: 3 stars, standard, especially useful (bag_functions) Exercise: 3 stars, standard, optional (bag_more_functions) Exercise: 2 stars, standard, especially useful (add_inc_count) Exercise: 3 stars, standard (list_exercises) Exercise: 2 stars, standard (eqblist) Exercise: 1 star, standard (count_member_nonzero) Exercise: 3 stars, advanced (remove_does_not_increase_count) Exercise: 3 stars, standard, optional (bag_count_sum) Exercise: 3 stars, advanced (involution_injective) Exercise: 2 stars, advanced (rev_injective) Exercise: 2 stars, standard (hd_error) Exercise: 1 star, standard, optional (option_elim_hd) Exercise: 1 star, standard (eqb_id_refl) Exercise: 1 star, standard (update_eq) Exercise: 1 star, standard (update_neq) Pairs of Numbers 我们可以定义一个 pair 类型：","tags":null,"title":"Working with Structured Data","type":"docs"},{"authors":null,"categories":null,"content":"Isolation We want strong isolation between applications so that if there\u0026rsquo;s a bug in one application, the others will not be damaged. We also want isolation between applications and the operating system so that if weird arguments were passed to the OS, OS wouldn\u0026rsquo;t crash. Let\u0026rsquo;s consider what happens if there\u0026rsquo;s no operating system, a strawman design. In this case, several applications (e.g. shell, echo etc.) run on the hardware, there is no abstraction layer between H/W and applications.\nThere\u0026rsquo;s a demand for switching between applications. Because there\u0026rsquo;s no OS, shell needs to proactively \u0026ldquo;give up\u0026rdquo; and \u0026ldquo;quit\u0026rdquo; the CPU to let others use the hardware. This is the so-called cooperating schedule. However, if there\u0026rsquo;s a dead loop in shell or shell is a malware, it will not quit and the hardware is completely occupied by this application. Therefore, we need a kind of \u0026ldquo;enforced multipliexing\u0026rdquo;: no matter what the application does, it will be forced to give up the CPU once in a while.\nDifferent applications share the same memory space. For example, shell\u0026rsquo;s memory may start at address 1000 and echo\u0026rsquo;s memory may start at address 2000. There\u0026rsquo;s no boundary between their memory space and it\u0026rsquo;s easy for one application to overwrite others\u0026rsquo; memory and cause tricky bugs.\nIn summary, we need operating systems to enforce both multiplexing and strong memory isolation. Strawman design is not very common in today\u0026rsquo;s computer system. Some real-time system doesn\u0026rsquo;t have OS because applications trust each other, but in most cases we need OS to ensure isolation.\nUnix inferfaces are sophisticated design. They abstracts the hardware resources and make isolation possible. For example,\nProcess is the abstraction of CPU. Applications use fork() to create new processes, but it cannot assign a CPU core directly. How to schedule the processes on the CPU and how to arrange different CPU cores are the jobs of OS. Exec is the abstraction of memory. Application use exec() to load a new applications, during which it loads the memory image which describes the text, data segments etc. During execution, applications can use system calls like sbrk() to modify the memory image, but they cannot act directly on the physical memory. OS is responsible for allocating physical memory to the memory image. File is the abstraction of disk blocks. Applications do operations on the files but they don\u0026rsquo;t have direct access to the physical storage device. They don\u0026rsquo;t know where the \u0026ldquo;file\u0026rdquo; is actually stored, which is the job belongs to OS. OS should be defensive: it should treat all the processes as malicious applications written by attackers and ensure that\nApps cannot crash the OS. Apps cannot break out of the isolation. Strong isolation is totally depend on the OS. The kernel is call \u0026ldquo;trusted computing base\u0026rdquo; (TCB). Kernels must have as few bugs as possible because any bug may be taken advantage of and becomes an exploit.\nStrong isolation between applications and the OS are typically implemented by hardware support. Ususally there\u0026rsquo;re two: use/kernel mode and virtual memory.\nUser/Kernel mode When running in kernel mode, CPU can execute privileged instructions which interact directly with CSRs e.g. setting up page table register, disable clock interrupts etc.\nIn user mode, CPU can only execute unprivileged instructions such as add jmp etc. There is a bit in the CSR to let hardware check which mode the current process/thread is in (0 for kernel, 1 for user). If the CPU decode one instruction, find out that it\u0026rsquo;s a privileged one and the mode bit is 1, it will deny executing the instruction. (Of course, the instruction for changing the mode bit is a privileged one.)\nIf a user application wants to execute privileged instructions, it should transfer from user mode to kernel mode first and let the kernel execute the instruction.\nThere is a method for applications to enter the kernel. In RISC-V, the instruction is ecall. The user store ssystem call number in a particular register and ecall, the PC jumps to a specific address in the kernel, and kernel checks the syetem call number, does security checks and jumps to corresponding service functions.\nVirtual Memory Each process has its own page table: it maps virtual addresses to physical addresses. If the OS allocates different memory space to different processes, processes will not be able to access other processes\u0026rsquo;s memory space because those addresses are not in its page table. In this way, the OS provides strong memory isolation.\nKernel Design An instant question is: since kernel should be TCB, what kind of code should be run in kernel mode? Most Unix-like operating system put the whole OS into the kernel mode(including xv6). This style is call monolithic kernel design. Though this design contains more code and increases the risk of having serious bugs, it\u0026rsquo;s helpful for tight integration between different modules (file system, virtual memory, processes etc.) and can achieve better performance.\nAnother style, which aims at running as fewer lines as possible in the kernel to avoid bug risks, is called micro kernel design. The kernel only contains some core modules and other modules like file system are run in user mode and treated like ordinary user applications. The challenge for this design is how to improve performance. For example, if an application wants to access the file system, frequent jumps between kernel mode and user mode are needed to achieve that. (app(u) $\\rightarrow$ IPC(k) $\\rightarrow$ FS(u) $\\rightarrow$ IPC(k) $\\rightarrow$ app(u))\nXv6 Code Details Xv6 uses monolithic kernel design. All the *.c programs in /kernel are run in kernel mode. The Makefile grabs all the C files in /kernel and generates relocatable files: *.c$\\overset{CC}{\\rightarrow}$*.S$\\overset{AS}{\\rightarrow}$*.o. ld is responsible for linking all the *.o files and generate an executable file /kernel/kernel. /kernel/kernel.asm containing disassembled code of the kernel will also be generated for debugging.\nXv6 starts at address 0x80000000. The code is written directly in assembly and is in /kernel/entry.S. /kernel/kernel.ld ensures that the assembly code will be linked to 0x80000000. Currently, xv6 runs in machine mode - no protection, no virtual memory etc. The job for xv6 is to enter supervisor mode(kernel mode) as soon as possible.\nWhen xv6 jumps to main() in /kernel/main.c, it has been in supervisor mode. Here we use make CPUS=1 qemu-gdb to fire up xv6, so there\u0026rsquo;s only one CPU core in our simulated CPU. The code in main() is shown as below:\nif(cpuid() == 0){ consoleinit(); printfinit(); printf(\u0026quot;\\n\u0026quot;); printf(\u0026quot;xv6 kernel is booting\\n\u0026quot;); printf(\u0026quot;\\n\u0026quot;); kinit(); // physical page allocator kvminit(); // create kernel page table kvminithart(); // turn on paging procinit(); // process table trapinit(); // trap vectors trapinithart(); // install kernel trap vector plicinit(); // set up interrupt controller plicinithart(); // ask PLIC for device interrupts binit(); // buffer cache iinit(); // inode cache fileinit(); // file table virtio_disk_init(); // emulated hard disk userinit(); // first user process __sync_synchronize(); started = 1; } Xv6 initializes lots of things and then jumps to userinit() run the first process. userinit() (in /kernel/proc.c) loads the first process. Because currently xv6 hasn\u0026rsquo;t built the file system and cannot load images, the assembly code is statically declared in the array initcode[]. The assembly code of the \u0026ldquo;first process loader\u0026rdquo; is in /user/initcode.S:\n# Initial process that execs /init. # This code runs in user space. #include \u0026quot;syscall.h\u0026quot; # exec(init, argv) .globl start start: la a0, init la a1, argv li a7, SYS_exec ecall # for(;;) exit(); exit: li a7, SYS_exit ecall jal exit # char init[] = \u0026quot;/init\\0\u0026quot;; init: .string \u0026quot;/init\\0\u0026quot; # char *argv[] = { init, 0 }; .p2align 2 argv: .long init .long 0 initcode.S prepares arguments for the SYS_exec system call and uses ecall instruction to go back to kernel space. ecall will lead us to syscall() in /kernel/syscall.c:\nvoid syscall(void) { int num; struct proc *p = myproc(); num = p-\u0026gt;trapframe-\u0026gt;a7; if(num \u0026gt; 0 \u0026amp;\u0026amp; num \u0026lt; NELEM(syscalls) \u0026amp;\u0026amp; syscalls[num]) { p-\u0026gt;trapframe-\u0026gt;a0 = syscalls[num](); } else { printf(\u0026quot;%d %s: unknown sys call %d\\n\u0026quot;, p-\u0026gt;pid, p-\u0026gt;name, num); p-\u0026gt;trapframe-\u0026gt;a0 = -1; } } The variable num\u0026rsquo;s value, after the instruction num = p-\u0026gt;trapframe-\u0026gt;a7, equals 7, which is SYS_exec\u0026rsquo;s value defined in /kernel/syscall.h. The kernel knows that some user program wants to use the exec system call, so it goes to syscalls[num](), which is a function table for providing system call services.\nThe function sys_exec() is in /kernel/sysfile.c. In line 444:\nint ret = exec(path, argv) If we print the value of \u0026ldquo;path\u0026rdquo;, we will find that it equals \u0026ldquo;/init\u0026rdquo;. So xv6 loads user program /user/init.c.\ninit.c mainly forks some child processes and exec sh.c, so xv6 starts the shell and the booting procedure is completed.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9bac06ec716342b68d249f0d412ff998","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec03/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec03/","section":"notes","summary":"Isolation We want strong isolation between applications so that if there\u0026rsquo;s a bug in one application, the others will not be damaged. We also want isolation between applications and the operating system so that if weird arguments were passed to the OS, OS wouldn\u0026rsquo;t crash.","tags":null,"title":"MIT-6.S081 Lecture 03: OS Organization and System Calls","type":"docs"},{"authors":null,"categories":null,"content":"值得一提的是下面几道题：\nQ1: Num Eights 一个值得注意的 python 优先级问题：笔者刚开始写了一行\nreturn num_eights(pos // 10) + 1 if pos % 10 == 8 else 0 但这样前面的一整个 num_eights(pos // 10) + 1 都会成为 if 条件成立的结果。正确的写法应当加上括号：\nreturn num_eights(pos // 10) + (1 if pos % 10 == 8 else 0) Q4: Count Coins 如何不重不漏地计数是本题的难点。我们去重的方法是：对于每一种组合方案只计算将钱币升序排列的那一种。因此我们递归时不仅要记录剩余的 change，还要记录当前已经考虑到哪种面值的钱币。假设函数记为 count(change, coin)，转移我们要考虑 count(change - coin, coin) 和 count(change, descending_coin(coin)) 两种类型。\nQ6: Anonymous Factorial 这是一道相当具有挑战性的题目，要求在不使用函数名的情况下完成递归。根据 make_anonymous_factorial()(5) 的形式可以看出 make_anonymous_factorial() 是一个返回值为函数的高阶函数。\n我们的核心思想是：**既然用于计算阶乘的函数是匿名函数无法直接通过函数名调用，那么我们就将该函数本身作为函数的一个参数一路传下去。**按照这个思想我们可以写出如下的一个 lambda 表达式：lambda fact, n: 1 if n == 0 else n * fact(fact, n-1)。\n我们要把这个函数本身作为参数 fact 传进去，因此我们外面还得再套一层壳。外面的壳使用一下 function currying 就可以再接受一个参数 n。最终的结果如下：\nreturn (lambda f: lambda n: f(f, n))(lambda fact, n: 1 if n == 0 else n * fact(fact, n-1)) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e3bbdbfb41a15248678b828adf148d5f","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/homework/hw03/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/homework/hw03/","section":"notes","summary":"值得一提的是下面几道题：\nQ1: Num Eights 一个值得注意的 python 优先级问题：笔者刚开始写了一行\nreturn num_eights(pos // 10) + 1 if pos % 10 == 8 else 0 但这样前面的一整个 num_eights(pos // 10) + 1 都会成为 if 条件成立的结果。正确的写法应当加上括号：","tags":null,"title":"UCB-CS61A Homework 03: Recursion, Tree Recursion","type":"docs"},{"authors":null,"categories":null,"content":" Polymorphism Polymorphic Lists Type Annotation Inference Type Argument Synthesis Implicit Arguments Supplying Type Arguments Explicitly Polymorphic Pairs Polymorphic Options Functions as Data Higher-Order Functions Filter Anonymous Functions Maps Fold Functions That Construct Functions Exercises Exercise: 2 stars, standard, optional (mumble_grumble) Exercise: 1 star, standard, optional (combine_checks) Exercise: 2 stars, standard, especially useful (split) Exercise: 1 star, standard, optional (hd_error_poly) Exercise: 2 stars, standard (filter_even_gt7) Exercise: 3 stars, standard (partition) Exercise: 3 stars, standard (map_rev) Exercise: 2 stars, standard, especially useful (flat_map) Exercise: 1 star, standard, optional (fold_types_different) Exercise: 2 stars, standard (fold_length) Exercise: 3 stars, standard (fold_map) Exercise: 2 stars, advanced (currying) Church Numerals (Advanced) Exercise: 2 stars, advanced (church_scc) Exercise: 3 stars, advanced (church_plus) Exercise: 3 stars, advanced (church_mult) Exercise: 3 stars, advanced (church_exp) 这一章节我们主要关注函数式编程的两个基本概念：多态 (polymorphism)，即对函数操作的对象的类型进行抽象；高阶函数，即将函数本身看作数据。\nPolymorphism Polymorphic Lists 上一章节中我们定义的列表只能处理自然数。在真正的程序中列表中的元素类型是丰富的，甚至可以有 list of lists。我们不可能对每种类型都定义一种列表——因为我们不仅要定义类型，还要将列表相关的所有定理对每种类型都证明一遍，这几乎是不可能的。\n基于以上需求，Coq 支持了 polymorphic 的 inductive type definition。比如下面是一个多态的 list 类型：\nInductive list (X : Type) : Type := | nil | cons (x : X) (l : list X). 多态的本质很简单：我们之前定义的类型以归纳的方式描述了一个集合，现在 list 是一个 Type -\u0026gt; Type 的函数：\nCheck list: Type -\u0026gt; Type 它接收一个类型 X 作为参数，返回 list X 这个类型，“list X” 类型是一个包含了所有由 X 类型元素构成的链表的集合。\nlist 定义中的类型 X 会自动成为 constructor 的参数——即现在 nil 和 con 都是多态 constructor，以后使用它们时需要在后面写上类型。例如：\nCheck (cons nat 3 (nil nat)) : list nat. nil 和 cons 的类型也都是从 Type 映射到 list X 的“函数”：\nCheck nil : forall X : Type, list X. Check cons: forall X : Type, X -\u0026gt; list X -\u0026gt; list X. 有了多态的列表定义后，我们可以把之前写的函数也改成多态的。下面以 repeat 为例：\nFixpoint repeat (X : Type) (x : X) (count : nat) : list X := match count with | 0 =\u0026gt; nil X | S count' =\u0026gt; cons X x (repeat X x count') end. Type Annotation Inference 如果我们在书写函数时不显式声明参数的类型，例如\nFixpoint repeat' X x count : list X := match count with | 0 =\u0026gt; nil X | S count' =\u0026gt; cons X x (repeat X x count') end. 我们会发现 Check repeat 和 Check repeat' 的结果是完全一样的。这是因为 Coq 可以自动进行 type inference，例如根据 count match 的方法可以看出 count 一定是 nat 类型等等。\nType Argument Synthesis synthesis 和 inference 的原理类似：在某些地方你可以直接用 _ 来代替类型名，Coq 会结合所有的上下文信息自动分析出这里该填写什么。例如下面两句代码在功能上是等价的：\nDefinition list123 := cons nat 1 (cons nat 2 (cons nat 3 (nil nat))). Definition list123' := cons _ 1 (cons _ 2 (cons _ 3 (nil _))). Implicit Arguments 利用 implicit argument 技术，我们甚至可以将 _ 省略掉。\n第一种方法是使用 Arguments 语法：Arguments 可以指定一个函数/constructor的名字，以及需要被处理为 implicit 的类型名，以后再使用该函数/constructor时就不需要再显式地给出类型名或类型名的占位符。例如：\nArguments nil {X}. Arguments cons {X}. Arguments repeat {X}. 这时我们定义 list123 就可以直接写：\nDefinition list123'' := cons 1 (cons 2 (cons 3 nil)). 第二种更方便的语法是：我们在定义 Type/函数的时候，可以用 {} 代替 () 把用于多态的类型名框起来，这样以后自动省略类型名参数。下面我们用这种语法把 list 的其他几个重要函数重写一下，可以看到使用了 implicit arguments 后，函数体内部的代码就和之前的没有区别了：\nFixpoint app {X : Type} (l1 l2 : list X) : list X := match l1 with | nil =\u0026gt; l2 | cons h t =\u0026gt; cons h (app t l2) (* 注意我们还没有对多态的list定义::等notation，所以现在还不能 用 h::t 的方式书写，一会儿定义了之后就可以了*) end. Fixpoint rev {X : Type} (l : list X) : list X := match l with | nil =\u0026gt; nil | cons h t =\u0026gt; app (rev t) (cons h nil) end. Fixpoint length {X : Type} (l : list X) : list X := match l with | nil =\u0026gt; 0 | cons h t =\u0026gt; 1 + (length t) end. Supplying Type Arguments Explicitly 将参数定义为隐式的一个坏处在于，某些特殊情况下 Coq 可能无法自动识别参数类型。这种情况下我们需要临时地显式给出参数类型。例如：\nFail Definition mynil := nil. （注：这里的 Fail 命令表示如果后面的语句执行失败，Coq 会在交互区打印出错误信息，但程序仍然可以继续执行。）\n这样的定义是不成立的，因为完全没有上下文信息可以看出 nil X 的 X 是什么类型。我们有两种解决方法，一种是显式地指定 mynil 的类型：\nDefinition mynil : list nat := nil. 第二种是使用 @ 让 nil 临时显式地接收一个类型参数：\nDefinition mynil' := @nil nat. 我们定义的多态 list 和之前的 list 本质上是两种类型，因此所有的 Notation 我们也要重新定义一遍：\nNotation \u0026quot;x :: y\u0026quot; := (cons x y) (at level 60, right associativity). Notation \u0026quot;[ ]\u0026quot; := nil. Notation \u0026quot;[ x ; .. ; y ]\u0026quot; := (cons x .. (cons y []) ..). Notation \u0026quot;x ++ y\u0026quot; := (app x y) (at level 60, right associativity). Polymorphic Pairs 在上一章节中我们定义的两个自然数的 pair 也可以拓展成多态的 pair，这就是离散数学中的笛卡尔积：\nInductive prod (X Y : Type) : Type := | pair (x : X) (y : Y). Argument pair {X} {Y}. Notation \u0026quot;( x, y )\u0026quot; := (pair x y). Notation \u0026quot;X * Y\u0026quot; := (prod X Y) : type_scope. 这里的 \u0026ldquo;type_scope\u0026rdquo; 表明了笛卡尔积只作用在两个类型 (集合) 上，避免和自然数上的乘法混淆。\n(x, y) 和 X * Y 在初期容易混淆。一个好的理解方式是：X * Y 是一个类型，即一个集合。如果 x 的类型是 X，y 的类型是 Y，那么 (x, y) 是类型 X * Y 的一个实例 (集合 X * Y 中的一个元素)。\n下面的函数 combine 接收两个 list，返回一个把对应 index 元素打包成 pair 的 list。这个函数在通常的编程语言中称为 zip()：\nFixpoint combine {X, Y : Type} (l1 : list X) (l2 : list Y) -\u0026gt; list (X * Y) := match lx, ly with | nil, _ =\u0026gt; nil | _, nil =\u0026gt; nil | x :: tx, y :: ty =\u0026gt; (x, y) :: (combine tx ty) end. Polymorphic Options 对于之前定义的 natoption，我们也将其转化为多态：\nInductive option (X : Type) : Type := | Some (x : X) | None. Arguments Some {X}. Arguments None {X}. 然后我们可以将 nth_error 函数也转化为多态：\nFixpoint nth_error {X : Type} (l : list X) (n : nat) : option X := match l with | nil =\u0026gt; None | a :: l' =\u0026gt; match n with | 0 =\u0026gt; a | S n' =\u0026gt; nth_error l' n' end end. Functions as Data 和多数函数式编程语言一样，Coq 将函数视为 first-class citizen，即函数可以作为函数参数，可以作为函数返回值，可以作为数据存储在数据结构中。\nHigher-Order Functions 下面是一个简单的接受函数作为参数的高阶函数：\nDefinition doit3times {X : Type} (f : X -\u0026gt; X) (n : X) : X := f (f (f n)). 参数 f 是一个从 X 映射到 X 的函数，我们可以检查 doit3times 的类型：\nCheck @doit3times : forall X : Type, (X -\u0026gt; X) -\u0026gt; X -\u0026gt; X. Filter 下面展示一个更有意思的高阶函数：filter 函数接收一个函数 test 和一个 list，返回一个新的 list，其中包含原 list 中通过 test 测试的元素：\nFixpoint filter {X : Type} (test : X -\u0026gt; bool) (l : list X) : list X := match l with | nil =\u0026gt; nil | h :: t =\u0026gt; if test h then h :: (filter test t) else filter test t end. 多态的 list 可以接收任何类型的元素，甚至是 list 自己，形成 list of lists，下面是一个例子：\nDefinition length_is_1 {X : Type} (l : list X) : bool := (length l) =? 1. Example test_filter : filter length_is_1 [ [1; 2]; [3]; [4]; [5; 6; 7]; []; [8] ] = [ [3]; [4]; [8]; ]. Proof. reflexivity. Qed. Anonymous Functions 有的时候，必须给函数命名以方便使用是一件令人沮丧的事情，因为很多时候我们只是想临时创建一个函数丢给高阶函数当参数使用，比如上面例子中的 length_is_1。Coq 为我们提供了一种临时创建函数的方式，这种方式类似于 Python 中的 lambda 表达式，不需要给函数命名，该函数也不会出现在 top level environment 中。下面是一个例子：\nExample test_filter' : filter (fun l =\u0026gt; (length l) =? 1) [ [1; 2]; [3]; [4]; [5;6;7]; []; [8] ] = [ [3]; [4]; [8] ]. 其中 (fun l =\u0026gt; (length l) =? 1) 的意思是该函数接收一个参数 l，返回 (length l) =? 1 (我们可以不指明参数和返回值的类型，Coq 会自己做 type inference)。\nMaps map 也是许多函数式语言支持的常用高阶函数。它接收一个转换函数 f 和一个列表 l，返回一个新列表，其内容是把 f 作用到 l 里的每个元素后的结果。\nFixpoint map {X Y : Type} (f : X -\u0026gt; Y) (l : list X) : list Y := match l with | nil =\u0026gt; nil | h :: t =\u0026gt; (f h) :: (map f t) end. 值得注意的是传入的列表的元素类型和返回的列表的元素类型不一定一样。\n我们不仅可以对 list 做 map，也可以对其他的数据类型做 map，比如下面的例子对 option 做 map：\nDefinition option_map {X Y : Type} (f : X -\u0026gt; Y) (xo : option X) : option Y := match xo with | None =\u0026gt; None | Some x =\u0026gt; Some (f x) end. Fold 一个更加强大的高阶函数是 fold，它是 Google map-reduced 框架的 reduce 函数的灵感来源：\nFixpoint fold {X Y : Type} (f : X -\u0026gt; Y -\u0026gt; Y) (l : list X) (b : Y) : Y := match l with | nil =\u0026gt; b | h :: t =\u0026gt; f h (fold f t b) end. 从直观上来理解，该函数接收函数 f，列表 l 和初始值 b。然后从初始值 b 开始，把列表中的元素按照从右往左的顺序依次与 type Y 的结果做函数 f 操作。比如 fold plus [1; 2; 3; 4] 0 就意味着 1+(2+(3+(4+0)))。\nFunctions That Construct Functions 我们之前讨论的高阶函数都是将函数作为参数传入，我们在这里看一些将函数作为函数返回值的例子。下面是一个比较 dummy 的例子，constfun 返回的函数不论接收什么都会输出固定值：\nDefinition constfun {X : Type} (x : X) : nat -\u0026gt; X := fun (k : nat) =\u0026gt; x. 事实上，函数式编程本质上不支持多参数的函数，我们之前看到的多参数的函数都是通过 currying 完成的。以 plus 为例：\nCheck plus : nat -\u0026gt; nat -\u0026gt; nat. 这里的 -\u0026gt; 可以理解为作用在 type 类型元素上的一种二元运算符，它是 right associative 的，即 plus 的类型实际上是 nat -\u0026gt; (nat -\u0026gt; nat)。我们使用 plus 时都给它传两个参数，但实际上传一个也是可以的，按照 nat -\u0026gt; (nat -\u0026gt; nat)，plus 可以被理解为 “这是一个函数，它接收一个加数，返回另一个函数，这个返回的函数接收另一个加数作为参数，返回加法的结果”。\nDefinition plus3 := plus 3 Check plus3 : nat -\u0026gt; nat. Example test_plus3 : plus3 4 = 7. Proof. reflexivity. Qed. 这种给 currying 的函数传一个参数的手法称为 partial application。\nExercises Exercise: 2 stars, standard, optional (mumble_grumble) d (b a 5) (* NO, the first argument of d should be a type *) d mumble (b a 5) (* YES, grumble mumble *) d bool (b a 5) (* YES, grumble bool *) e bool true (* YES, grumble bool *) e mumble (b c 0) (* YES, grumble mumble *) e bool (b c 0) (* NO, the second argument shoule be type bool *) c (* YES, mumble *) Exercise: 1 star, standard, optional (combine_checks) Check @combine : forall X Y : Type, list X -\u0026gt; list Y -\u0026gt; list (X * Y). Compute (combine [1; 2] [false; false; true; true]). (* [(1, false); (2, false)] *) Exercise: 2 stars, standard, especially useful (split) Fixpoint split {X Y : Type} (l : list (X*Y)) : (list X) * (list Y) := match l with | nil =\u0026gt; (nil, nil) | (x, y) :: l' =\u0026gt; (x :: fst (split l'), y :: snd (split l')) end. Example test_split: split [(1,false);(2,false)] = ([1;2],[false;false]). Proof. reflexivity. Qed. Exercise: 1 star, standard, optional (hd_error_poly) Definition hd_error {X : Type} (l : list X) : option X := match l with | nil =\u0026gt; None | h :: t =\u0026gt; Some h end. Check @hd_error : forall X : Type, list X -\u0026gt; option X. Example test_hd_error1 : hd_error [1;2] = Some 1. Proof. reflexivity. Qed. Example test_hd_error2 : hd_error [[1];[2]] = Some [1]. Proof. reflexivity. Qed. Exercise: 2 stars, standard (filter_even_gt7) Definition filter_even_gt7 (l : list nat) : list nat := filter (fun n =\u0026gt; (even n) \u0026amp;\u0026amp; (8 \u0026lt;=? n)) l. Example test_filter_even_gt7_1 : filter_even_gt7 [1;2;6;9;10;3;12;8] = [10;12;8]. Proof. reflexivity. Qed. Example test_filter_even_gt7_2 : filter_even_gt7 [5;2;6;19;129] = []. Proof. reflexivity. Qed. Exercise: 3 stars, standard (partition) Definition partition {X : Type} (test : X -\u0026gt; bool) (l : list X) : list X * list X := ((filter test l), (filter (fun x =\u0026gt; negb(test x)) l)). Example test_partition1: partition odd [1;2;3;4;5] = ([1;3;5], [2;4]). Proof. reflexivity. Qed. Example test_partition2: partition (fun x =\u0026gt; false) [5;9;0] = ([], [5;9;0]). Proof. reflexivity. Qed. Exercise: 3 stars, standard (map_rev) Lemma app_map : forall (X Y : Type) (f : X -\u0026gt; Y) (l1 l2 : list X), map f (l1 ++ l2) = (map f l1) ++ (map f l2). Proof. intros X Y f l1 l2. induction l1 as [| n l1' IHl1']. - reflexivity. - simpl. rewrite IHl1'. reflexivity. Qed. Theorem map_rev : forall (X Y : Type) (f : X -\u0026gt; Y) (l : list X), map f (rev l) = rev (map f l). Proof. intros X Y f l. induction l as [| n l' IHl']. - reflexivity. - simpl. rewrite \u0026lt;- IHl'. rewrite app_map. reflexivity. Qed. 在证明主要定理之前，需要先证明一个和列表 append 相关的引理。\nExercise: 2 stars, standard, especially useful (flat_map) Fixpoint flat_map {X Y: Type} (f: X -\u0026gt; list Y) (l: list X) : list Y := match l with | nil =\u0026gt; nil | h :: t =\u0026gt; (f h) ++ (flat_map f t) end. Example test_flat_map1: flat_map (fun n =\u0026gt; [n;n;n]) [1;5;4] = [1; 1; 1; 5; 5; 5; 4; 4; 4]. Proof. reflexivity. Qed. Exercise: 1 star, standard, optional (fold_types_different) fold 参数中的函数 f 的类型是 f : X -\u0026gt; Y -\u0026gt; Y，X 和 Y 不同的情况也是很有用的，比如传入的 list 是一系列动作 (上下左右)，b 是一个初始位置，那么使用 fold 函数就可以得出做完这一系列移动后的最终位置。\nExercise: 2 stars, standard (fold_length) Theorem fold_length_correct : forall X (l : list X), fold_length l = length l. Proof. intros X l. induction l as [|n l' IHl']. - reflexivity. - simpl. rewrite \u0026lt;- IHl'. reflexivity. Qed. 这段证明有一个值得关注的细节：在 successor case 的最后一步之前，证明的 goal 是\nfold_length (n :: l') = S (fold_length l') 在这一步使用 simpl. 无法化简，但我们知道根据 fold_length 的定义这一步是可以化简的，事实上使用 reflexivity. 就可以直接解决问题。reflexivity 使用了更加 aggressive 的化简方法，有时卡壳时可以一试。\nExercise: 3 stars, standard (fold_map) Definition fold_map {X Y: Type} (f: X -\u0026gt; Y) (l: list X) : list Y := fold (fun x l =\u0026gt; [f x] ++ l) l nil. Theorem fold_map_correct : forall (X Y : Type) (f : X -\u0026gt; Y) (l : list X), fold_map f l = map f l. Proof. intros X Y f l. induction l as [| n l' IHl']. - reflexivity. - simpl. rewrite \u0026lt;- IHl'. reflexivity. Qed. Exercise: 2 stars, advanced (currying) 将一个 (X * Y) -\u0026gt; Z 类型的函数转换为 X -\u0026gt; (Y -\u0026gt; Z) 类型的函数的过程称为 currying，反过来称为 uncurrying。\nDefinition prod_uncurry {X Y Z : Type} (f : X -\u0026gt; Y -\u0026gt; Z) (p : X * Y) : Z := (f (fst p))(snd p). Theorem uncurry_curry : forall (X Y Z : Type) (f : X -\u0026gt; Y -\u0026gt; Z) x y, prod_curry (prod_uncurry f) x y = f x y. Proof. intros X Y Z f x y. reflexivity. Qed. Theorem curry_uncurry : forall (X Y Z : Type) (f : (X * Y) -\u0026gt; Z) (p : X * Y), prod_uncurry (prod_curry f) p = f p. Proof. intros X Y Z f p. destruct p as [n m]. reflexivity. Qed. prod_uncurry f 接收了一个 X -\u0026gt; Y -\u0026gt; Z 类型的函数参数，返回了一个 (X * Y) -\u0026gt; Z 类型的参数。prod_curry 正好相反。\n注意第二个证明中，由于我们定义 prod_uncurry 时使用了 fst 和 snd，所以使用 reflexivity 之前要先用 destruct 把 pair p 给展开。\nChurch Numerals (Advanced) Exercise: 2 stars, advanced (church_scc) Definition scc (n : cnat) : cnat := fun (X : Type) (f : X -\u0026gt; X) (x : X) =\u0026gt; n X f (f x). Example scc_1 : scc zero = one. Proof. reflexivity. Qed. Example scc_2 : scc one = two. Proof. reflexivity. Qed. Example scc_3 : scc two = three. Proof. reflexivity. Qed. Exercise: 3 stars, advanced (church_plus) Definition plus (n m : cnat) : cnat := fun (X : Type) (f : X -\u0026gt; X) (x : X) =\u0026gt; m X f (n X f x). Example plus_1 : plus zero one = one. Proof. reflexivity. Qed. Example plus_2 : plus two three = plus three two. Proof. reflexivity. Qed. Example plus_3 : plus (plus two two) three = plus one (plus three three). Proof. reflexivity. Qed. Exercise: 3 stars, advanced (church_mult) Definition mult (n m : cnat) : cnat := fun (X : Type) (f : X -\u0026gt; X) (x : X) =\u0026gt; n X (m X f) x. Example mult_1 : mult one one = one. Proof. reflexivity. Qed. Example mult_2 : mult zero (plus three three) = zero. Proof. reflexivity. Qed. Example mult_3 : mult two three = plus three three. Proof. reflexivity. Qed. Exercise: 3 stars, advanced (church_exp) Definition exp (n m : cnat) : cnat := fun (X : Type) (f : X -\u0026gt; X) (x : X) =\u0026gt; (m (X -\u0026gt; X) (n X) f) x. Example exp_1 : exp two two = plus two two. Proof. reflexivity. Qed. Example exp_2 : exp three zero = one. Proof. reflexivity. Qed. Example exp_3 : exp three two = plus (mult two (mult two two)) one. Proof. reflexivity. Qed. 关于 church numeral 可以参考 UCB CS61A 的作业。这里额外再对乘方函数做一点解读，因为其结构比较复杂。\nn X 的类型是 (X -\u0026gt; X) -\u0026gt; X -\u0026gt; X，根据 -\u0026gt; right associativity 的性质也可以看作 (X -\u0026gt; X) -\u0026gt; (X -\u0026gt; X)，即传给它一个 X -\u0026gt; X 的函数，它会返回另一个 X -\u0026gt; X 的函数。这里我们将 f 作为底层参数传给 m，可以认为整个操作提高了一阶，我们不是将一个 X -\u0026gt; X 的函数作用在元素 X 上 m 次，而是将一个 (X -\u0026gt; X) -\u0026gt; (X -\u0026gt; X) 的函数作用在函数 f 上 m 次，这个作用函数的语义又恰好是将接收的函数参数重复 n 次，所以就形成了 $1 \\to n \\to n^2 \\to \\cdots \\to n^m $ 的格局。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a5be433970509f33d8605860eb69a0f4","permalink":"https://kristoff-starling.github.io/notes/booknotes/softwarefoundations/lf/poly/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/booknotes/softwarefoundations/lf/poly/","section":"notes","summary":"Polymorphism Polymorphic Lists Type Annotation Inference Type Argument Synthesis Implicit Arguments Supplying Type Arguments Explicitly Polymorphic Pairs Polymorphic Options Functions as Data Higher-Order Functions Filter Anonymous Functions Maps Fold Functions That Construct Functions Exercises Exercise: 2 stars, standard, optional (mumble_grumble) Exercise: 1 star, standard, optional (combine_checks) Exercise: 2 stars, standard, especially useful (split) Exercise: 1 star, standard, optional (hd_error_poly) Exercise: 2 stars, standard (filter_even_gt7) Exercise: 3 stars, standard (partition) Exercise: 3 stars, standard (map_rev) Exercise: 2 stars, standard, especially useful (flat_map) Exercise: 1 star, standard, optional (fold_types_different) Exercise: 2 stars, standard (fold_length) Exercise: 3 stars, standard (fold_map) Exercise: 2 stars, advanced (currying) Church Numerals (Advanced) Exercise: 2 stars, advanced (church_scc) Exercise: 3 stars, advanced (church_plus) Exercise: 3 stars, advanced (church_mult) Exercise: 3 stars, advanced (church_exp) 这一章节我们主要关注函数式编程的两个基本概念：多态 (polymorphism)，即对函数操作的对象的类型进行抽象；高阶函数，即将函数本身看作数据。","tags":null,"title":"Polymorphism and Higher-Order Functions","type":"docs"},{"authors":null,"categories":null,"content":"本章没有特别值得一提的题目，主要就是两点：\n和树相关的操作使用递归可以让代码变得简洁。 注意 data abstraction，不要越层使用 API。 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a6eb14b27b91789a79916d4aa8e74f04","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/homework/hw04/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/homework/hw04/","section":"notes","summary":"本章没有特别值得一提的题目，主要就是两点：\n和树相关的操作使用递归可以让代码变得简洁。 注意 data abstraction，不要越层使用 API。 ","tags":null,"title":"UCB-CS61A Homework 04: Data Abstraction, Trees","type":"docs"},{"authors":null,"categories":null,"content":"Address Spaces Virtual memory helps realize memory isolation. The basic idea is simple: we want each process to have its own address space. The address spaces are independent.\nPaging Hardware We need a method to maintain the mappings of virtual memory to physical memory. The most common method is to maintain page tables.\nWe should be aware that page table is a hardware mechanism: all the addresses that the CPU gets are virtual addresses. The memory management unit (MMU) is responsible for translating virtual addresses to physical addresses according to the page table and we use the \u0026ldquo;pa\u0026rdquo; to access main memory. The page tables are stored somewhere in the main memory and the satp register in the CPU stores the physical address the current page table.\nIf we maintain the mappings for each virtual address, we will have $2^{64}$ entries and it\u0026rsquo;s obviously unreasonable. Actually we maintain the mappings for pages. The size of each page is 4096 bytes. i.e. The lower 12 bits of va are offset in page. We use 39 bits virtual address - 27 bits for VPN and 12 for offset, and we use 56 bits physical address.\nMaintaining $2^{27}$ entries is also a huge task. If all the processes store their page table in the memory, the physical memory will soon be used up. The real RISC-V design of page table has multi-level page tables. The 27 bits are divided into 9+9+9. We use the top 9 bits to index the page directory, and we get the physical address of the lower level page directory. Then we use the second 9 bits to index the next page directory\u0026hellip; Each page table/directory is stored in a page. Since each page is 4KB in size and each PTE is 8B in size, there are $512=2^9$ entries in a page, that\u0026rsquo;s where the \u0026ldquo;9\u0026rdquo; comes from.\nThe advantage of the page table tree is that we can leave unused page table entry empty. In that case, we don\u0026rsquo;t need to create the lower-level page tables for that entry, and it greatly saves memory space.\nThe hierarchical page tables make the translation very expensive. In modern design there\u0026rsquo;s a kind of \u0026ldquo;cache of PTE entries\u0026rdquo;, called Translation Look-aside Buffer (TLB), that helps accelerate the procedure. It stores the recently used [VA,PA] mappings and before translation you can firstly refer to to TLB to see if the mapping exists.\nIn most architectures, the TLB is transparent to the OS. i.e. OS doesn\u0026rsquo;t care about the implementation details of TLB. It just needs to be aware of the existence of TLB and when switching page tables, it needs to flush the TLB. (In RISC-V, that\u0026rsquo;s the instruction sfence.vma())\nCode: xv6 VMcode \u0026amp; Layout In xv6, physical addresses above 0x80000000 are mapped to the DRAM chips. physical addresses below 0x80000000 are used by I/O devices.\nFor simplicity, the kernel mappings are identity mappings. i.e. va=pa. Pages for kernel stacks and guard pages are exceptions: guard pages are not mapped so they\u0026rsquo;re put in the high address of virtual address space to save physical memory space. Refer to the \u0026ldquo;Xv6-book Notes\u0026rdquo; for details.\nRefer to the \u0026ldquo;Xv6 Source code Manual\u0026rdquo; for details about how the kernel sets up the kernel address space.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"01b90a1c1d1c5cad2d7f3ce2f92f3f79","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec04/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec04/","section":"notes","summary":"Address Spaces Virtual memory helps realize memory isolation. The basic idea is simple: we want each process to have its own address space. The address spaces are independent.\nPaging Hardware We need a method to maintain the mappings of virtual memory to physical memory.","tags":null,"title":"MIT-6.S081 Lecture 04: Page Tables","type":"docs"},{"authors":null,"categories":null,"content":"Higher-Order Functions 以函数作为参数的，或者以函数作为返回值的函数被称为 higher-order function。例如\n以函数作为参数：\ndef cube(k): return k ** 3 def summation(n, term): \u0026quot;\u0026quot;\u0026quot;Sum the first N terms of a sequence \u0026gt;\u0026gt;\u0026gt; summation(5, cube) 225 \u0026quot;\u0026quot;\u0026quot; total, k = 0, 1; while k \u0026lt;= n: total = total + term(k) k += 1 return total 传入的 term 是一个函数。\n以函数为返回值：\ndef make_adder(n): \u0026quot;\u0026quot;\u0026quot;Return a function that takes one argument k and returns k + n \u0026gt;\u0026gt;\u0026gt; add_three = make_adder(3) \u0026gt;\u0026gt;\u0026gt; add_three(4) 7 \u0026quot;\u0026quot;\u0026quot; def adder(k): return k + n return adder 这样我们就可以将一个 call expression 作为一个 operator。例如\nmake_adder(1)(2) 其中 make_adder(1) 形式上是 call expression，但返回结果是 adder 这一 operator，因此最终会返回 3。\nLambda Expression lambda 表达式定义了一个匿名函数，其格式为\nlambda \u0026lt;parameters\u0026gt;: \u0026lt;expression\u0026gt; lambda 表达式作为函数参数传给高阶函数是很方便的，例如之前的 summation 的例子中我们可以写\nsummation(5, lambda x: x ** 3) 从而不需要额外定义 cube 这个函数。\n带有条件的 lambda 表达式举例 (取绝对值函数)：\nlambda x: x if x \u0026gt; 0 else -x ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"611c370cf94bd47faa35c1307ab82bb3","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec04/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec04/","section":"notes","summary":"Higher-Order Functions 以函数作为参数的，或者以函数作为返回值的函数被称为 higher-order function。例如\n以函数作为参数：\ndef cube(k): return k ** 3 def summation(n, term): \u0026quot;\u0026quot;\u0026quot;Sum the first N terms of a sequence \u0026gt;\u0026gt;\u0026gt; summation(5, cube) 225 \u0026quot;\u0026quot;\u0026quot; total, k = 0, 1; while k \u0026lt;= n: total = total + term(k) k += 1 return total 传入的 term 是一个函数。","tags":null,"title":"UCB-CS61A Lecture 04: Higher-Order Functions","type":"docs"},{"authors":null,"categories":null,"content":"C $\\rightarrow$ ASM A C program\nint main () { ... exit(0); } cannot be directly understood by a processor. It should go through a \u0026ldquo;C -\u0026gt; Asm (.s files) -\u0026gt; binary (.o files) \u0026quot; process.\nRISC-V is a reduced instruction set while x86/x86-64, which is common in personal computers, is a complex instruction set. CISC has far more instructions and more complex instruction structure than RISC. CISC has some \u0026ldquo;big\u0026rdquo; instruction that does lots of things, while in RISC we use several \u0026ldquo;small\u0026rdquo; instructions together to achieve that.\nRISC-V has a base integer instruction set, which supports basic functions. A RISC-V processor can also choose to include some extension module to support more complicated functions. For example, if a RISC-V processor includes the \u0026ldquo;F\u0026rdquo; standard extension, it can support instructions about single-precision floating-point. Extension modules make RISC-V processors to have backward compatibility. If one day, a new extension is added, and the compiler will get the message from the processor and it can use new instructions to do the compilation.\nRISC-V Registers Why s1 register is separated from other s-series registers?\nRISC-V has a compressed version of instructions which have only 16 bits. In this version, only 8 registers (x8-x15) are used. (Just a guess)\nWhen function A is calling function B, for register x:\nIf x is a caller-saved register, e.g ra, A is responsible for saving its value on the stack and B can overwrite x without saving it. If x is a callee-saved register, A don\u0026rsquo;t need to save its value before calling B and B should save x\u0026rsquo;s value on the stack before using it, and before returning, B is responsible for restore x\u0026rsquo;s value. Stack Frames return address * previous fp saved registers local variables \u0026hellip; return address fp register previous fp (pointed to *) saved registers local variables \u0026hellip; sp register Stack frames may have different sizes and contents, but the general structure is similar: every stack frame begins with the return value of this function and the value of fp register in the previous function. sp register always points to the bottom of the current stack frame while fp register always points to the top of the current stack frame. When ret instruction is executed, pseudo code below will be implemented to adjust stack pointers and PC:\npc = return address sp = fp + ENTRY_SIZE fp = previous fp To comply with the calling conventions, the assembly of a function usually consists of a \u0026ldquo;prologue\u0026rdquo;, a \u0026ldquo;body part\u0026rdquo; and a \u0026ldquo;epilogue\u0026rdquo;. In the prologue, the function modifies sp fp registers and creates the stack frame (save values of needed registers). In the epilogue, the function modifies sp fp registers and restore values of callee-saved registers.\nFor example, the assembly of a simple function sum_then_double which calls function sum_to is shown below (note: the .global sign means that the function can be fetched at any place):\n.global sum_then_double sum_then_double: addi sp, sp, -16\t# prologue sd ra, 0(sp)\tcall sum_to li t0, 2 mul a0, a0, t0 ld ra, 0(sp)\t# epilogue addi sp, sp, 16 ret ra is a caller-saved register, so before calling sum_to, sum_then_double should firstly save the return address on the stack to avoid ra being overwritten by sum_to. At last, sum_then_double restore the value of ra from the stack.\nIf we delete the prologue and epilogue:\n.global sum_then_double sum_then_double:\tcall sum_to li t0, 2\t(*) mul a0, a0, t0 ret The processor will fall into a dead loop: sum_to modifies ra\u0026rsquo;s value to the address of the next instruction. (*), so when sum_then_double execute ret, it cannot trace back to its caller and will go to li t0, 2.\nGDB Skills Use layout src layout asm layout reg to open a tui window and display source code, assembly code or register values. Use layout split to display source code and assembly code at the same time. Use focus src/asm/reg to switch between different windows.\nUse i frame to display information of the current stack frame.\nUse backtrace/bt to display previous calling functions. Furthermore, use i frame #num to specify a stack frame to print.\nUse p [variable] to print values of variables. Notice that modern compilers have compiling optimization and some variables may be optimized out.\nIf x is a pointer variable, p *x can dereference the pointer and print the value.\nUse i args to print the arguments of the current function. p *argv can print the first argument. If you want to get a complete list of arguments, use p *argv@argc.\nWatchpoints are used to monitor variables and gdb stops running as soon as the values of the expressions of the watchpoints change.\nconditional breakpoint is very powerful. For example, if you want to set a breakpoint in a for-loop but only want to trigger it when i=5, use b ... if i==5.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6170064ea1c264a75ad25224b55b5756","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec05/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec05/","section":"notes","summary":"C $\\rightarrow$ ASM A C program\nint main () { ... exit(0); } cannot be directly understood by a processor. It should go through a \u0026ldquo;C -\u0026gt; Asm (.s files) -\u0026gt; binary (.","tags":null,"title":"MIT-6.S081 Lecture 05: RISC-V Calling Convention and Stack Frames","type":"docs"},{"authors":null,"categories":null,"content":" The apply Tactic The apply with Tactic The injection and discriminate Tactics Using Tactics on Hypotheses Varying the Induction Hypothesis Unfolding Definitions Using destruct on Compound Expressions Exercises (tbd) Exercise: 2 stars, standard, optional (silly_ex) Exercise: 2 stars, standard (apply_exercise1) Exercise: 3 stars, standard, optional (trans_eq_exercise) Exercise: 3 stars, standard (injection_ex3) Exercise: 1 star, standard (discriminate_ex3) Exercise: 2 stars, standard (eqb_true) Exercise: 3 stars, standard, especially useful (plus_n_n_injective) Exercise: 3 stars, standard, especially useful (gen_dep_practice) Exercise: 3 stars, standard (combine_split) Exercise: 2 stars, standard (destruct_eqn_practice) Exercise: 3 stars, standard (eqb_sym) Exercise: 3 stars, standard, optional (eqb_trans) The apply Tactic 我们在证明过程中经常遇到某个 goal 正好是假设/某个之前已经证明过的定理的情况。这时候写一步 rewrite 再写一步 reflexivity 显得略为繁琐，我们可以用 apply 这个 tactic 来一步到位：\nTheorem silly1 : forall n m : nat, n = m -\u0026gt; n = m. Proof. intros n m eq. apply eq. Qed. 当 apply 应用于一个蕴含式时，Coq 会把蕴含式的条件设置成一个新的 goal。如果 apply 后面跟的表达式中有全称量词，Coq 可以自动将其实例化：\nTheorem silly2a : forall (n m : nat), (n,n) = (m,m) -\u0026gt; (forall (q r : nat), (q,q) = (r,r) -\u0026gt; [q] = [r]) -\u0026gt; [n] = [m]. Proof. intros n m eq1 eq2. apply eq2. apply eq1. Qed. 在使用 apply 时，被 applied 的表达式必须和 goal 完全匹配，比如 n = m 和 m = n 就不算完全匹配。但这种情况我们可以通过 symmetry 这个 tactic 来调整等号左右的位置：\nTheorem silly3 : forall n m : nat, n = m -\u0026gt; m = n. Proof. intros n m H. symmetry. apply H. Qed. The apply with Tactic 考虑如下例子：假设我们已经有了这样一个引理：\nLemma trans_eq : forall (X : Type) (n m o : X), n = m -\u0026gt; m = o -\u0026gt; n = o. Proof. intros X n m o eq1 eq2. rewrite eq1. rewrite eq2. reflexivity. Qed. 现在我们希望证明如下命题：\nExample trans_eq_example : forall (a b c d e f : nat), [a;b] = [c;d] -\u0026gt; [c;d] = [e;f] -\u0026gt; [a;b] = [e;f]. 如果我们想要用 apply 直接使用之前的引理，Coq 会根据 goal 自动进行实例化，从而得到 X 是 list nat，n 是 [a;b]，o 是 [e;f]，但 apply 无法从 goal 推断出 m 应该取什么。所以我们要用 apply with tactic 显式地把 m 的值提供给 Coq：\nProof. intros a b c d e f eq1 eq2. apply trans_wq with (m:=[c;d]). apply eq1. apply eq2. Qed. 事实上我们可以省略 m，即直接写 apply trans_eq with [c;d].Coq 可以智能地判定我们提供的值是谁的。\n除此之外，Coq 有一个名叫 transtivity 的 tactic 专门负责做这项工作，所以实际上我们不需要证明 trans_eq 这个引理，直接用这个 tactic，同时显式地给出中间变量的取值即可：\nProof. intros a b c d e f eq1 eq2. transtivity [c;d]. apply eq1. apply eq2. Qed. The injection and discriminate Tactics 考虑自然数的定义：\nInductive nat : Type := | O | S (n : nat). 从这个定义中我们除了知道自然数唯二两种可能的形式，还可以看出两条性质：\nconstructor S 是 injective (one-to-one) 的，即若 S n = S m，则有 n = m。 O 和 S 这两个 constructor 是 disjoint 的，即对于任意 n，O 不等于 S n。 上面两条性质其实可以推广到任何归纳定义的类型上，即一个类型中所有的 constructor 都是 injective 的；不同的 constructor 产生的 value 不可能相等。\n我们先考虑前者，forall n m : nat, S n = S m -\u0026gt; n = m. 这个定理可以通过归纳法证明，事实上所有 constructor 的 injectivity 都可以通过类似的归纳法证明，因此 Coq 提供了 injection 这个 tactic。我们看一个使用 tactic 的例子 (注意：injection 只能用在 constructor 的 injectivity 上，不能用于一般的单射！)：\nTheorem injection_ex : forall (n m o : nat), [n;m] = [o;o] -\u0026gt; n = m. Proof. intros n m o H. injective H as H1 H2. rewrite H1. rewrite H2. reflexivity. Qed. injection H as H1 H2. 表示将 H 这个表达式中所有可以通过 injectivity 得到的结论全部做成当前上下文的 hypothesis，分别命名为 H1 H2。这里 H : [n;m] = [o;o]，完全展开就是 cons n (cons m nil) = cons o (cons o nil)。根据 injectivity 我们可以知道 n = o 和 cons m nil = cons o nil，再次利用 injectivity 可知 m = o，因此 Coq 的 injection 可以帮我们自动分析出两条结论。\n我们再来讨论后者。disjointness 告诉我们如果我们的 hypothesis 中出现了一个定义中的两个不同的 constructor 的 value 相等，那么就可以由条件假推出一切真，这也被称为 principle of explosion。在 Coq 中我们可以使用 discrimate 这个 tactic 来完成这件事，只要我们指定一个确定是错误的假设 (不一定是 disjointness 的这种，任何错误的表达式都可以)，就可以直接证完当前结论。下面是一个例子：\nTheorem discriminate_ex : forall (n : nat), S n = O -\u0026gt; 2 + 2 = 5. Proof. intros n contra. discriminate contra. Qed. injectivity 告诉我们 S n = S m -\u0026gt; n = m。这件事情反过来也是成立的，即如下定理：\nTheorem f_equal : forall (A B : Type) (f : A -\u0026gt; B) (x y : A), x = y -\u0026gt; f x = f y. 该定理用 rewrite 很好证。事实上 Coq 为我们提供了 f_equal 这个 tactic，我们不需要证明该定理就可以使用这个结论，下面是一个例子：\nTheorem eq_implies_succ_equal : forall (n m : nat), n = m -\u0026gt; S n = S m. Proof. intros n m H. f_equal. apply H. Qed. 如果当前的 goal 形如 f a1 a2 ... an = g b1 b2 ... bn，则 f_goal 会自动将其转化为 f = g a1 = b1 \u0026hellip; an = bn 这些 subgoal，如果其中有 trivial 的 (比如两个函数相同，对应位置的两个参数相同) f_equal 还会自动过滤到它们。\nUsing Tactics on Hypotheses 默认情况下，大部分的 tactic 都是在保持 context 不变的情况下针对 goal 进行的。事实上 Coq 提供了 \u0026ldquo;in\u0026rdquo; 的语法，可以让 tactic 作用在 context 中的 hypothesis 上，例如 simpl：\nTheorem S_inj : forall (n m : nat) (b : bool), ((S n) =? (S m)) = b -\u0026gt; (n =? m) = b. Proof. intros n m b H. simpl in H. apply H. Qed. 再比如 symmetry 和 apply：\nTheorem silly4 : forall (n m p q : nat), (n = m -\u0026gt; p = q) -\u0026gt; m = n -\u0026gt; q = p. Proof. intros n m p q EQ H. symmetry in H. apply EQ in H. symmetry in H. apply H. Qed. 值得注意的是 apply 和 apply in 的区别：\napply in 采用的是 forward reasoning，即 apply L in H 的功能是：如果 L 是蕴含式 X -\u0026gt; Y，H 是 X，则我们可以转而去证明 Y。 apply 采用的是 backward reasoning，即 apply H 的功能是：如果 H 是蕴含式 X -\u0026gt; Y，当前的结论是 Y，则我们只要能证明 X 就足已完成证明。 人类的 informal proof 倾向于 forward reasoning，但 Coq 等证明工具通常更多采用 backward reasoning。\nVarying the Induction Hypothesis 该章节介绍了两段具有一定技巧性的证明。有时候，不管三七二十一把所有的变量和假设全部都 intros 了反而会使证明卡住。考虑如下证明 double() 是单射的定理：\nTheorem double_injective : forall n m, double n = double m -\u0026gt; n = m. 如果我们先把 n m 都 intros 了再对 n 进行归纳，则会得到\nProof. intros n m. induction n as [| n' IHn']. - (* n = 0 *) simpl. intros eq. destruct m as [| m'] eqn:E. + reflexivity. + discriminate eq. - (* n = S n' *) intros eq. destruct m as [| m'] eqn:E. + discriminate eq. + apply f_equal. Abort. (注：两次 discriminate 的等式 eq 均为 double (S n') = double 0。这里可以根据 disjointment 直接 pass 的原因是我们可以根据 double 的定义将式子化简为 S (S (double n')) = 0，在自然数的两个 constructor 下触发 disjointment。)\n在 successor case 中 m = S m' 的情况下，我们需要证明 n' = m'，而我们的归纳假设是 double n' = double (S m') -\u0026gt; n' = S m'，这和我们要证明的结论没什么联系，从而证明卡住。出现这个问题的原因是：在归纳假设和归纳目标的式子中我们的 m 需要取到不同的值，但我们在开始归纳之前过早地 intros m 导致 m 只能是一个具体的值。正确的证明过程应当先对 n 进行归纳，保证归纳假设中是 forall m 而不是一个具体的 m，这样在 successor case 时我们就可以让归纳假设中的 m 实例化为具体需要的变量，从而完成证明。\nTheorem double_injective : forall n m, double n = double m -\u0026gt; n = m. Proof. intros n. induction n as [| n' IHn']. - (* n = 0 *) simpl. intros m eq. destruct m as [| m'] eqn:E. + reflexivity. + discriminate eq. - intros m eq. destruct m as [| m'] eqn:E. + discriminate eq. + apply f_equal. apply IHn' (* IHn'中是forall m，apply，可以完成关键的实例化 *) simpl in eq. injection eq as goal. apply goal. Qed. 刚才的例子展示了 fewer intros 的技巧，但有的时候我们发现我们不得不对全称量词中的变量顺序进行调换。比如刚才的定理，如果我们想对 m 进行归纳就会遇到一些困难：\nProof. intros m. induction m as [| m' IHm']. 我们会发现 intros m. 时变量 n 也被实例化了，因为在 forall 中 n 出现在 m 前面。在不修改定理描述的前提下，我们可以使用 generalize dependent 这个 tactic 来将某个变量“去实例化”：\nProof. intros n m. generalize dependent n. ... 执行完 generalize dependent n 后，变量 n 又会回到 forall 中。\nUnfolding Definitions 有的时候我们需要手动将某个函数的定义展开，从而将证明推进下去。比如我们定义了平方函数：\nDefinition square n := n * n. 并且试图证明定理\nLemma square_mult : forall n m, square (n * m) = (square n) * (square m) Proof. intros n m. simpl. (* get stuck! *) simpl. 并不能帮助我们化简。这时候我们可以使用 unfold square 把定义展开，这样再使用乘法的交换律、结合律就可以完成证明。\n这里我们把 unfold 和 simpl reflexivity 的定义展开功能做一个对比。simpl 和 reflexivity 也有一定的定义展开功能，但不是很强。例如：\nDefinition foo (x : nat) := 5. Fact silly_fact_1 : forall m, foo m + 1 = foo (m + 1) + 1. Proof. intros m. reflexivity. Qed. reflexivity 可以帮我们自动把 foo 这个常值函数展开，直接完成证明。但如果函数的结构稍微复杂一点 simpl 和 reflexivity 就无能为力了：\nDefinition bar x := match x with | O =\u0026gt; 5 | S _ =\u0026gt; 5 end. Fact silly_fact_2_FAILED : forall m, bar m + 1 = bar (m + 1) + 1. Proof. intros m. simpl. Abort. 虽然我们人眼可以看出来不管自然数 x 走哪个分支 bar x 的结果都是 5，但 Coq 没有这么强的分析能力。这种情况我们只能老老实实对着 x 做 destruct。\nUsing destruct on Compound Expressions 在 Coq 中，destruct 的对象可以是任意的表达式，只要该表达式的结果是归纳定义的，destruct 就会对其每种 constructor 分类讨论。\n另外值得注意的一点是：当我们对一个表达式做 destruct 时，通常 eqn 是必不可少的，因为表达式的取值应当作为 context 的一部分参与证明，如果只是让 Coq 做纯代入，我们可能会丢失必要的信息。\nExercises (tbd) Exercise: 2 stars, standard, optional (silly_ex) Theorem silly_ex : forall p, (forall n, even n = true -\u0026gt; even (S n) = false) -\u0026gt; (forall n, even n = false -\u0026gt; odd n = true) -\u0026gt; even p = true -\u0026gt; odd (S p) = true. Proof. intros p H1 H2 H3. apply H2. apply H1. apply H3. Qed. Exercise: 2 stars, standard (apply_exercise1) Theorem rev_exercise1 : forall (l l' : list nat), l = rev l' -\u0026gt; l' = rev l. Proof. intros l l' H. replace l' with (rev (rev l')). - rewrite H. reflexivity. - apply rev_involutive. Qed. Exercise: 3 stars, standard, optional (trans_eq_exercise) Example trans_eq_exercise : forall (n m o p : nat), m = (minustwo o) -\u0026gt; (n + p) = m -\u0026gt; (n + p) = (minustwo o). Proof. intros n m o p eq1 eq2. transitivity m. apply eq2. apply eq1. Qed. Exercise: 3 stars, standard (injection_ex3) Example injection_ex3 : forall (X : Type) (x y z : X) (l j : list X), x :: y :: l = z :: j -\u0026gt; j = z :: l -\u0026gt; x = y. Proof. intros X x y z l j H1. injection H1 as eq1. rewrite \u0026lt;- H. intros H2. injection H2 as eq2. rewrite eq1. rewrite eq2. reflexivity. Qed. Exercise: 1 star, standard (discriminate_ex3) Example discriminate_ex3 : forall (X : Type) (x y z : X) (l j : list X), x :: y :: l = [] -\u0026gt; x = z. Proof. intros X x y z l eq1 eq2. discriminate eq2. Qed. (注：不知为何 Coq 自动把 goal 修改为了 list X -\u0026gt; ... -\u0026gt; x = z，导致多了一个条件。)\nExercise: 2 stars, standard (eqb_true) Theorem eqb_true : forall n m, n =? m = true -\u0026gt; n = m. Proof. intros n. induction n as [| n' IHn']. - destruct m as [| m'] eqn:E. + reflexivity. + discriminate. - destruct m as [| m'] eqn:E. + discriminate. + intros H. apply IHn' in H. apply f_equal. apply H. Qed. Exercise: 3 stars, standard, especially useful (plus_n_n_injective) Theorem plus_n_n_injective : forall n m, n + n = m + m -\u0026gt; n = m. Proof. intros n. induction n as [| n' IHn']. - destruct m as [| m'] eqn:E. + reflexivity. + discriminate. - destruct m as [| m'] eqn:E. + discriminate. + intros H. simpl in H. injection H as H'. rewrite \u0026lt;- plus_n_Sm in H'. rewrite \u0026lt;- plus_n_Sm in H'. injection H' as H''. apply IHn' in H''. apply f_equal. apply H''. Qed. Exercise: 3 stars, standard, especially useful (gen_dep_practice) Theorem nth_error_after_last: forall (n : nat) (X : Type) (l : list X), length l = n -\u0026gt; nth_error l n = None. Proof. intros n X l. generalize dependent n. induction l as [| h l' IHl']. - reflexivity. - destruct n as [| n'] eqn:E. + discriminate. + simpl. intros H. apply IHl'. injection H as goal. apply goal. Qed. Exercise: 3 stars, standard (combine_split) Theorem combine_split : forall X Y (l : list (X * Y)) l1 l2, split l = (l1, l2) -\u0026gt; combine l1 l2 = l. Proof. intros X Y l. induction l as [| (x, y) l' IHl']. - simpl. intros l1 l2 H. injection H as H1 H2. rewrite \u0026lt;- H1. rewrite \u0026lt;- H2. reflexivity. - intros l1 l2 H. simpl in H. destruct (split l') as [lx ly]. destruct l1 as [| h1 l1']. + discriminate. + destruct l2 as [| h2 l2']. * discriminate. * simpl. injection H as eq1 eq2 eq3 eq4. rewrite eq1. rewrite eq3. apply f_equal. apply IHl'. rewrite eq2. rewrite eq4. reflexivity. Qed. Exercise: 2 stars, standard (destruct_eqn_practice) Theorem bool_fn_applied_thrice : forall (f : bool -\u0026gt; bool) (b : bool), f (f (f b)) = f b. Proof. intros f b. destruct b. - destruct (f true) eqn:ft. + rewrite ft. apply ft. + destruct (f false) eqn:ff. * apply ft. * apply ff. - destruct (f false) eqn:ff. + destruct (f true) eqn:ft. * apply ft. * apply ff. + rewrite ff. apply ff. Qed. Exercise: 3 stars, standard (eqb_sym) Theorem eqb_sym : forall (n m : nat), (n =? m) = (m =? n). Proof. intros n. induction n as [| n' IHn']. - destruct m as [| m']. + reflexivity. + reflexivity. - intros m. destruct m as [| m']. + reflexivity. + simpl. apply IHn'. Qed. Exercise: 3 stars, standard, optional (eqb_trans) Theorem eqb_trans : forall n m p, n =? m = true -\u0026gt; m =? p = true -\u0026gt; n =? p = true. Proof. intros n m p H1 H2. generalize dependent n. generalize dependent p. induction m as [| m' IHm']. - destruct n as [| n']. + destruct p as [| p']. * reflexivity. * discriminate. + discriminate. - intros n Hn p Hp. destruct n as [| n']. + discriminate. + destruct p as [| p']. * discriminate. * simpl. rewrite eqb_sym. simpl in Hn. rewrite eqb_sym in Hn. simpl in Hp. rewrite eqb_sym in Hp. apply IHm'. apply Hp. apply Hn. Qed. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c41f037f89413dd46e66345f47fbf3b6","permalink":"https://kristoff-starling.github.io/notes/booknotes/softwarefoundations/lf/tactics/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/booknotes/softwarefoundations/lf/tactics/","section":"notes","summary":"The apply Tactic The apply with Tactic The injection and discriminate Tactics Using Tactics on Hypotheses Varying the Induction Hypothesis Unfolding Definitions Using destruct on Compound Expressions Exercises (tbd) Exercise: 2 stars, standard, optional (silly_ex) Exercise: 2 stars, standard (apply_exercise1) Exercise: 3 stars, standard, optional (trans_eq_exercise) Exercise: 3 stars, standard (injection_ex3) Exercise: 1 star, standard (discriminate_ex3) Exercise: 2 stars, standard (eqb_true) Exercise: 3 stars, standard, especially useful (plus_n_n_injective) Exercise: 3 stars, standard, especially useful (gen_dep_practice) Exercise: 3 stars, standard (combine_split) Exercise: 2 stars, standard (destruct_eqn_practice) Exercise: 3 stars, standard (eqb_sym) Exercise: 3 stars, standard, optional (eqb_trans) The apply Tactic 我们在证明过程中经常遇到某个 goal 正好是假设/某个之前已经证明过的定理的情况。这时候写一步 rewrite 再写一步 reflexivity 显得略为繁琐，我们可以用 apply 这个 tactic 来一步到位：","tags":null,"title":"More Basic Tactics","type":"docs"},{"authors":null,"categories":null,"content":"Environments 刚开始有一个 global frame，每发生一次函数调用，就会随之生成一个 local frame。 每个用户定义的 function 都有一个 parent frame。一个函数的 parent 指的是函数定义所在的 frame。 每个 frame 也有一个 parent frame，一个 frame 的 parent 指的是生成这个 frame 的函数的 parent。 environment 指的是一串 frame 序列。 Environment Diagram 当一个函数被定义时：\n创建一个 function value：func \u0026lt;name\u0026gt;(\u0026lt;formal parameters\u0026gt;) [parent=\u0026lt;label\u0026gt;]，这里的 parent 就是当前的 frame。 当前 frame 中的 \u0026lt;name\u0026gt; 指向创建的 function value。 当一个函数被调用时：\n添加一个 local frame，frame 的名字是被调用的函数的名字，frame 的 parent 是被调用的函数的 parent。 \u0026lt;formal parameters\u0026gt; 指向传入的参数。 Self-Reference 高阶函数可以拿自己作为返回值，例如\ndef print_sums(n): print(n) def next_sum(k): return print_sums(n + k) return next_sum 调用 print_sums(1)(3)(5) 后会打印出 1\\n 4\\n 9\\n，且最后的返回值仍然是一个 next_sum() 函数。\nFunction Currying Currying 指的是将接收多个参数的函数转化为只接收一个参数的高阶函数。例如我们可以实现一个这样的函数：\ndef curry(f): def g(x): def h(y): return f(x, y) return h return g 或者用 lambda 表达式：\ncurry = lambda f: lambda x: lambda y: f(x, y) 调用 curry(add)(2, 3) 和调用 add(2, 3) 的效果一样。利用 Currying 创建一些中间状态的辅助函数可以减少重复传参。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"61d134ff6d8902cedf634b4151a14ce0","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec05/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec05/","section":"notes","summary":"Environments 刚开始有一个 global frame，每发生一次函数调用，就会随之生成一个 local frame。 每个用户定义的 function 都有一个 parent frame。一个函数的 parent 指的是函数定义所在的 frame。 每个 frame 也有一个 parent frame，一个 frame 的 parent 指的是生成这个 frame 的函数的 parent。 environment 指的是一串 frame 序列。 Environment Diagram 当一个函数被定义时：","tags":null,"title":"UCB-CS61A Lecture 05: Environments","type":"docs"},{"authors":null,"categories":null,"content":"没有值的特别注意的题目。递归地使用 generator function 是一个难点，但只要掌握了普通就可以进行类比。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5122a7ba78d32e8de9438cc725d27a34","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/homework/hw05/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/homework/hw05/","section":"notes","summary":"没有值的特别注意的题目。递归地使用 generator function 是一个难点，但只要掌握了普通就可以进行类比。","tags":null,"title":"UCB-CS61A Homework 05: Iterators and Generators","type":"docs"},{"authors":null,"categories":null,"content":"Introduction When going into traps, we need to carefully change the hardware state so that isolation will not be broken. The hardware state of RISC-V machine includes:\n32 general registers\nWe keep a copy of general registers because we want to resume the user code later transparently, particularly when it\u0026rsquo;s a unexpected device interrupt.\nPC\nMode: we need to switch to supervisor mode.\nSupervisor mode has the following privileges:\nread/write control registers use PTEs without PTE_U sign. Page table (satp): page table currently points to the user page table, which only contains user\u0026rsquo;s code and data. To run kernel code, we need to switch to kernel page table.\nstvec\nsepc\nsscratch\nThere are some high-level principles of trap design:\nWe cannot count on anything in the user space. We can\u0026rsquo;t assume anything about the registers since they are likely to contain malicious values. In xv6, the trap handler just saves them. We want to be transparent to the user code. The high-level procedure of a system call Shell $\\rightarrow$ write() $\\overset{ecall}{\\rightarrow}$ uservec (asm) $\\rightarrow$ usertrap() $\\rightarrow$ syscall() $\\rightarrow$ sys_write() $\\rightarrow$ syscall() $\\rightarrow$ usertrapret() $\\rightarrow$ userret (asm) $\\rightarrow$ the next instruction of ecall.\nSystem call is quite expensive. So can we return some address mappings instead of a file descriptor in open() , so that the user program can directly write to the memory without using system calls?\nYes. Modern operating systems support this mechanism and it\u0026rsquo;s called memory mapped file access. It makes read/write much faster compared with the file descriptor method.\nCode: write() system call Preliminaries The shell program uses write() system call to print a $ to the console.\nstatic void putc(int fd, char c) { write(fd, \u0026amp;c, 1); } write() function is defined in usys.asm\nwrite: li a7, SYS_write ecall ret It loads the system call number \u0026ldquo;SYS_write\u0026rdquo; into register a7. a0 a1 a2 stores the arguments of the system call. In GDB, we can use x/2c $a1 to print the argument strings.\nGDB Tips\nUse b *addr to set a breakpoint at a specific address. This method is useful when we want to set breakpoints at particular instructions.\nBefore switching to kernel, we are using the user page table. We cannot print the page table in GDB, but luckily, QEMU provides functions to print the current page table. Type \u0026lt;c-a\u0026gt; c to get into the QEMU monitor, and type info mem to print the page table:\nvaddr paddr size attr ---------------- ---------------- ---------------- ------- 0000000000000000 0000000087f60000 0000000000001000 rwxu-a- 0000000000001000 0000000087f5d000 0000000000001000 rwxu-a- 0000000000002000 0000000087f5c000 0000000000001000 rwx---- 0000000000003000 0000000087f5b000 0000000000001000 rwxu-ad 0000003fffffe000 0000000087f6f000 0000000000001000 rw---ad 0000003ffffff000 0000000080007000 0000000000001000 r-x--a- The last column shows the privilege flags of PTEs. The first and second PTEs are code and data page of the shell program. The third page, which doesn\u0026rsquo;t have the PTE_U flag, is the guard page below the stack page. The fourth page is the stack page. The last two pages, which have high virtual addresses, are the trap frame and the trampoline page. Those pages also don\u0026rsquo;t have PTE_U flag and can only be accessed by the kernel.\nPTE\u0026rsquo;s PTE_A \u0026amp; PTE_D flags\nxv6 doesn\u0026rsquo;t use these flags. These flags are used for page exchanges when there\u0026rsquo;s a page fault and the physical memory pages are used out.\nTrampoline We\u0026rsquo;re now ready for executing ecall. After executing ecall, our PC register goes to the trampoline page: 0x3fffff000. ecall doesn\u0026rsquo;t switch the page table, which means that the trampoline page must be mapped in the user page table. Although user page table contains this mapping, the corresponding PTE doesn\u0026rsquo;t have PTE_U flag so this page is protected against user code.\necall actually does 3 things:\nSwitch from user mode to supervisor mode. Save the value of PC into sepc. Jump to the address held in stvec register. ecall only does the minimum things. Some hardware does more when triggering a system call: they save the registers, switch the page table and set the stack pointer. RISC-V doesn\u0026rsquo;t choose to include those parts into the hardware because it wants the software to achieve the maximum flexibility. For example:\nIn some system calls the kernel can finish jobs without the help of kernel page table. Also, some operating systems combine the user page table and kernel page table together, which means they don\u0026rsquo;t need to change the page table during system calls. According to the specific function, some system calls won\u0026rsquo;t use all the general registers and some registers\u0026rsquo; values don\u0026rsquo;t need to be saved. Some easy system call may not require a kernel stack. Stack switching is not necessary. Although xv6 doesn\u0026rsquo;t utilize those freedom, modern operating systems care a lot about the performance. There are a lot of sophisticated, clever schemes that make full use of the flexibility and achieve better efficiency.\nIf we check the general registers\u0026rsquo; values, we\u0026rsquo;ll find that they are the same as those in the user space. Currently we cannot modify any register, otherwise the user data would be damaged. We should firstly store them somewhere and restore them before returning.\nSome hardware may switch to the kernel page table and store the 32 values somewhere in a physical page. But now we even don\u0026rsquo;t know the address of the kernel page table! xv6\u0026rsquo;s solution for saving registers includes two parts:\nUse a trap frame. User page table contains the mapping of this per-process trap frame. The trap frame contains 32 slots for register values, and some other useful values such as the address of kernel page table. The (virtual) address of the trap frame is beforehand stored in sscratch register. xv6 utilize csrrw instruction to atomically swap the values in a0 and sscratch. So sscratch temporarily stores the old value of a0 and a0 contains the address of the trap frame. We now can use sd instruction to save register values in the slots. Q: Where does the kernel set the value of sscratch register?\nThe function usertrapret() in /kernel/trap.c sets control registers including stvec, sscratch etc.\nw_stvec(TRAMPOLINE + (uservec - trampoline)); p-\u0026gt;trapframe-\u0026gt;kernel_satp = r_satp(); // kernel page table p-\u0026gt;trapframe-\u0026gt;kernel_sp = p-\u0026gt;kstack + PGSIZE; // process's kernel stack p-\u0026gt;trapframe-\u0026gt;kernel_trap = (uint64)usertrap; p-\u0026gt;trapframe-\u0026gt;kernel_hartid = r_tp(); // hartid for cpuid() unsigned long x = r_sstatus(); x \u0026amp;= ~SSTATUS_SPP; // clear SPP to 0 for user mode x |= SSTATUS_SPIE; // enable interrupts in user mode w_sstatus(x); w_sepc(p-\u0026gt;trapframe-\u0026gt;epc); uint64 satp = MAKE_SATP(p-\u0026gt;pagetable); uint64 fn = TRAMPOLINE + (userret - trampoline); ((void (*)(uint64,uint64))fn)(TRAPFRAME, satp); The last line calls userret() and transmits two arguments including the address of TRAPFRAME, in userrret(), TRAPFRAME is stored into sscratch register.\nQ: Every time after ecall, we have a chance to execute usertrapret() and set the correct value in sscratch, but how do we set it correctly before the first execution?\nWhen xv6 is booting, it firstly goes into the supervisor mode. So the kernel also use usertrapret() to start executing a user program. usertrapret() is the only way xv6 provides to enter into the user program from the kernel.\nQ: Why should we use a particular trap frame instead of saving the values on the user stack?\nNot all the program languages have the same stack structure. Some program languages don\u0026rsquo;t have a stack, and some languages organize stack space in a weird way that kernel cannot understand (e.g. by allocating memory blocks). The principle for trap design is that the kernel cannot count on anything from the user space. The safest way for kernel is to save the values in the trap frame - a frame that belongs to the kernel and is reliable.\n(Author\u0026rsquo;s question: can we use a control register in RISC-V to store the address of kernel stack and save the register values on the kernel stack? In this way we don\u0026rsquo;t need an additional trap frame?)\nAfter saving registers, the kernel use ld sp, 8(a0) to load the address of kernel stack into the sp register. If we type print/x $sp in GDB, we\u0026rsquo;ll see that sp = 0x3fffffc000. Recalling the structure of kernel space mappings, the address is reasonable - just below the trap frame, there\u0026rsquo;s a guard page and the first kernel stack.\nNext, the hart id is stored into tp register. The address of the function to be jumped to (usertrap()) is stored into t0 register. csrw satp, t1 switches to the kernel page table.\nQ: Why doesn\u0026rsquo;t the kernel crash since we keep using user\u0026rsquo;s virtual addresses?\nThat\u0026rsquo;s because we\u0026rsquo;re executing in the trampoline page. The kernel and user page tables both have mappings to the trampoline page. (The same virtual address) The page is named \u0026ldquo;trampoline\u0026rdquo; because xv6 bounces on this page between user code and kernel code.\nAn important thing to remember is that: page table switching can only be implemented in the trampoline because the virtual address in this page maps to the same physical page in kernel and user page tables. Otherwise, the instruction addresses could not be interpreted and the kernel would crash.\nusertrap() After executing jr t0, we jump to the C-code function usertrap(). The first thing we do is\nw_stvec((uint64)kernelvec) which overwrites the stvec register. Xv6 handles traps differently depending on whether they come from user space or the kernel.\nstruct proc *p = myproc(); p-\u0026gt;trapframe-\u0026gt;epc = r_sepc(); These lines save the value of sepc into the trap frame. It\u0026rsquo;s necessary because the kernel may switch to another process. After returning to the user space of that process, the user program may do another system call, and the sepc register will be overwritten. (Note: it\u0026rsquo;s also correct to save sepc in the trampoline assembly code.)\nHere we\u0026rsquo;re doing write() system call, so the value in scause register is 8. We firstly add 4 to the sepc value in the trap frame in order not to re-execute the ecall instruction. Then we call intr_on() to accept interrupts. Interrupts are always turned off by the RISC-V trap hardware, so we need to explicitly open it in the code.\nXv6 enters syscall() in /kernel/syscall.c to handle system calls. In syscall(), xv6 retrieves the value in the a7 register (context in trap frame) to acquire the system call number and uses that to index the syscalls[] function array. After returning from sys_write(), the return value is stored in p-\u0026gt;trapframe-\u0026gt;a0.\nusertrapret()/userret() After handling the system call, xv6 enters usertrapret(). The job for usertrapret() is to set control registers to appropriate states for user mode. At the end, it calls userret() in /kernel/trampoline.S to resume registers. Refer to code details in \u0026ldquo;Xv6 Source Code Manual\u0026rdquo;.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"682bf0eb463ce76984d0a01ac772fcb6","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec06/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec06/","section":"notes","summary":"Introduction When going into traps, we need to carefully change the hardware state so that isolation will not be broken. The hardware state of RISC-V machine includes:\n32 general registers","tags":null,"title":"MIT-6.S081 Lecture 06: Traps","type":"docs"},{"authors":null,"categories":null,"content":"The Q\u0026amp;A focuses on lab pgtbl. The lab contain few lines of code, but hard-to-debug problems. Harsh environment of kernel programming makes it more difficult.\nTask 01 page table 0x0000000087f6e000 ..0: pte 0x0000000021fda801 pa 0x0000000087f6a000 .. ..0: pte 0x0000000021fda401 pa 0x0000000087f69000 .. .. ..0: pte 0x0000000021fdac1f pa 0x0000000087f6b000 .. .. ..1: pte 0x0000000021fda00f pa 0x0000000087f68000 .. .. ..2: pte 0x0000000021fd9c1f pa 0x0000000087f67000 ..255: pte 0x0000000021fdb401 pa 0x0000000087f6d000 .. ..511: pte 0x0000000021fdb001 pa 0x0000000087f6c000 .. .. ..510: pte 0x0000000021fdd807 pa 0x0000000087f76000 .. .. ..511: pte 0x0000000020001c0b pa 0x0000000080007000 0-0-0: text and data of the init program. 0-0-1: the guard page (of the user stack) 0-0-2: user stack (tighter privilege can be set: PTE_X flags can be erased, the user stack is not supposed to store instructions.) 255-511-510: trap frame 255-511-511: trampoline One interesting fact is that: the physical pages allocated to the continuous virtual pages are not continuous. That\u0026rsquo;s the magic of virtual memory.\nQ: The trampoline page is at the highest virtual memory address MAXVA, why the first page directory\u0026rsquo;s index is 255 instead of 511?\nRISC-V Sv39 support 39 bits virtual address, but xv6 only uses 38 bits to avoid dealing with sign extension. Therefore, the first page directory\u0026rsquo;s index is only up to 255.\nQ: Why the text page and data page are merged into one page in init?\nGenerally, separate text page and data page can support more careful privilege settings. But in init program, we don\u0026rsquo;t use the exec() system call to load memory image, for simplicity of code in userinit() function, we combine text and data into one page.\nTask 02 One possible approach is to just copy the mappings in the kernel page tables that keep unchanged.\npagetable_t kvmcreate() { pagetable_t pagetable; int i; pagetable = uvmcreate(); for (i = 1; i \u0026lt; 512; i ++) pagetable[i] = kernel_pagetable[i]; kvmmapkern(pagetable, UART0, UART0, PGSIZE, PTE_R | PTE_W); kvmmapkern(pagetable, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W); kvmmapkern(pagetable, CLINT, CLINT, 0x10000, PTE_R | PTE_W); kvmmapkern(pagetable, PLIC, PLIC, 0x400000, PTE_R | PTE_W); return pagetable; } For the creation of a user kernel page table, we\u0026rsquo;re sure that later we only use the range [0, PLIC) for user memory, so only the first page directory entry may change. We can directly copy the kernel\u0026rsquo;s first level page directory of range [1,512) . Don\u0026rsquo;t forget to map several I/O devices in the first page directory entry.\nvoid kvmfree(pagetable_t kpagetable, uint64 sz) { pte_t pte = kpagetable[0]; pagetable_t level1 = (pagetable_t) PTE2PA(pte); for (int i = 0; i \u0026lt; 512; i ++) { pte_t pte = level1[i]; if (pte \u0026amp; PTE_V) { uint64 level2 = PTE2PA(pte); kfree((void *)level2); level1[i] = 0; } } kfree((void *) level1); kfree((void *) kpagetable); } To free the user page table, we don\u0026rsquo;t need to do anything about the 1~511 page directory entries since they\u0026rsquo;re just copied from the kernel page table. We need to walk through the first page directory entry to free the remaining pages. (Notice: kvmfree() is only responsible for freeing page table pages, the leaf physical pages for user memory should be beforehand freed.)\nIn the function scheduler(), we should switch to user kernel page table before swtch() and switch to kernel page table after swtch():\nkvmswitch(p-\u0026gt;kpagetable); swtch(\u0026amp;c-\u0026gt;context, \u0026amp;p-\u0026gt;context); kvminithart(); Q: Why must we switch back to the kernel page table after going back?\nIf there\u0026rsquo;s no running process, the kernel should have an page table to use. Also, if we want to free a process, we must firstly switch back to the kernel page table before the process \u0026ldquo;disappears\u0026rdquo;.\nTask 03 The advantages of adding user mappings into user kernel page table include:\nduring copyin()/copyout(), we don\u0026rsquo;t need to call walk() in the kernel to translate the user virtual address since now hardware can do the same thing for us, which is a relief to kernel programmers. performance is enhanced since we do less page table walks. kernel has more freedom to manipulate with user space. it can directly read/write data without repeatedly calling copyin()/copyout(). The core function should be responsible for copying mappings from user page table to user kernel page table:\nvoid kvmmapuser(int pid, pagetable_t kpagetable, pagetable_t upagetable, uint64 newsz, uint64 oldsz) { uint64 va; pte_t *upte; pte_t *kpte; if (newsz \u0026gt;= PLIC) panic(\u0026quot;kvmmapuser: news too large\u0026quot;); for (va = oldsz; va \u0026lt; newsz; va += PGSIZE) { upte = walk(upagetabe, va, 0); if (upte == 0) panic(\u0026quot;kvmmapuser: no upte\u0026quot;); if ((*upte \u0026amp; PTE_V) == 0) panic(\u0026quot;kvmmapuser: no valid upte\u0026quot;); kpte = walk(kpagetable, va, 1); if (kpte == 0) panic(\u0026quot;kvmmapuser: no kpte\u0026quot;); *kpte = *upte; *kpte \u0026amp;= ~(PTE_U|PTE_W|PTE_X); } } The line *kpte = *upte means that user physical pages are shared between user space and kernel space although the kernel allocates new pages for page directories/tables.\nThe PTE_U bit is cleared because in RISC-V hardware, kernel doesn\u0026rsquo;t have the privilege to read/write pages with PTE_U flag. The reason for this mechanism is not isolation, but convenience for kernel debugging. Xv6 without modification should never write/execute user memory.\nQ: Currently we require that the user memory space cannot exceed PLIC. What if we want to use all the space below KERNBASE?\nWe can remap the I/O devices: CLINT, PLIC, UART0 etc. Actually there is still much space between PHYSTOP and the kernel stacks. Put I/O devices there in the kernel\u0026rsquo;s virtual address space and map them to low physical addresses. In this case, low virtual addresses are available for user memory.\nQ: Why should we put the kernel stacks high in the virtual address space?\nBelow every kernel stack there is a guard page, which is not mapped to any physical page, in order of detecting stack overflow issue. If the guard pages are put in the range of [KERNBASE, PHYSTOP), physical pages will be wasted.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5c3d5c835c68bbe43d7721642e9ee5b6","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec07/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec07/","section":"notes","summary":"The Q\u0026amp;A focuses on lab pgtbl. The lab contain few lines of code, but hard-to-debug problems. Harsh environment of kernel programming makes it more difficult.\nTask 01 page table 0x0000000087f6e000 .","tags":null,"title":"MIT-6.S081 Lecture 07: Q\u0026A for Labs #1","type":"docs"},{"authors":null,"categories":null,"content":"Decorators 考虑如下的高阶函数 trace() ：\ndef square(x): return x * x def trace(f): def traced(x): print(f'arg: {x}') r = f(x) print(f'return: {r}') return r return traced 当我们调用 trace(square) 时，我们就会获得一个函数，这个函数的功能和 square() 是一样的，但传入的参数和返回值会被打印出来。\n如果我们想要每次调用 square() 时都使用这个 traced 的版本，每次都写 trace(square) 有点太麻烦了。这时我们可以使用装饰器 (decorator)：\n@trace def square(x): return x * x 这样调用 square() 时就会自动 trace 参数和返回值。装饰器的原理是：如下的代码\n@ATTR def func(...): ... 等价于\ndef func(...): ... func = ATTR(func) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"326c345390890dbb85f3f045c55f4a27","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec07/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec07/","section":"notes","summary":"Decorators 考虑如下的高阶函数 trace() ：\ndef square(x): return x * x def trace(f): def traced(x): print(f'arg: {x}') r = f(x) print(f'return: {r}') return r return traced 当我们调用 trace(square) 时，我们就会获得一个函数，这个函数的功能和 square() 是一样的，但传入的参数和返回值会被打印出来。","tags":null,"title":"UCB-CS61A Lecture 07: Function Examples","type":"docs"},{"authors":null,"categories":null,"content":"The benefits of virtual memory, besides offering isolation, include levels of indirection. We have already seen some interesting usage of mappings, such as trampoline page and guard page, but these mappings are relatively static. With the aid of page faults, the mappings become dynamic: when page faults occur, the kernel can change page table mappings. Combination of page table and page fault provides enormous amount of flexibility.\nThe kernel needs necessary information to handle with page faults:\nThe faulting virtual address: RISC-V hardware stores it in the stval register.\nThe type of page faults, including instruction page fault, load page fault and store page fault. RISC-V manual specifies each type\u0026rsquo;s scause number:\npage fault type scause number instruction page fault 12 load page fault 13 store page fault 15 the va of instruction that causes the exception. The PC value is stored in sepc register and transferred into the trap frame.\nLazy allocation Xv6 provides sbrk() system call for user program to grow or shrink its heap size. Xv6 uses \u0026ldquo;eager allocation\u0026rdquo; for sbrk(), i.e. it immediately allocates physical memory for the applications. However, it\u0026rsquo;s difficult for applications to estimate the amount of heap space, so they usually ask for more pages than they need. Using page faults, kernel can respond to the system call in a more intelligent manner.\nIn lazy allocation, when sbrk() is called, we only increase p-\u0026gt;sz by n, not allocating any physical pages. When the user program load/store a virtual address later in the heap, page fault exception is triggered. The kernel checks the faulting va in stval register: if p-\u0026gt;stack \u0026lt; faulting va \u0026lt; p-\u0026gt;sz, we call kalloc() to allocate physical page, update the user page table, and re-execute the instruction.\nHere\u0026rsquo;s a simple version of code implementation:\nIn sys_sbrk(), we don\u0026rsquo;t need to call growproc() to allocate physical pages, the only thing we need to do is to modify p-\u0026gt;sz:\nuint64 sys_sbrk(void) { int addr; int n; if(argint(0, \u0026amp;n) \u0026lt; 0) return -1; addr = myproc()-\u0026gt;sz; + p-\u0026gt;sz = p-\u0026gt;sz + n; - if(growproc(n) \u0026lt; 0) - return -1; return addr; } Currently, if we boot xv6 and execute shell instruction echo hello, we\u0026rsquo;ll get a kernel panic:\nusertrap(): unexpected scause 0x000000000000000f pid=3 sepc = 0x00000000000012a4 stval=0x0000000000004008 The instruction at 0x12a4 is a store instruction, so the value in scause is 0xf. User program shell has 4 pages and the faulting va stored in stval register is just above the stack and belongs to the heap area.\nWe need to modify the kernel to let xv6 handle with the page fault instead of directly triggering panic:\nvoid usertrap(void) { ... if(r_scause() == 8){ // system call ... } else if((which_dev = devintr()) != 0){ // ok + } else if (r_scause() = 15){ + uint64 va = r_stval(); + printf(\u0026quot;page fault %p\\n\u0026quot;, va); + uint64 ka = (uint64) kalloc(); + if(ka == 0){ + p-\u0026gt;killed = 1; + } else{ + memset((void *)ka, 0, PGSIZE); + va = PGROUNDDOWN(va); + if (mappages(p-\u0026gt;pagetable, va, PGSIZE, ka, PTE_W|PTE_U|PTE_R) != 0) + { + kfree((void *)ka); + p-\u0026gt;killed = 1; + } + } } else { printf(\u0026quot;usertrap(): unexpected scause %p pid=%d\\n\u0026quot;, r_scause(), p-\u0026gt;pid); printf(\u0026quot; sepc=%p stval=%p\\n\u0026quot;, r_sepc(), r_stval()); p-\u0026gt;killed = 1; } if(p-\u0026gt;killed) exit(-1); // give up the CPU if this is a timer interrupt. if(which_dev == 2) yield(); usertrapret(); } in usertrap(), we insert a branch for handling with page faults. We read stval register to get the faulting virtual address, allocate a new physical page, and call mappages() to insert mappings in the user page table.\nHowever, we cannot let xv6 run correctly by only those modification. There\u0026rsquo;s another kernel panic message:\npanic: uvmunmap: not mapped uvmunmap() doesn\u0026rsquo;t allow us to unmap pages that hasn\u0026rsquo;t benn allocated, but in lazy allocation this is valid. Therefore we need to modify uvmunmap():\nvoid uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free) { uint64 a; pte_t *pte; if((va % PGSIZE) != 0) panic(\u0026quot;uvmunmap: not aligned\u0026quot;); for(a = va; a \u0026lt; va + npages*PGSIZE; a += PGSIZE){ if((pte = walk(pagetable, a, 0)) == 0) panic(\u0026quot;uvmunmap: walk\u0026quot;); if((*pte \u0026amp; PTE_V) == 0) - panic(\u0026quot;uvmunmap: not mapped\u0026quot;); + continue; if(PTE_FLAGS(*pte) == PTE_V) panic(\u0026quot;uvmunmap: not a leaf\u0026quot;); if(do_free){ uint64 pa = PTE2PA(*pte); kfree((void*)pa); } *pte = 0; } } Zero fill in demand Ususally there are lots of zero pages in the user space. For example, in the ELF file there is a .bss segment, in xv6, when we use exec() system call to load a program, the kernel allocate pages for the .bss segment and set the values as zero.\nA clever implementation is: during exec(), we only allocate one zero page in the physical memory and map all the zero pages in the virtual memory space to it. Those mappings should be read only. In the future when one zero page needs to be modified, a page fault exception will be triggered, and the kernel should allocate another zero page in the physical memory and modify page table\u0026rsquo;s PTE to map the virtual page being written to the new page (read-and-write).\nThis \u0026ldquo;lazy zero page allocation\u0026rdquo; has at least 2 advantages:\nIn some cases, only a small part of the .bss segment will be modified and zero-fill-in-demand saves lots of physical space. In exec() we don\u0026rsquo;t need to do lots of allocations, which makes exec() faster and provides better interact performance between users and the kernel. (Of course, we somehow \u0026ldquo;postpone\u0026rdquo; the penalty: a page fault contains hundreds of load/store instructions, which is very expensive.) Copy-on-write (COW) fork An observation is that: when we use fork() system call, xv6 creates physical pages and copies all the memory pages in the parent process into child process. Usually, there\u0026rsquo;s an exec() system call afterwards and xv6 frees the pages that have just be created.\nCopy-on-write fork somehow optimizes it. During a fork() system call, we copy the parent process\u0026rsquo;s page table into the child\u0026rsquo;s page table, i.e. let parent and child map to the same physical pages, instead of making copies of physical pages at once.\nHowever, we should remember that parent and child\u0026rsquo;s modifications cannot be visible to each other. To achieve the isolation, we set the PTEs as read-only PTEs. In the future, when parent/child process makes a modification, a page fault exception will be triggered, and the kernel is responsible for copying the corresponding physical page, updating page tables, changing the PTEs as read-and-write PTEs, and restarting the faulting instruction.\nQ: How can the kernel tells the copy-on-write page fault from other invalid page faults?\nAlmost all the hardware supporting paging, including RISC-V, can address this issue. In RISC-V\u0026rsquo;s PTE format, there are some bits called RSW bits, which are available for kernel use. Kernel can set copy-on-write bit in the RSW area, and when page faults happen, the kernel checks the copy-on-write bit to decide whether it\u0026rsquo;s a valid page fault.\nIf copy-on-write fork is implemented, there\u0026rsquo;s another things worth attention: in unmodified xv6, one physical page belongs to more or less one process except the trampoline page, which will never be freed. However, in copy-on-write-fork situation, there will be pages belonging to multiple processes, so when a process is being freed, it cannot directly free all the corresponding physical pages since other processes may be using them. A reasonable approach is that, we maintain a \u0026ldquo;ref count\u0026rdquo; for each page recording the number of processes using this page, and we free a page when its ref count equals zero.\nDemand paging For unmodified xv6, In exec() system call the kernel loads all the text segment pages and data segment pages into the memory. Accessing files is quite expensive and sometimes the user program doesn\u0026rsquo;t use all its instructions and data.\nIf demand paging is implemented, in exec(), the kernel doesn\u0026rsquo;t load the pages, but set the PTEs as invalid (PTE_V bit removed). So when the user program executes its first instruction, a page fault exception will be triggered. The text/data segment pages are beforehand binded to corresponding files, and in the page fault handler, the kernel copies pages from the file to the memory, updating page tables and restarting the faulting instruction.\nIn some situation, when a page fault happens and the kernel needs to load a new page into memory, there\u0026rsquo;s no free pages - the memory is used up. In this case, the kernel should firstly choose one page and evict it into the file/disk, and then use the just freed physical page to load the new page. After that, it can restart the faulting instruction.\nThere are several strategies for choosing the evicted page. The most commonly used strategy is to evict the least recently used page (LRU strategy). Another useful strategy is that the kernel prefers to choose non-dirty page than dirty page, since evicting non-dirty page only requires disabling the corresponding PTE. In hardware, RISC-V\u0026rsquo;s PTE format includes PTE_A bit representing whether the page has been accessed recently, which is helpful for implementing LRU (of course, the operating system should periodically clear all the PTE_A bits). There\u0026rsquo;s also a PTE_D bit representing whether the page has ever been modified.\nMemory-mapped files Most modern operating system provides mmap() system call, which aims at letting user program use load/store instructions to directly read/write files instead of repeatedly using expensive read() / write() system calls. The declaration of mmap() is\nvoid *mmap(void *va, size_t length, int prot, int flags, int fd, off_t offset); It will map the specified virtual address to the file descriptor. Some operating systems eagerly do the mappings: it loads pages in the files into the memory. However, by utilizing page fault mechanism, we can firstly only maintain a virtual memory area (vma) recording necessary information, and when a paging fault happens, it loads needed pages into memory, and when the file is closed, the kernel should write dirty pages back to the file/disk.\nQ: What if multiple processes share one file page?\nWe don\u0026rsquo;t know the exact order of read/write operations in the two processes, so it\u0026rsquo;s an undefined behavior, we don\u0026rsquo;t need to do extra maintenance. If we implement a file locking in the file system, we can address the synchronizing issue.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3142d947280f5c082707ef2d0985726f","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec08/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec08/","section":"notes","summary":"The benefits of virtual memory, besides offering isolation, include levels of indirection. We have already seen some interesting usage of mappings, such as trampoline page and guard page, but these mappings are relatively static.","tags":null,"title":"MIT-6.S081 Lecture 08: Page Faults","type":"docs"},{"authors":null,"categories":null,"content":"Type top in the command line and you can check the memory usage, processes information etc. in the terminal:\ntop - 11:57:33 up 1 day, 1:04, 1 user, load average: 0.21, 0.25, 0.32 Tasks: 354 total, 1 running, 353 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.9 us, 0.7 sy, 0.0 ni, 98.4 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st MiB Mem : 15661.3 total, 586.9 free, 2944.0 used, 12130.4 buff/cache MiB Swap: 19531.0 total, 19528.5 free, 2.5 used. 11403.6 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 840 root 20 0 421340 21428 16712 S 9.0 0.1 3:59.57 Network+ 4461 starling 9 -11 2834104 17456 13760 S 4.0 0.1 32:30.95 pulseau+ 949 root 20 0 10488 6496 4940 S 1.0 0.0 14:10.30 EasyMon+ 962 root 20 0 407004 9836 7688 S 1.0 0.1 8:50.53 ECAgent 113206 starling 20 0 36.3g 67604 51524 S 0.7 0.4 0:17.59 code 4466 starling 20 0 10520 6480 3740 S 0.3 0.0 0:27.20 dbus-da+ 4615 starling 20 0 6096848 442400 163960 S 0.3 2.8 18:26.29 gnome-s+ 5241 starling 20 0 561596 35788 26204 S 0.3 0.2 5:20.81 sogoupi+ 112573 starling 20 0 4934416 716796 396344 S 0.3 4.5 1:10.73 GeckoMa+ 113141 starling 20 0 36.3g 165072 55252 S 0.3 1.0 0:08.28 code 113678 starling 20 0 40.6g 274404 121660 S 0.3 1.7 4:42.63 Typora 116933 starling 20 0 2571540 173676 127868 S 0.3 1.1 0:24.61 Isolate+ 120059 root 20 0 0 0 0 I 0.3 0.0 0:00.03 kworker+ 120151 starling 20 0 21704 4412 3460 R 0.3 0.0 0:00.77 top 1 root 20 0 165108 11200 7684 S 0.0 0.1 0:04.22 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.15 kthreadd 3 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_gp We can see that there\u0026rsquo;s little free memory left, most memory is used by the buffer cache. That\u0026rsquo;s a very common case in modern operating systems. Leaving too much memory space idle is wasteful, so operating systems usually make full use of the memory space. In this case, handling page fault exception and evicting pages out to the disk is very frequent.\nSometimes the hardware wants attention, so they generate interrupts. The software should save its work, process the interrupts, and afterwards resume its work. The saving and resuming procedures are similar to those of system calls and traps, they all use the same mechanism. But the following features make interrupts different and be worth of a lecture:\nAsynchronous: interrupts can happen at any time. A system call must happen when a user program is running, but when interrupts come, we have no idea which process is being executed, or whether there is a process running. Concurrency. We have to address a lot of issues about concurrency and parallelism. This is the start point of talking about concurrency. The devices and the CPU are independent parts: CPU executes instructions while devices handling I/O events. This is true parallelism. Device programming: devices like ether-net cards and UART needs programming. There may be manual illustrating the function of each control register, but devices are often pool documented. RISC-V Interrupt Structure The first question is: where are interrupts come from? Interrupts come from the various devices. Devices send the interrupts to a device called platform-level interrupt controller (PLIC), CPU cores can access PLIC to see whether there\u0026rsquo;s an pending interrupts. When a CPU core finishes processing an interrupt, it sends a signal to the PLIC and PLIC knows that this interrupts can be forgot.\nQ: Does PLIC has some mechanism to ensure fairness?\nIt\u0026rsquo;s up to the kernel. The kernel programs the PLIC hardware. PLIC doesn\u0026rsquo;t really actively choose service of delivering interrupts. The kernel fetches the interrupts and decides where interrupts should be sent. The kernel can also decide the priority of different kinds of interrupts. There is a huge amount of flexibility.\nOrganization of Drivers Drivers are codes used for managing devices. A typical driver structure includes 2 parts:\nTop part: this part handle system calls related to the device such as read() and write() system calls. It interacts with the user processes, so things like copyin()/copyout() are done in this part. Bottom part: this part serves as the interrupt handler of the corresponding device. When the device raises an interrupt, the kernel catches it and calls functions in the bottom part of its driver to handle the interrupt. It may happen that the current process is not the previous pending process, so the interrupt handler cannot count on any information about the process in the CPU core (e.g. page table). Programming Devices In xv6 we use memory mapped I/O. In this case devices show up at particular addresses in the physical memory space, which are determined by the hardware board manufacturers. The operating systems should know these addresses in order to programming devices. OS can use normal load/store instructions to read/write the control registers of the devices.\nInterrupts on Hardware The PLIC hardware is responsible for receiving interrupts from different devices and routing them to CPU cores. If a CPU core receives an interrupt and the SIE bit of sstatus register is set (i.e. interrupt enabled), the hardware will do the following things:\nClear the SIE bit in sstatus register to temporarily disable interrupts. store PC value into sepc register. save the current mode, and then switch to supervisor mode. copy the address in stvec register into PC. In xv6, it goes to usertrap()/kerneltrap(). Case Study: $ We want to know how the prompt $ shows up in the console. In general, the device puts $ into the UART, and UART generates an interrupt when the char has been sent.\nRISC-V hardware has some supports for interrupts:\nSIE register. The supervisor interrupt enable register has a bit for external interrupt, a bit for software interrupt and a bit for timer interrupt. Here we only focus on external interrupts. SSTATUS register. This control register contains a bit that can enable/disable interrupts. SIP register. The supervisor interrupt pending register, together with SCAUSE register, contain information about what interrupt is coming. In main(), xv6 does a bunch of preparations which get ready for interrupts. The true time when interrupt is able to come in is when scheduler() calls intr_on():\nvoid scheduler(void) { struct proc *p; struct cpu *c = mycpu(); c-\u0026gt;proc = 0; for(;;){ // Avoid deadlock by ensuring that devices can interrupt. intr_on(); ... } } intr_on() is responsible for writing SSTATUS_SIE bit into SSTATUS register:\nstatic inline void intr_on() { w_sstatus(r_sstatus() | SSTATUS_SIE); } Every CPU core runs scheduler() code, and when intr_on() is called, the corresponding core is able to accept interrupts.\nThe first user process, init, opens the console device and assign 0/1/2 to standard input/output/error.\nif(open(\u0026quot;console\u0026quot;, O_RDWR) \u0026lt; 0){ mknod(\u0026quot;console\u0026quot;, CONSOLE, 0); open(\u0026quot;console\u0026quot;, O_RDWR); } dup(0); // stdout dup(0); // stderr Then in user program /user/sh.c, getcmd() function uses fprintf() to print a prompt to stderr. Here fprintf() doesn\u0026rsquo;t know what\u0026rsquo;s behind the file descriptor 2, maybe a file, a pipe or a device.\nint getcmd(char *buf, int nbuf) { fprintf(2, \u0026quot;$ \u0026quot;); memset(buf, 0, nbuf); gets(buf, nbuf); if(buf[0] == 0) // EOF return -1; return 0; } fprintf() will eventually use write() system call to write a character. Refer to the xv6-book notes for the procedure after that.\nCase Study: ls We want to know how the command ls is typed into the console. In general, the keyboard connects to the receive line of UART. When a character is typed, UART generates an interrupt to let the kernel fetches that char.\nWhen a interrupt is received by the kernel, usertrap()/kerneltrap() calls devintr() to check whether there\u0026rsquo;s an interrupt and do corresponding operations. devintr() calls plic_claim() to make the CPU core claim the type of device and call uartintr() to handle UART interrupt. In uartintr(), it calls uartgetc() to get the character l and s, and calls consoleintr() to put them into buffer.\nInterrupts and Concurrency Concurrency issues in interrupts are difficult to tackle with. Here are some common concurrency problems:\nDevices and CPU cores run in parallel. It\u0026rsquo;s called producer-consumer parallelism and needs to be carefully managed. Interrupts can stop the current program. If it stops the user program, the procedure is similar to traps. However, interrupt can also stop the kernel, which means that the instruction sequence in kernel code may not be continuous either now. We have to carefully enable/disable interrupts in kernel code to avoid crashing. The top of drivers and the bottom of drivers may run in parallel. For example, when the shell program use write() system call to put a dollar prompt on the display, i.e. the top of the console driver is running, another CPU core may be handling interrupts from uart. The top and bottom share resources such as the buffer array. To make sure each core can see the correct, up-to-date content, we need a mechanism to ensure that only one core can do operations to shared resources at a time. Xv6 uses locks to realize that. Xv6 uses buffer array to address the producer-consumer parallelism. There are a read pointer and a write pointer for each buffer. The buffer is empty when r==w, the buffer is full when w+1 mod BUFFER_SIZE==r. The producer puts characters at the end of the queue and updates write pointer, while the consumer reads characters at the beginning of the queue and updates read pointer. Buffer array successfully decouple devices and CPU cores, making them able to run separately at high speed.\nQ: Is there multiple buffer arrays, one for each CPU core?\nThe buffer array is an array declared in /kernel/uart.c and is set in RAM. There\u0026rsquo;s only one RAM so there\u0026rsquo;s only one buffer array. There are several CPU cores running processes in parallel, and they may access the UART device at the same time, i.e. access the buffer array in parallel.\nThe main task for locking is to serialize accesses. Only the core that acquires the lock has access to the array and the read/write pointers. After it releases the lock, other cores can acquire the lock.\nInterrupt Evolution Interrupts used to be very fast because hardware is very simple in old times. Nowadays, interrupts are slow because devices are more complicated. They have to do lots of preliminary work before generating an interrupt. On the other hand, kernel design becomes more complicated and it takes longer to handle an interrupt.\nFor some fast devices, e.g. high performing network card, there may be a stream of packets and the period is even shorter than the interrupt handling time. In this case, we have another strategy - polling. The CPU keeps checking a particular control register, once there\u0026rsquo;s data in, the CPU handles it. For slow devices, polling wastes CPU cycles on checking registers, but if devices are fast, polling can save frequent entry/exit cost.\nNowadays, sophisticated devices can dynamically switch between polling and interrupts.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a8def34e5a1088a10cd924fe625f2d97","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec09/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec09/","section":"notes","summary":"Type top in the command line and you can check the memory usage, processes information etc. in the terminal:\ntop - 11:57:33 up 1 day, 1:04, 1 user, load average: 0.","tags":null,"title":"MIT-6.S081 Lecture 09: Interrupts","type":"docs"},{"authors":null,"categories":null,"content":"没有需要特别注意的知识点。\n(注：这里的 tree recursion 指的不是在树上搜索的递归，而是一个函数在函数体内多次调用自己，整个调用构成了一棵树的情形，最经典的例子就是不带记忆化地递归计算斐波那契数列。)\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"641fcc9bce140509d05ac43ddc833007","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec09/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec09/","section":"notes","summary":"没有需要特别注意的知识点。\n(注：这里的 tree recursion 指的不是在树上搜索的递归，而是一个函数在函数体内多次调用自己，整个调用构成了一棵树的情形，最经典的例子就是不带记忆化地递归计算斐波那契数列。)","tags":null,"title":"UCB-CS61a Lecture 09: Tree Recursion","type":"docs"},{"authors":null,"categories":null,"content":"Applications may want multiple CPU cores, so the kernel must handle parallel system calls, e.g. carefully maintain shared data structure in parallel. We use locks to ensure correct sharing, but on the other hand, locks can limit performance.\nThe frequency of CPU clock gradually reaches a limit at 2010, which means that single thread performance cannot be optimized. However, the number of transistors keeps growing, so having multiple cores is our only choice to increase performance.\nWhy Lock? We use lock to avoid race conditions. For example, if we delete the acquire(kmem.lock) and release(kmem.lock) in kfree(), it\u0026rsquo;s possible that pages are lost during freeing.\nLock Abstraction The lock in xv6 is simply a struct:\nstruct lock { int locked; ... }; there are two APIs: acquire(struct lock *lk) and release(struct lock *lk)，at one time, only one process can acquire the lock, and other processes have to wait until the first process calls release().\nThe area between acquire() and release() is called critical section. The code in critical sections are executed atomically, i.e. either all or none of the code is executed, it\u0026rsquo;s impossible for codes in the same critical section to interweave.\nPrograms usually have many locks, aiming at more parallelism. If there\u0026rsquo;s only one lock in the kernel, to ensure correctness, the lock must protects all the codes in the kernel (the so called \u0026lsquo;big kernel lock\u0026rsquo;). In this case, the execution of the whole kernel is serialized. If we use multiple locks, it\u0026rsquo;s allowable to let two processes using different locks run in parallel.\nWhen to Lock? A conservative rule (guideline): if 2 processes access a shared data structure and at least one operation is writing, then we have to lock that data structure.\nFrom some aspects, the guideline is too strict: we can use lock-free programming. But lock-free programming is so tricky that we won\u0026rsquo;t cover that. From some aspects, the guideline is too loose: in printf() we use lock to ensure that the printed message is atomic.\nWe may want data structures to automatically acquire and release locks when we\u0026rsquo;re accessing them, but there are cases when we need more flexible lock management. Consider a system call rename() . Suppose now we deal with rename(\u0026quot;d1/x\u0026quot;, \u0026quot;d2/y\u0026quot;), if we act like this:\nlock(d1); erase(\u0026quot;d1/x\u0026quot;); release(d1); (**) lock(d2); add(\u0026quot;d2/y\u0026quot;); release(d2); then at time **, from other processes\u0026rsquo; perspective, the file doesn\u0026rsquo;t exist! - obviously incorrect. The correct implementation is\nlock(d1 and d2); erase(\u0026quot;d1/x\u0026quot;); add(\u0026quot;d2/y\u0026quot;); release(d1 and d2); In this example, we see that sometimes we need multiple locks before doing operations.\nLock Perspectives Locks help avoid lost updates. (e.g. kfree() ) Locks make multi-step operations (critical section) atomic. Locks help maintain invariants. (e.g. in kfree(), the lock protects moments when there are multiple pointers pointing to the head node.) Deadlock Let\u0026rsquo;s look at a case which may lead to deadlock:\nCPU1 CPU2 rename(\u0026quot;d1/x\u0026quot;, \u0026quot;d2/y\u0026quot;) rename(\u0026quot;d2/a\u0026quot;, \u0026quot;d1/b\u0026quot;) acquire(d1) acquire(d2) acquire(d2) \u0026lt;-- blocked acquire(d1) \u0026lt;-- blocked The solution is to always acquire locks in order. (actually, it\u0026rsquo;s OK for CPU2 to acquire d1 and then d2 in this case.) Here the lock ordering is a partial order.\nLock makes modularity more complicated. Suppose a function f() in module 1 calls a function g() in module 2, f() must ensure that locks in g() will not violate global lock ordering, which means that the internals of module 2 (in terms of locks) must be visible to module 1, which somehow violates the module abstraction principle.\nLock Performance Locks lead to serialization, which influences performance. To increase performance, we need to split up data structures and introduce more locks, which require lots of work.\nA general approach is to firstly use coarse-grained locks, and do profiling tests to see whether we need smaller locks to increase parallelism.\nCode: Lock Implementation The most common way to acquire locks is to use the hardware test-and-set support. In RISC-V, we use the amoswap addr, r1, r2 atomic instruction. It can be viewed as the following pseudo instructions:\nlock addr tmp \u0026lt;-- *addr *addr \u0026lt;-- r1 r2 \u0026lt;-- tmp unlock addr Hardware test-and-set support is dependent on memory system. If the memories are sitting on a share bus, a memory controller (bus arbiter) is responsible for sorting the locks in order. If processors have caches, the cache coherence protocol will ensure the consistency.\nIn acquire() in xv6, we use the C function __sync_lock_test_and_set() to do atomic operations. Refer to Xv6 Source Code Manual for more details.\nIn release(), we may wonder that why we still need to use atomic instruction to set the lock: a simple store instruction can finish that. However, the store instruction may be executed differently depending on architecture design. sw may be decomposed to several micro instructions, which leads to lost of atomicity.\nCode: Locks and Interrupts In acquire(), we must firstly turn off the interrupts. That\u0026rsquo;s because unexpected interrupts may cause deadlock. For example, in /kernel/uart.c:\nvoid uartputc(int c) { acquire(\u0026amp;uart_tx_lock); if(panicked){ for(;;) ; } ...... } void uartintr(void) { // read and process incoming characters. while(1){ int c = uartgetc(); if(c == -1) break; consoleintr(c); } // send buffered characters. acquire(\u0026amp;uart_tx_lock); uartstart(); release(\u0026amp;uart_tx_lock); } Suppose that we don\u0026rsquo;t turn off interrupts when holding locks, we acquire the lock uart_tx_lock in uartputc(), and when we\u0026rsquo;re in the critical section, the uart hardware sends an interrupt, leading us to uartintr(). In uartintr() the kernel tries to acquire the lock uart_tx_lock, but the lock is held by the interrupted thread, on the other hand, it\u0026rsquo;s impossible for the interrupted thread to move on unless interrupt handler returns. So a deadlock appears.\nCode: Memory Ordering Modern compilers and processors usually adjust instruction order to increase performance. For example,\nlock = 1; x = x + 1; // ---+ lock = 0; // | // \u0026lt;--+\tIt\u0026rsquo;s possible for compilers/processors to move x = x + 1 to the end of the paragraph. If the code is executed in a single-core, serial mode, it\u0026rsquo;s absolutely OK and correct. But if it\u0026rsquo;s executed on mult-core processors, it\u0026rsquo;s a disaster.\nTo avoid such things, we can build a memory fence. In RISC-V, it\u0026rsquo;s a mfence instruction and it\u0026rsquo;s encapsulated as __sync_synchronize() in libc. We put memory fence at the beginning of acquire() and the end of release() to ensure that no instruction will be unexpectedly moved out of our critical section.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1c6adea44cdb690c1780a0813b538024","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec10/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec10/","section":"notes","summary":"Applications may want multiple CPU cores, so the kernel must handle parallel system calls, e.g. carefully maintain shared data structure in parallel. We use locks to ensure correct sharing, but on the other hand, locks can limit performance.","tags":null,"title":"MIT-6.S081 Lecture 10: Multiprocessors and Locks","type":"docs"},{"authors":null,"categories":null,"content":"List Comprehension 通过一个已经存在的 list 创建一个新的 list。\n完整的语法为：\n[\u0026lt;map exp\u0026gt; for \u0026lt;name\u0026gt; in \u0026lt;iter exp\u0026gt; if \u0026lt;filter exp\u0026gt;] 在执行这样一条语句时，Python 解释器会做这样的事情：\n临时创建一个新的 frame，这个 frame 的 parent frame 是执行该语句的当前 frame。 创建一个空的 list 作为当前语句的结果 执行 \u0026lt;iter exp\u0026gt;，结果必须是一个 iterable 的东西。 对于 \u0026lt;iter exp\u0026gt; 结果中的每个元素，将 \u0026lt;name\u0026gt; 绑定到该元素上，并执行 \u0026lt;filter exp\u0026gt; 以决定是否放入 list。 临时 frame 的返回值就是结果 list。 注意：list comprehension 中的 if 语句不能跟 else。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"11c16ecb995a078cbdb4118cf9fdc134","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec10/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec10/","section":"notes","summary":"List Comprehension 通过一个已经存在的 list 创建一个新的 list。\n完整的语法为：\n[\u0026lt;map exp\u0026gt; for \u0026lt;name\u0026gt; in \u0026lt;iter exp\u0026gt; if \u0026lt;filter exp\u0026gt;] 在执行这样一条语句时，Python 解释器会做这样的事情：\n临时创建一个新的 frame，这个 frame 的 parent frame 是执行该语句的当前 frame。 创建一个空的 list 作为当前语句的结果 执行 \u0026lt;iter exp\u0026gt;，结果必须是一个 iterable 的东西。 对于 \u0026lt;iter exp\u0026gt; 结果中的每个元素，将 \u0026lt;name\u0026gt; 绑定到该元素上，并执行 \u0026lt;filter exp\u0026gt; 以决定是否放入 list。 临时 frame 的返回值就是结果 list。 注意：list comprehension 中的 if 语句不能跟 else。","tags":null,"title":"UCB-CS61A Lecture 10: Containers","type":"docs"},{"authors":null,"categories":null,"content":"Copying 我们平时写的\nlistA = [0, 1, 2, 3] 本质上是一个名叫 \u0026ldquo;listA\u0026rdquo; 的指针指向了 [0, 1, 2, 3] 这个对象。\n拷贝分深拷贝和浅拷贝两种。浅拷贝只是让两个指针指向了同一个对象，而深拷贝会将对象复制一遍，然后让新指针指向新复制的对象。例如：\n\u0026gt;\u0026gt;\u0026gt; listA = [0, 1, 2, 3] \u0026gt;\u0026gt;\u0026gt; listB = listA # 浅拷贝 \u0026gt;\u0026gt;\u0026gt; listC = list(listA) # 深拷贝 \u0026gt;\u0026gt;\u0026gt; listA[0] = 1 \u0026gt;\u0026gt;\u0026gt; listB, listC ([1, 1, 2, 3], [0, 1, 2, 3]) Built-in Functions for Iterables 一些常见的内置函数有：\nFunction Description sum(iterable) 求和 all(iterable) 返回 True 当且仅当 iterable 中所有元素均为 True any(iterable) 返回 True 当且仅当 iterable 中存在元素为 True max(iterable, key=None) 最大值 min(iterable, key=None) 最小值 其中 max() min() 可以通过给 key 传递函数的方式自定义比大小的标准，例如：\n\u0026gt;\u0026gt;\u0026gt; coords = [ [37, -144], [-22, -115], [56, -163] ] \u0026gt;\u0026gt;\u0026gt; max(coords, key=lambda coord: coord[0]) [56, -163] ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a3b640994d0e1edd854623db9dac91b8","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec11/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec11/","section":"notes","summary":"Copying 我们平时写的\nlistA = [0, 1, 2, 3] 本质上是一个名叫 \u0026ldquo;listA\u0026rdquo; 的指针指向了 [0, 1, 2, 3] 这个对象。\n拷贝分深拷贝和浅拷贝两种。浅拷贝只是让两个指针指向了同一个对象，而深拷贝会将对象复制一遍，然后让新指针指向新复制的对象。例如：\n\u0026gt;\u0026gt;\u0026gt; listA = [0, 1, 2, 3] \u0026gt;\u0026gt;\u0026gt; listB = listA # 浅拷贝 \u0026gt;\u0026gt;\u0026gt; listC = list(listA) # 深拷贝 \u0026gt;\u0026gt;\u0026gt; listA[0] = 1 \u0026gt;\u0026gt;\u0026gt; listB, listC ([1, 1, 2, 3], [0, 1, 2, 3]) Built-in Functions for Iterables 一些常见的内置函数有：","tags":null,"title":"UCB-CS61A Lecture 11: Sequences","type":"docs"},{"authors":null,"categories":null,"content":"Introduction People want threads for the following reasons:\nPeople want their computers to \u0026ldquo;seemingly\u0026rdquo; simultaneously do multiple jobs. Programmers can use multiple threads to write simple and elegant code. prime.c in Lab 1 is a good example, it uses multiple processes but the principle is similar. We can utilize multiple threads to speed up our programs on a multi-core machine. A thread is an abstract concept that can be viewed as a serial execution. The state of an execution includes the PC, the registers and a stack. Operating systems interleave the execution of multiple threads, which is implemented in mainly two ways:\nMulti-core machine: a machine with multiple CPU cores can naturally interleave the executions. There are automatically multiple sets of PCs, registers, etc. Thread switching. Even on a multi-core machine, we need to focus on how a single core an execute multiple threads by executing the first one for a while and switching to the second and so forth. An important issue about threads is: does threads have shared memory? If threads have shared memory, then each thread\u0026rsquo;s changes are visible to other threads and we need locks to access shared resources. In xv6, kernel threads do have shared memories while user processes with only one thread don\u0026rsquo;t have shared memory - each thread lives in the address space of its corresponding process. In real OS like Linux, which supports user processes to have multiple threads, threads of the same process share the same address space.\nThere are several challenges for implementing a threading system:\nHow to decide which thread to execute - scheduling. What and where to save/restore the thread state. How to deal with compute bound threads: threads may not voluntarily yield the CPU ,so we need a method to automatically revoking control from some long running compute bound process, setting it aside and running it later. The answer to the third question is timer interrupts. There is a piece of hardware on the CPU that periodically generates interrupt signals and the signals are somehow transferred to the kernel. So even if the process is running in user level, the coming signal will interrupt it and give the control to the kernel. Then the kernel voluntarily yields the CPU.\nThis kind of policy is called preemptive scheduling. Here the \u0026ldquo;preemptive\u0026rdquo; means that even if the user process is unwilling to yield the CPU, our kernel will force it to quit. Correspondingly another policy is called voluntary scheduling, which counts on processes to proactively yield the CPU. An interesting thing is, xv6 implements preemptive scheduling by letting kernel threads voluntarily yield CPU.\nKernel threads have multiple states, some of which are listed below:\nRUNNING: the thread is currently running on one of the core. RUNNABLE: the thread is able to run and wants to be scheduled onto CPU as soon as possible. SLEEPING: the thread cannot run currently (maybe because it\u0026rsquo;s waiting for I/O). Preemptive scheduling is responsible for changing a running thread to a runnable thread. In xv6, since kernel threads share memory, thread state only includes CPU information. A running thread\u0026rsquo;s state is stored in the CPU hardware while a runnable/sleeping thread\u0026rsquo;s state, i.e. PC and registers, is stored elsewhere.\nA Roadmap for Thread Switching Generally, in xv6, a user process cannot directly switch to another user process, it must realize it in an indirect way: the user process first falls into the kernel, during which the user level information is stored in the trapframe, then it saves the context of its kernel thread, switches to another process\u0026rsquo;s kernel thread by restoring the context. At last it goes back to the user space of another process.\nA more detailed picture is described below: suppose we have two processes P1 and P2, P1 is running using its own user stack. Now a timer interrupt comes and the execution of P1 is suspended. In trampoline.S, it stores the user level information in the trapframe, switches to the corresponding kernel stack, and now it\u0026rsquo;s P1\u0026rsquo;s kernel thread running.\nThe kernel thread voluntarily yields the CPU by calling a function swtch(). In swtch(), the context of P1\u0026rsquo;s kernel thread (i.e. values of registers) is saved and a scheduler thread\u0026rsquo;s context is restored. After restoring scheduler thread\u0026rsquo;s context, our execution flow jumps to the return address of an swtch() call in scheduler thread\u0026rsquo;s function scheduler(). Also, the stack is switched to the scheduler\u0026rsquo;s stack (this stack is allocated in entry.S).\nThe scheduler thread is responsible for choosing an runnable thread and switching to it. After deciding which thread to switch to, the scheduler thread does the same procedure again: it calls swtch(), saves the context and restore the context of the target process\u0026rsquo;s kernel thread. Now the execution flow jumps to the return address of an swtch() call in P2\u0026rsquo;s kernel thread. Also the stack is switched to P2\u0026rsquo;s kernel stack. Finally, P2 restores user level information through P2\u0026rsquo;s trapframe and goes back to the user space.\nWhere are the context stored?\nContexts of processes\u0026rsquo;s kernel threads are stored in p-\u0026gt;context. Context of scheduler thread is stored in the CPU struct.\nA process is either running in the user space, or running in the kernel level, or it\u0026rsquo;s not running at all. In the last case the information of the process is stored in the combination of trapframe and thread context.\nCode: spin.c struct cpu { struct proc *proc; // The process running on this cpu, or null. struct context context; // swtch() here to enter scheduler(). int noff; // Depth of push_off() nesting. int intena; // Were interrupts enabled before push_off()? }; struct proc { struct spinlock lock; // p-\u0026gt;lock must be held when using these: enum procstate state; // Process state struct proc *parent; // Parent process void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed int xstate; // Exit status to be returned to parent's wait int pid; // Process ID // these are private to the process, so p-\u0026gt;lock need not be held. uint64 kstack; // Virtual address of kernel stack uint64 sz; // Size of process memory (bytes) pagetable_t pagetable; // User page table struct trapframe *trapframe; // data page for trampoline.S struct context context; // swtch() here to run process struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory char name[16]; // Process name (debugging) }; process struct and CPU struct are shown above. In struct proc we can see variable state representing the status of the process, kstack representing the address of the process\u0026rsquo;s kernel stack, trapframe storing user level information and context storing kernel thread context. In struct cpu there\u0026rsquo;s also a context storing the context of scheduler thread.\nWe use a demo program, spin.c, to illustrate the complete procedure of thread switching.\n// // spin.c // a demo program illustrating the principle of thread switching. // #include \u0026quot;kernel/types.h\u0026quot; #include \u0026quot;user/user.h\u0026quot; int main (int argc, char *argv[]) { int pid; char c; pid = fork(); if (pid == 0) { c = '/'; } else { printf(\u0026quot;parent pid is %d, child is %d\\n\u0026quot;, getpid(), pid); c = '\\\\'; } for (int i = 0; ; i++) if (i % 1000000 == 0) write(2, \u0026amp;c, 1); exit(0); } In spin.c two processes print / and \\ respectively. Due to timer interrupt, two kinds of slashes are printed alternatively. We use GDB to set a breakpoint at where devintr() recognizes an timer interrupt.\nTip: GDB Usage\nWe can set breakpoints at a particular line in the source code. In this case, we can use b trap.c:207.\nIf we check the trapframe by p/x p-\u0026gt;trapframe:\n$6 = {kernel_satp = 0x8000000000087fff, kernel_sp = 0x3fffff8000, kernel_trap = 0x80002880, epc = 0x62, kernel_hartid = 0x0, ra = 0x62, sp = 0x2fb0, gp = 0x505050505050505, tp = 0x505050505050505, t0 = 0x505050505050505, t1 = 0x505050505050505, t2 = 0x505050505050505, s0 = 0x2fe0, s1 = 0x1c4a4111, a0 = 0x1, a1 = 0x2fbf, a2 = 0x1, a3 = 0x3ea0, a4 = 0x1400, a5 = 0x99691, a6 = 0x505050505050505, a7 = 0x10, s2 = 0xf4240, s3 = 0x20, s4 = 0x146b, s5 = 0x13f0, s6 = 0x505050505050505, s7 = 0x505050505050505, s8 = 0x505050505050505, s9 = 0x505050505050505, s10 = 0x505050505050505, s11 = 0x505050505050505, t3 = 0x505050505050505, t4 = 0x505050505050505, t5 = 0x505050505050505, t6 = 0x505050505050505} The epc points at 0x62, by looking up in spin.asm, this is addiw s1, s1, 1 instruction, which demonstrates that our process is interrupted when doing infinite calculation.\nWe continue and go into the yield() function, which makes the kernel thread voluntarily yield the CPU.\nvoid yield(void) { struct proc *p = myproc(); acquire(\u0026amp;p-\u0026gt;lock); p-\u0026gt;state = RUNNABLE; sched(); release(\u0026amp;p-\u0026gt;lock); } Before doing jobs, yield() firstly acquires the lock of the current process because it\u0026rsquo;s about to change the state of the process to RUNNABLE. We want this procedure to be atomic to other cores because the invariant that p-\u0026gt;state represents the current status of the process is temporarily violated: the process is indeed running, but the status becomes RUNNABLE. If other cores\u0026rsquo; scheduler threads were able to see the change now and decide to execute this process, our current process would be running simultaneously on multiple CPUs, which is a disaster.\nWe go into sched(). After finishing several sanity checks, sched() calls swtch(), which is the core function of thread switching.\nswtch(\u0026amp;p-\u0026gt;context, \u0026amp;c-\u0026gt;context); This line will save the current context into p-\u0026gt;context and restore c-\u0026gt;context. We can use p/x cpus[0].context to check the context we are going to switch to:\n$12 = {ra = 0x80001fce, sp = 0x8000a7c0, s0 = 0x8000a810, s1 = 0x800121a0, s2 = 0x2, s3 = 0x80017768, s4 = 0x80011950, s5 = 0x1, s6 = 0x80011970, s7 = 0x1, s8 = 0x3, s9 = 0x0, s10 = 0x0, s11 = 0x0} We are particularly interested in the ra register because it determines where we\u0026rsquo;ll go to after returning from swtch(). We use x/i cpus[0].context-\u0026gt;ra:\n0x80001fce \u0026lt;scheduler+138\u0026gt;: sd zero,24(s4) We are assured that after executing swtch(), we will be in the scheduler thread.\nswtch.S is written in assembly. It stores and restores values according to a0 and a1, which are registers containing the first and the second argument, i.e. p-\u0026gt;context and c-\u0026gt;context.\nWhy don\u0026rsquo;t we save the PC register? Without saving the PC register, how can we know which instruction to jump to?\nWe use the ra register to indirectly record PC. When swtch() returns by executing ret, the value in ra will be put into PC, which is exactly the next instruction of call swtch in scheduler().\nThere are 32 general registers in RISC-V, why swtch() only saves 14 of them?\nIn C code, swtch() is only a normal function call, according to the calling convention, swtch() only need to carefully manage callee-saved registers. Even if swtch() do nothing with caller-saved registers, the caller will be able to restore the caller-saved registers (from the kernel stack or somewhere). This is ensured by the C compiler.\nAfter executing 28 ld and sd instructions, we now use x $sp to print the stack:\n0x8000a7c0 \u0026lt;stack0+3984\u0026gt;: 0x00000000 our stack pointer now points to stack0, which is the stack we allocate to the scheduler thread during booting. If we use where to unwind the stack information, we\u0026rsquo;ll get\n#0 0x00000000800026b8 in swtch () #1 0x0000000080001fce in scheduler () at kernel/proc.c:489 #2 0x0000000080000f2c in main () at kernel/main.c:44 We\u0026rsquo;re now in scheduler thread, which is created at the last line of main.c during booting. We return from a swtch() call which scheduler() makes a while ago.\nscheduler() loops and tries to find process that is RUNNABLE state. It\u0026rsquo;s worth attention that we need to acquire lock before checking the status and doing subsequent jobs. Generally, after we acquire a process lock, we usually do the following jobs to realize thread switching:\nModify the status of the target process. Call swtch() to save and restore context. Previously we talked about acquiring lock can avoid other cores discovering processes in temporary incorrect state. Another significant point of acquiring lock is that we explicitly turn off interrupts in acquire(), this is important because we don\u0026rsquo;t want to respond to timer interrupts when doing swtch(), otherwise the register values would be damaged.\nAfter scheduler() decides the target process to switch to, it will call swtch() again, save scheduler thread\u0026rsquo;s context into c-\u0026gt;context, restore context in p-\u0026gt;context (another process\u0026rsquo;s kernel thread\u0026rsquo;s context), and resume executing that process.\nHow can a process be switched to at the first time, since it hasn\u0026rsquo;t called swtch() yet?\nIn xv6 there is a function forkret(), it serves as the target address of the first \u0026ldquo;fake\u0026rdquo; context: in allocproc(), we set up a fake context with ra pointing to forkret() and sp pointing to the corresponding kernel stack. We don\u0026rsquo;t care about other registers\u0026rsquo; values before the first execution. The only thing forkret() does is to release the process lock.\nIn addition, there is a situation in which xv6 creates a \u0026ldquo;fake\u0026rdquo; trapframe: in userinit(), xv6 creates a fake trapframe with epc=0 and sp=PGSIZE. In other situations, a new process is created by fork() and fork() copies the trapframe of parent process.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ccd04d3f08e4a1fc57e8fe2cdb6e35cd","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/lectures/lec11/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/lectures/lec11/","section":"notes","summary":"Introduction People want threads for the following reasons:\nPeople want their computers to \u0026ldquo;seemingly\u0026rdquo; simultaneously do multiple jobs. Programmers can use multiple threads to write simple and elegant code. prime.c in Lab 1 is a good example, it uses multiple processes but the principle is similar.","tags":null,"title":"MIT-6.S081 Lecture 11: Thread Switching","type":"docs"},{"authors":null,"categories":null,"content":"Abstraction Barriers 抽象是一层一层的，好的程序设计应当只使用上一层抽象提供的接口，不应该跨层地去使用底层的接口。\nDictionary Dictionary Selection 一个有用的 API：\n\u0026gt;\u0026gt;\u0026gt; people = {'alice': 'girl', 'bob': 'boy'} \u0026gt;\u0026gt;\u0026gt; people.get(\u0026quot;eve\u0026quot;, \u0026quot;🤔\u0026quot;) 🤔 dict.get(key, default=None) 会返回字典 dict 中 key 对应的 value，如果 key 不存在则会返回 default 的内容。\nDictionary Rules 字典的 key 不能是 list, dictionary 等 mutable 的东西，且 key 是两两不同的，但 value 可以是任意内容。\nDictionary Iteration \u0026gt;\u0026gt;\u0026gt; insects = {\u0026quot;spiders\u0026quot;: 8, \u0026quot;centipedes\u0026quot;: 100, \u0026quot;bees\u0026quot;: 6} \u0026gt;\u0026gt;\u0026gt; for name in insects: \u0026gt;\u0026gt;\u0026gt; print(insects[name]) 8 100 6 遍历字典时按照 key-value pair 被加入字典时的顺序访问。\nDictionary Comprehensions General syntax:\n{key: value for \u0026lt;name\u0026gt; in \u0026lt;iter exp\u0026gt;} Example:\nsquares = {x: x * x for x in range(3, 6)} ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"20c29e429114d75aac7004c4efa7815b","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec12/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec12/","section":"notes","summary":"Abstraction Barriers 抽象是一层一层的，好的程序设计应当只使用上一层抽象提供的接口，不应该跨层地去使用底层的接口。\nDictionary Dictionary Selection 一个有用的 API：\n\u0026gt;\u0026gt;\u0026gt; people = {'alice': 'girl', 'bob': 'boy'} \u0026gt;\u0026gt;\u0026gt; people.get(\u0026quot;eve\u0026quot;, \u0026quot;🤔\u0026quot;) 🤔 dict.get(key, default=None) 会返回字典 dict 中 key 对应的 value，如果 key 不存在则会返回 default 的内容。","tags":null,"title":"UCB-CS61A Lecture 12: Data Abstraction","type":"docs"},{"authors":null,"categories":null,"content":"Tree: Data Abstraction 我们希望 tree 这个抽象数据类型提供如下的几个 API:\ntree(label, branches)：创建以 label 为根，branches 为子树的树 (branches 是一个列表，其中的每个元素都是一个 tree)。 label(tree)：返回一个树 tree 的根。 branches(tree) 返回一个树的子树的列表。 is_leaf(tree) 判断 tree 是不是一个叶子 (没有子树)。 Tree: A Simple Implementation 使用嵌套的列表去实现：\ndef tree(label, branches=[]): return [label] + list(branches) def label(tree): return tree[0] def branches(tree): return tree[1:] def is_leaf(tree): return len(branches(tree)) == 0 Exercise: List of Leaves def leaves(t): \u0026quot;\u0026quot;\u0026quot;Return a list containing the leaf labels of T. \u0026gt;\u0026gt;\u0026gt; t = tree(20, [tree(12, [tree(9, [tree(7), tree(2)]), tree(3)]), tree(8, [tree(4), tree(4)])]) \u0026gt;\u0026gt;\u0026gt; leaves(t) [7, 2, 3, 4, 4] \u0026quot;\u0026quot;\u0026quot; if is_leaf(t): return [label(t)] else leaf_labels = [leaves(b) for b in branches(t)] return sum(leaf_labels, []) 注：sum() 函数如果接受两个 list，其中第一个 list 里是若干个 list，那么它的行为是将第一个 list 中的所有 list 中的元素整合成一个大 list，接在第二个参数的 list 后面。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4626ab633fb0ac2ecd4d6bf3d79e67e8","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec13/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec13/","section":"notes","summary":"Tree: Data Abstraction 我们希望 tree 这个抽象数据类型提供如下的几个 API:\ntree(label, branches)：创建以 label 为根，branches 为子树的树 (branches 是一个列表，其中的每个元素都是一个 tree)。 label(tree)：返回一个树 tree 的根。 branches(tree) 返回一个树的子树的列表。 is_leaf(tree) 判断 tree 是不是一个叶子 (没有子树)。 Tree: A Simple Implementation 使用嵌套的列表去实现：","tags":null,"title":"UCB-CS61A Lecture 13: Trees","type":"docs"},{"authors":null,"categories":null,"content":"Objects 对象 (object) 是一组数据和行为 (函数) 的集合。在 Python 中所有的 value 都是对象，对象有一系列属性 (attribute) 也有一系列方法 (method)。比如 Python 中的字符串可以通过索引的方式获取具体位置的数据，也可以使用 upper(), lower() 等方法对其进行操作。\nList Mutation append() 和 extend() 这两个方法的行为是有区别的：\nappend() 只能向 list 的后面添加一个元素。如果 append() 的参数是一个 list，那么它会在本 list 的后面添加一个元素，这个元素是一个 list (形成了一个嵌套的 list) extend() 的参数必须是一个 iterable 的东西，它会将这个东西里的所有元素添加到本 list 中。 \u0026gt;\u0026gt;\u0026gt; s1, s2 = [2, 3] \u0026gt;\u0026gt;\u0026gt; t = [4, 5] \u0026gt;\u0026gt;\u0026gt; s1.append(t) \u0026gt;\u0026gt;\u0026gt; s2.extend(t) \u0026gt;\u0026gt;\u0026gt; s1 [2, 3, [4, 5]] \u0026gt;\u0026gt;\u0026gt; s2 [2, 3, 4, 5] remove(v) 方法用于删除 list 中的第一个元素 v (如果 list 中没有 v 会报错)。\nTuples tuple 和 list 基本相同，除了 tuple 中的元素不可修改。创建 tuple 应使用小括号。值得注意的是如果要创建只有一个元素 v 的 tuple，应当写成 (v,) 而不是 (v)。\nlist 中一些只读的操作 tuple 中同样有，比如 slicing，+ 合并，in 判断某个元素是否存在等等。\nImmutability vs. Mutability immutable 的 value 一旦创建就不能修改。常见的 immutable 的例子有 int, float, string, tuple 等。注：我们平时可以写 a += 2 这种操作修改变量的值，本质上是让 a 这个变量名与一个新的 int value 捆绑，而不是对原值的修改。\n如果一个 imuutable 的对象里的元素是 mutable 的 (比如 tuple 的元素是 list)，那么该元素是可以修改的：\n\u0026gt;\u0026gt;\u0026gt; t = (1, [2, 3]) \u0026gt;\u0026gt;\u0026gt; t[1][0] = 99 \u0026gt;\u0026gt;\u0026gt; t[1][1] = \u0026quot;problem\u0026quot; \u0026gt;\u0026gt;\u0026gt; t (1, [99, 'problem']) Equality of contents vs. Identity of objects\n== 和 is 这两个比较方法是有区别的。== 的返回值为 True 当且仅当两个对象的 value 相同。而 is 要求两个变量名指向同一个对象。is 返回值为 True 的 == 必定为 True，反之则不一定。\n\u0026gt;\u0026gt;\u0026gt; list1, list2 = [1, 2, 3], [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; list1 == list2 True \u0026gt;\u0026gt;\u0026gt; list1 is list2 False \u0026gt;\u0026gt;\u0026gt; list2 = list1 \u0026gt;\u0026gt;\u0026gt; list1 is list2 True Mutable Functions Python 函数可以对 parent frame 中的 mutable 的对象进行修改。下面是一个例子：\ndef make_withdraw_account(initial): balance = [initial] def withdraw(amount): if balance[0] - amount \u0026lt; 0: return 'Insufficient funds' balance[0] -= amount return balance[0] return withdraw 注：如果我们想要用一个变量 balance 来存储金额，那么在 withdraw() 函数中就要用 nonlocal balance 来声明下面的 balance 是对 parent frame 中的变量进行的操作。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"948f7432f196a1cc7c4ee014a5372b28","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec14/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec14/","section":"notes","summary":"Objects 对象 (object) 是一组数据和行为 (函数) 的集合。在 Python 中所有的 value 都是对象，对象有一系列属性 (attribute) 也有一系列方法 (method)。比如 Python 中的字符串可以通过索引的方式获取具体位置的数据，也可以使用 upper(), lower() 等方法对其进行操作。\nList Mutation append() 和 extend() 这两个方法的行为是有区别的：\nappend() 只能向 list 的后面添加一个元素。如果 append() 的参数是一个 list，那么它会在本 list 的后面添加一个元素，这个元素是一个 list (形成了一个嵌套的 list) extend() 的参数必须是一个 iterable 的东西，它会将这个东西里的所有元素添加到本 list 中。 \u0026gt;\u0026gt;\u0026gt; s1, s2 = [2, 3] \u0026gt;\u0026gt;\u0026gt; t = [4, 5] \u0026gt;\u0026gt;\u0026gt; s1.","tags":null,"title":"UCB-CS61A Lecture 14: Mutability","type":"docs"},{"authors":null,"categories":null,"content":"Syntax Tree 中间的节点称为 non-terminal，叶子节点称为 terminal，一个 syntax tree 描述了一个句子的句法结构。\n我们可以使用上一课中提到的嵌套列表的方法作为 syntax tree 这一抽象的实现：\ndef phrase(tag, branches): return tree(tag, branches) def word(tag, text): return tree([tag, text]) def text(word): return label(word)[1] def tag(t): \u0026quot;\u0026quot;\u0026quot;Return the tag of a phrase or word.\u0026quot;\u0026quot;\u0026quot; if is_leaf(t): return label(t)[0] else: return label(t) Generating Sentences 一个 language model 描述了每种文本出现的概率。我们可以使用 sampling 的方法根据一个 language model 来生成语言。\nlanguage model 中有很多 syntax tree，树上的每个节点都被打了标签。我们首先遍历所有的树来获取每种 tag 的节点列表：\ndef index_trees(trees): index = {} for t in trees: for tag, node in nodes(t): if tag not in index: index[tag] = [] index[tag].append(node) return index trees = [tokens_to_parse_tree(s) for s in all_sentences()] tree_index = index_trees(trees) 接下来我们可以根据 index 列表来生成一句新的话：我们从一棵已有的 syntax tree 开始，每次随机决定是否将一个子树换成 tag 相同的另一个子树：\ndef gen_tree(t, tree_index, flip): new_branches = [] if is_leaf(t): return t for b in branches(t): if flip(): b = random.choice(tree_index[tag(b)]) new_branches.append(gen_tree(b, tree_index, flip)) return phrase(tag(t), new_branches) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a004330317bd69dd88815ec7909d5a36","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec15/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec15/","section":"notes","summary":"Syntax Tree 中间的节点称为 non-terminal，叶子节点称为 terminal，一个 syntax tree 描述了一个句子的句法结构。\n我们可以使用上一课中提到的嵌套列表的方法作为 syntax tree 这一抽象的实现：\ndef phrase(tag, branches): return tree(tag, branches) def word(tag, text): return tree([tag, text]) def text(word): return label(word)[1] def tag(t): \u0026quot;\u0026quot;\u0026quot;Return the tag of a phrase or word.","tags":null,"title":"UCB-CS61A Lecture 15: Syntax","type":"docs"},{"authors":null,"categories":null,"content":"Iterators 迭代器 (iterator) 是一种对象，提供了对某个 itarable 的 sequential access。iter(iterable) 会返回一个指向 iterable 第一个元素的 iterator，之后可以用 next() 函数来查看后续的元素。\ntoppings = [\u0026quot;pineapple\u0026quot;, \u0026quot;pepper\u0026quot;, \u0026quot;mushroom\u0026quot;, \u0026quot;roasted red pepper\u0026quot;] topperator = iter(toppings) next(topperator) # 'pineapple' next(topperator) # 'pepper' next(topperator) # 'mushroom' next(topperator) # 'roasted red pepper' next(topperator) # ❌ StopIteration exception 注：如果给 iter() 传入的参数是 iterator，那么它会返回一个一样的 iterator。\n\u0026gt;\u0026gt;\u0026gt; topperator2 = iter(topperator) \u0026gt;\u0026gt;\u0026gt; topperator is topperator2 True list, tuple, dictionary, string, range 都属于 iterable，这里提一下对于字典的访问：从 Python 3.6 开始，字典中的元素按照它们插入的顺序排列，使用 iter(dic.keys()) 可以获得 key 的 iterator；使用 iter(dic.values()) 可以获得 value 的 iterator；使用 iter(dic.items)) 可以获得 key-value pair 的 iterator。\n如果在 for 循环中使用 iterator，那么每次执行完循环体后 Python 都会调用 next() 让 iterator 指向下一个元素，直到没有更多元素：\nnums = range(1, 4) num_iter = iter(nums) first = iter(num_iter) # 1 for num in num_iter: print(num) # 2 # 3 # 4 Useful Bulit-in Functions 一些比较好用的返回 iterable 的函数：\nlist(iterable)：返回一个 list，该 list 中的元素是 iterable 中的元素 (这里传入的也可以是一个 iterator)。 tuple(iterable)：类似，返回一个 tuple。 sorted(iterable) ：返回一个 list，里面的元素是排好序的。 一些比较好用的返回 iterator 的函数：\nmap(func, iterable) 会对 iterable 中的每个元素 x 执行 func(x)，并返回一个 iterator。我们可以用 list(map(func, iterable)) 的方式来获得列表，这句话的功能和 [func(x) for x in iterable] 等价。\nfilter(func, iterable) 会保留 iterable 中那些满足 func(x) 为 True 的元素 x，并返回一个 iterator。list(filter(func, iterable)) 的功能和 [x for x in iterable if func(x)] 等价。\nzip(*iterables) 接收两个 iterable，将这个 iterable 处于相同下标的元素组成 pair，返回一个 pair list 的 iterator。例如：\nnum1, num2 = [1, 2, 3], [4, 5, 6] num_pairs = list(zip(num1, num2)) for n1, n2 in num_pairs: print(n1, n2) # 1 4 # 2 5 # 3 6 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e489955486c6134286b2e4e3049e7e9b","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec16/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec16/","section":"notes","summary":"Iterators 迭代器 (iterator) 是一种对象，提供了对某个 itarable 的 sequential access。iter(iterable) 会返回一个指向 iterable 第一个元素的 iterator，之后可以用 next() 函数来查看后续的元素。\ntoppings = [\u0026quot;pineapple\u0026quot;, \u0026quot;pepper\u0026quot;, \u0026quot;mushroom\u0026quot;, \u0026quot;roasted red pepper\u0026quot;] topperator = iter(toppings) next(topperator) # 'pineapple' next(topperator) # 'pepper' next(topperator) # 'mushroom' next(topperator) # 'roasted red pepper' next(topperator) # ❌ StopIteration exception 注：如果给 iter() 传入的参数是 iterator，那么它会返回一个一样的 iterator。","tags":null,"title":"UCB-CS61A Lecture 16: Iterators","type":"docs"},{"authors":null,"categories":null,"content":"Generators generator function 中不使用 return 返回结果，而使用 yield。generator 是一种 iterator，它通过 generator function 来逐个地获得结果。这里 generator function 可以理解为一个状态机，当遇到 yield 语句时，它会将自己的执行状态暂时封存起来并返回结果。下一次 generator 再次调用该函数时，generator function 将会从上一次 yield 后的第一条语句开始继续执行，直到遇到下一个 yield。如果没有遇到 yield 而是函数一直执行到结束，generator function 会返回一个 StopIteration exception。\n下面是一个例子：\ndef evens(start, end): num = start + (start % 2) while num \u0026lt; end: yield num num += 2 for num in evens(55, 61): print(num) # 56 # 58 # 60 这个例子的功能和\nevens = [num for num in range(55, 61) if num % 2 == 0] 相同。使用 generator 的好处时 generator function 每次只生成下一个元素。如果列表很长，直接生成出整个列表再遍历的方式会消耗很多内存。\nYield From yield from 语句可以将一个 iterable 中的元素逐个 yield 出去。例如下面两段程序的功能等价：\ndef yield_list(a): for item in a: yield item def yield_list(a): yield from a 更有趣的用法是：yield from 后面跟的东西可以是 generator function，甚至是自己本身这个 generator function，我们可以利用这个性质写出一些类似于”递归“ 的 generator function。下面是一个”递归“版本的 countdown：\ndef countdown(k): if k \u0026gt; 0: yield k yield from countdown(k - 1) Generator Functions with Returns 如果 generator function 执行过程中遇到 return，那么即使下次再调用后面的内容也不会再执行，return value 不会作为 yield 的一部分。如果你确实想要将返回值也 yield 出来，可以这样写：\ndef g(x): yield x yield x + 1 return x + 2 def h(x): r = yield from g(x) yield r list(h(2)) # [2, 3, 4] Example 下面展示一个用 generator function 来生成所有整数 partition 的例子：\ndef partitions(n, m): \u0026quot;\u0026quot;\u0026quot;List partitions. \u0026gt;\u0026gt;\u0026gt; for p in partitions(6, 4): print(p) 4 + 2 4 + 1 + 1 3 + 3 3 + 2 + 1 3 + 1 + 1 + 1 2 + 2 + 2 2 + 2 + 1 + 1 2 + 1 + 1 + 1 + 1 1 + 1 + 1 + 1 + 1 + 1 \u0026quot;\u0026quot;\u0026quot; if n \u0026lt; 0 or m == 0: return else: if n == m: yield str(m) for p in partitions(n-m, m): yield str(m) + \u0026quot; + \u0026quot; + p yield from partitions(n, m - 1) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"bf94f134ad362c3f707f7c5f5159e4d2","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec17/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec17/","section":"notes","summary":"Generators generator function 中不使用 return 返回结果，而使用 yield。generator 是一种 iterator，它通过 generator function 来逐个地获得结果。这里 generator function 可以理解为一个状态机，当遇到 yield 语句时，它会将自己的执行状态暂时封存起来并返回结果。下一次 generator 再次调用该函数时，generator function 将会从上一次 yield 后的第一条语句开始继续执行，直到遇到下一个 yield。如果没有遇到 yield 而是函数一直执行到结束，generator function 会返回一个 StopIteration exception。","tags":null,"title":"UCB-CS61A Lecture 17: Generators","type":"docs"},{"authors":null,"categories":null,"content":"Python OOP Terminology 类 (class) 是一个定义新的数据类型的模板。 class 的一个具体的实例 (instance) 被称为对象 (object)。 每个对象有一些 data attribute，称为 instance variable；每个对象也有一些 function attribute，称为 method。 Classes Class Instantiation pina_bar = Product('Piña Chocolotta\u0026quot;, 7.99, [\u0026quot;200 calories\u0026quot;, \u0026quot;24 g sugar\u0026quot;]') 这里的 Product(args) 称为 constructor，constructor 被调用时，Python 会创建 class 的一个实例并调用 class 中的 __init__() 函数，该函数的第一个参数是对象自己，用 self 表示。\nclass Product: def __init__(self, name, price, nutrition_info): self.name = name self.price = price self.nutrition_info = nutrition_info self.inventory = 0 在 __init__() 中，你可以定义 instance variable 并赋予它们初始值。该 class 的其他 method 可以使用和修改这些 instance variable。\nMethod Invocation pina_bar.increase_inventory(2) 调用了该 class 中的一个 method。\nclass Product: def increase_inventory(self, amount): self.invetory += amount 这里的 pina_bar.increase_inventory() 是一个 bound method：第一个参数被预先绑定为了 self，之后传参数只需要传一个就行。pina_bar.increase_inventory(2) 和 Product.increase_inventory(pina_bar, 2) 是等价的。\nClass Variables class variable 是指不在任何一个 method 中赋值的变量，例如：\nclass Product: sales_tax = 0.07 class variable 的特点在于所有该 class 的 instance 都有这个变量 (注：不同 instance 对该变量的修改是彼此不可见的)。\nAccessing Attributes getattr() 函数允许我们通过 string 的方式来查询一个 attribute 的值。hasattr() 可以查询某个 attribute 是否存在：\ngetattr(pina_bar, 'inventory') # 1 hasattr(pina_bar, 'reduce_inventory') # True Private v.s. Public Python 的所有 attribute 都是 public 的。一个常见的约定是：如果某个 attribute 的名字以下划线开头，那么该 attritube 被认为是 private 的，虽然从语法上你仍然可以直接访问它，但你应当通过 public method call 对其进行操作。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1691d72ac2f1ee07628772a267bd9ab4","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec18/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec18/","section":"notes","summary":"Python OOP Terminology 类 (class) 是一个定义新的数据类型的模板。 class 的一个具体的实例 (instance) 被称为对象 (object)。 每个对象有一些 data attribute，称为 instance variable；每个对象也有一些 function attribute，称为 method。 Classes Class Instantiation pina_bar = Product('Piña Chocolotta\u0026quot;, 7.99, [\u0026quot;200 calories\u0026quot;, \u0026quot;24 g sugar\u0026quot;]') 这里的 Product(args) 称为 constructor，constructor 被调用时，Python 会创建 class 的一个实例并调用 class 中的 __init__() 函数，该函数的第一个参数是对象自己，用 self 表示。","tags":null,"title":"UCB-CS61A Lecture 18: Objects","type":"docs"},{"authors":null,"categories":null,"content":"Motivation 比如我们想要定义一些动物的 class：rabbit, elephant, lion\u0026hellip; 它们作为动物有一些共同的属性和方法，各自也有独特的属性和方法。那么与其在各自的 class 中重复书写代码，我们不如定义一个动物 class，在这个 class 中定义动物共有的属性和方法，然后为各个动物建立 subclass，让这些 subclass 继承 (inherit) 动物 class。\nInheritance 上文中的动物 class 称为 base class，或者 superclass。下面是一个例子：\nclass Animal: species_name = \u0026quot;Animal\u0026quot; scientific_name = \u0026quot;Animalia\u0026quot; play_multiplier = 2 interact_increment = 1 def __init__(self, name, age=0): self.name = name self.age = age self.calories_eaten = 0 self.happiness = 0 def eat(self, food): self.calories_eaten += food.calories print(f\u0026quot;Om nom nom yummy {food.name}\u0026quot;) if self.calories_eaten \u0026gt; self.calories_needed: self.happiness -= 1 print(\u0026quot;Ugh so full\u0026quot;) class AmorphousBlob(Animal): # 在括号中写上superclass的名字！ pass subclass 中可以定义已经存在的变量和方法，这被称为 overriding。\n在 subclass 的 method 中如果想要使用 superclass 中的内容，可以用 super().xxx 的方式访问。\nMultiple Inheritance 一个 class 可以继承多个 class 的内容，下面是一个例子：\nclass Predator(Animal): def interact_with(self, other): if other.type == \u0026quot;meat\u0026quot;: self.eat(other) print(\u0026quot;om nom nom, I'm a predator\u0026quot;) else: super().interact_with(other) class Prey(Animal): type = \u0026quot;meat\u0026quot; calories = 200 接下来我们可以定义一些动物 class，同时继承 Animal 和 Predator/Prey：\nclass Rabbit(Prey, Animal): pass class Lion(Predator, Animal): pass Python 会在所有的 superclass 中寻找对应的属性和方法。\nComposition 一个对象中可以包含其他 class 对象的 refenrence。例如我们可以在 animal 类中添加一个 mate 属性：\nclass Animal: def mate_with(self, other): if other is not self and other.species_name == self.species_name: self.mate = other other.mate = self Composition v.s. Inheritance Inheritance 适合表示 \u0026ldquo;is-a\u0026rdquo; 关系：\nRabbit is a specific type of animal, so Rabbit inherits from Animal. Composition 适合表示 \u0026ldquo;has-a\u0026rdquo; 关系：\nAn animal has a mate, so Animal has mate as an instance variable. Quiz class Parent: def f(s): print(\u0026quot;Parent.f\u0026quot;) def g(s): s.f() class Child(Parent): def f(me): print(\u0026quot;Child.f\u0026quot;) a_child = Child() a_child.g() 有两点需要注意：\nclass 中的 method 都是 bound method，第一个参数代表的是自己，不论这个参数名字是 self s 还是 me 效果都是一样的。 在执行到 Parent 中的 g() 时，由于 Child override 了 f() 方法，所以 g() 调用的是 Child 中的 f 而不是 Parent 中的 f。 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ff9757993a01ee2038bc79df60f0f2de","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/lectures/lec19/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/lectures/lec19/","section":"notes","summary":"Motivation 比如我们想要定义一些动物的 class：rabbit, elephant, lion\u0026hellip; 它们作为动物有一些共同的属性和方法，各自也有独特的属性和方法。那么与其在各自的 class 中重复书写代码，我们不如定义一个动物 class，在这个 class 中定义动物共有的属性和方法，然后为各个动物建立 subclass，让这些 subclass 继承 (inherit) 动物 class。\nInheritance 上文中的动物 class 称为 base class，或者 superclass。下面是一个例子：\nclass Animal: species_name = \u0026quot;Animal\u0026quot; scientific_name = \u0026quot;Animalia\u0026quot; play_multiplier = 2 interact_increment = 1 def __init__(self, name, age=0): self.","tags":null,"title":"UCB-CS61A Lecture 19: Inheritance","type":"docs"},{"authors":null,"categories":null,"content":"随着科学技术的发展, 在国际学术交流中使用英语已经成为常态: 顶尖的论文无一不使用英文来书写, 在国际上公认的计算机领域经典书籍也是使用英文编著。顶尖的论文没有中文翻译版; 如果需要获取信息, 也应该主动去阅读英文材料, 而不是等翻译版出版。\u0026ldquo;我是中国人, 我只看中文\u0026quot;这类观点已经不符合时代发展的潮流, 要站在时代的最前沿, 阅读英文材料的能力是不可或缺的。\n想要学好计算机，大家一定要趁早“逼迫”自己熟悉英语环境，尤其强化自己的英语阅读能力 (将来快速略读大段的英文手册很可能是你的工作/学习常态)。我们强烈建议你注意以下几个方面：\n不要依赖教材的中文翻译版本。 将来大家学习的《算法导论》等教材是比较容易找到中文翻译版本的，但正如名著的翻译版时常体现不出名著本身的意境，翻译版的教材在很多细节上可能与原版有出入，影响大家的理解，也不利于大家熟悉一些英文术语。我们认为，英文阅读能力合格的标准之一便是阅读学术方面的英文材料和中文材料应该基本不存在速度差异。这个过程刚开始可能会比较痛苦，但随着学期深入大家一定能克服障碍。大家也不必对这个标准感到过于惊慌，因为助教认为自己的英语阅读能力也不合格 不要依赖百度等中文网站解决问题。 在刚刚接触计算机以及学习算法的初级阶段，中文的博客 (以CSDN为主) 可以帮助大家解决一部分问题。但随着大家水平的提高，很多复杂的问题 (尤其是与系统配置，环境配置相关的问题) 在中文环境下很难找到契合的回答。这时推荐大家使用对应的英文关键字在 google/bing/stackoverflow 上搜索回答。 (如果我想到了会再添加) 英语的学习和强化方法是一个见仁见智的问题。我们的建议是不要期待 大学英语读写/大学英语视听说 能给你带来质的改变。提升语言能力的核心还是多读多听多说多写。引用陈道蓄老师的话: “坚持一年, 你就会发现有不同; 坚持两年, 你就会发现大有不同。”\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"bae75e576fd11fe5715aec4b63cf2228","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/cser0/english/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/cser0/english/","section":"courses","summary":"随着科学技术的发展, 在国际学术交流中使用英语已经成为常态: 顶尖的论文无一不使用英文来书写, 在国际上公认的计算机领域经典书籍也是使用英文编著。顶尖的论文没有中文翻译版; 如果需要获取信息, 也应该主动去阅读英文材料, 而不是等翻译版出版。\u0026ldquo;我是中国人, 我只看中文\u0026quot;这类观点已经不符合时代发展的潮流, 要站在时代的最前沿, 阅读英文材料的能力是不可或缺的。\n想要学好计算机，大家一定要趁早“逼迫”自己熟悉英语环境，尤其强化自己的英语阅读能力 (将来快速略读大段的英文手册很可能是你的工作/学习常态)。我们强烈建议你注意以下几个方面：\n不要依赖教材的中文翻译版本。 将来大家学习的《算法导论》等教材是比较容易找到中文翻译版本的，但正如名著的翻译版时常体现不出名著本身的意境，翻译版的教材在很多细节上可能与原版有出入，影响大家的理解，也不利于大家熟悉一些英文术语。我们认为，英文阅读能力合格的标准之一便是阅读学术方面的英文材料和中文材料应该基本不存在速度差异。这个过程刚开始可能会比较痛苦，但随着学期深入大家一定能克服障碍。大家也不必对这个标准感到过于惊慌，因为助教认为自己的英语阅读能力也不合格 不要依赖百度等中文网站解决问题。 在刚刚接触计算机以及学习算法的初级阶段，中文的博客 (以CSDN为主) 可以帮助大家解决一部分问题。但随着大家水平的提高，很多复杂的问题 (尤其是与系统配置，环境配置相关的问题) 在中文环境下很难找到契合的回答。这时推荐大家使用对应的英文关键字在 google/bing/stackoverflow 上搜索回答。 (如果我想到了会再添加) 英语的学习和强化方法是一个见仁见智的问题。我们的建议是不要期待 大学英语读写/大学英语视听说 能给你带来质的改变。提升语言能力的核心还是多读多听多说多写。引用陈道蓄老师的话: “坚持一年, 你就会发现有不同; 坚持两年, 你就会发现大有不同。”","tags":null,"title":"English","type":"docs"},{"authors":null,"categories":null,"content":"正所谓“工欲善其事，必先利其器”，想要拥有良好的代码书写体验就应当配置好一套舒适的代码编写环境。打开 Windows 的“记事本”编写代码可不是什么好的选择——一方面记事本无法提供代码高亮、自动补全、智能缩进等功能，盯着白纸黑字写代码颇为心累；另一方面即使你写完了代码，记事本也没有集成好配套的编译、调试工具帮助你确定代码的正确性。\n很多优秀的程序员都会选择 IDE (Integrated Development Environment，中文翻译为集成开发环境）来书写代码。所谓集成开发环境，就是将写代码所需要的一系列工具都集成在了一个软件里，从书写代码所需的编辑器，到编译运行代码所需的编译器、链接器，到调试代码所需的调试器……IDE里应有尽有，且很多功能都可以“一键运行”，极好地将程序员的精力解放了出来。\n由于本课程主要希望培养大家掌握 C/C++ 这门语言，所以我们着重介绍了几个和 C/C++ 配合体验良好的 IDE，包括 Dev-C++ (极其推荐新手入门使用，入门门槛低)，Visual Studio (工业级的重型IDE，功能强大但身材略显臃肿), Visual Studio Code (宇宙最强编辑器) 等，大家可以参考杜星宇助教撰写的 这篇文档 来学习。\n如果你已经是比较有经验的代码书写者，你可能并不需要 IDE。你也许会习惯使用 Vim/Emacs 等老牌编辑器，自己写脚本编译和运行代码，使用 GDB 进行调试……如果你能驾驭这些，我们当然也鼓励你充分地使用这些命令行工具。不过我们还是极力地推荐你尝试一下 VS Code (这不是为微软打广告)，其丰富的第三方插件库，强大的远程连接功能，自由的代码跳转、补全、纠错使其成为编辑器界的 killer application。毕竟写代码怎么舒服怎么来，能拥有一个 这样 炫酷的界面何乐而不为呢？\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b5ddf09ec14c22b1ab33962aeaa17411","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/cser0/ide/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/cser0/ide/","section":"courses","summary":"正所谓“工欲善其事，必先利其器”，想要拥有良好的代码书写体验就应当配置好一套舒适的代码编写环境。打开 Windows 的“记事本”编写代码可不是什么好的选择——一方面记事本无法提供代码高亮、自动补全、智能缩进等功能，盯着白纸黑字写代码颇为心累；另一方面即使你写完了代码，记事本也没有集成好配套的编译、调试工具帮助你确定代码的正确性。\n很多优秀的程序员都会选择 IDE (Integrated Development Environment，中文翻译为集成开发环境）来书写代码。所谓集成开发环境，就是将写代码所需要的一系列工具都集成在了一个软件里，从书写代码所需的编辑器，到编译运行代码所需的编译器、链接器，到调试代码所需的调试器……IDE里应有尽有，且很多功能都可以“一键运行”，极好地将程序员的精力解放了出来。\n由于本课程主要希望培养大家掌握 C/C++ 这门语言，所以我们着重介绍了几个和 C/C++ 配合体验良好的 IDE，包括 Dev-C++ (极其推荐新手入门使用，入门门槛低)，Visual Studio (工业级的重型IDE，功能强大但身材略显臃肿), Visual Studio Code (宇宙最强编辑器) 等，大家可以参考杜星宇助教撰写的 这篇文档 来学习。\n如果你已经是比较有经验的代码书写者，你可能并不需要 IDE。你也许会习惯使用 Vim/Emacs 等老牌编辑器，自己写脚本编译和运行代码，使用 GDB 进行调试……如果你能驾驭这些，我们当然也鼓励你充分地使用这些命令行工具。不过我们还是极力地推荐你尝试一下 VS Code (这不是为微软打广告)，其丰富的第三方插件库，强大的远程连接功能，自由的代码跳转、补全、纠错使其成为编辑器界的 killer application。毕竟写代码怎么舒服怎么来，能拥有一个 这样 炫酷的界面何乐而不为呢？","tags":null,"title":"Coding Environment","type":"docs"},{"authors":null,"categories":null,"content":"A. 最短路1 题面描述 给一张 $n$ 个点 $m$ 条边的有向带权图，求 $1$ 号点到所有点的最短路长度。 $n\\leq 10^5,m\\leq 2\\times 10^5,1\\leq w_i\\leq 10^9$​。 题解 直接使用 Dijkstra 算法求单源最短路即可，注意开 long long。\nB. 最短路2 题面描述 给一张 $n$ 个点 $m$ 条边的有向带权图，求 $1$ 号点到所有点的最短路长度。\n$n\\leq 2000,m\\leq 5000,-10^9\\leq w_i\\leq 10^9$​。\n题解 本题图中有负权边，因此应该使用 Bellman-Ford 算法求最短路。总时间复杂度 $O(nm)$。\nC. 最短路计数 题面描述 给一张 $n$ 个点 $m$ 条边的有向带权图，求 $1$ 号点到所有点的最短路的条数。 $n\\leq 10^6,m\\leq 2\\times 10^6,1\\leq w_i\\leq 10^9$​。 题解 先用 Dijkstra 算法求出最短路，然后以最短路长度为顺序进行 dp，对于满足 $dist[u]+w(u,v)=dist[v]$ 的边 $(u,v)$ 进行转移。\n总时间复杂度 $O(mlogm+n)$。\nD. Le Mythe De Acesrc 题面描述 给定一个 $n$ 个数的集合 ${a_1,a_2,\u0026hellip;,a_n}$，有 $q$ 个询问，每次给定一个 $x$ ，问 $x$ 是否能用集合中的若干个数相加得到（一个数可以用多次）。 $n\\leq 10000,1\\leq a_i\\leq 20000,x\\leq 10^9$​​，$a_i$ 按照递增序给出。 题解 考虑最短路对 $a_n$​ 取模的值，令 $f[i]=argmin_{x}[(x\\cdot a_n+i)$​可以构造出来$]$。如果求出了数组 $f$ ，对于一个询问 $x$ ，只要 $\\left\\lfloor x/a_n\\right\\rfloor\u0026gt;f[x\\space mod \\space a_n]$，就可以构造出来（因为有无限个 $a_n$​​ 可用），否则不行。\n现考虑如何计算 $f[i]$。建图，对于 $i$ 和 $j$，如果存在一个 $a_k$ 使得 $i+a_k=j$​ ，则建一条从 $i$ 到 $j$ ，边权为 $0$ 的有向边；如果存在一个 $a_k$ 使得 $i+a_k=a_n+j$，则建一条从 $i$ 到 $j$ ，边权为 $1$ 的边。这样只要在图上跑一个 01bfs 即可。\n总时间复杂度 $O(na_n+q)$。\n补充题1. [Luogu1462] 通往奥格瑞玛的道路 题面描述 传送门 给一个 $n$ 个点 $m$ 条边的无向图。每条边有一个权值 $w_i$ 表示经过这条边需要耗费的血量。每个顶点有一个权值 $f_i$ 表示经过这个点需要耗费的钱。现从 $1$ 号点出发到 $n$ 号点，对于一条路径，其耗费血量定义为经过的所有边的耗费之和，其耗费的钱定义为经过的所有节点的耗费的最大值。给定初始血量 $b$，问在能够到达终点的情况下耗费钱的最小值。 $n\\leq 10000,m\\leq 500000$。 题解 二分答案，这样我们每次只要将大于答案的点以及与之相关的边从图中去掉，在剩下的图中跑最短路即可。\n补充题2. [Luogu2371] 墨墨的等式 题面描述 传送门 给定 $a_1,a_2,\u0026hellip;,a_n$ 和 $[l,r]$ ，对于方程组 $\\sum_{i=1}^na_ix_i=b$​​，求有多少个 $b\\in [l,r]$ 使得原方程组有非负整数解。 $n\\leq 12,1\\leq a_i\\leq 5\\times 10^5,1\\leq l\\leq r\\leq 10^{12}$。 题解 D题是本题的弱化版。欲解决本题，在求出 dist 数组之后，只需要分类枚举 $a_n$ 的所有余数，然后计算有多少个数落在了 $[l,r]$ 区间内即可。\n总时间复杂度 $O(na_n)$。\n补充题3. [Luogu4822] 冻结 题面描述 传送门 给定一张 $n$ 个点 $m$ 条边的图。每条边有一个权值，保证是偶数。现在可以使用不超过 $k$ 次魔法，使用一次魔法可以使得一条边的权值变为原来的一半，每条边至多只能被使用一次魔法。求最短路。 $n\\leq 50,m\\leq 1000$。 题解 由于最短路经过的边数不会超过 $n$ ，因此实际上 $k$ 可以和 $n$ 取 min（在本题的原限制中 $k$ 已经满足该条件）。\n考虑重新建图。令 $dist[u][i]$ 表示到点 $u$ ，恰好使用了 $i$ 次魔法的情况下的最小代价。对于原图中的每一条边 $(u,v,w)$，在新图中连边 $((u,i),(v,i),w)$ 和 $((u,i),(v,i+1),w/2)$。\n新图共有 $n\\times k$ 个节点，$m\\times k$ 条边，在这张图上跑 Dijkstra 即可。\n总时间复杂度 $O(mklog(mk))$。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c7d59cc55e7755cfc3a8089fd47c061b","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iii-01/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iii-01/","section":"notes","summary":"A. 最短路1 题面描述 给一张 $n$ 个点 $m$ 条边的有向带权图，求 $1$ 号点到所有点的最短路长度。 $n\\leq 10^5,m\\leq 2\\times 10^5,1\\leq w_i\\leq 10^9$​。 题解 直接使用 Dijkstra 算法求单源最短路即可，注意开 long long。\nB. 最短路2 题面描述 给一张 $n$ 个点 $m$ 条边的有向带权图，求 $1$ 号点到所有点的最短路长度。","tags":null,"title":"问题求解 III - 01 题解","type":"docs"},{"authors":null,"categories":null,"content":"A. 最长路 题面描述 给定一个 $n$ 个点 $m$ 条边的有向无环图，求图中最长路的长度。 $1\\leq n\\leq 2\\times 10^{5},1\\leq m\\leq min\\{\\frac{n(n-1)}{2},5\\times 10^5\\}$。 题解 令 $dp[u]$ 表示从节点 $u$ 出发的最长路长度，则 $dp[u]=max_{(u,v)\\in E} dp[v]+w(u,v)$。\n总时间复杂度 $O(n+m)$。\nB. 旅行问题 题面描述 给定一个 $n$ 个点的完全图，$A_{ij}$ 表示从 $i$ 到 $j$ 的边权。现要求从任意一点出发，至少经过每个点一次，到任意一点结束，求最小路径长度。 $n\\leq 20$。 题解 先用 Floyd 预处理两两之间的最短路 $dist[i][j]$。然后考虑状压 dp: 令 $dp[Mask][i]$ 表示当前在节点 $i$ ，已经经过的点的状态为 $Mask$ 的情况下的最小距离，转移考虑枚举上一个节点 $j$ 即可。即 $$ dp[Mask][i]=\\min_{j\\in Mask,j\\neq i}dp[Mask-j][j]+dist[i][j] $$ 注意我们无需担心在从 $i$ 到 $j$ 的最短路上经过的其他点没有被标注进 $Mask$，因为如果没有被标注进是对答案的损失，而事实上一定有一种转移方式是正确的。\n总时间复杂度 $O(2^nn^2)$。\nC. 修建公路 题面描述 给定一个 $n$ 个点，没有边的图。再给定 $m$ 条有向边，将其一一加入图中。问对于每一个 $1\\leq i\\leq m$，在第 $i$ 条边被加入后，有多少个有序对 $(u,v),u\\neq v$ 满足有从 $u$ 到 $v$ 的路径。 $n\\leq 400$。 题解1 考虑给每条边一个权值：它被加入图的时间。定义一条路径的长度为经过的所有边的权值的最大值。则我们用 Floyd-Warshall 算法可以求出多源最短路（考虑 Floyd 的动态规划过程易证其正确性），这个最短路长度 $d(u,v)$ 的意义是从时刻 $d(u,v)$ 开始，以后一直存在从 $u$ 到 $v$ 的路径。因此我们枚举每个点对，根据 $d$ 值看它对答案的贡献即可。\n总时间复杂度 $O(n^3)$。\n题解2 对于每条新加的边 $(u,v)$ ，如果在此之前 $u$ 已经可以到 $v$ ，则这条边加的没有意义。否则我们考虑这条边的加入会给传递闭包带来什么影响。\n考虑对每个节点维护两个 bitset，$b_1(u)$ 表示 $u$ 目前可达的点，$b_2(u)$ 表示目前可达 $u$ 的点。那么对于 $(u,v)$，我们考虑 $b_2(u)$ 中的所有点，给它们的 $b_1$ bitset 或上 $b_1(v)$ 即可，同理对于$b_1(v)$ 中的所有点给它们的 $b_2$ bitset 或上 $b_2(u)$。这样的复杂度为 $O(\\frac{mn^2}{w})$，不能通过。\n考虑做一个简单的优化：对于 $b_2(u)$ 中的点，如果它们可以在加入 $(u,v)$ 之前就可以到达 $v$ ，那么显然这次或操作是无效的，因此我们只对那些 可以到 $u$ 但不能到 $v$ 的节点 进行或操作（这些节点可以通过位运算快速得出）。我们可以证明这样进行或操作的次数最多 $O(n^2)$ 次：\n$n$ 个点的 bitset 中一共有 $O(n^2)$ 个位置，每次或操作至少可以使 bitset 中到 $v$ 的那个位置从 0 变成 1，因此每次或操作都会使 1 的个数增加，所以最多有 $O(n^2)$ 次或操作。\n对于 $v$ 可到但 $u$ 不能到 的节点也是同理。通过复杂度分析，我们可以看到该算法的复杂度降到 $O(\\frac{n^3}{w})$。\nD. 倍数 题面描述 给定整数 $n$ ，问所有的 $n\\times k (k\u0026gt;0)$ 在二进制表示下 $1$​ 的个数最少是多少。 $n\\leq 10^6$。 题解 任何一个 $n$ 的倍数都可以通过这个方式生成：\n进行以下操作有限次：\n给当前数 $+n$ 并 $\\times 2$ ，或者给当前数 $+0$ 并 $\\times 2$。\n这样生成的数必定可以被表示为 $\\sum n\\times 2^k$ 的形式，因此可以表示所有的 $n$ 的倍数。\n考虑如下动态规划：令 $dp[i]$ 表示生成一个前缀为 $i$ 的数，在 $i$ 之后的部分最少有多少个 $1$ 。考虑向后转移：进行一次上述的操作可以确定二进制下的一位，所以 $$ \\begin{align} dp[i\u0026gt;\u0026gt;1] \u0026amp;\\leftarrow dp[i]+(i\\\u0026amp;1) \\\\ dp[(i+n)\u0026gt;\u0026gt;1]\\ \u0026amp;\\leftarrow dp[i]+((i+n)\\\u0026amp;1) \\end{align} $$ 由于我们不能确定转移的顺序，所以可以建图之后跑最短路。注意到边权只有 $0$ 和 $1$ 两种，所以用 01bfs 即可。\n总时间复杂度 $O(n)$。\n补充题1. [POJ1734] Sightseeing Trip 题面描述 传送门 给定一个 $n$ 个点 $m$ 条边的无向图，要求在其中找到一个点数大于 $2$ 的环，使其边权之和最小，输出这个圈或者输出 No solution. 。 $n\\leq 100,m\\leq 10000$。 题解 对 Floyd-Warshall 算法的应用。考虑 Floyd 原式的动态规划思想，在第 $k$ 轮循环开始时，$dist[i][j]$ 保存的是从 $i$ 到 $j$ 且中间只经过了 $1$~$k-1$ 的最短距离。因此在第 $k$ 轮循环开始时，我们考虑所有编号最大的点是 $k$ 的环，我们枚举与 $k$ 相邻的两个点 $i$ 和 $j$ $(i,j\u0026lt;k)$，用 $dist[i][j]$ 和 $k$ 与 $i$ ，$k$ 与 $j$ 的边权之和来更新答案。\n欲打印这个圈，我们对每个 $dist[i][j]$ 额外记录一个 $mid[i][j]$ 表示最短路中权值最大的点是哪个。这样可以将路径分成 $i\\rightsquigarrow mid[i][j]$ 和 $mid[i][j]\\rightsquigarrow j$ 两部分，递归求解。须要注意的是，路径必须在找到更短路径的同时就出来，否则在后续循环中 $mid[i][j]$ 会被更新。\n总时间复杂度 $O(n^3)$。\n补充题2. [Luogu1119] 灾后重建 题面描述 传送门 给定一个 $n$ 个点 $m$ 条边的图，第 $i$ 个点会在 $t_i$ 时刻以及之后开放。有 $q$ 个询问，每个询问给定 $x,y,t$ ，问在 $t$ 时刻从 $x$ 到 $y$ 的最短距离。 $n\\leq 200,q\\leq 50000$。 题解 仍然是对 Floyd-Warshall 算法的应用。我们按照节点开放的时间顺序作为中转点进行 floyd 并实时计算当前应该计算的询问即可。总时间复杂度 $O(n^3)$。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"707b9626961771a76325b7433c68b736","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iii-02/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iii-02/","section":"notes","summary":"A. 最长路 题面描述 给定一个 $n$ 个点 $m$ 条边的有向无环图，求图中最长路的长度。 $1\\leq n\\leq 2\\times 10^{5},1\\leq m\\leq min\\{\\frac{n(n-1)}{2},5\\times 10^5\\}$。 题解 令 $dp[u]$ 表示从节点 $u$ 出发的最长路长度，则 $dp[u]=max_{(u,v)\\in E} dp[v]+w(u,v)$。\n总时间复杂度 $O(n+m)$。\nB. 旅行问题 题面描述 给定一个 $n$ 个点的完全图，$A_{ij}$ 表示从 $i$ 到 $j$ 的边权。现要求从任意一点出发，至少经过每个点一次，到任意一点结束，求最小路径长度。 $n\\leq 20$。 题解 先用 Floyd 预处理两两之间的最短路 $dist[i][j]$。然后考虑状压 dp: 令 $dp[Mask][i]$ 表示当前在节点 $i$ ，已经经过的点的状态为 $Mask$ 的情况下的最小距离，转移考虑枚举上一个节点 $j$ 即可。即 $$ dp[Mask][i]=\\min_{j\\in Mask,j\\neq i}dp[Mask-j][j]+dist[i][j] $$ 注意我们无需担心在从 $i$ 到 $j$ 的最短路上经过的其他点没有被标注进 $Mask$，因为如果没有被标注进是对答案的损失，而事实上一定有一种转移方式是正确的。","tags":null,"title":"问题求解 III - 02 题解","type":"docs"},{"authors":null,"categories":null,"content":"A. 拓扑排序 题面描述 给定 $n$ 个点 $m$ 条边的有向无环图，求字典序最小的拓扑序。 $n,m\\leq 10^5$。 题解 将所有入度为 0 的点加入小根堆，每次取堆顶元素，更新其相邻节点的入度，并将新产生的入度为 0 的点入堆即可。总时间复杂度 $O(m+nlogn)$。\nB. Acesrc Riding the Fences 题面描述 给定 $n$ 个点 $m$ 条边的无向图，保证存在欧拉路径/欧拉回路。求字典序最小的欧拉回路/路径。 $n\\leq 500,m\\leq 1024$。 题解 基于 Fleury 算法的基本思想，给出如下的核心代码。该算法直接贪心地走尽可能小的邻边，不去详细分析某条边是否是桥，如果在有其他选择的时候走了桥，那么在回溯的时候会被自动视为最后走了桥。\nvoid fleury(int cur)\r{\rsta[++stot]=cur;\rrep(i,1,500) if (ga[cur][i])\r{\rga[cur][i]--;ga[i][cur]--;\rfleury(i);\r}\rans[++tot]=sta[stot--];\r}\r时间复杂度 $O(nm)$，使用邻接表存储图可以做到 $O(n+m)$。\nC. 旅行家 题面描述 给定一张 $n$ 个点 $m$ 条边的带权无向图。一条路径的代价是所有边的边权依次连接起来组成的数的大小。求 1 号节点到每个节点的代价的最小值对 $1e9+7$ 取模的结果。 $n,m\\leq 10^5,1\\leq w\\leq 10^9$。 题解 将每条边拆成位数条边，每条边的权值都是一位数，这样对这幅图做宽搜，边数最少的路径一定也是组成的数位数最小的路径。\n一个困难点是如何处理权值相同的点。例如 $x$ 和 $y$ 的权值都是 123，$x$ 先出队并更新 $z$ 的权值为 1234 入队，$y$ 再出队并更新 $w$ 的权值为 1231 入队，这时队列中的单调性就被打破了。\n因此我们应该将权值相同的点一并考虑，对于某种权值，对于所有满足该权值的点，从小到大枚举邻边，并将所有满足条件的相邻点打包起来放进队列。\n新建的图中将有 $10m$ 级别的边，对于宽搜来说量级是可以接受的。\n总时间复杂度 $O(\\mid w\\mid (n+m))$。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"79c867386851a111623785ff9e972d9b","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iii-03/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iii-03/","section":"notes","summary":"A. 拓扑排序 题面描述 给定 $n$ 个点 $m$ 条边的有向无环图，求字典序最小的拓扑序。 $n,m\\leq 10^5$。 题解 将所有入度为 0 的点加入小根堆，每次取堆顶元素，更新其相邻节点的入度，并将新产生的入度为 0 的点入堆即可。总时间复杂度 $O(m+nlogn)$。\nB. Acesrc Riding the Fences 题面描述 给定 $n$ 个点 $m$ 条边的无向图，保证存在欧拉路径/欧拉回路。求字典序最小的欧拉回路/路径。 $n\\leq 500,m\\leq 1024$。 题解 基于 Fleury 算法的基本思想，给出如下的核心代码。该算法直接贪心地走尽可能小的邻边，不去详细分析某条边是否是桥，如果在有其他选择的时候走了桥，那么在回溯的时候会被自动视为最后走了桥。","tags":null,"title":"问题求解 III - 03 题解","type":"docs"},{"authors":null,"categories":null,"content":"A. Acesrc\u0026rsquo;s Bizarre Adventure 题面描述 给定 $n$ 个红色的点和 $n$ 个蓝色的点，每个点有坐标 $(x,y)$。如果一个蓝色的点满足两个坐标都是某个红色点坐标的两倍以上，则该蓝点和红点可以配对。问最多能配成多少对。 $n\\leq 100$。 题解 在可以配对的蓝点和红点之间连边，该问题即转化为二分图最大匹配。可以利用匈牙利算法求解，也可以建立超级源点、超级汇点后求最大流。\nB. Acesrc Doesn\u0026rsquo;t Want To Bite The Dust 题面描述 有 $n$ 个二次函数，第 $i$ 个形如 $f_i(x)=a_ix^2+b_ix+c_i$，要求 $x_i\\in [L_i,R_i]$。有 $m$ 个额外的限制，每个限制是一个三元组 $(u,v,d)$，表示要求 $x_u\\leq x_v+d$。求在满足所有限制的情况下，$\\sum_{i=1}^nf_i(x_i)$ 的最大值。 $n\\leq 50,m\\leq 100,-100\\leq L_i,R_i\\leq 100$。 题解 原型是洛谷3227切糕，比较难想的最小割建模。\n如果没有额外限制，那么一个最小割模型是显然的：对于每个函数，建一条有 $R-L+1$ 条边的链。每条边的容量是二次函数自变量在该处取值时的函数值。将 $n$ 条链的首尾分别与超级源点，超级汇点连接即可。\n现在考虑如何满足额外限制。最小割建模模拟限制的核心思想在于使网络在约束不满足时有无法割去的 $s-t$ 通路。 对于一个 $x_u\\leq x_v+d$，当 $x_v=x$ 时，我们在 $v$ 的函数上割去的是对应 $x$ 的边，那么 $x+1$ 即以上的边都属于 $T$ 集合。如果此时 $x_u\\geq x+d+1$，那么边 $x+d+1$ 左边的节点一定在 $S$ 集合中。因此，我们只要对于每个 $x$，从 $u$ 函数的 $x+d+1$ 边左端点向 $v$ 函数的 $x+1$ 边左端点连容量为 $\\infty$ 的边即可。\n还有一个微小的问题是这样求出的是目标函数的最小值，而我们要求的是最大值。我们可以设定一个很大的阈值 $M$，然后令 $f\u0026rsquo;(x)=M-f(x)$，这样最小化 $\\sum_{i=1}^nf\u0026rsquo;(x_i)$ 就是最大化 $\\sum_{i=1}^nf(x_i)$。\nC. 最小化 题面描述 有 $n$ 个变量，每个取值可以是 $-w$ 或 $w$。有 $q$ 个限制和一些目标函数，求目标函数最小值。 $n\\leq 1000，q\\leq 3000$。 题解 每个变量只有两种取值，这种给一些变量进行二分类的需求是最小割模型的典型特征。\n我们建立超级源点、超级汇点，并给每个变量建一个点。在最终完成最小割的残余网络中，如果一个点连向 $s$ 表示它最终的取值是 $-w$，连向 $t$ 表示它最终的取值是 $w$。考虑如何建边以满足约束。\n每个节点向 $s$ 连容量为 $w$ 的边，表示割去这条边意味着该点去了 $T$，会付出 $w$ 的代价。类似地，每个节点向 $t$ 连容量为 $-w$ 的边。 对于限制 $w_x\\leq w_y$，建立从 $y$ 到 $x$ ，容量为 $\\infty$ 的边。这样如果 $y\\in S,x\\in T$，将会存在无法割去的 $s-t$ 通路。 对于限制 $w_x=w_y$ ，分别建立从 $x$ 到 $y$ 和从 $y$ 到 $x$，容量为 $\\infty$ 的边。一旦这两个点分属于不同的集合，将会存在无法割去的 $s-t$ 通路。 对于限制 $w_x\u0026lt;w_y$，相当于规定了 $w_x=-w,w_y=w$，我们在第一步的约束中修改 $(s,x)$ 和 $(y,t)$ 的容量为 $\\infty$ 即可。 对于代价函数中的 $c|w_x-w_y|$ 部分，当 $w_x\\neq w_y$ 时会产生 $2cw$ 的代价，否则没有代价。因此分别建立从 $x$ 到 $y$ 和从 $y$ 到 $x$，容量为 $2cw$ 的边。一旦这两个点分属于不同的集合，就必须割掉这条边付出相应的代价。 对于代价函数中的 $c(w_x-w_y)$ 部分，可以拆括号将系数分到每个变量自己头上。我们再次修改第一步中的权值，提前计算好每个变量在目标函数中被累加的次数，边权乘上该系数即可。 该网络已经可以模拟原题，但还有一个问题在于该网络中存在负权，不方便使用最大流算法求解。解决负权的常用手法是先预计算一个小的代价，如果最终选择了大的再补差价。以第一种建边为例，我们先预先在答案中加上 $-w\\cdot n$，表示先认为每个变量的取值都是 $-w$，这样建边时如果它确实是 $-w$，则代价为0，如果是 $w$ 则代价为 $2w$，从而转为非负权。其他部分的处理手法类似。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b85029f35294061639dc9309cd688ca8","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iii-04/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iii-04/","section":"notes","summary":"A. Acesrc\u0026rsquo;s Bizarre Adventure 题面描述 给定 $n$ 个红色的点和 $n$ 个蓝色的点，每个点有坐标 $(x,y)$。如果一个蓝色的点满足两个坐标都是某个红色点坐标的两倍以上，则该蓝点和红点可以配对。问最多能配成多少对。 $n\\leq 100$。 题解 在可以配对的蓝点和红点之间连边，该问题即转化为二分图最大匹配。可以利用匈牙利算法求解，也可以建立超级源点、超级汇点后求最大流。\nB. Acesrc Doesn\u0026rsquo;t Want To Bite The Dust 题面描述 有 $n$ 个二次函数，第 $i$ 个形如 $f_i(x)=a_ix^2+b_ix+c_i$，要求 $x_i\\in [L_i,R_i]$。有 $m$ 个额外的限制，每个限制是一个三元组 $(u,v,d)$，表示要求 $x_u\\leq x_v+d$。求在满足所有限制的情况下，$\\sum_{i=1}^nf_i(x_i)$ 的最大值。 $n\\leq 50,m\\leq 100,-100\\leq L_i,R_i\\leq 100$。 题解 原型是洛谷3227切糕，比较难想的最小割建模。","tags":null,"title":"问题求解 III - 04 题解","type":"docs"},{"authors":null,"categories":null,"content":"A. 常系数线性递推 题面描述 给定递推式 $a_n=x_0+\\sum_{i=1}^kx_ia_{n-i}$，求 $a_p$。 $k\\leq 60,p\\leq 2\\times 10^9$。 题解 令向量 $$ x_{n}= \\left( \\begin{matrix} a_n\\\\a_{n+1}\\\\ \\vdots\\\\a_{n+k-1}\\\\x_0 \\end{matrix} \\right) $$ 则令 $$ A=\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 0\\\\ \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \u0026amp; \\vdots\\\\0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \u0026amp; 0\\\\ x_k \u0026amp; x_{k-1} \u0026amp; \\dots \u0026amp; x_1 \u0026amp; 1\\\\0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] $$ 有 $$ Ax_n=x_{n+1} $$ 因此只要求 $A^{p-k+1}x_0$，即可求得 $a_p$。矩阵乘法可以用快速幂加速。总时间复杂度 $O(k^3logp)$。\nB. 骨牌覆盖 题面描述 给定一个 $m$ 行 $n$ 列的棋盘，要求用 $1\\times 2$ 的骨牌铺满，求方案数。 $n\\leq 3,m\\leq 10^{18}$。 题解 当 $n=1$ 时，显然当 $m$ 为偶数时有 1 种方案，$m$ 为奇数时没有方案。\n当 $n=2$ 时，容易发现答案是 Fibonacci 数列的第 $m$ 项，使用矩阵快速幂计算答案即可。\n当 $n=3$ 时，首先考虑一个状压 dp 的思路：令 $dp[i][Mask]$ 表示当前看到第 $i$ 行，第 $i$ 行已经被覆盖的状态为 $Mask$ 的方案数。由于骨牌的长度不超过 2，所以在第 $i$ 行放骨牌只会影响第 $i$ 行和第 $i+1$ 行，从 $dp[i][Mask]$ 可以轻松转移到 $dp[i+1][Mask\u0026rsquo;]$。\n但此题 $m$ 过大，需要优化该 dp 思路。我们可以把 $dp[i][Mask]\\rightarrow dp[i+1][Mask\u0026rsquo;]$ 的转移方式写成一个 $8\\times 8$ 的矩阵，将 $dp[i]$ 写成一个 $8$ 维向量，使得乘上该矩阵即可从 $i$ 转移到 $i+1$ ，这样就可以用矩阵快速幂优化了。\n总时间复杂度 $O(2^nlogm)$。\nC. 简单的题 题面描述 给定有 $t$ 条边的无向图，求从 $s$ 到 $t$ 恰好经过了 $n$ 条边的最短路。 $n\\leq 10^6,t\\leq 100$。 题解 由于边数不多，所以图中的点数至多是百级。设该图的邻接矩阵为 $A$，考虑 $A^n$，其中重新定义矩阵乘法的运算，用 $+$ 代替 $\\times$，用 $\\min$ 代替 $+$，可以证明这种新式矩阵乘法仍然满足结合律，所以仍然可以矩阵快速幂。$A^n$ 中保存的即为恰好经过 $n$ 条边的最短路。\n总时间复杂度 $O(t^3logn)$。\nD. 线段覆盖 题面描述 给定 $n$ 条线段，第 $i$ 条线段为 $[l_i,r_i]$。每条线段有一个代价 $c_i$，表示可以花费 $c_i$ 的代价使线段向左或向右延长一个单位长度。问要使得这些线段覆盖全部 $[0,m]$ 至少需要多少代价。 $n\\leq 1000,m\\leq 10^6$。 题解 考虑 $[0,m]$ 上有多少段还没有被线段覆盖，显然“空白段”的数量是 $O(n)$ 级别的。我们发现有如下重要性质：在最优的覆盖方案中，一个空白段不会被多个线段覆盖。\n如果两个线段交汇在一个空白段的中间，那我们总可以缩短代价长的那个线段，增长代价小的线段，使得代价变小。 如果两个线段同时覆盖了一整个空白段，可以发现代价小的线段一定能以相同或更小的代价完成两个线段要覆盖的线段，因此不需要大代价线段付出。 基于以上重要性质，我们可以进行动态规划。令 $dp[i][j]$ 表示当前考虑到第 $i$ 个空白段，第 $i$ 个空白段是被第 $j$ 个线段覆盖的情况下的最小代价。转移分为两种情况：\n第 $i-1$ 段空白段也是被第 $j$ 个线段覆盖的，此时只需要根据第 $i-1$ 个空白段，第 $i$ 个空白段和第 $j$ 个线段的位置关系计算第 $j$ 个线段要完整覆盖住第 $i$ 个空白段所需的额外代价即可。 第 $i-1$ 段空白段不是被第 $j$ 个线段覆盖的。根据之前分析的性质，我们只需要考虑第 $i-1$ 段空白段被 $min(j,i)$ 之前的线段覆盖，因此只需要维护一个 dp 数组的前缀 min 即可。事实上在写代码时，我们可以直接用 $i-1$ 的全局最小值来更新答案，因为这样只会误计算一些非最优解的值，仍然可以保证我们算出最优解的代价。（当然维护前缀 min也是可以的）。 总时间复杂度 $O(n^2)$。\n此外在发现性质之后也可以建图跑最短路：为每条线段建一个点，为起点 0 和 终点 $m$ 也各建立一个点。之前的性质可以被翻译为：两条线段在延伸之后的相交处必然在某条线段的端点处。对于两条线段代表的点，我们只需要建从一条线段到另一条线段（左端点和右端点中较近的一个，取决于线段之间的相对位置）延伸所需的代价即可。该图是一个阶数为 $n$ 的稠密图，在上面跑不带堆优化的 Dijkstra 算法，也可在 $O(n^2)$ 内得到结果。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"697ba896a561de32a972d6c53a25a3c6","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iii-05/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iii-05/","section":"notes","summary":"A. 常系数线性递推 题面描述 给定递推式 $a_n=x_0+\\sum_{i=1}^kx_ia_{n-i}$，求 $a_p$。 $k\\leq 60,p\\leq 2\\times 10^9$。 题解 令向量 $$ x_{n}= \\left( \\begin{matrix} a_n\\\\a_{n+1}\\\\ \\vdots\\\\a_{n+k-1}\\\\x_0 \\end{matrix} \\right) $$ 则令 $$ A=\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 0\\\\ \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \u0026amp; \\vdots\\\\0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \u0026amp; 0\\\\ x_k \u0026amp; x_{k-1} \u0026amp; \\dots \u0026amp; x_1 \u0026amp; 1\\\\0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] $$ 有 $$ Ax_n=x_{n+1} $$ 因此只要求 $A^{p-k+1}x_0$，即可求得 $a_p$。矩阵乘法可以用快速幂加速。总时间复杂度 $O(k^3logp)$。","tags":null,"title":"问题求解 III - 05 题解","type":"docs"},{"authors":null,"categories":null,"content":"A. 最大内切球 题面描述 给定 $n$ 个半平面，求半平面围出的三维凸包的最大内切球的半径。 $\\sum n\\leq 2500$。 题解 设球的半径为 $r$，则我们的约束是球心到每个平面的距离不小于 $r$。此处根据空间解析几何的知识，如果一个半平面形如 $ax+by+cz+d\\leq 0$，那么将其单位化之后（即令 $cos\\alpha=\\frac{a}{\\sqrt{a^2+b^2+c^2}},cos\\beta=\\frac{b}{\\sqrt{a^2+b^2+c^2}},$$cos\\gamma=\\frac{c}{\\sqrt{a^2+b^2+c^2}}$，将方程改写为 $cos\\alpha\\cdot x+cos\\beta\\cdot y+cos\\gamma\\cdot z+\\rho=0$的形式），直接将点的坐标代入即可得到点到平面的距离，因此每个约束都是一个线性不等式，共有 4 个变量，我们要最大化的式子就是 $r$，用单纯形求解即可。\nB. 文理分科 题面描述 给定排成矩阵的 $n\\times m$ 个学生，每个学生学文有 $a_{ij}$ 的收益，学理有 $b_{ij}$ 的收益。如果一个学生和他相邻的所有学生都学文/理，可以额外获得 $sa_{ij}/sb_{ij}$ 的收益。求最大收益。 $n,m\\leq 100$。 题解 考虑最小割，我们先假设所有人拿满了学文学理的收益和区域相同的收益，考虑最少需要扣除多少收益。\n建立超级源点 $S$ 和超级汇点 $T$。\n对于每个学生，从 $S$ 向他连容量为 $a_{ij}$ 的边，表示如果割去，他去学理，则会损失该部分收益。相似地，从他向 $T$ 连容量为 $b_{ij}$ 的边。\n对于每个学生和其相邻人同时学文的情况，我们需要扣除该部分收益当且仅当这些人中至少有一个学理。因此我们从 $S$ 向该学生的一个“副本点”连容量为 $sa_{ij}$ 的边，再从该副本点向该学生及其相邻人连容量为 $\\infty$ 的边。这样这些人中一旦有一个人学理，就不得不割去容量为 $sa_{ij}$ 的边。$sb$ 的处理方法类似。\nC. Did You Just Say \u0026hellip;\u0026hellip; Acesrc? 题面描述 给定一个 $2\\times n$ 的“梯子”图，求该图有多少个连通的子图。 $n\\leq 10^{18}$。 题解 考虑动态规划。如果从左向右考虑，我们发现一个性质：到第 $i$ 列时，之前的点要么是连通的，要么分属两个连通块，且第 $i$ 列的两个点不连通。令 $f(i)$ 表示当前考虑到第 $i$ 列，只有一个连通块的方案数，$g(i)$ 表示当前考虑到第 $i$ 列，有两个连通块的方案数。稍微考虑以下第 $i$ 个“梯子格子”中的三条边，转移是容易的： $$ \\begin{align} f(i)=4f(i-1)+g(i-1)\\\\ g(i)=2f(i-1)+g(i-1) \\end{align} $$注意到该动态规划是线性递推，因此可以将 $f$ 和 $g$ 写成一个列向量，用矩阵表示转移，从而用矩阵快速幂优化转移。总时间复杂度 $O(logn)$。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"782ad36ec18577cf361989707c22d812","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iii-06/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iii-06/","section":"notes","summary":"A. 最大内切球 题面描述 给定 $n$ 个半平面，求半平面围出的三维凸包的最大内切球的半径。 $\\sum n\\leq 2500$。 题解 设球的半径为 $r$，则我们的约束是球心到每个平面的距离不小于 $r$。此处根据空间解析几何的知识，如果一个半平面形如 $ax+by+cz+d\\leq 0$，那么将其单位化之后（即令 $cos\\alpha=\\frac{a}{\\sqrt{a^2+b^2+c^2}},cos\\beta=\\frac{b}{\\sqrt{a^2+b^2+c^2}},$$cos\\gamma=\\frac{c}{\\sqrt{a^2+b^2+c^2}}$，将方程改写为 $cos\\alpha\\cdot x+cos\\beta\\cdot y+cos\\gamma\\cdot z+\\rho=0$的形式），直接将点的坐标代入即可得到点到平面的距离，因此每个约束都是一个线性不等式，共有 4 个变量，我们要最大化的式子就是 $r$，用单纯形求解即可。\nB. 文理分科 题面描述 给定排成矩阵的 $n\\times m$ 个学生，每个学生学文有 $a_{ij}$ 的收益，学理有 $b_{ij}$ 的收益。如果一个学生和他相邻的所有学生都学文/理，可以额外获得 $sa_{ij}/sb_{ij}$ 的收益。求最大收益。 $n,m\\leq 100$。 题解 考虑最小割，我们先假设所有人拿满了学文学理的收益和区域相同的收益，考虑最少需要扣除多少收益。","tags":null,"title":"问题求解 III - 06 题解","type":"docs"},{"authors":null,"categories":null,"content":"A. 多项式乘法模板 题面描述 给定一个 $n$ 次多项式 $A$ 和一个 $m$ 次多项式 $B$，求乘积。 $1\\leq n,m\\leq 10^5$。 题解 可以使用 FFT，介于多项式的系数不会太大，也可以使用 NTT。\nB. 一个叫yjher的同学决定去做A*B Problem 题面描述 给定两个大整数 $a,b$，求乘积。 $1\\leq a,b\\leq 10^{200000}$。 题解 设 $a=\\overline{a_na_{n-1}\\cdots a_1a_0}$，考虑生成函数 $A(x)=a_0+a_1x+\\cdots+a_nx^n$​，则 $a=A(10)$，$b$ 也是同理。因此只要求两个生成函数的乘积再将 10 代入即可。\nC. 方程求解 题面描述 $T$ 组数据，每次给定正整数 $n$，求四元不定方程 $ab+cd=n$ 的解的个数。 $T\\leq 10000,n\\leq 5\\times 10^5$。 题解 设 $ab=n$ 的解的个数为 $f(n)$，显然有 $f(n)=\\sigma(n)$，其中 $\\sigma(n)$ 表示 $n$ 的约数个数。那么原不定方程解的个数为 $$ F(n)=\\sum_{i=1}^{n-1}f(i)f(n-i) $$ 该表达式是卷积形式，可以用 FFT 优化。\n至于如何求 $\\sigma(n)$ ，可以在线性筛素数的同时保存每个数的最小质因子，这样便可在 $O(nlogn)$ 的时间内完成 1-n 所有数的标准分解，从而确定每个数的约数个数。\n总时间复杂度 $O(nlogn+T)$。\nD. 讨厌质数的人 题面描述 给定 $n$ 个数的集合，求其最大的一个子集，使得子集中的数两两之和都不是质数。 $n\\leq 3000,1\\leq a_i\\leq 10^5$。 题解 对于任意两个数，如果它们的和是质数，就在它们之间连一条边。那么该问题就转化为了求图的最大独立集。\n如果不考虑 1 的参与，那么有边的两个数一定是一个奇数一个偶数，所以这个图是一个二分图。此时再考虑 1，显然最终的集合里不会有两个1，因此如果有多个 1，只保留一个参与最大独立集的计算即可。\n二分图的最大独立集等于总点数减去最大匹配，用网络流求解即可。一个不太紧的时间复杂度的上界是 $O(n^{2.5})$。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0584b9e163432def731fa2011adde170","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iii-07/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iii-07/","section":"notes","summary":"A. 多项式乘法模板 题面描述 给定一个 $n$ 次多项式 $A$ 和一个 $m$ 次多项式 $B$，求乘积。 $1\\leq n,m\\leq 10^5$。 题解 可以使用 FFT，介于多项式的系数不会太大，也可以使用 NTT。\nB. 一个叫yjher的同学决定去做A*B Problem 题面描述 给定两个大整数 $a,b$，求乘积。 $1\\leq a,b\\leq 10^{200000}$。 题解 设 $a=\\overline{a_na_{n-1}\\cdots a_1a_0}$，考虑生成函数 $A(x)=a_0+a_1x+\\cdots+a_nx^n$​，则 $a=A(10)$，$b$ 也是同理。因此只要求两个生成函数的乘积再将 10 代入即可。","tags":null,"title":"问题求解 III - 07 题解","type":"docs"},{"authors":null,"categories":null,"content":"A. 加密 题面描述 使用题目中给定的一套类 RSA 算法加密，公钥 $E=2^{30}+3$。已知密文 $w^E\\equiv C(mod\\space n)$，给定 $n,C$，求原文 $w$。 $T\\leq 10^5,n\\leq 10^{18}$。 题解 根据题目中 $n$ 的生成方式可知，$n=pq$ 且 $p,q$ 的差非常小，因此可以从 $\\sqrt n$ 开始往上往下枚举第一个 $n$ 的因子，即可得到 $p$ 和 $q$。那么 $\\phi(n)=(p-1)(q-1)$，从而可以用扩展欧几里得求出 $E$ 关于 $\\phi(n)$ 的逆元 $D$（密钥）。\n根据数论知识，我们有 $C^{DE}\\equiv w^{DE}\\equiv w(mod\\space n)$。因此使用快速幂求解 $C^{DE}$ 即可。\n注：如果使用嵌套快速乘的快速幂，时间复杂度将达到 $O(T\\log^2n)$，可能会超时。使用 __int128 类型可以避免这个问题。\nB. 可以看见的点 题面描述 给定 $n\\times n$ 的方格纸，问从 $(0,0)$ 出发可以画出多少种不同斜率的直线（直线必须经过至少两个格点）。 $n\\leq 10^5$。 题解 设直线经过的另一个格点是 $(a,b)$ ，那么显然只有 $a,b$ 互质我们才应该将其计入答案，否则会导致重复计数。因此 $$ \\begin{align} ans\u0026amp;=\\sum_{i=1}^n\\sum_{j=1}^n[\\gcd(i,j)=1]\\\\ \u0026amp;=1+2\\sum_{i=1}^n\\sum_{j=1}^{i-1}[\\gcd(i,j)=1]\\\\ \u0026amp;=1+2\\sum_{i=1}^n\\varphi(i) \\end{align} $$因为此题 $n$ 只有 1e5，所以 $O(\\log n)$ 地求每个数的欧拉函数值再求和即可。当 $n$ 更大时可以借助线性筛或数论筛法来解决。\nC. POWERMOD 题面描述 给定 $a,b,m$，求 $a^b(mod\\space m)$。 $a,b,m\\leq 10^{18}$。 题解 此题的难点在于普通的快速幂在执行乘法时会爆 long long，所以我们应当用“快速乘”来代替普通的乘法。快速乘用 $O(\\log n)$ 次加法来代替一次乘法，其原理和快速幂完全一样，大致的代码如下：\n#define LL long long LL quick_mul(LL x, LL y, LL m) { LL res = 0; while (y) { if (y \u0026amp; 1) res = (res + x) % m; x = (x + x) % m; y \u0026gt;\u0026gt;= 1; } return res; } 这样我们可以在 $O(\\log ^2n)$ 的时间复杂度内完成快速幂。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0c6b208e2177a3df68e374ee40d44af7","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iii-10/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iii-10/","section":"notes","summary":"A. 加密 题面描述 使用题目中给定的一套类 RSA 算法加密，公钥 $E=2^{30}+3$。已知密文 $w^E\\equiv C(mod\\space n)$，给定 $n,C$，求原文 $w$。 $T\\leq 10^5,n\\leq 10^{18}$。 题解 根据题目中 $n$ 的生成方式可知，$n=pq$ 且 $p,q$ 的差非常小，因此可以从 $\\sqrt n$ 开始往上往下枚举第一个 $n$ 的因子，即可得到 $p$ 和 $q$。那么 $\\phi(n)=(p-1)(q-1)$，从而可以用扩展欧几里得求出 $E$ 关于 $\\phi(n)$ 的逆元 $D$（密钥）。","tags":null,"title":"问题求解 III - 10 题解","type":"docs"},{"authors":null,"categories":null,"content":"A. Majority 3-SAT 题面描述 现有 $k$ 个逻辑变量 $x_1,\\cdots, x_k$，给出 $n$ 个三元组 $(a_i,b_i,c_i)$，其中每个逻辑式可以取任意一个逻辑变量或其否定，每个三元组表示三个逻辑式至少两个为真，问是否能找到一种赋值法，满足所有 $n$ 个三元组。\n$k, n\\leq 10^4$。\n题解 对于一个三元组 $(a_i,b_i,c_i)$，由于至少要有两个表达式为 true，所以我们可以将其翻译成如下的一些蕴含式：如果 $a_i$ 为假，则 $b_i$ 为真；如果 $a_i$ 为假，则 $c_i$ 为真……这些逻辑式上的蕴含式最终可以转化成逻辑变量上的蕴含式，每个蕴含式形如“如果 $x_i$ 为真/假，则 $x_j$ 为真/假”。于是这个问题被转化为了一个 2-SAT 问题，以下给出 2-SAT 问题的通用解法：\n我们为每个逻辑变量建立两个节点，一个表示该逻辑变量取 true，一个表示该逻辑变量取 false。这样我们可以将之前得到的所有蕴含式通过有向边表达在这张图上。我们求出这张图中所有的强连通分量，一个强连通分量中的点的意义是：只要有一个成立，则剩下的所有的都成立。因此如果一个逻辑变量的 true 节点和 false 节点在同一个强连通分量中，则原问题无解；否则我们一定能找到一种安排方案满足所有蕴含式，从而满足所有三元组的要求。\nB. 旅行问题 题面描述 给定一个 $n$ 个点的带权图，求从任意点出发，遍历所有节点至少一次并在任意点结束的最小距离。 $n\\leq 20$。 题解 考虑状态压缩动态规划。令 $dp(Mask, i)$ 表示当前在节点 $i$，已经经历过的点为 $Mask$ 的最小距离。转移是容易的：枚举下一个去的节点 $j$，则 $$ dp(Mask+j, j)=\\min(dp(Mask\\cup j,j),dp(Mask, i)+w_{ij}) $$ 总时间复杂度 $O(n^2\\cdot 2^n)$。\nC. 极大团 题面描述 给定 $n$ 个点 $m$ 条边的图，求图中极大团的个数。 $n\\leq 18$。 题解 我们枚举所有可能的点集 $S$，然后检查图中的每个节点 $v$：对于任意 $v\\in S$，应当有 $S\\subseteq neigh(v)$；对于任意 $v\\notin S$，应当有 $S-neigh(v)\\neq \\emptyset$。提前预处理每个点 $v$ 的 $neigh(v)$，检查可以在线性时间内完成。\n总时间复杂度 $O(n\\cdot 2^n)$。\nD. 扫地机器人 题面描述 给定一个 $n\\times m$ 的方格纸，求一条从 $(x,y)$ 出发，将所有格子经过恰好一次，在任意格子结束的路径。 $n,m\\leq 500$，且 $n,m$ 中至少有一个是偶数。 题解 下面的讨论中我们假设 $m$ 是偶数。偶数给了我们这样一个好的性质：要么 $y$ 和 $m-y$ 都是偶数，要么 $y-1$ 和 $m+1-y$ 都是偶数，因此我们可以给出一个形如这样的哈密尔顿回路构造方法：\n（注：上图是 $y$ 是偶数的情况；如果 $y$ 是奇数则先向右走。）\n为了代码书写的简便，我们可以先在旋转/翻转的地图上走出路径，然后再将路径逆旋转/翻转回去。这样代码量会减小很多。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2bdddfe53f7837930fb880c63ad05105","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iv-02/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iv-02/","section":"notes","summary":"A. Majority 3-SAT 题面描述 现有 $k$ 个逻辑变量 $x_1,\\cdots, x_k$，给出 $n$ 个三元组 $(a_i,b_i,c_i)$，其中每个逻辑式可以取任意一个逻辑变量或其否定，每个三元组表示三个逻辑式至少两个为真，问是否能找到一种赋值法，满足所有 $n$ 个三元组。\n$k, n\\leq 10^4$。\n题解 对于一个三元组 $(a_i,b_i,c_i)$，由于至少要有两个表达式为 true，所以我们可以将其翻译成如下的一些蕴含式：如果 $a_i$ 为假，则 $b_i$ 为真；如果 $a_i$ 为假，则 $c_i$ 为真……这些逻辑式上的蕴含式最终可以转化成逻辑变量上的蕴含式，每个蕴含式形如“如果 $x_i$ 为真/假，则 $x_j$ 为真/假”。于是这个问题被转化为了一个 2-SAT 问题，以下给出 2-SAT 问题的通用解法：","tags":null,"title":"问题求解 IV - 02 题解","type":"docs"},{"authors":null,"categories":null,"content":"A. Game 题面描述 给定一个 $n$ 个节点的树，现要求将一些节点涂黑，使得每条边的两个端点都至少有一个被涂黑。求涂黑节点的最小个数。 $n\\leq 1500$。 题解 考虑树上动态规划：令 $dp(u,0/1)$ 表示当前考虑以 $u$ 为根的子树，$u$ 这个节点不涂黑/涂黑的情况下子树内最小需要涂黑的节点个数，转移是简单的： $$ \\begin{align} dp(u,0)\u0026amp;=\\sum_{v\\in son(u)}dp(v,1)\\\\ dp(u,1)\u0026amp;=1+\\sum_{v\\in son(u)}\\min(dp(v,0),dp(v,1)) \\end{align} $$ 总时间复杂度 $O(n)$。\nB. 01背包问题 题面描述 给定 $n$ 个物品，第 $i$ 个物品的体积是 $v_i$，价值是 $c_i$。现给定背包容量 $V$，问背包容量限制下可以取到的最大价值是多少。 $n\\leq 40,v_i,c_i\\leq 10^9$。 题解 该题的题面是经典的01背包问题，但由于体积和价值都过大，所以无法使用动态规划求解。\n考虑折半搜索：将物品分成前 $n/2$ 个和后 $n/2$ 个两部分，对于每一部分都枚举所有可能的选取子集，从而得到两堆 (体积,价值) 对。我们现在的目标是从第一个堆和第二个堆里各选出一个 pair，使得它们的体积之和不超过上限且价值之和最大。\n我们将两堆数对都按照体积从小到大排序，然后倒序枚举第一堆里的每个 pair，随着第一个堆里体积的减小，第二个堆里可行的体积上限逐渐增大，这个过程是单调的，因此我们枚举的过程中动态维护第二个堆中可行 pair 的价值的最大值即可。\n总时间复杂度 $O(\\frac{n}{2}\\cdot 2^{\\frac{n}{2}})$。\nC. 虫食算 题面描述 给定一个字母竖式，求出一个字母-数字的映射，使得竖式成立。 竖式中数的位数 $\\leq 21$。 题解 按照竖式从右到左的顺序搜索+剪枝。剪枝主要关注数字不能重复使用，以及每一列枚举了两个数字第三个数字就可以直接算出来这两个特性。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a2958c32e58ea96e9ba1f265ac26dbc1","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-problem-solving/oj-solutions/iv-03/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-problem-solving/oj-solutions/iv-03/","section":"notes","summary":"A. Game 题面描述 给定一个 $n$ 个节点的树，现要求将一些节点涂黑，使得每条边的两个端点都至少有一个被涂黑。求涂黑节点的最小个数。 $n\\leq 1500$。 题解 考虑树上动态规划：令 $dp(u,0/1)$ 表示当前考虑以 $u$ 为根的子树，$u$ 这个节点不涂黑/涂黑的情况下子树内最小需要涂黑的节点个数，转移是简单的： $$ \\begin{align} dp(u,0)\u0026amp;=\\sum_{v\\in son(u)}dp(v,1)\\\\ dp(u,1)\u0026amp;=1+\\sum_{v\\in son(u)}\\min(dp(v,0),dp(v,1)) \\end{align} $$ 总时间复杂度 $O(n)$。\nB. 01背包问题 题面描述 给定 $n$ 个物品，第 $i$ 个物品的体积是 $v_i$，价值是 $c_i$。现给定背包容量 $V$，问背包容量限制下可以取到的最大价值是多少。 $n\\leq 40,v_i,c_i\\leq 10^9$。 题解 该题的题面是经典的01背包问题，但由于体积和价值都过大，所以无法使用动态规划求解。","tags":null,"title":"问题求解 IV - 03 题解","type":"docs"},{"authors":null,"categories":null,"content":"return and print def what_prints(): print('Hello World!') return 'Exiting this function.' print('61A is awesome!') 该程序的运行结果是\n\u0026gt;\u0026gt;\u0026gt; what_prints() Hello World! 'Exiting this function.' 注意 print 的结果是不带引号的，return 的结果是带引号的。\nBoolean Operators 如果多个语句用 AND 连接，那么 python 会执行到第一个为假的表达式，后面的不再执行，这就是短路 (short circuiting)。此时即使后面写了执行会导致 Error 的语句也不会 crash。OR 同理。\n\u0026gt;\u0026gt;\u0026gt; 1 / 0 ZeroDivisionError \u0026gt;\u0026gt;\u0026gt; True or (1 / 0) True 逻辑表达式总是会返回最后一个元素，该规则在短路情况下同样适用，下面是一些例子：\n\u0026gt;\u0026gt;\u0026gt; True and 13 13 \u0026gt;\u0026gt;\u0026gt; not 10 False \u0026gt;\u0026gt;\u0026gt; False or [] [] \u0026gt;\u0026gt;\u0026gt; 0 or False or 2 or 1 / 0 2 0 [] None 也会被视为 False，但如果对一个 True 的东西取 not，返回结果只可能是 False。\nDebugging Traceback Message Traceback Message 类似于 GDB 的回溯顺序，实际的函数调用顺序是从下往上的。\nDebugging Techniques Running doctests python3 的 -m 选项提供 doctest 功能：我们可以把简单的测试用例写在源代码中。例如\n# square.py def square(x): \u0026quot;\u0026quot;\u0026quot; \u0026gt;\u0026gt;\u0026gt; square(4) 16 \u0026quot;\u0026quot;\u0026quot; return x * x 用一对 \u0026quot;\u0026quot;\u0026quot; 括起来的注释内容中可以书写测试用例，测试用例的写法类似于 python 的交互界面，在 \u0026gt;\u0026gt;\u0026gt; 后写下要执行的语句，并另起一行写下期望的结果。使用\npython3 -m doctest square.py 进行测试，如果程序运行的结果和期望结果不同 python 会报错。\n如果使用 -v 选项，python 不仅会报错，还会将通过的测试用例的信息也显示出来。\nInteractive Debugging 使用一个交互式的 REPL 是 debug 的好方式。假设当前我们要 debug file.py 这个程序，使用命令\npython3 -i file.py 可以打开一个 python 的 REPL，它已经执行了 file.py 中的所有定义，我们可以输入任意的命令进行测试。\nUsing ok python3 ok -q MODULE_NAME -i 可以打开 REPL。\npython3 ok q MODULE_NAME --trace 可以打开程序的可视化窗口。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6e980681fe611328119c91feb69f3392","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/labs/lab01/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/labs/lab01/","section":"notes","summary":"return and print def what_prints(): print('Hello World!') return 'Exiting this function.' print('61A is awesome!') 该程序的运行结果是\n\u0026gt;\u0026gt;\u0026gt; what_prints() Hello World! 'Exiting this function.' 注意 print 的结果是不带引号的，return 的结果是带引号的。\nBoolean Operators 如果多个语句用 AND 连接，那么 python 会执行到第一个为假的表达式，后面的不再执行，这就是短路 (short circuiting)。此时即使后面写了执行会导致 Error 的语句也不会 crash。OR 同理。","tags":null,"title":"UCB-CS61A Lab 01: Variables \u0026 Functions, Control","type":"docs"},{"authors":null,"categories":null,"content":"没有需要特别注意的知识点和题目。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"683422e3076539dceeff0e01566b6862","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/labs/lab02/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/labs/lab02/","section":"notes","summary":"没有需要特别注意的知识点和题目。","tags":null,"title":"UCB-CS61A Lab 02: Higher-Order Functions, Lambda Expressions","type":"docs"},{"authors":null,"categories":null,"content":"下面的两道题是比较有意思的：\nQ1: WWPD: Journey to the Center of the Earch \u0026gt;\u0026gt;\u0026gt; def crust(): ... print(\u0026quot;70km\u0026quot;) ... def mantle(): ... print(\u0026quot;2900km\u0026quot;) ... def core(): ... print(\u0026quot;5300km\u0026quot;) ... return mantle() ... return core ... return mantle \u0026gt;\u0026gt;\u0026gt; drill = crust \u0026gt;\u0026gt;\u0026gt; drill = drill() ______ \u0026gt;\u0026gt;\u0026gt; drill = drill() ______ \u0026gt;\u0026gt;\u0026gt; drill = drill() ______ \u0026gt;\u0026gt;\u0026gt; drill() ______ 值得注意的是第三次和第四次调用 drill() 的区别。两次调用的 drill() 都是 core() 这个函数，它们首先会输出 \u0026ldquo;5300km\u0026rdquo;，然后调用 mantle() 之后输出 \u0026ldquo;2900km\u0026rdquo;，最后返回函数 core()。但第一次的语句是一个赋值语句，赋值语句的返回值是 None，第二次的语句是一个单纯的调用，所以最后函数的返回值 \u0026ldquo;Function\u0026hellip;\u0026rdquo; 也会被打印出来。\nQ7: Riffle Shuffle 这道题有一点小难度，因为 list comprehension 中不能带有 else，所以我们要想出一种统一的方法来根据下标从数组中取数。我们可以利用 i % 2 的结果参与运算：\nreturn [deck[i // 2 + (i % 2) * len(deck) // 2] for i in range(len(deck))] ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"81b95f0635a031ea02a6d40096fadca1","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/labs/lab04/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/labs/lab04/","section":"notes","summary":"下面的两道题是比较有意思的：\nQ1: WWPD: Journey to the Center of the Earch \u0026gt;\u0026gt;\u0026gt; def crust(): ... print(\u0026quot;70km\u0026quot;) ... def mantle(): ... print(\u0026quot;2900km\u0026quot;) ... def core(): ... print(\u0026quot;5300km\u0026quot;) ... return mantle() ... return core .","tags":null,"title":"UCB-CS61A Lab 04: Recursion, Tree Recursion, Python Lists","type":"docs"},{"authors":null,"categories":null,"content":"Data Abstraction data abstraction 中通常包括以下两类函数：\nconstructors: 用于构建数据结构。 selectors: 用于从数据结构中提取信息。 本实验的题目不算太难，充分利用树的递归性可以写出既简洁又满足 abstraction barrier 的代码。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"186f42bcc65e301874d7591cd74258b9","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/labs/lab05/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/labs/lab05/","section":"notes","summary":"Data Abstraction data abstraction 中通常包括以下两类函数：\nconstructors: 用于构建数据结构。 selectors: 用于从数据结构中提取信息。 本实验的题目不算太难，充分利用树的递归性可以写出既简洁又满足 abstraction barrier 的代码。","tags":null,"title":"UCB-CS61A Lab 05: Python Lists, Trees","type":"docs"},{"authors":null,"categories":null,"content":"List API 一些重要的 API 的补充说明：\nlist.pop(index=-1) 的作用是弹出 list[index] 这个元素，没有填写参数默认为 -1。该 method 的返回值是弹出的元素的值。\nlist.remove(x) 删除 list 中的第一个元素 x。\nlist.insert(index, obj) 的作用是在 index 为 index 的元素前面添加元素 obj (即插入完元素后 obj 的下标是 index)\nlist.append() 的返回值是 None。 一道例题很好地展现了这个特性：\n\u0026gt;\u0026gt;\u0026gt; lst = [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; lst.extend(lst.append(4), list.append(5)) \u0026gt;\u0026gt;\u0026gt; lst [1, 2, 3, None, None] Iterators 两个值得注意的细节：\n如果一个 iterater iter 在 for 循环中被使用，例如 for x in iter，那么 for 循环结束时 iter 的值是被改变了的，再调用 next() 会得到 StopIteration。 使用 list(iter) 获得列表的话会修改 iter 的位置，所以如果只想取前 n 个元素且保证 iter 的位置，不能使用 list(iter)[:n] 的方式。 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7f56745a8b05117d35d0f49f1318d416","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/labs/lab06/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/labs/lab06/","section":"notes","summary":"List API 一些重要的 API 的补充说明：\nlist.pop(index=-1) 的作用是弹出 list[index] 这个元素，没有填写参数默认为 -1。该 method 的返回值是弹出的元素的值。\nlist.remove(x) 删除 list 中的第一个元素 x。\nlist.insert(index, obj) 的作用是在 index 为 index 的元素前面添加元素 obj (即插入完元素后 obj 的下标是 index)\nlist.append() 的返回值是 None。 一道例题很好地展现了这个特性：","tags":null,"title":"UCB-CS61A Lab 06: Mutability and Iterators","type":"docs"},{"authors":null,"categories":null,"content":"本实验中比较有意思的题目是实现卡牌游戏的“小项目”。我们在填写代码之前就可以思考一下如何用 oop 的思想来设计程序框架：卡牌、玩家、卡牌池应当被设计为对象，对象之间可以交互；普通卡牌是一个大类，拥有特殊效果的卡牌可以使用继承机制使用大类的属性并添加自己的独特属性；玩家手上有 5 张手牌，这是一个 \u0026ldquo;has a\u0026rdquo; 的关系，应当使用 composition 维护一个卡牌对象的列表……\nPass by Value v.s. Pass by Reference\nPython 不像 C 语言那样可以明确给函数传递的参数是指针还是普通变量，但 Python 有自己的 specification：如果传递的是一个 immutable 的东西 (如 string, int)，那么是按值传递的；如果传递的是 mutable 的东西 (如 list, object)，那么是按引用传递的。因此在该实验中，将对象传给另一个对象的 method，method 对参数对象的修改可以直接影响原对象的状态。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cfe3657abd25ad41f1772f65a8d8b6b0","permalink":"https://kristoff-starling.github.io/notes/coursenotes/ucb-cs61a/labs/lab07/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/ucb-cs61a/labs/lab07/","section":"notes","summary":"本实验中比较有意思的题目是实现卡牌游戏的“小项目”。我们在填写代码之前就可以思考一下如何用 oop 的思想来设计程序框架：卡牌、玩家、卡牌池应当被设计为对象，对象之间可以交互；普通卡牌是一个大类，拥有特殊效果的卡牌可以使用继承机制使用大类的属性并添加自己的独特属性；玩家手上有 5 张手牌，这是一个 \u0026ldquo;has a\u0026rdquo; 的关系，应当使用 composition 维护一个卡牌对象的列表……\nPass by Value v.s. Pass by Reference\nPython 不像 C 语言那样可以明确给函数传递的参数是指针还是普通变量，但 Python 有自己的 specification：如果传递的是一个 immutable 的东西 (如 string, int)，那么是按值传递的；如果传递的是 mutable 的东西 (如 list, object)，那么是按引用传递的。因此在该实验中，将对象传给另一个对象的 method，method 对参数对象的修改可以直接影响原对象的状态。","tags":null,"title":"UCB-CS61a Lab 07: Object-Oriented Programming","type":"docs"},{"authors":null,"categories":null,"content":"Progress Implement copy-on write (hard) Implement Copy-on Write 写时拷贝 fork 的大体思路是：在 fork 时不为子进程创建新的页面，而是让子进程指向父进程的所有页面，并将页面的权限改为只读。将来如果某个进程 (父/子) 需要修改页面，会发生 page fault exception，在 kernel 的处理程序中，如果是 COW page，则新分配一个页面，将当前的只读页面内容复制过去，让当前进程的页表指向这个新的页面并将权限设置为可读可写。\nkalloc()/kfree() 引入了 copy-on write 之后，一个物理页面可能会被多个进程的页表指向，这使得 kfree() 变得困难：某个进程被释放时，它拥有的物理页面不能被直接释放，否则别的进程就用不了这个页面了。我们需要为每个页面维护一个 reference count，只有一个页面的 reference count 为 0 了才能释放它。\n维护 reference count 的时机很有讲究。笔者最初使用的方案是在“映射“和“解除映射”的时候修改 reference count，即在 mappages() 函数、 uvmunmap() 函数和 COW 相关函数中修改 reference count。但 xv6 中对 mappages() 的用法比较灵活，例如\nvoid kvminit() { ...... // map kernel data and the physical RAM we'll make use of. kvmmap((uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W); ...... } 上述 kvmmap() 会对所有的物理页面做一个恒等映射。其实内核并没有真正拥有这些页面，做 mappages() 时，真实分配好的页面是不存在的，在 kvmmap() 中做这一步只是为了简化内核代码的书写 (如在调用 memmove() 时不需要在软件中跑一遍内核页表)。因此如果在 mappages() 的时候维护 reference count，会得到不正确的结果。\n一个合理的解决方案是在 COW 相关函数中增加 reference count，在 kfree() 中减少 reference count。kalloc() 中新出厂的页面默认 reference count 为 1。\nuvmcopy()/uvmcow() 我们需要修改 uvmcopy() 的实现，不为子进程分配新的页面，而是让子进程指向父进程的页面，更新父进程的 reference count，并设置页表项的标志位。这里要注意的是，除了取消页面的 PTE_W，为了将 cow page 的异常和普通的越权修改异常区分开来，我们应当在页表项中标志一个 PTE_COW 位。RISC-V ISA 的页表项格式中，8，9,10 三位是 RSW 位，留给软件自由使用，我们可以利用这些位来标记 PTE_COW。\nuvmcow() 是 COW 导致的 page fault exception 的处理函数。我们应当分配一个新页面，新页面没有 PTE_COW 位，有 PTE_W 位，将原始页面的内容复制过来，并修改当前进程的页表。\nConcurrency 该实验中我们要开始面对并发 bug。/kernel/kalloc.c 中的空闲页面链表是用 kmem.lock 保护起来的。与此同理，我们维护 reference count 的数组也应该用一把锁保护起来。我们当然可以使用 kmem.lock，但如果新建一把锁专门用于保护 reference count 数组 (甚至是每个 referenct count 的单元格) 可以获得更好的并行度。\nConcurrency bug 中常见的一种是 TOCTTOU (time to check to time to use)。笔者曾经遇到过 xv6 在单核情况下可以正常运行，在多核情况下内存不够用的问题。经过排查发现问题出在如下代码：\nif (krref(pa) == 1) { *pte |= PTE_W; *pte \u0026amp;= (~PTE_COW); } else { if ((mem = kalloc()) == 0) return -2; flags \u0026amp;= (~PTE_COW); flags |= (PTE_W); memmove(mem, (void *)pa, PGSIZE); kmref(pa, -1); if (mappages(pagetable, va, PGSIZE, (uint64)mem, flags) != 0) return -1; } 这段代码的逻辑是：如果当前页面只剩一个 reference，就不必再申请新页面，而是直接修改一下本页面页表项的标志信息。否则当前页面有多个 reference，申请一个新页面并让当前进程指向它，调用 kmref(pa,-1) 更新原页面的 reference count。\n这段代码的 bug 在于进入 else 分支后，krref(pa)\u0026gt;=2 的假设不一定成立。假设有两个进程并发地执行该程序段且 pa 有且仅有两个 reference，那么两个进程都会通过 if 判断进入 else 分支，然后使用 kmref() 更新 reference count，这样 pa 页面的 reference count 变成了 0 但没有进程去 free 它，我们丢失了一个页面。这个 bug 触发次数越多，系统内可用的内存就越少。\n想要修复这个 bug，一种选择是给整个 if 语句上锁，另一种选择是不使用 if 并把 kmref() 改成 kfree() 或 uvmunmap()。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f347a4d886bd40ee780cbc1319c03546","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/labs/lab06/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/labs/lab06/","section":"notes","summary":"Progress Implement copy-on write (hard) Implement Copy-on Write 写时拷贝 fork 的大体思路是：在 fork 时不为子进程创建新的页面，而是让子进程指向父进程的所有页面，并将页面的权限改为只读。将来如果某个进程 (父/子) 需要修改页面，会发生 page fault exception，在 kernel 的处理程序中，如果是 COW page，则新分配一个页面，将当前的只读页面内容复制过去，让当前进程的页表指向这个新的页面并将权限设置为可读可写。\nkalloc()/kfree() 引入了 copy-on write 之后，一个物理页面可能会被多个进程的页表指向，这使得 kfree() 变得困难：某个进程被释放时，它拥有的物理页面不能被直接释放，否则别的进程就用不了这个页面了。我们需要为每个页面维护一个 reference count，只有一个页面的 reference count 为 0 了才能释放它。","tags":null,"title":"MIT-6.S081 Lab 06: Copy-on-write fork","type":"docs"},{"authors":null,"categories":null,"content":"Progress Eliminate allocation from sbrk() (easy) Lazy allocation (moderate) Lazytests and Usertests (moderate) Eliminate allocation from sbrk() (easy) 该部分要做的事情很简单：在 sbrk() 系统调用的处理函数中，不要分配内存，只修改进程的 sz 即可。由于我们只修改了 sz 而没有为新申请的空间绑定页面，所以当用户程序使用这块内存的时候 (load/store指令)，就会因为页表无法翻译虚拟地址而报 kernel panic。\nLazy allocation (moderate) 在该部分需要做的修改和注意事项在课上基本讲过，可以参考 Lecture 08 的课堂笔记。总体来说，我们需要在 usertrap() 中识别出缺页异常并写一个缺页异常的处理函数：申请一个物理页面，将导致错误的虚拟地址所在的虚拟页面映射过去。此外，由于延迟分配的存在，我们在 uvmunmap() 时释放的不一定是已经映射过的地址，应当取消其中的一些 panic 语句。\nLazytests and Usertests (moderate) 在该部分我们要额外处理 sbrk() 系统调用的一些细节：\n当 sbrk() 传入的参数是负数时，我们应当调用 uvmdealloc() 正常进行释放。uvmdealloc() 释放的虚拟页面可能已经映射了物理页面，可能还没有映射物理页面。我们在上一个部分中已经取消了 uvmunmap() 函数中对该内容的检查，所以没有问题。\n当 sbrk() 进行了非法的操作，如引起错误的虚拟地址不在堆区范围内，或者内存不足、无法分配新物理页面，则杀死当前进程。\n除了缺页异常中需要处理延迟分配的问题，read() / write() 系统调用中也要处理延迟分配问题。该系统调用的函数调用路径 (以 write() 为例) 为 sys_write() $\\rightarrow$ filewrite() $\\rightarrow$ writei() $\\rightarrow$ either_copyin() $\\rightarrow$ copyin() $\\rightarrow$ walkaddr()。内核为了在内核空间和用户空间之间传递数据，会调用 copyin()/copyout()/copyinstr()。这些函数会抓着用户虚拟地址在用户页表中进行一次 page table walk，以翻译出其物理地址。该过程中可能会因为延迟分配的问题翻译失败，我们要判断这种情况，并进行分配，代码细节和 usertrap() 中的非常类似，但需要注意的是由于 usertests 的设置问题，在 walkaddr() 中遇到非法情况不能直接杀死进程。\n(注：事实上，如果将 lab pgtbl 中的代码添加进来，用户进程和内核共用一份页表，就可以由硬件完成所有的 page table walk，延迟分配的处理函数也只需要写一遍。)\n该实验中还有如下的几个细节：\n笔者查阅了一些网上的代码，发现它们处理 “用户栈地址” 的方式各不相同：有的人使用 p-\u0026gt;kernel_sp，这实际上是进程的内核栈的栈顶地址。有的人使用 p-\u0026gt;trapframe-\u0026gt;sp，这是用户进程在陷入内核时的用户栈指针，由于用户栈此时不一定空，所以 p-\u0026gt;trapframe-\u0026gt;sp 并不一定指向栈底。从严谨的角度来说，获取栈底地址应该使用 PGROUNDUP(p-\u0026gt;trapframe-\u0026gt;sp)。笔者采用的另一种稍愚笨一些的方法为：在 proc 结构体中新建一个 ustack 变量，在 exec() 系统调用中把用户栈底的地址保存在其中。 该实验中对于边界情况的判断要格外小心，usertest 中有很多针对边界情况的测试。p-\u0026gt;sz，即 program break，指向的是用户内存顶部的下一个地址，第一个未被使用的地址，因此判断合法范围时一定是 va \u0026lt; p-\u0026gt;sz。此外 PGROUNDUP(p-\u0026gt;trapframe-\u0026gt;sp) 得到的地址为用户栈底地址的下一位，因此下界一定是 PGROUNDUP(p-\u0026gt;trapframe-\u0026gt;sp) \u0026lt;= va 。(usertest 中的 copyinstr3 测试了当参数字符串的结束符处于未分配空间时程序是否能返回 -1) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5c2c035ff3198fd1725504385c9401b6","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/labs/lab05/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/labs/lab05/","section":"notes","summary":"Progress Eliminate allocation from sbrk() (easy) Lazy allocation (moderate) Lazytests and Usertests (moderate) Eliminate allocation from sbrk() (easy) 该部分要做的事情很简单：在 sbrk() 系统调用的处理函数中，不要分配内存，只修改进程的 sz 即可。由于我们只修改了 sz 而没有为新申请的空间绑定页面，所以当用户程序使用这块内存的时候 (load/store指令)，就会因为页表无法翻译虚拟地址而报 kernel panic。\nLazy allocation (moderate) 在该部分需要做的修改和注意事项在课上基本讲过，可以参考 Lecture 08 的课堂笔记。总体来说，我们需要在 usertrap() 中识别出缺页异常并写一个缺页异常的处理函数：申请一个物理页面，将导致错误的虚拟地址所在的虚拟页面映射过去。此外，由于延迟分配的存在，我们在 uvmunmap() 时释放的不一定是已经映射过的地址，应当取消其中的一些 panic 语句。","tags":null,"title":"MIT-6.S081 Lab 05: Lazy allocation","type":"docs"},{"authors":null,"categories":null,"content":"Progress Print a page table (easy) A kernel page table per process (hard) Simplify copyin/copyinstr (hard) Print a page table (easy) 在 /kernel/vm.c 中新建一个函数 vmprint() 用于打印页表信息。为了方便编码，笔者在 /kernel/vm.c 中又定义了一个函数 vmprint_recursive()，该函数不仅接收页表地址，还接收一个 layer 参数，用于确定打印信息时在前面加多少组 ..。vmprint_recursive() 遍历传入页表的 512 个页表项，如果页表项的 PTE_V 位为 1 (页表存在) ，则打印页表项的值和其对应的物理地址。如果当前页表项不是底层页表项 (叶子节点)，就递归地继续打印。我们可以根据页表项的标志信息来判断它是不是叶子节点：叶子节点的页表项除了 PTE_V 还会有其他的 RWXU 等权限位，而各级页目录页表项只有 PTE_V 为 1。\nExplain the output of vmprint in terms of Fig 3-4 from the text. What does page 0 contain? What is in page 2? When running in user mode, could the process read/write the memory mapped by page 1?\n第 0 个页面存储了用户的代码段和数据段，第 2 个页面是用户栈。在用户态下，进程不能读写第 1 个页面，因为根据第一个页面的页表项，其 PTE_U 位为 0，用户态无访问权限 (第 1 个页面是用户栈下方的保护页面，在创建后通过 uvmclear() 函数清除了 PTE_U 位)。\nA kernel page table per process (hard) 根据 RISC-V 架构的约定，page table walk 的工作理应交给硬件完成，那么为什么 xv6 中要有 walkaddr() 这样的函数来在软件层面进行 page table walk呢？\nxv6 中当用户陷入内核态时，satp 寄存器会切换到内核页表。内核页表中只有内核部分的映射，因此在内核态中如果想要访问用户内存中的数据，就必须在软件层面进行虚拟地址的翻译：抓着用户页表和用户虚拟地址调用 walkaddr() 函数获得物理地址，再拿着物理地址进行操作 (内核页表是恒等映射，因此这个物理地址也可以当做 \u0026ldquo;虚拟地址\u0026rdquo; 使用)。\n该实验部分和下一个实验部分的目的是：为每一个进程创建一个“用户内核页表”。该页表的内核部分映射与内核页表相同，用户部分映射与用户页表相同。这样用户进程从用户态陷入内核态时，不再切换到内核页表，而是切换到本进程的“用户内核页表”，这样在内核中执行操作时，页表中包含用户部分的映射，用户部分虚拟地址的翻译就可以交给硬件做了。\n该实验部分主要负责完成用户内核页表的内核部分的映射。根据提示内容，\nAdd a field to struct proc for the process\u0026rsquo;s kernel page table.\n在 struct proc 中添加一个 pagetable_t 类型的变量 k_pagetable 来存储用户内核页表。\nA reasonable way to produce a kernel page table for a new process is to implement a modified version of kvminit that makes a new page table instead of modifying kernel_pagetable. You\u0026rsquo;ll want to call this function from allocproc.\n笔者起初认为：为什么不让每个进程的 k_pagetable 直接指向 kernel_pagetable 呢？这样就省去了为每个进程做映射的工作？如果理解了整个实验的目的，我们就会明白这是不合理的。我们的目的不仅是完成内核映射，还要让这份页表同时拥有该进程的用户映射，内核中的原始份内核页表无法将各个进程的用户映射都存下来 (彼此冲突)。这样做也许可以通过这个实验部分，但将在下一个实验部分走入死胡同。\n正确的做法是仿照 kvminit() 函数写一份初始化映射，将页表基地址保存在 p-\u0026gt;k_pagetable 中。allocproc() 函数在 userinit() 和 fork() 中被调用，负责创建一个新进程。我们在 allocproc() 中调用用户内核页表的初始化映射函数即可。\nMake sure that each process\u0026rsquo;s kernel page table has a mapping for that process\u0026rsquo;s kernel stack. In unmodified xv6, all the kernel stacks are set up in procinit. You will need to move some or all of this functionality to allocproc.\n笔者没有动 procinit() 的代码，即内核页表中有所有进程内核栈的映射，并准备在每个进程的用户内核页表中映射自己进程的内核栈地址。这里笔者犯的错误是：在 allocproc() 中又 kalloc() 了一个新的页面作为用户栈。这样用户内核页表中的用户栈和内核页表中的用户栈实际上指向了不同的物理页面实体。我们要时刻记住用户内核页表只应该复制映射，映射应该指向相同的实体，这样陷入内核态之后才能看到页面中的改变。\nModify scheduler() to load the process\u0026rsquo;s kernel page table into the core\u0026rsquo;s satp register (see kvminithart for inspiration). Don\u0026rsquo;t forget to call sfence_vma() after calling w_satp().\nscheduler() should use kernel_pagetable when no process is running.\n这是笔者感到迷茫的部分，因为根据课程 schedule 的进度，做该实验时理应还没有看中断部分的内容，所以笔者对 scheduler() 函数的意义很不了解。经过大致的摸索，核心循环\nfor(p = proc; p \u0026lt; \u0026amp;proc[NPROC]; p++) { acquire(\u0026amp;p-\u0026gt;lock); if(p-\u0026gt;state == RUNNABLE) { // Switch to chosen process. It is the process's job // to release its lock and then reacquire it // before jumping back to us. p-\u0026gt;state = RUNNING; c-\u0026gt;proc = p; swtch(\u0026amp;c-\u0026gt;context, \u0026amp;p-\u0026gt;context); // Process is done running for now. // It should have changed its p-\u0026gt;state before coming back. c-\u0026gt;proc = 0; found = 1; } release(\u0026amp;p-\u0026gt;lock); } 负责找到第一个处于 RUNNABLE 状态的进程，然后将其状态设置为 RUNNING，并通过 swtch() 函数切换过去。也就是说，执行完 swtch 之后，xv6 就会转去执行进程 p (此时仍然在内核态中)，因此应该在 swtch() 之前将 satp 寄存器改写为 p 进程的用户内核页表。\n一个进程运行完毕后，会返回到 swtch 的下一条语句执行，这时候 CPU 核处于没有进程运行的状态。因此应该在 swtch() 之后调用 kvminithart() 函数将 satp 寄存器改写为内核页表。\nFree a process\u0026rsquo;s kernel page table in freeproc.\nYou\u0026rsquo;ll need a way to free a page table without also freeing the leaf physical memory pages.\nfreeproc() 函数负责进程的释放。其中 proc_freepagetable() 函数负责将该进程的用户页表释放。我们需要再写一个函数将用户内核页表也释放。注意用户内核页表的实体是那些内核物理页面和该进程的用户物理页面。该进程的用户物理页面已经随着用户页表的释放而释放了，而内核物理页面不能被释放，否则内核代码就消失了。因此我们不能直接调用 proc_freepagetable()，而要再写一个 proc_freekpagetable()。\n此外，proc_freepagetable() 中调用的 freewalk() 函数负责递归地释放所有的页表页面，该函数默认底层的物理页面已经被释放，如果不符合要求会触发 kernel panic。但在用户内核页表页面的释放过程中底层的 (内核) 物理页面是没有被释放的，因此不能直接调用 freewalk() 函数，而要仿照它再写一个不会对底层物理页面存在报错的 kfreewalk()。\nSimplify copyin/copyinstr (hard) 该实验部分承接上一个实验部分，要补全用户内核页表的用户部分的映射。我们只要做到 xv6 中任何对用户页表有修改的地方，我们在用户内核页表中将这些修改的映射抄一份即可。这里务必要注意的一点是：用户页表中会申请新的物理页面，但我们不应该在用户内核页表中也申请新的页面，而是应该映射到用户页表申请的物理页面。只有这样我们才能在陷入内核态时访问到用户态时保存的数据。\nxv6 涉及用户页表修改的有三处：fork()，exec()，和 growproc()。\nfork() 函数会申请一个新的进程，调用 uvmcopy() 函数将父进程的用户页表复制给子进程的用户页表。注意：我们不能调用 uvmcopy() 来将父进程的用户页表内容复制到子进程的用户内核页表。因为父进程和子进程互相独立，所以 uvmcopy() 在复制的时候不仅复制页表内容，所有底层的物理页面也申请了新的并复制了一遍 (在 copy-on-write fork 中这一点会得到改善)。我们的用户内核页表是不应该将底层物理页面复制的。子进程的用户内核页表一定要抄子进程的用户页表，映射到子进程的用户页表的物理页面上。\nexec() 函数根据 ELF 文件创建了一个新的内存镜像，并用新的页表替换旧的页表。在用户进程页表中我们也应该进行相对应的更新：首先将旧页表相关的映射删除 (这里需要格外小心的一点是：exec() 调用 proc_freepagetable() 释放旧页表时，已经将旧页表的底层物理页面一并释放了，我们在删除用户内核页表中的旧页表内容时，不需要再释放一遍底层物理页面，只需要清除相关的页表项即可。)，然后将新页表的映射抄进用户内核页表。\ngrowproc() 函数根据 n 的正负分别调用 uvmalloc() 和 uvmdealloc() 来调整用户内存的大小。我们在用户内核页表中也应该进行相对应的更新。对于 uvmalloc() 来说，要注意用户内核页表要映射到用户页表创建的那些物理页面中，为此笔者写了一个类似于 uvmcopy() 的函数来进行复制。对于 uvmdealloc() 来说，要注意用户页表负责释放底层物理页面，用户内核页表不能做重复的事。\n(注：内核部分映射和用户部分映射可以合二为一的重要前置条件是两者没有重复的映射。根据 xv6 手册，低于 0x80000000 的很多部分的内存是作为外设地址的。因此用户实际可用的内存空间其实远小于 MAXVA。式样讲义规定用户只能使用 PLIC 以下的地址。但事实上 CLINT 映射的地址比 PLIC 还要低，实验证明如果不取消 CLINT 的映射，用户内存会覆盖到这部分，触发 \u0026lsquo;remap\u0026rsquo; kernel panic。因此笔者只能在用户内核页表的映射中将 CLINT 移除。)\nWhat permissions do the PTEs for user addresses need in a process\u0026rsquo;s kernel page table? (A page with PTE_U set cannot be accessed in kernel mode.)\n用户内核页表的页表项不能照抄用户页表，因为 QEMU 模拟的 RISC-V 硬件在内核态下是不能访问带有 PTE_U 位的页面的。因此用户内核页表的底层页表项都要将 PTE_U 挖去。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0674a379007869bec887a4df9cefc548","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/labs/lab03/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/labs/lab03/","section":"notes","summary":"Progress Print a page table (easy) A kernel page table per process (hard) Simplify copyin/copyinstr (hard) Print a page table (easy) 在 /kernel/vm.c 中新建一个函数 vmprint() 用于打印页表信息。为了方便编码，笔者在 /kernel/vm.c 中又定义了一个函数 vmprint_recursive()，该函数不仅接收页表地址，还接收一个 layer 参数，用于确定打印信息时在前面加多少组 .","tags":null,"title":"MIT-6.S081 Lab 03: Page tables","type":"docs"},{"authors":null,"categories":null,"content":"Progress System call tracing (moderate) Sysinfo (moderate) System call tracing (moderate) 该实验可以对 xv6 中系统调用的过程有一个大致的了解。\n在 /user/trace.c 中，程序解析了 trace() 后的所有，将 trace 之后的那一个数字作为 trace 的参数，剩下的作为另外的一条命令调用 exec()。\ntrace() 函数是用 assembly 写的，由 /user/usys.pl 生成。/user/usys.pl 是一个脚本，内容如下：\n#!/usr/bin/perl -w # Generate usys.S, the stubs for syscalls. print \u0026quot;# generated by usys.pl - do not edit\\n\u0026quot;; print \u0026quot;#include \\\u0026quot;kernel/syscall.h\\\u0026quot;\\n\u0026quot;; sub entry { my $name = shift; print \u0026quot;.global $name\\n\u0026quot;; print \u0026quot;${name}:\\n\u0026quot;; print \u0026quot; li a7, SYS_${name}\\n\u0026quot;; print \u0026quot; ecall\\n\u0026quot;; print \u0026quot; ret\\n\u0026quot;; } entry(\u0026quot;fork\u0026quot;); entry(\u0026quot;exit\u0026quot;); ... 对于每一个系统调用，它会生成一个函数，将系统调用号 SYS_name 放到 a7 寄存器中，然后使用 ecall 陷入内核。根据 calling convention，剩下的系统调用参数放在 a0 a1 …… 寄存器中，因为和 trace.c 中准备参数的过程相同，所以不需要额外再做一次参数准备。\n硬件提升完特权级后，根据 stvec 寄存器的值进行地址跳转，stvec 内保存的地址是 /kernel/trampoline.S 中的 uservec。uservec 是用 assembly 写的，保存了上下文，并跳转到 /kernel/trap.c 中的函数 usertrap。usertrap 根据 scause 寄存器的值，认定这是一个系统调用，于是转到 /kernel/syscall.c 中的函数 syscall。\nsyscall 根据 a7 寄存器的值获取系统调用号，并执行相应的系统调用服务程序（所有的服务程序都存在 syscalls[] 数组中）。\n对于 trace() 系统调用来说，我们需要注册一个函数 sys_trace() 。xv6 提供了一系列函数来获取系统调用的参数（本质上是根据 calling convention 提取寄存器的值），argint() 用于获取值，argaddr() 用于获取地址，argstr() 用于获取字符串（本质上是对寄存器的值进行了不同的类型解释）。我们需要在 proc 结构体中新定义一个变量来存储 trace mask，将参数取出放进这个变量即可。\n此外，在 syscall 中，每执行完一个系统调用准备返回时，我们要根据 trace mask 决定是否将其相关的信息打印。我们需要额外准备一个数组存储所有系统调用的名字，进程号可以通过 p-\u0026gt;pid 获得。\n根据讲义的定义，父进程 fork 出的子进程要继承 trace mask，因此需要修改一下 fork 函数的代码，将 p-\u0026gt;tMask 复制给 np-\u0026gt;tMask 即可。\nSysinfo (moderate) 该实验与上一个实验的主要不同在于：\nsysinfo(struct sysinfo *) 系统调用需要将信息写回到 user space 的结构体中，因此需要从 kernel space 向 user space 复制信息，可以参考 fstat() 系统调用的实现来运用 copyout() 函数，由于目前还未实现虚拟存储相关细节，故不深究 copyout() 的具体原理。\n当前进程的个数很好统计，进程信息保存在 /kernel/proc.c 的 proc[] 数组里，proc[] 数组的每个元素是一个 proc 结构体，只要结构体的 state 变量不是 UNUSED 就是一个当前的进程。\n当前剩余的内存统计稍为复杂。xv6 实现了分页机制，/kernel/kalloc.c 负责物理内存的分配和释放。具体的组织形式和各个函数的意义见 Xv6 源码解读手册。\n要实现剩余内存的统计，我们只要数一数 freelist 链表中有多少个页面即可。可以每次现场数一遍，也可以维护一个变量，在 kalloc() 和 kfree() 的时候动态统计空闲页面的个数。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a6b7f8e440123ba78e40a6fcf8bbb616","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/labs/lab02/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/labs/lab02/","section":"notes","summary":"Progress System call tracing (moderate) Sysinfo (moderate) System call tracing (moderate) 该实验可以对 xv6 中系统调用的过程有一个大致的了解。\n在 /user/trace.c 中，程序解析了 trace() 后的所有，将 trace 之后的那一个数字作为 trace 的参数，剩下的作为另外的一条命令调用 exec()。\ntrace() 函数是用 assembly 写的，由 /user/usys.pl 生成。/user/usys.pl 是一个脚本，内容如下：","tags":null,"title":"MIT-6.S081 Lab 02: System calls","type":"docs"},{"authors":null,"categories":null,"content":"Progress Uthread: switching between threads (moderate) Using threads (moderate) Barrier (moderate) Uthread: Switching Between Threads (moderate) 该实验要实现一个“用户态协程库”，每个协程通过 yield() 函数主动让出 CPU 来让其他协程运行。笔者定义了如下的结构体：\nstruct thread { char stack[STACK_SIZE]; /* the thread's stack */ int state; /* FREE, RUNNING, RUNNABLE */ struct context *context; }; 其中 context 指针指向的地方用于存储和恢复寄存器现场，笔者的代码会利用堆栈低地址处的 sizeof(struct context) 的空间来存放这个 context。\nthread_create() 类似于 xv6 中的设计，创建线程时我们要在 context 中伪造一个用于返回的寄存器现场：设置 ra 为目标函数地址，sp 为改线程的栈的地址即可。\n笔者曾经遇到一个非常难以理解的 bug：某函数的代码在运行过程中被修改，导致段错误。经过排查发现：笔者忘了为 main() 函数对应的线程设置 context 指针，context 指针默认初始值为 0，从而在第一次上下文切换时，main() 的上下文覆盖了代码段。我们应该在 thread_init() 中为 main() 的线程做好初始化。\nxv6 的用户进程中代码段是从 0 地址开始保存的，查看 /kernel/exec.c 可知 xv6 通过 uvmalloc() 申请页面并将代码放入，uvmalloc() 也是 sbrk() 系统调用底层的函数，申请的页面默认是 R/W/X/U 的，所以用户进程有修改的权利 (加载时将代码段设置为不可写或许更容易暴露 bug)。\nthread_switch() 这部分代码用汇编实现，可以完全参考 /kernel/swtch.S 的实现。类似地，因为 thread_switch() 在 C 代码中被当作一个普通函数调用，编译器会帮我们保证 caller-saved registers 的封存 (栈上)，我们只需要保存 callee-saved registers 即可。\nthread_schedue() 该函数负责挑选一个 RUNNABLE 的线程，然后通过 thread_switch() 跳过去。\nthread_yield() 该函数只需要将当前线程的状态改为 RUNNABLE，然后调用 thread_schedule() 即可。\nUsing Threads (moderate) 该实验使用 Linux 的 pthread 线程库，是非常基础的带锁并发编程实验。为哈希表的每个 bucket 上一把锁就可以既保证正确性又通过速度测试。\nBarrier (moderate) 该实验使用 Linux 的 pthread 线程库，是非常基础的条件变量编程实验。我们甚至不需要生产者-消费者模型——我们只要让先来的线程在条件变量上睡眠，最后一个到来的线程 broadcast 一下即可。\n一个小细节是我们要在 barrier() 中修改 round，但 round 只能被修改一次。我们可以让每个线程上来先保存一个旧的 round 值，然后被唤醒后每个线程上锁检查 round，只有看到 old == new 的线程可以 +1。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e972b9cd051cc27851a7de3b8b2c679e","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/labs/lab07/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/labs/lab07/","section":"notes","summary":"Progress Uthread: switching between threads (moderate) Using threads (moderate) Barrier (moderate) Uthread: Switching Between Threads (moderate) 该实验要实现一个“用户态协程库”，每个协程通过 yield() 函数主动让出 CPU 来让其他协程运行。笔者定义了如下的结构体：\nstruct thread { char stack[STACK_SIZE]; /* the thread's stack */ int state; /* FREE, RUNNING, RUNNABLE */ struct context *context; }; 其中 context 指针指向的地方用于存储和恢复寄存器现场，笔者的代码会利用堆栈低地址处的 sizeof(struct context) 的空间来存放这个 context。","tags":null,"title":"MIT-6.S081 Lab 07: Multithreading","type":"docs"},{"authors":null,"categories":null,"content":"Progress RISC-V assembly (easy) Backtrace (moderate) Alarm (hard) RISC-V assembly (easy) Q: Which registers contain arguments to functions? For example, which register holds 13 in main\u0026rsquo;s call to printf?\nRISC-V 中，函数调用的参数按顺序存放在 a0 a1 a2 a3 …… 中。以 printf() 为例，13 是它的第三个参数，所以存放在 a2 寄存器中。\nQ: Where is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)\n汇编代码中没有直接调用函数 f() 和 g()，因为 f() 和 g() 是非常简单的函数，编译器对其做了优化，直接将 f(8)+1 的结果 12 写入了寄存器 a1。\nQ: At what address is the function printf located?\nprintf() 函数的地址为 0x628。可以在 call.asm 中直接搜索到，也可以通过 main() 函数的汇编代码\n30:\t00000097 auipc\tra,0x0 34:\t5f8080e7 jalr\t1528(ra) # 628 \u0026lt;printf\u0026gt; 看出 printf() 函数的地址。\nQ: What value is in the register ra just after the jalr to printf in main?\nra 寄存器中存储的应该是 printf() 函数的返回地址。根据 RISC-V 手册中 jalr 指令的定义，pc+4 的值会被写入 ra 寄存器。因此当前 ra 的值为 0x38。\nQ: Run the following code.\nunsigned int i = 0x00646c72; printf(\u0026quot;H%x Wo%s\u0026quot;, 57616, \u0026amp;i); What is the output? Here\u0026rsquo;s an ASCII table that maps bytes to characters.\nThe output depends on that fact that the RISC-V is little-endian. If the RISC-V were instead big-endian what would you set i to in order to yield the same output? Would you need to change 57616 to a different value?\nHere\u0026rsquo;s a description of little- and big-endian and a more whimsical description.\n输出的结果是：\nHe110 World 第一，十进制数 57616 转换成十六进制是 E110H。使用 \u0026ldquo;%x\u0026rdquo; 打印时，十六进制中的字母都是小写字母，所以第一处打印结果为 e110。\n第二，变量 i 的地址被传给了 printf()，printf() 会将该地址处的数据按照字符串类型进行解读，即每个字节按照 ASCII 码翻译成字符进行输出。RISC-V 是小端机器，因此地址 \u0026amp;i 处往后若干个字节的内容为\n\u0026amp;i \u0026amp;i + 1 \u0026amp;i + 2 \u0026amp;i + 3 72 $\\rightarrow$ \u0026lsquo;r\u0026rsquo; 6c $\\rightarrow$ \u0026rsquo;l' 64 $\\rightarrow$ \u0026rsquo;d' 00 $\\rightarrow$ \u0026lsquo;\\0\u0026rsquo; 遇到结束符即停止输出，因此第二处打印结果为 rld。\n如果 RISC-V 是大端机器，为了使第二处输出结果不变，i 的值应该修改为 0x726c6400。第一处的 57616 不需要修改，因为只要存和取都遵循大端方式，数据的值就不会改变。\nQ: In the following code, what is going to be printed after 'y='? (note: the answer is not a specific value.) Why does this happen?\nprintf(\u0026quot;x=%d y=%d\u0026quot;, 3); y= 后的内容是进入 printf() 函数后 a2 寄存器中的值。由于这里的 printf() 函数少了一个参数，a2 寄存器中的值是 UB，输出结果会是一个无法预料的随机数。\nBacktrace (moderate) 要实现的 Backtrace 功能和 GDB 中的 backtrace 基本相同：根据栈帧内容回溯函数调用的过程。\n首先需要获取当前函数的栈帧。sp 寄存器指向栈顶，但栈帧的大小是不确定的，我们需要的是栈底指针 fp (即 s0 寄存器)。可以通过内联汇编的方式来读取 fp 寄存器的值。\nstatic inline uint64 r_fp() { uint64 x; asm volatile(\u0026quot;mv %0, s0\u0026quot; : (=r) (x)); return x; } 由于现在处在内核态，当前的栈帧存储在上一个用户进程的内核栈上。内核栈大小为一个页面，可以通过 PGROUNDDOWN(fp) 和 PGROUNDUP(fp) 来分别获得内核栈的栈顶地址和栈底地址。我们的函数回溯追踪只在内核栈范围内，因为更远的回溯会到用户栈上。\n根据 RISC-V 的栈帧格式，fp 指针实际上指向的是上一个栈帧的底部 (课程中 TA 的说法有误)。在 RV64 中，fp-8 的位置存储了当前函数的返回地址，这个地址理应在当前函数的 caller 函数范围内，打印这个地址就相当于追踪到了上一个函数。fp-16 的位置存储了上一个栈帧的 fp 的内容。将这个值赋给 fp 即可实现顺着栈帧向上爬的功能。\n关于 printf() 的输出不能得到正确的结果\n笔者起初使用 printf() 的 %x 来输出返回地址，但得到的结果出入很大。xv6 中的 printf() 不是调用的 C 库函数，而是自己实现的。阅读 printf() 的源码可以看到，%x 输出十六进制数只能输出 int 范围内的。要打印一个地址应该使用 %p 模式来输出。\nAlarm (hard) 我们需要实现两个系统调用\nint sigalarm(int ticks, void (*handler)()); int sigreturn(void); sigalarm() 负责在当前进程中打开一个定时器，每过 ticks 个周期就执行一次 handler 函数。为了实现这个功能，我们需要在 proc 结构体中添加一些字段：nticks 负责存储当前的周期，handler 负责存储回调函数的地址 (用户虚拟地址)，curticks 负责记录自上一次调用 handler 之后，已经过了多少个周期。在 sys_sigalarm() 函数中，我们应当更新这些字段。\n此处的周期指的不是 CPU 的时钟周期，而是指时钟中断的周期。因此在 usertrap() 函数中，每次判断到 which_dev == 2 ，即时钟中断到来，则 curticks++，若 curticks 达到了 nticks，则下一次返回用户态应转移到回调函数。sepc 寄存器决定了返回用户态时的地址，因此只要将 handler 赋给 p-\u0026gt;trapframe-\u0026gt;epc 即可。\n回调函数的最后一定会使用 sigreturn() 系统调用，该系统调用负责回到原本用户程序的中断处继续执行。触发了回调函数的这次中断走过的路程应该是这样的：\n​\t用户程序 $\\overset{时钟中断}{\\rightarrow}$ 内核 $\\rightarrow$ 回调函数 $\\overset{系统调用}{\\rightarrow}$ 内核 $\\rightarrow$ 用户程序\n在触发时钟中断时，用户程序的上下文会被保存在 p-\u0026gt;trapframe 中，但从回调函数再进入内核的时候，trapframe 里的上下文会被覆盖。要想对用户程序完全透明地执行这个过程，我们要在执行回调函数之前将原始上下文保存起来。因此我们需要在 proc 结构体中再定义一些变量用来保存原始上下文。笔者使用的一种简单的方法是定义一个 trapframe 结构体 u_trapframe，在进入回调函数之前将 p-\u0026gt;trapframe 里的内容写到 u_trapframe 里。\n此外 test2 中还测试了一种问题：我们在进入回调函数的时候，应该关闭 sigalarm() 设置的定时器。否则如果回调函数执行时间过长，在执行回调函数的过程中某一次时钟中断又触发定时器调用回调函数，就会陷入死递归。因此我们在 proc 结构体中还需要一个变量来记录当前是否是从回调函数中陷入内核态的。这个状态应该在前一次准备进入回调函数时置 1，在 sigreturn() 中清零。当该变量置 1 时，时钟中断不对计时器进行检查。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"163b71a2d152c535be564e57c9c0ca55","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/labs/lab04/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/labs/lab04/","section":"notes","summary":"Progress RISC-V assembly (easy) Backtrace (moderate) Alarm (hard) RISC-V assembly (easy) Q: Which registers contain arguments to functions? For example, which register holds 13 in main\u0026rsquo;s call to printf?\nRISC-V 中，函数调用的参数按顺序存放在 a0 a1 a2 a3 …… 中。以 printf() 为例，13 是它的第三个参数，所以存放在 a2 寄存器中。","tags":null,"title":"MIT-6.S081 Lab 04: Traps","type":"docs"},{"authors":null,"categories":null,"content":"Progress boot xv6 (easy) sleep (easy) pingpong (easy) primes (medium)/(hard) find (medium) xargs (medium) Boot xv6 (easy) 刚刚克隆完项目后文件夹里没有东西，这是正常的。切换到 util 分支之后即可看到内容。\n使用 make grade 命令进行尝试时发现报错：\n/usr/bin/env: python: No such file or directory 笔者根据 stakoverflow 上的 这个回答进行了修复：首先检查了一下 python3 是否安装，发现已经安装。出现上述报错的原因是系统内只有 python3 这个程序。因此只要创建一个名为 python 的指向 python3 的软链接即可。\nsudo ln -s /usr/bin/python3 /usr/bin/python 想要使用 gdb 调试 xv6 的话，可以先在一个窗口工作目录下执行\nmake CPUS=1 qemu-gdb 然后新开一个窗口，在工作目录下执行 riscv64-linux-gnu-gdb 或 gdb-multiarch，后者会自行判断架构。初次运行可能会遇到 .gdbinit 相关的问题。此时需要创建文件 ~/.gdbinit，并在其中写\nadd-auto-load-safe-path ~/xv6-labs-2020/.gdbinit sleep (easy) C 语言编程练习，只需要使用 sleep() 系统调用即可。不过需要注意 sleep 的参数规则：\n如果 sleep 没有参数，应当给出错误提示。 sleep 可以有多个参数，应该将多个参数相加的值传给 sleep() 系统调用。 sleep 的任何一个参数中有非数字字符时，应当给出错误提示。 pingpong (easy) 笔者最初只是用了一个管道，在父进程中 write(p[1], \u0026quot;a\u0026quot;, 1) 后又 read(p[0], buf, sizeof(buf))，但这样相当于父进程从管道里读到了自己的输出，没有完成和子进程的互动。\n因此需要使用两个管道，第一个管道用于父进程输出，子进程读入，第二个管道用于子进程输出，父进程读入。\nprimes (moderate)/(hard) 笔者的初代实现如下：\n以第一层为例，父进程创建一个管道之后 fork 出一个子进程，然后将 $2,3,\\cdots,35$ 喂给管道的输出端。子进程从管道的输入端接收这些数。子进程收到的第一个数一定是质数，它可以用这个数将剩下的数中这个质数的倍数筛除。之后子进程自己变成一个“父进程”，将收到的数中除了最小质数和被筛除的数的其他数传给自己的子进程。该过程一直持续，直到没有数为止。\n核心代码：\nwhile (tot \u0026gt; 0) { pipe(p); int pid = fork(); if (pid \u0026lt; 0) exit_error(); else if (pid == 0) { close(p[1]); int cur, curp; tot = -1; while (read(p[0], \u0026amp;cur, sizeof(cur)) \u0026gt; 0) { if (tot == -1) { printf(\u0026quot;prime %d\\n\u0026quot;, cur); tot ++; curp = cur; } else { if (cur % curp != 0) a[tot ++] = cur; } } close(p[0]); } else { close(p[0]); for (int i = 0; i \u0026lt; tot; i ++) write(p[1], a + i, sizeof(int)); close(p[1]); int status; wait(\u0026amp;status); if (status != 0) exit_error(); exit(0); } } 这样做有一个关键的问题：每一层进程都是完全接收了上一层的数，做完筛法i，再把所有的数传给下一层进程，没有使筛法充分并行起来。\n真正并发/并行的做法是：每个进程有一个管道和父亲通信，另开一个管道和自己的子进程通信。每从自己的父进程接收到一个数就立刻传给自己的子进程。这样的话，比如在第一层进程中 5 通过了 2 的筛查，被传入了第二层，然后第一层进程在筛查 6，7，8，9\u0026hellip; 的时候，第二层进程已经在用 3 筛查 5 了，这样真正做到了并行。将递归与这个过程结合起来写代码会非常舒服，否则需要维护一大堆管道的编号，使编码变复杂。\n需要注意的一点是管道的使用。父进程在给子进程传递完数据后，一定要先关闭管道的输出端再调用 wait() ，否则子进程的 read() 在管道输出没有被全部关闭的情况下是不会退出的。\nfind (moderate) 参考 ls 程序的实现可以对 find 的实现起到很大的帮助。\nfind 的实现需要对 xv6 的文件系统有一个粗浅的了解。以下知识是对该任务的实现有帮助的：\n当我们拿到一个文件时，可以用 fstat() 系统调用来获取它的信息。fstat() 系统调用将文件信息写到作为参数的 stat 结构体中，stat 结构体的 type 参数刻画了这是一个文件，文件夹还是设备。\n在通俗的观念中，文件夹是一个“容器”，里面放了很多的文件。但事实上文件夹本身也是一个文件。按照 xv6 的 /kernel/fs.h 中所说，\u0026ldquo;Directory is a file containing a sequence of dirent structures.\u0026rdquo; dirent 结构体的定义如下：\n#define DIRSIZ 14 struct dirent { int inum; char name[DIRSIZ]; } inum 是该文件占据的 inode 的个数，我们不必访问那些 inum 为 0 的文件。name 是文件名，在 xv6 中，我们默认文件名不超过 14 个字节。因此在 open 了一个文件夹文件后，我们只要不断用 read(fd, \u0026amp;de, sizeof(dirent)) 命令来读取信息，就可以获得文件夹内所有文件的文件名。将文件名和之前的路径拼接起来，就可以访问文件夹内部的文件。\n可以用递归来实现文件夹内部文件的访问，但不要对 . 和 .. 递归，否则会造成死递归。\n笔者最初实现完发现文件系统后面的若干的文件都显示 find: cannot open ...，经过筛查发现这是因为没有多余的文件描述符可以使用了。在 xv6 中，资源比较有限，我们应该养成打开一个文件，读取完相关信息就关闭它的好习惯。\nxargs (moderate) 有一些命令不支持从管道读取输入，而 xargs 命令可以帮助这些命令从管道读取信息。注意：管道的创建和输出输入的重定向是由 shell 来完成的，我们的 xargs 程序无需关心输入的来源，只需要从标准输入 (文件描述符 1) 读取信息即可。\n为新命令准备参数的环节是较好的 C 语言指针练习。笔者新建了一个 char *child_args[MAXARG] 数组来为子进程传递参数。xargs 后紧跟的那几个参数是确定的，再后面的参数需要读入，目前还不能确定长度，所以应该在读取完之后用 malloc() 来申请内存空间，并在子进程执行完成后用 free() 释放空间防止内存泄漏。为了能够准确识别到 \\n 以执行多条指令，笔者采取了一个字符一个字符地从标准输入读取信息的方式。读取到的字符暂存在局部数组 buf 中，一旦遇到 \u0026rsquo; \u0026rsquo; 或 \u0026lsquo;\\n\u0026rsquo; 就根据 buf 的长度申请内存，将 buf 复制到参数数组里。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7c83806135a053abf683e15255399146","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-operating-system/labs/lab01/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-operating-system/labs/lab01/","section":"notes","summary":"Progress boot xv6 (easy) sleep (easy) pingpong (easy) primes (medium)/(hard) find (medium) xargs (medium) Boot xv6 (easy) 刚刚克隆完项目后文件夹里没有东西，这是正常的。切换到 util 分支之后即可看到内容。\n使用 make grade 命令进行尝试时发现报错：\n/usr/bin/env: python: No such file or directory 笔者根据 stakoverflow 上的 这个回答进行了修复：首先检查了一下 python3 是否安装，发现已经安装。出现上述报错的原因是系统内只有 python3 这个程序。因此只要创建一个名为 python 的指向 python3 的软链接即可。","tags":null,"title":"MIT-6.S081 Lab 01: Xv6 and Unix utilities","type":"docs"},{"authors":null,"categories":null,"content":"Consider 2 equations with 2 unknowns. Here\u0026rsquo;s an example: $$ \\begin{cases} 2x-y=0\\\\ -x+2y=3 \\end{cases} $$ In linear algebra, we have $A=\\left [\\begin{matrix}2 \u0026amp; -1\\\\-1 \u0026amp; 2\\end{matrix}\\right ]$ the coefficient matrix, vector $\\mathbf{x}=\\left(\\begin{matrix}x\\\\y\\end{matrix}\\right)$, $\\mathbf{b}=\\left(\\begin{matrix}0\\\\3\\end{matrix}\\right)$. Then the equations can be written in the form $$ A\\mathbf{x}=\\mathbf{b} $$ If we focus on the \u0026ldquo;column picture\u0026rdquo;, the equations can be regarded as linear combinations of vectors $$ x\\begin{bmatrix}2 \\\\-1\\end{bmatrix}+y\\begin{bmatrix}-1\\\\2\\end{bmatrix}=\\begin{bmatrix}0\\\\3\\end{bmatrix} $$ The column picture of the solution to the equations is shown below:\nUnder the idea of linear combinations, the question\nCan I solve $A\\mathbf{x}=\\mathbf{b}$ for every $\\mathbf{b}\\in \\mathbb{R}^n$ ?\nis equivalent to the question\nDo the combinations of the columns fill the n-dimensional space?\nThe answer is not always \u0026ldquo;yes\u0026rdquo;. For instance, if one vector is the combination of another 2 vectors, the combinations of the columns cannot fill the whole space. This case is called a singular case and the coefficient matrix $A$ is not invertible.\nThe product of a matrix and a vector $$ \\left [\\begin{matrix}a \u0026amp; b\\\\c \u0026amp; d\\end{matrix}\\right]\\left (\\begin{matrix}x\\\\y\\end{matrix}\\right)=\\left (\\begin{matrix}ax+by\\\\cx+dy\\end{matrix}\\right) $$ can be understood as $$ \\left [\\begin{matrix}a \u0026amp; b\\\\c \u0026amp; d\\end{matrix}\\right]\\left (\\begin{matrix}x\\\\y\\end{matrix}\\right)=x\\left(\\begin{matrix}a\\\\c\\end{matrix}\\right)+y\\left(\\begin{matrix}b\\\\d\\end{matrix}\\right) $$ which means that $A\\mathbf{x}$ can be interpreted as the linear combinations of vectors.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"241e3bbd367c61013bf2bfd9f497981d","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec01/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec01/","section":"notes","summary":"Consider 2 equations with 2 unknowns. Here\u0026rsquo;s an example: $$ \\begin{cases} 2x-y=0\\\\ -x+2y=3 \\end{cases} $$ In linear algebra, we have $A=\\left [\\begin{matrix}2 \u0026amp; -1\\\\-1 \u0026amp; 2\\end{matrix}\\right ]$ the coefficient matrix, vector $\\mathbf{x}=\\left(\\begin{matrix}x\\\\y\\end{matrix}\\right)$, $\\mathbf{b}=\\left(\\begin{matrix}0\\\\3\\end{matrix}\\right)$.","tags":null,"title":"MIT-18.06 Lecture 01: The Geometric Interpretation of Equations","type":"docs"},{"authors":null,"categories":null,"content":"Consider the 3 equations with 3 unknowns: $$ \\begin{cases} x+2y+z = 2\\\\ 3x+8y+z = 12\\\\ 4y+z = 2 \\end{cases} $$ The coefficient matrix $$ A=\\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1\\\\ 3 \u0026amp; 8 \u0026amp; 1\\\\ 0 \u0026amp; 4 \u0026amp; 1 \\end{matrix} \\right] $$ The process of elimination is $$ \\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1\\\\ 3 \u0026amp; 8 \u0026amp; 1\\\\ 0 \u0026amp; 4 \u0026amp; 1 \\end{matrix} \\right] \\overset{(2,1)}{\\rightarrow} \\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1\\\\ 0 \u0026amp; 2 \u0026amp; -2\\\\ 0 \u0026amp; 4 \u0026amp; 1 \\end{matrix} \\right] \\overset{(3,2)}{\\rightarrow} \\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1\\\\ 0 \u0026amp; 2 \u0026amp; -2\\\\ 0 \u0026amp; 0 \u0026amp; 5 \\end{matrix} \\right] $$ The basic procedure is repeatedly choosing pivots (Pivots cannot be zero) and using the pivot to eliminate other lines. The final target is the upper triangle matrix $U$.\nWhen a non-zero pivot cannot be chosen from the currently available equations, the elimination failed.\nTo find the solution to the equations, we need to apply the elimination steps on the augmented matrix. Augmented matrix means the coefficient matrix with an extra column. $$ \\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1 \u0026amp; 2\\\\ 3 \u0026amp; 8 \u0026amp; 1 \u0026amp; 12\\\\ 0 \u0026amp; 4 \u0026amp; 1 \u0026amp; 2 \\end{matrix} \\right] \\overset{(2,1)}{\\rightarrow} \\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1 \u0026amp; 2\\\\ 0 \u0026amp; 2 \u0026amp; -2 \u0026amp; 6\\\\ 0 \u0026amp; 4 \u0026amp; 1 \u0026amp; 2 \\end{matrix} \\right] \\overset{(3,2)}{\\rightarrow} \\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1 \u0026amp; 2\\\\ 0 \u0026amp; 2 \u0026amp; -2 \u0026amp; 6\\\\ 0 \u0026amp; 0 \u0026amp; 5 \u0026amp; -10 \\end{matrix} \\right] $$\nTypically, we call the target of $\\mathbf{b}$​​​ the vector $\\mathbf{c}$​​​. The target of elimination is to transform $A\\mathbf{x}=\\mathbf{b}$​ into $U\\mathbf{x}=\\mathbf{c}$. After back substitution, the solution is $x=2, y=1,z=-2$​​​.\nIn the last lecture we mentioned that a matrix multiplying a column vector can be interpreted as linear combinations of the column vectors of the matrix. In the same way,\n$$ (x,y,z)\\begin{bmatrix}a_1 \u0026amp; a_2 \u0026amp; a_3\\\\b_1 \u0026amp; b_2 \u0026amp; b_3\\\\c_1 \u0026amp; c_2 \u0026amp; c_3\\end{bmatrix}=x\\cdot (a_1,a_2,a_3)+y\\cdot (b_1,b_2,b_3)+z\\cdot (c_1,c_2,c_3) $$\na row vector multiplying a matrix can be interpreted as linear combinations of the row vectors of the matrix.\nSo we can use “matrix language” to explain the above elimination steps.\nStep 1: Subtract $3\\times row_1$ from $row_2$​ (the target is to eliminate (2,1), so we call it $E_{2,1}$, here $E$ means elementary or elimination) $$ E_{2,1}=\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\-3 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] $$ Step 2: Subtract $2\\times row_2$ from $row_3$ $$ E_{3,2}=\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; -2 \u0026amp; 1\\end{matrix}\\right] $$ So in matrix language, the above elimination steps can be written as $$ E_{3,2}\\cdot (E_{2,1}\\cdot A)=U $$ which is extremely simple. Notice that matrix multiplication satisfies the associative law, so we can use an $E=E_{3,2}\\cdot E_{2,1}$ to directly achieve the goal.\nIn this case we only need one type of elementary matrix: subtract $x\\times row_i$ from $row_j$. But in some cases we need to do row exchanges, and we need another type of elementary matrix: the permutation matrix.\nUnder the idea of linear combinations of row vectors, it’s super-easy to construct a permutation matrix. Take the $2\\times 2$ matrix as an example: $$ \\left[\\begin{matrix}0 \u0026amp; 1\\\\1 \u0026amp; 0\\end{matrix}\\right] \\left[\\begin{matrix}a \u0026amp; b\\\\c \u0026amp; d\\end{matrix}\\right]= \\left[\\begin{matrix}c \u0026amp; d\\\\a \u0026amp; b\\end{matrix}\\right] $$\nPermutation matrices that do column exchanges have the similar principle. But notice that matrices multiplied on the left are responsible for row transformation, if we want to do column transformation we need to multiply the matrix on the right, that is\n$$ \\begin{bmatrix}a \u0026amp; b\\\\c \u0026amp; d\\end{bmatrix}\\begin{bmatrix}0 \u0026amp; 1\\\\1 \u0026amp; 0\\end{bmatrix}=\\begin{bmatrix}b \u0026amp; a\\\\d \u0026amp; c\\end{bmatrix} $$\nTake the elementary matrix from the last lecture as an example to talk a little about inverse: $$ \\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\-3 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] $$ the function of the matrix is to subtract $3\\times row_1$ from $row_2$. So if there’s a matrix that can “undo” the operation, its function is to add $3\\times row_1$ to $row_2$, which leads to $$ \\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\3 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] \\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\-3 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right]= \\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] $$ we can simply write it as $E^{-1}\\cdot E=I$. The matrix on the left is the inverse matrix of the matrix on the right.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"278b3d7cb736166575c55a1209755ffe","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec02/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec02/","section":"notes","summary":"Consider the 3 equations with 3 unknowns: $$ \\begin{cases} x+2y+z = 2\\\\ 3x+8y+z = 12\\\\ 4y+z = 2 \\end{cases} $$ The coefficient matrix $$ A=\\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1\\\\ 3 \u0026amp; 8 \u0026amp; 1\\\\ 0 \u0026amp; 4 \u0026amp; 1 \\end{matrix} \\right] $$ The process of elimination is $$ \\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1\\\\ 3 \u0026amp; 8 \u0026amp; 1\\\\ 0 \u0026amp; 4 \u0026amp; 1 \\end{matrix} \\right] \\overset{(2,1)}{\\rightarrow} \\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1\\\\ 0 \u0026amp; 2 \u0026amp; -2\\\\ 0 \u0026amp; 4 \u0026amp; 1 \\end{matrix} \\right] \\overset{(3,2)}{\\rightarrow} \\left[ \\begin{matrix} 1 \u0026amp; 2 \u0026amp; 1\\\\ 0 \u0026amp; 2 \u0026amp; -2\\\\ 0 \u0026amp; 0 \u0026amp; 5 \\end{matrix} \\right] $$ The basic procedure is repeatedly choosing pivots (Pivots cannot be zero) and using the pivot to eliminate other lines.","tags":null,"title":"MIT-18.06 Lecture 02: Elimination Matrices","type":"docs"},{"authors":null,"categories":null,"content":"Suppose $AB=C$ and $A,B,C$ are matrices, the formula for calculating a single entry of $C$ is $$ C_{i,j}=(row_i\\space of\\space A)\\cdot(col_j\\space of\\space B)=\\sum_{k=1}^nA_{i,k}B_{k,j} $$ To apply matrix multiplication, we must ensure that the number of columns of $A$​ equals the number of row s of $B$​. If $A$​ is $m\\times n$​ in size and $B$​ is $n\\times p$​ in size, then C is $m\\times p$​ in size.\nAccording to what we’ve covered in the last two lectures, if we divide $B$ into several columns, then $C$ can be interpreted as several linear combinations of column vectors of $A$ sitting together. Similarly, if we divide $A$ into several rows, $C$​ can be interpreted as several linear combinations of row vectors of $B$ sitting together.\nThe fourth way of doing matrix multiplication is $$ C=\\sum_{k=1}^n(col_i\\space of A)\\times (row_i\\space of\\space B) $$ notice that here we use the cross product. The matrix produced by $(col_i\\space of\\space A)\\times (row_i\\space of\\space B)$ has some good properties: each column of the result matrix is multiples of $(col_i\\space of\\space A)$ and each row of the result matrix is multiples of $(row_i\\space of\\space B)$. In other words, the row space and column space of the result matrix are both a single line.\nThe fifth way is block multiplication. For example, if $A$ and $B$ are square matrices, we divide $A$ and $B$ into four blocks, then $$ C=\\left[\\begin{matrix}C_1 \u0026amp; C_2\\\\C_3 \u0026amp; C_4\\end{matrix}\\right] =\\left[\\begin{matrix}A_1 \u0026amp; A_2\\\\A_3 \u0026amp; A_4\\end{matrix}\\right] \\left[\\begin{matrix}B_1 \u0026amp; B_2\\\\B_3 \u0026amp; B_4\\end{matrix}\\right] $$ $C_1=A_1B_1+A_2B_3$ ,here the multiplication are all matrix multiplication. Other blocks follow the same rule.\nFor convenience, let’s focus on the inverses of square matrices.\nIf a square matrix $A$ has an inverse, then $A^{-1}A=I$. Here for square matrices, the left inverse equals to the right inverse, so $AA^{-1}$ will also give $I$​.\nLet’s consider the cases that a square matrix has no inverse, which we call it singular or non-invertible. $$ A=\\left[\\begin{matrix}1 \u0026amp; 3\\\\2 \u0026amp; 6\\end{matrix}\\right] $$ Why doesn’t it have an inverse? Suppose it has an inverse matrix, consider the linear combinations of the row vectors of $A$. The two vectors are collinear, so it’s impossible to make the linear combinations equals $(1,0)$ and $(0,1)$.\nWe can consider it in another way: We can find a non-zero vector $\\mathbf{x}$ such that $A\\mathbf{x}=0$​. For this example, $\\mathbf{x}=\\left(\\begin{matrix}3\\\\-1\\end{matrix}\\right)$ is a suitable column vector. If there exists a non-zero vector $\\mathbf{x}$ such that $A\\mathbf{x}=0$, then suppose $A$​ has an inverse, then $A^{-1}(A\\mathbf{x})=(A^{-1}A)\\mathbf{x}=I\\mathbf{x}=\\mathbf{x}\\neq 0$，however, $A^{-1}\\cdot 0=0$, which leads to a contradiction.\nThe two ways describe the same thing: If one of the row/column is useless, i.e. it can be constructed by other rows/columns, the matrix is non-invertible.\nFor the invertible/non-singular matrices, how to calculate the inverse? Here we introduce the Gauss-Jordan method.\nConsider an invertible $2\\times 2$ square matrix $$ \\left[\\begin{matrix}1 \u0026amp; 3\\\\2 \u0026amp; 7\\end{matrix}\\right] $$ let’s put the identity matrix besides it to make it an augmented matrix. $$ \\left[\\begin{matrix}1 \u0026amp; 3 \u0026amp; 1 \u0026amp; 0\\\\2 \u0026amp; 7 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] $$ Let’s do eliminations on the left matrix. Different from the classic Gauss elimination whose target is to get the upper triangle matrix,here we need to get the identity matrix. To implement that, after we choose a pivot, we should eliminate all the elements that are in the same column and not in the current row, including the elements above. $$ \\left[\\begin{matrix}1 \u0026amp; 3 \u0026amp; 1 \u0026amp; 0\\\\2 \u0026amp; 7 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right]\\overset{(2,1)}{\\rightarrow}\\left[\\begin{matrix}1 \u0026amp; 3 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp; -2 \u0026amp; 1\\end{matrix}\\right] \\overset{(1,2)}{\\rightarrow}\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 7 \u0026amp; -3\\\\0 \u0026amp; 1 \u0026amp; -2 \u0026amp; 1\\end{matrix}\\right] $$ The matrix on the right $\\left[\\begin{matrix}7 \u0026amp; -3\\\\-2 \u0026amp; 1\\end{matrix}\\right]$ is the inverse.\nThe principle is easy: according to the last lectures, elimination steps can be interpreted as several elimination matrices. Consider all the elimination steps give us $E$, then $EA=I$, which means that $E=A^{-1}$. The right matrix is $EI=E=A^{-1}$, so we get the right solution.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d7d4833b581dd513bfb000c49dbb0201","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec03/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec03/","section":"notes","summary":"Suppose $AB=C$ and $A,B,C$ are matrices, the formula for calculating a single entry of $C$ is $$ C_{i,j}=(row_i\\space of\\space A)\\cdot(col_j\\space of\\space B)=\\sum_{k=1}^nA_{i,k}B_{k,j} $$ To apply matrix multiplication, we must ensure that the number of columns of $A$​ equals the number of row s of $B$​.","tags":null,"title":"MIT-18.06 Lecture 03: Multiplication and Inverse Matrix","type":"docs"},{"authors":null,"categories":null,"content":"What’s the inverse of $AB$, supposing $A$ and $B$​ are both invertible matrices? We can use $B^{-1}A^{-1}$ to check: $$ \\begin{align} (B^{-1}A^{-1})AB=B^{-1}(A^{-1}A)B=B^{-1}B=I\\\\ AB(B^{-1}A^{-1})=A(BB^{-1})A^{-1}=AA^{-1}=I \\end{align} $$ So $(AB)^{-1}=B^{-1}A^{-1}$.\nWhat’s the inverse of $A^T$? Consider $AA^{-1}=I$. Transpose both sides and we get $$ (AA^{-1})^T=(A^{-1})^TA^T=(I)^T=I $$ so $(A^T)^{-1}=(A^{-1})^T$. In other words, you can change the order of inversing and transposing.\nConsider a $2\\times 2$ matrix $$ A=\\left[ \\begin{matrix} 2 \u0026amp; 1\\\\ 8 \u0026amp; 7 \\end{matrix} \\right] $$ To eliminate it to an upper triangle matrix $U$， we use the elementary matrix $$ E_{2,1}=\\left[\\begin{matrix}1 \u0026amp; 0\\\\-4 \u0026amp; 1\\end{matrix}\\right],E_{2,1}A=U=\\left[\\begin{matrix}2 \u0026amp; 1\\\\0 \u0026amp; 3\\end{matrix}\\right] $$ To write it in the form of $A=LU$，we can easily find that $L=E^{-1}$ and for elementary matrices, the inverse is easy to calculate - just add a negative sign \u0026lsquo;-\u0026rsquo;. So $L=\\left[\\begin{matrix}1 \u0026amp; 0\\\\4 \u0026amp; 1\\end{matrix}\\right]$. Here $L$ represents lower triangle matrix. $$ A=LU=\\left[\\begin{matrix}1 \u0026amp; 0\\\\4 \u0026amp; 1\\end{matrix}\\right]\\left[\\begin{matrix}2 \u0026amp; 1\\\\0 \u0026amp; 3\\end{matrix}\\right] $$\nIn some cases, we write $$ A=LDU=\\left[\\begin{matrix}1 \u0026amp; 0\\\\4 \u0026amp; 1\\end{matrix}\\right]\\left[\\begin{matrix}2 \u0026amp; 0\\\\0 \u0026amp; 3\\end{matrix}\\right]\\left[\\begin{matrix}1 \u0026amp; \\frac{1}{2}\\\\0 \u0026amp; 1\\end{matrix}\\right] $$ We extract the diagonal matrix $D$ from $U$ to makes it cleaner.\nHere we cannot see differences between $EA=U$ and $A=LU$. Let\u0026rsquo;s consider a $3\\times 3$ example. Say there\u0026rsquo;s no row exchanges, $E_{3,2}E_{3,1}E_{2,1}A=U$，$E_{3,1}$ is an identity matrix and $$ E_{3,1}=\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\-2 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] , E_{3,2}=\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; -5 \u0026amp; 1\\end{matrix}\\right] $$ so $$ E=E_{3,2}E_{3,1}E_{2,1}= \\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\-2 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] \\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; -5 \u0026amp; 1\\end{matrix}\\right] = \\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\-2 \u0026amp; 1 \u0026amp; 0\\\\10 \u0026amp; -5 \u0026amp; 1\\end{matrix}\\right] $$ It\u0026rsquo;s not obvious to tell why the number $10$ appears. Actually it\u0026rsquo;s because that we firstly subtract $2\\times row_1$ from $row_2$，then we subtract $5\\times (new)row_2$ from $row_3$, and in total we add $10\\times row_1$ to $row_3$.\nIf we use the $A=LU$ form, then $$ L=E_{2,1}^{-1}E_{3,1}^{-1}E_{3,2}^{-1}=\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\2 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right]\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\0 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 5 \u0026amp; 1\\end{matrix}\\right]=\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 0\\\\2 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 5 \u0026amp; 1\\end{matrix}\\right] $$ We can see that due to the elaborate order, operations will not interfere with each other. If there\u0026rsquo;s no row exchange, the multipliers during eliminations will go directly into $L$.\nThat\u0026rsquo;s the advantage of $A=LU$. With $L$ and $U$ we can completely forget about $A$ since $LU$ contains all the information about $A$. What\u0026rsquo;s more, $L$ , the inverse of $E$, has the beautiful property that it contains the complete information about elimination steps.\nHow many operations on $A$ during elimination?\nFor a $n\\times n$ matrix, it takes us approximately $n^2$ operations to tackle with the first row and the first column, then the problem becomes a $(n-1)\\times (n-1)$ one. So the cost is $$ \\sum_{k=1}^nk^2\\sim \\int_1^nx^2\\mathrm{d}x\\sim \\frac{1}{3}n^3 $$ And for a column vector, say $\\mathbf{b}$, the cost is approximately $n^2$.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"435eefd52bd42d6ea46456561cda3c0f","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec04/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec04/","section":"notes","summary":"What’s the inverse of $AB$, supposing $A$ and $B$​ are both invertible matrices? We can use $B^{-1}A^{-1}$ to check: $$ \\begin{align} (B^{-1}A^{-1})AB=B^{-1}(A^{-1}A)B=B^{-1}B=I\\\\ AB(B^{-1}A^{-1})=A(BB^{-1})A^{-1}=AA^{-1}=I \\end{align} $$ So $(AB)^{-1}=B^{-1}A^{-1}$.\nWhat’s the inverse of $A^T$?","tags":null,"title":"MIT-18.06 Lecture 04 - A’s LU Decomposition","type":"docs"},{"authors":null,"categories":null,"content":"Now let\u0026rsquo;s allow row exchanges to come in during elimination, so we need permutation matrices.\nPermutation matrices can be regarded as identity matrices with some rows exchanged. For $n\\times n$ matrix, there are $n!$ kinds of permutation matrices (the identity matrix is a special permutation matrix).\nAn important property of permutation matrices is that $$ P^{-1}=P^T $$ The property is easy to understand: only the $i_{th}$ row and the $i_{th}$ column have $1$ in the same position, so $P^TP=I$.\nIf we take row exchanges into consideration, the formula will be $$ PA=LU $$ where $P$ is one of the permutation matrices to make the pivots at the right positions.\nTranspose is defined as follows: $$ (A^T){ij}=A{ji} $$ Symmetric matrices are those satisfying $A^T=A$. It\u0026rsquo;s easy to construct a symmetric matrix because for any matrix $R$, $R^TR$ is a symmetric matrix. ($(R^TR)^T=R^T(R^T)^{T}=R^TR$)\nVector spaces are bunches of vectors. There are two basic operations: vector addition and multiplying a scalar to a vector. There are some rules for these two operations (refer to the textbook). The most important one is:\nThe result of addition and multiplication (i.e. linear combinations of vectors) should stay in the vector space.\nWe can easily check that $\\mathbb{R}^n$ is a vector space, it contains all the column vectors with $n$ real components, while the first quadrant of $\\mathbb{R}^2$ is not a vector space because it\u0026rsquo;s not closed under multiplication by all real numbers.\nLet consider subspaces of $\\mathbb{R}^2$. There are three types of subspaces:\n$\\mathbb{R}^2$ itself Any line that crosses through $\\left(\\begin{matrix}0\\\\0\\end{matrix}\\right)$ (we call it $L$) Zero vector only (we call it $Z$) The conclusion can be easily extended to $\\mathbb{R}^n$.\nLet\u0026rsquo;s see how we can use matrices to produce vector spaces. Take the $3\\times 2$ matrix $$ \\left[\\begin{matrix}1 \u0026amp; 3\\\\2 \u0026amp; 3\\\\4 \u0026amp; 1\\end{matrix}\\right] $$ as an example, the columns of the matrix (i.e. two column vectors $\\left(\\begin{matrix}1\\\\2\\\\4\\end{matrix}\\right)$ and $\\left(\\begin{matrix}3\\\\3\\\\1\\end{matrix}\\right)$) span a subspace in $\\mathbb{R}^3$. In geometry, the subspace is a plane going through the origin in $\\mathbb{R}^3$.\nIn general, all the linear combinations of the column vectors of a matrix $A$ form a subspace called column space, denoted as $C(A)$.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5c702eef13da4fca3b081dec5e1ff577","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec05/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec05/","section":"notes","summary":"Now let\u0026rsquo;s allow row exchanges to come in during elimination, so we need permutation matrices.\nPermutation matrices can be regarded as identity matrices with some rows exchanged. For $n\\times n$ matrix, there are $n!","tags":null,"title":"MIT-18.06 Lecture 05: Permutation, Transpose and Vector Spaces","type":"docs"},{"authors":null,"categories":null,"content":"Suppose there are two vector spaces $S$ and $T$, their intersection $S\\cap T$ is also a subspace.\nProof: suppose $v,w\\in S\\cap T$ are vectors, then consider a linear combination $av+bw$, since $v,w\\in S$, $av+bw\\in S$ , also we have $av+bw\\in T$, so $av+bw\\in S\\cap T$, which proves the theorem.\nConsider $$ A=\\left[\\begin{matrix}1 \u0026amp; 1 \u0026amp; 2\\\\2 \u0026amp; 1 \u0026amp; 3\\\\3 \u0026amp; 1 \u0026amp; 4\\\\4 \u0026amp; 1 \u0026amp; 5\\end{matrix}\\right] $$ all the linear combinations of the three column vectors of $A$ forms a column space $C(A)$. It\u0026rsquo;s a subspace of $\\mathbb{R}^4$ since all the vectors have 4 dimensions.\nWe can find that the subspace cannot fill the whole $\\mathbb{R}^4$. Let\u0026rsquo;s consider the linear equations $$ A\\mathbf{x}= \\left[\\begin{matrix}1 \u0026amp; 1 \u0026amp; 2\\\\2 \u0026amp; 1 \u0026amp; 3\\\\3 \u0026amp; 1 \u0026amp; 4\\\\4 \u0026amp; 1 \u0026amp; 5\\end{matrix}\\right] \\left(\\begin{matrix}x_1\\\\x_2\\\\x_3\\end{matrix}\\right) =\\left(\\begin{matrix}b_1\\\\b_2\\\\b_3\\\\b_4\\end{matrix}\\right)=\\mathbf{b} $$ There are four equations with three unknowns. The equations don\u0026rsquo;t necessarily have solutions. We care about what b\u0026rsquo;s allow the equations to be solved.\nIf we use linear combinations to understand matrix multiplications, we can find that $A\\mathbf{x}$ is the linear combinations of the column vectors of $A$, so $\\mathbf{b}$ allows the equations to be solved exactly when $\\mathbf{b}\\in C(A)$.\nWhat\u0026rsquo;s more, we can find that the third column vector makes no contribution: $col_1+col_2=col_3$. If we delete the third column vector, the column space won\u0026rsquo;t be changed. So actually $C(A)$ is a 2-dimensional subspace of $\\mathbb{R}^4$. We call the first two columns pivot columns.\n(Actually we can choose any column and discard it, but by convention we choose the first several columns that are independent.)\nThe null space of a matrix $A$, denoted as $N(A)$, contains all the solutions to $A\\mathbf{x}=\\mathbf{0}$. For the example $A$, all the vectors $\\left(\\begin{matrix}c\\\\c\\\\-c\\end{matrix}\\right)$ are in the null space, $N(A)$ is a line in $\\mathbb{R}^3$.\nThe null space is really a subspace because for any $A\\mathbf{v}=\\mathbf{0}$ and $A\\mathbf{w}=\\mathbf{0}$, $A\\mathbf{(v+w)}=A\\mathbf{v}+A\\mathbf{w}=\\mathbf{0}$.\nFrom column spaces and null spaces we can see that there are two ways to construct a subspace:\nuse the linear combinations of several vectors to form a subspace. add constraints to linear equations to form a subspace. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d64b1723ca009db30b2b7dc3b3d694b4","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec06/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec06/","section":"notes","summary":"Suppose there are two vector spaces $S$ and $T$, their intersection $S\\cap T$ is also a subspace.\nProof: suppose $v,w\\in S\\cap T$ are vectors, then consider a linear combination $av+bw$, since $v,w\\in S$, $av+bw\\in S$ , also we have $av+bw\\in T$, so $av+bw\\in S\\cap T$, which proves the theorem.","tags":null,"title":"MIT-18.06 Lecture 06: Column Space, Null space","type":"docs"},{"authors":null,"categories":null,"content":"We solve the equation $A\\mathbf{x}=\\mathbf{0}$ through elimination. Obviously, elimination won\u0026rsquo;t change the null space of $A$. For example, let $$ A=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\2 \u0026amp; 4 \u0026amp; 6 \u0026amp; 8\\\\3 \u0026amp; 6 \u0026amp; 8 \u0026amp; 10\\end{matrix}\\right] $$ through elimination we get the echelon matrix $U$: $$ A=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\2 \u0026amp; 4 \u0026amp; 6 \u0026amp; 8\\\\3 \u0026amp; 6 \u0026amp; 8 \u0026amp; 10\\end{matrix}\\right]\\overset{(2,1),(3,1)}{\\longrightarrow}\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 4\\\\0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 4\\end{matrix}\\right]\\overset{(3,3)}{\\longrightarrow}\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 4\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\end{matrix}\\right]=U $$ The number of pivots is call the rank of $A$. There are two pivots, so $rank(A)=2$.\nBy convention, we choose 1st and 3rd column as pivot columns, and the rest are free columns. Accordingly, $x_1$ and $x_3$ are pivot variables, $x_2$ and $x_4$ are free variables. We can assign values to free variables freely, and for every set of values, there\u0026rsquo;s a unique solution to the pivot variables.\nIn particular, if we assign $x_2=1,x_4=0$ , and $x_2=0,x_4=1$, we can get two solutions: $$ \\mathbf{x_1}= \\left(\\begin{matrix}-2\\\\1\\\\0\\\\0\\end{matrix}\\right) \\qquad \\mathbf{x_2}= \\left(\\begin{matrix}2\\\\0\\\\-2\\\\1\\end{matrix}\\right) $$ These solutions are called special solutions. The linear combinations of the special solutions forms the null space. That is $$ N(A)=c\\left(\\begin{matrix}-2\\\\1\\\\0\\\\0\\end{matrix}\\right)+d\\left(\\begin{matrix}2\\\\0\\\\-2\\\\1\\end{matrix}\\right),c,d\\in \\mathbb{R} $$ And for a matrix $A$ with size $m\\times n$, the number of special solutions is $(n-rank(A))$.\nWe can work harder on $U$ to get the reduced row echelon form, denoted as $R$ or $rref(A)$. It eliminates values both above and below the pivots, and transform pivots to 1: $$ U=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 4\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\end{matrix}\\right]\\overset{(1,3)}{\\longrightarrow}\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 0 \u0026amp; -2\\\\0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\end{matrix}\\right]=R $$ To make it clear, we do column exchanges so that we put pivots columns together on the left and free columns together on the right: $$ \\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 0 \u0026amp; -2\\\\0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\end{matrix}\\right]\\overset{2\\leftrightarrow 3}{\\longrightarrow}\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 2 \u0026amp; -2\\\\0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 2\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\end{matrix}\\right] $$ The advantage of $R$ is that we can directly see the special solutions from the matrix. If we ignore the rows with all 0s, we find that $R=\\left[\\begin{matrix}I \\mid F\\end{matrix}\\right]$. $I$ is an identity matrix with size $r\\times r$ ( $r$ means the rank) and $F$ is $r\\times (n-r)$ in size. We can construct all the $(n-r)$ special solutions as a matrix: $$ N=\\left[\\begin{matrix}-F\\\\I\\end{matrix}\\right]=\\left[\\begin{matrix}-2 \u0026amp; 2\\\\0 \u0026amp; -2\\\\1 \u0026amp; 0\\\\0 \u0026amp; 1\\end{matrix}\\right] $$ $N$ is $n\\times (n-r)$ in size. (Here the $I$ may have the different size from the $I$ in $R$) If we use block multiplication of matrices, we can find out that $RN$ gives a matrix with all 0s.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1b186f2a96b718da10ab8bcb3c479d60","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec07/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec07/","section":"notes","summary":"We solve the equation $A\\mathbf{x}=\\mathbf{0}$ through elimination. Obviously, elimination won\u0026rsquo;t change the null space of $A$. For example, let $$ A=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\2 \u0026amp; 4 \u0026amp; 6 \u0026amp; 8\\\\3 \u0026amp; 6 \u0026amp; 8 \u0026amp; 10\\end{matrix}\\right] $$ through elimination we get the echelon matrix $U$: $$ A=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\2 \u0026amp; 4 \u0026amp; 6 \u0026amp; 8\\\\3 \u0026amp; 6 \u0026amp; 8 \u0026amp; 10\\end{matrix}\\right]\\overset{(2,1),(3,1)}{\\longrightarrow}\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 4\\\\0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 4\\end{matrix}\\right]\\overset{(3,3)}{\\longrightarrow}\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 4\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\end{matrix}\\right]=U $$ The number of pivots is call the rank of $A$.","tags":null,"title":"MIT-18.06 Lecture 07: Computing Null Space, Pivot Variables and Special Solutions","type":"docs"},{"authors":null,"categories":null,"content":"Take an example: $$ A\\mathbf{x}=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\2 \u0026amp; 4 \u0026amp; 6 \u0026amp; 8\\\\3 \u0026amp; 6 \u0026amp; 8 \u0026amp; 10\\end{matrix}\\right]\\left(\\begin{matrix}x_1\\\\x_2\\\\x_3\\end{matrix}\\right)\\left(\\begin{matrix}b_1\\\\b_2\\\\b_3\\end{matrix}\\right)=\\mathbf{b} $$\n$$ \\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2 \u0026amp; b_1\\\\2 \u0026amp; 4 \u0026amp; 6 \u0026amp; 8 \u0026amp; b_2\\\\3 \u0026amp; 6 \u0026amp; 8 \u0026amp; 10 \u0026amp; b_3\\end{matrix}\\right] \\overset{elimination}{\\longrightarrow} \\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2 \u0026amp; b_1\\\\0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 4 \u0026amp; b_2-2b_1\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; b_3-b_2-b_1\\end{matrix}\\right] $$\nSo the equations have solutions exactly when $b_3=b_1+b_2$.\nLet\u0026rsquo;s talk about the solvability. $A\\mathbf{x}=\\mathbf{b}$ is solvable exactly when $b\\in C(A)$. Another equivalent description is that: If a combination of rows of $A$ gives zero row, then the same combination of components of $\\mathbf{b}$ must give 0.\nTo find the complete solutions to $A\\mathbf{x}=\\mathbf{b}$:\nEnsure that the zero rows = 0. Find a particular solution $\\mathbf{x_p}$: set all free variables to 0 and solve $A\\mathbf{x}=\\mathbf{b}$ for pivot variables. Find $N(A)$, then the complete solution set is $X_c={\\mathbf{x}=\\mathbf{x_p}+\\mathbf{x_n}:\\mathbf{x_n}\\in N(A)}$ Let\u0026rsquo;s focus on a bigger picture: an $m\\times n$ matrix with rank $r$ (it\u0026rsquo;s obvious that $r\\leq m,r\\leq n$):\nCase 1: Full column rank $(r=n\u0026lt;m)$\nNo free variable, so $N(A)={\\mathbf{0}}$. The reduced row echelon form $R=\\left[\\begin{matrix}I\\\\0\\end{matrix}\\right]$.\nIf the particular solution $\\mathbf{x_p}$ exists, then it\u0026rsquo;s the unique solution. The equations have 0 or 1 solutions.\nCase 2: Full row rank $(r=m\u0026lt;n)$\nWe can solve $A\\mathbf{x}=\\mathbf{b}$ for arbitrary $\\mathbf{b}$. The reduced row echelon form $R=\\left[\\begin{matrix}I \u0026amp; F\\end{matrix}\\right]$. (Notice that the columns of $I$ and $F$ may mix together)\nSince $F$ exists, $N(A)$ contains more than $\\mathbf{0}$, the equations have $\\infty$ solutions.\nCase 3: $r=n=m$\nIn this case $R=I$, which indicates that $A$ is invertible. And the equations have a unique solution.\nCase 4: $r\u0026lt;n,r\u0026lt;m$\nThe row reduced echelon form $R=\\left[\\begin{matrix}I \u0026amp; F\\\\0 \u0026amp; 0\\end{matrix}\\right]$. The equations have either no solution (zero rows don\u0026rsquo;t match $\\mathbf{b}$) or $\\infty$ solutions.\nOne sentence to summarize: the rank $r$ tells you all the information about the number of solutions.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"522f401f6f9a904357de9377671757d0","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec08/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec08/","section":"notes","summary":"Take an example: $$ A\\mathbf{x}=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2\\\\2 \u0026amp; 4 \u0026amp; 6 \u0026amp; 8\\\\3 \u0026amp; 6 \u0026amp; 8 \u0026amp; 10\\end{matrix}\\right]\\left(\\begin{matrix}x_1\\\\x_2\\\\x_3\\end{matrix}\\right)\\left(\\begin{matrix}b_1\\\\b_2\\\\b_3\\end{matrix}\\right)=\\mathbf{b} $$\n$$ \\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2 \u0026amp; b_1\\\\2 \u0026amp; 4 \u0026amp; 6 \u0026amp; 8 \u0026amp; b_2\\\\3 \u0026amp; 6 \u0026amp; 8 \u0026amp; 10 \u0026amp; b_3\\end{matrix}\\right] \\overset{elimination}{\\longrightarrow} \\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2 \u0026amp; b_1\\\\0 \u0026amp; 0 \u0026amp; 2 \u0026amp; 4 \u0026amp; b_2-2b_1\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; b_3-b_2-b_1\\end{matrix}\\right] $$","tags":null,"title":"MIT-18.06 Lecture 08: Complete Solutions of Equations","type":"docs"},{"authors":null,"categories":null,"content":"suppose $A$ is $m\\times n$ in size $(m\u0026lt;n)$, then the equation $A\\mathbf{x}=\\mathbf{0}$ has nonzero solutions because there will be at least one free variable.\nVectors $\\mathbf{x_1},\\mathbf{x_2},\u0026hellip;,\\mathbf{x_n}$ are independent if no combination gives zero vector. (except the zero combination)\ni.e. for any $c_1,c_2,\u0026hellip;,c_n$, $\\sum_{i=1}^n c_i\\mathbf{x_i}\\neq \\mathbf{0}$ ($c_i$ are not all 0s). Otherwise they\u0026rsquo;re dependent.\nIf $\\mathbf{v_1},\\mathbf{v_2},\u0026hellip;,\\mathbf{v_n}$ are column vectors of matrix $A$\nThey\u0026rsquo;re independent if $N(A)={\\mathbf{0}}$. In this case $rank(A)=n$. (No free variable, the essence of free columns is that it belongs to the linear combinations of previous pivot columns) They\u0026rsquo;re dependent if for some nonzero vector $\\mathbf{c}$, $A\\mathbf{c}=\\mathbf{0}$. In this case $rank(A)\u0026lt;n$. $n$ m-dimensional vectors $\\mathbf{x_1},\u0026hellip;,\\mathbf{x_n}$ $(m\u0026lt;n)$ is absolutely dependent. That\u0026rsquo;s because if we put the vectors together to form a matrix $A=\\left[\\mathbf{x_1}\\space \\mathbf{x_2} \\cdots \\mathbf{x_m}\\right]$, $A\\mathbf{x}=\\mathbf{0}$ has nonzero solutions.\nVectors $v_1,v_2,..,v_l$ span a space means that the space consists of all the combinations of those vectors.\nBasis for a vector space is a sequence of vectors $\\mathbf{v_1},\\mathbf{v_2},\u0026hellip;,\\mathbf{v_d}$ satisfying\nThey\u0026rsquo;re independent. They span the whole space. (In other words, the number of vectors is exactly \u0026ldquo;right\u0026rdquo;.)\n$n$ vectors in $\\mathbb{R}^n$ give basis if the $n\\times n$ matrix with those columns is invertible.\nif they\u0026rsquo;re independent, then every column is pivot column, so the reduced echelon form $R=I$. And eliminations can be represented as matrices. So the original matrix is invertible.\nGiven a space, every basis for the space has the same number of vectors, and we call this number the dimension of the space.\nTake an example, $$ A=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 1\\\\1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 1\\\\1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 1\\end{matrix}\\right] $$ The column vectors are dependent because $\\left(\\begin{matrix}-1\\\\-1\\\\1\\\\0\\end{matrix}\\right)\\in N(A)$. $rank(A)=2$ and $dimC(A)=2$. We find a important property: the rank of a matrix $A$ equals the dimension of $C(A)$, $dimC(A)=r$.\nColumn vectors 1 and 2 gives a basis of $C(A)$ and 1 and 3, 2 and 3 are basis too.\nThe two special solutions in $N(A)$ are $$ \\mathbf{x_1}=\\left(\\begin{matrix}-1\\\\-1\\\\1\\\\0\\end{matrix}\\right)\\qquad\\mathbf{x_2}=\\left(\\begin{matrix}-1\\\\0\\\\0\\\\1\\end{matrix}\\right) $$ In fact, $span{\\mathbf{x_1},\\mathbf{x_2}}=N(A)$. We see that the dimension of $N(A)$ equals the number of free variables. That is $dimN(A)=n-r$.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6a38c6e5aac93ecb2fb3d9746776e2b1","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec09/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec09/","section":"notes","summary":"suppose $A$ is $m\\times n$ in size $(m\u0026lt;n)$, then the equation $A\\mathbf{x}=\\mathbf{0}$ has nonzero solutions because there will be at least one free variable.\nVectors $\\mathbf{x_1},\\mathbf{x_2},\u0026hellip;,\\mathbf{x_n}$ are independent if no combination gives zero vector.","tags":null,"title":"MIT-18.06 Lecture 09: Linear Dependence, Basis and Dimension","type":"docs"},{"authors":null,"categories":null,"content":"4 fundamental subspaces:\ncolumn space $C(A)$. null space $N(A)$. row space. It contains all the combinations of the row vectors of $A$. In other words, it contains all the combinations of the column vectors of $A^T$, so the notation is $C(A^T)$. left null space. It\u0026rsquo;s the null space of $A^T$, denoted as $N(A^T)$. If $A$ is a matrix with size $m\\times n$, then $C(A),N(A^T)\\subseteq \\mathbb{R}^m$ while $C(A^T),N(A)\\subseteq \\mathbb{R}^n$. We\u0026rsquo;ve known that $\\dim C(A)=r,\\dim N(A)=n-r$. Here an amazing fact is that $\\dim C(A)=\\dim C(A^T)=r$. Thus $\\dim N(A^T)=m-r$. The beautiful property is that $\\dim C(A)+\\dim N(A^T)=m$ and $\\dim C(A^T)+\\dim N(A)=n$, which corresponds to the fact that the number of pivot variables pluses the number of free variables equals $n$.\nAbout basis, the pivot columns are a set of basis of $C(A)$ and the special solutions of $A\\mathbf{x}=\\mathbf{0}$ form a basis of $N(A)$.\nOf course we can transpose $A$ and do row operations on $A^T$ to get a basis of $C(A^T)$. But here\u0026rsquo;s an easier way: we can get a basis of $C(A^T)$ through the reduced row echelon form. Let\u0026rsquo;s take an example: $$ A=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 1\\\\1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 1\\\\1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 1\\end{matrix}\\right] \\rightarrow U=\\left[\\begin{matrix}1 \u0026amp; 2 \u0026amp; 3 \u0026amp; 1\\\\0 \u0026amp; -1 \u0026amp; -1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\end{matrix}\\right] \\rightarrow R=\\left[\\begin{matrix}1 \u0026amp; 0 \u0026amp; 1 \u0026amp; 1\\\\ 0 \u0026amp; 1 \u0026amp; 1 \u0026amp; 0\\\\0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\end{matrix}\\right] $$ Through $R$, we can see that the first two columns are pivot columns, so the first two columns of $A$ are basis of $C(A)$. Here we do row operations on $A$, so $C(A)\\neq C(R)$ of course, but considering the fact that doing row operations is just doing linear combinations of row vectors of $A$, $C(A^T)=C(R^T)$. And we can easily tell that $\\dim R^T=2=r$ and the first $r$ row vectors of $R$ are basis of $C(A^T)$. (They\u0026rsquo;re independent and if we do the row operations inversely, we can get all the rows of $A$)\nTo find out a basis for $N(A^T)$. Firstly we want to figure out the matrix that represents the row operations of $A\\rightarrow R$, i.e. we want to find a matrix $E$ such that $EA=R$.\nAccording to Gauss-Jordan, we put a identity matrix besides $A$, i.e. $A\u0026rsquo;=[A_{m\\times n}\\quad I_{m\\times m}]$. Suppose $EA\u0026rsquo;=$\n$E[A\\quad I]=[R\\quad E\u0026rsquo;]$, then we have $E=E\u0026rsquo;$, so by applying all the row operations on $I$, we can get $E$. In the above example, we can get $$ E=\\left[\\begin{matrix}-1 \u0026amp; 2 \u0026amp; 0\\\\1 \u0026amp; -1 \u0026amp; 0\\\\-1 \u0026amp; 0 \u0026amp; 1\\end{matrix}\\right] $$ We claim that the last $m-r$ row vectors of $E$ form a basis of $N(A^T)$ because the last $m-r$ lines of $R$ are zero lines.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"97c748de9d4d6987ed97ba48c0bdd53d","permalink":"https://kristoff-starling.github.io/notes/coursenotes/mit-linearalgebra/lectures/lec10/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/mit-linearalgebra/lectures/lec10/","section":"notes","summary":"4 fundamental subspaces:\ncolumn space $C(A)$. null space $N(A)$. row space. It contains all the combinations of the row vectors of $A$. In other words, it contains all the combinations of the column vectors of $A^T$, so the notation is $C(A^T)$.","tags":null,"title":"MIT-18.06 Lecture 10: 4 Fundamental Subspaces","type":"docs"},{"authors":null,"categories":null,"content":"实验进度 我完成了所有安装任务，完成了必答题，并针对思考题和遇到的其他问题进行了资料搜索和思考。\n必答题 我按照实验要求编写了 hello.c 并编写 Makefile 文件进行编译，并且学习了 GDB 的使用。这些内容无法直接呈现，故省略。\n关于《提问的智慧》 我们从小被要求养成提问的习惯，提问被认为是有好奇心或者善于探索的象征，但我认为背后有思考的提问才是真正有价值的。《提问的智慧》中提及了大量的提问相关的 convention 和技巧，其核心原理都是思考。\n我曾在知乎上看到一句话：“道德是用来约束自己的，不是用来约束别人的。”这句话当时被用来说明你不能强求别人写给你看的题解像喂饭一样深入浅出。我觉得这句话用在提问上也一样合适。除非你花钱雇了一个人专职为你解答问题，否则别人解答你的问题是一种义务劳动。你没有权利浪费别人的时间，别人也没有义务去回答一些愚蠢的问题或者给你保姆级的教程。我总结了一些《提问的智慧》中我觉得比较精华的内容罗列如下：\n不要问一些直接 STFW/RTFM 就能轻松获得答案的知识性问题，他们通常具有 \u0026ldquo;xxx是什么？\u0026quot;“xxx怎么用” 等格式。 作为一个计算机界的后辈，你遇到的问题有极大的概率是已经有无数人遇到过的问题。一些经典的问题通常可以在 Stack Overflow 等知名平台上找到解答，所以你应该确保你的问题没有现成可查的解决方案。 你应该尽可能详细地刻画你的问题，比如写下你已经用过哪些方法但失败了，也可以贴一些截图。一方面，更详细的信息可以让别人更好地了解你的情况，提供帮助；另一方面，这可以体现你为了解决问题已经付出过你能力范围内的努力。 机器永远是对的，不要说“我觉得我的gcc有问题/我觉得我的电脑坏了”之类的话（这是我在帮助上“程序设计基础”课的同学解决问题时经常听到的话）。另外，你手上的源码有很大概率经过了很多人的验证，所以不要轻易宣布自己发现了 bug。 作为一个提问者你不能显得趾高气昂，在提问中适当使用委婉的词汇可以使你的态度更加诚恳，但也不用过度使用以至于语句冗余。 对于我们这样的初学者来说问题可能还没有领域之分，但在日后如果提出一些分类较细的问题，需要注意提问的平台是否合适。 总之，想要提出一个好的问题，你需要在遇到困难时先主动自己解决，尝试能力范围内可以使用的方法，并且在你的提问中展现这个过程。这样蕴含了你的思考的问题才是有价值的。\n以下是我的自由报告内容，我在做实验的过程中详细记录了自己遇到的所有问题和查阅的所有资料。这些笔记按照章节排列，每章通常有两个部分：\n思考题：包含笔者针对思考题查阅的资料和我尝试给出的答案。 补充：这里的内容是没有在讲义中提及的问题，以及讲义中建议自学的东西。 Installing GNU/Linux 补充 在安装系统时遇到问题：\nExecuting grub_install failed. This is a fatal error.\n重启后直接进入 GNU/grub 命令行，说明系统引导出现了问题。经过排查发现使用了与硬盘不匹配的引导方式。\n硬盘分区一般有两种格式：MBR 和 GPT。前者是传统的模式，后者较新。笔者因为在一套老式电脑中安装系统所以遇到了这种格式的硬盘。\nMBR+LegacyBIOS MBR分区格式下最多支持四个主分区。如果想划分更多的分区，可以将其中一个主分区变为扩展分区，然后在扩展分区中建立逻辑分区。逻辑分区一般从 5 开始编号。另外 MBR 分区表对硬盘的容量大小有限制。\nMBR （Master Boot Record，主引导记录）存放在第一个扇区（一个扇区512字节）中，这个扇区不属于任何一个分区。这个扇区中包含如下内容：\nBootloader：446字节，内含引导程序，主要负责识别活动分区并引导系统 DPT (Partition Table，分区表)：64字节，存储了分区信息 Magic Number: 2字节，固定为0x55AA，结束标志字。 分区表的64个字节分成4组每组16个字节，分别记录了4个主分区的信息。\nPartition Flag (00) Start CHS (01~03) Partition Bytes (04) End CHS (05~07) Start LBA (08~11) Size (12~15) 00: 不可引导 80: 可以引导 分区开始的 CHS 值 分区类型\n83/linux 82/swap 8e/LVM etc. 分区结束的 CHS 值 相对的起始扇区号 该分区拥有的扇区数量 CHS 和 LBA 是两种不同的硬盘寻址方式。\nCHS寻址模式将硬盘划分为磁头 (Heads)，柱面 (Cylinder) 和扇区 (Sector) 。\n磁头：每张磁盘的正反面各有一个磁头，一个磁头对应了一个磁面。 柱面：所有磁片中半径相同的同心圆磁道构成柱面。 扇区：将圆环形磁道划分成若干个区段，就是扇区。每个扇区的容量为 512 字节。 CHS 部分共使用了 3 个字节 24 个二进制位，因此寻址范围是 $2^{24} bit$ ，约为 8G。这种方式较为古老现在已经几乎不用。\nLBA (Logic Block Addressing) 模式中地址不再表示实际的物理地址，而是将 CHS 地址转换成一种唯一的线性地址。由于 LBA 部分共有 32 个二进制位，因此寻址范围扩大到约 2.2TB。这就是前文所说的 MBR 硬盘分区的容量限制，对于更大的硬盘，LBA寻址方式并不能表示其地址。\nMBR分区格式的硬盘使用 Legacy BIOS 来引导操作系统。安装系统时应当在 BIOS 中调整引导方式为 Legacy only 或将 Legacy 模式的优先级放在 UEFI之前。\n以 Windows 系统为例，传统 Legacy 引导操作系统时，会通过活动分区（MBR只允许有一个活动分区）下的 bootmgr（启动管理器）文件导入根目录下 boot 文件夹内的 BCD 文件，然后 BCD 文件根据自身的配置内容加载系统启动文件 根目录\\Windows\\system32\\winload.exe来启动系统。\nLinux 使用的引导程序是 GRUB。\nGPT+UEFI GPT分区格式没有4个主分区的限制，且没有主分区、扩展分区、逻辑分区这些概念的区分，对于硬盘的容量也（几乎）没有限制。与GPT对应的UEFI启动方式相较于LegacyBIOS，省去了加电自检的环节，可以更快地引导系统启动，且界面支持鼠标甚至蓝牙等。这都是GPT+UEFI相较于传统的方式优秀的地方。\nGPT格式的硬盘有如下部分：\nPMBR (Protective MBR)：占据第一个扇区，其目的是防止只能识别MBR格式的工具误识别并写入硬盘。 Primary GPT Header：占据第二个扇区 Partition Entries：占据第三、第四个扇区 Partitions Backup Partition Entries/Primary GPT Header：对之前的信息进行备份。如果表头遭到了误删等操作可以利用备份进行恢复，增加了安全性。 UEFI引导需要硬盘中有一个 EFI 分区。EFI 分区中存放了引导程序，如 Windows 的 bootmgfw.efi，Linux 的 grubx64.efi 等。\n装机注意事项 为了同时兼容 MBR 和 GPT 型的硬盘，现在的 BIOS 同时提供 Legacy 和 UEFI 两种启动方式，因此需要根据硬盘将 BIOS/UEFI 调整到正确的模式。对于 MBR 型的硬盘，不需要创建 EFI 分区（安装 Linux 的时候会警告你没有创建 EFI，但没关系），最后的启动分区默认即可。对于 GPT 型的硬盘，可以为新系统创建单独的 EFI 分区，也可以与老系统共用 EFI 分区，但得保证有 EFI 分区。如果启动分区选择了 Linux 的 EFI 分区，将由 Linux 引导 Windows，在 GNU/GRUB 界面上可以选择 Ubuntu 或者 Windows Boot Manager。\nFirst Exploration with GNU/Linux 思考题 Why executing the poweroff command requires superuser privilege?\nCan you provide a scene where bad things will happen if the poweroff command does not require superuser privilege?\n例如我有一台服务器，我作为服务器的管理者可以用root的权限对网站进行修改操作。网站的使用者注册账号之后可以用普通账户来访问允许范围内的资源。如果普通账户拥有过大的权限以至于可以修改服务器的系统文件甚至直接关机，那么网站将直接崩溃。\nInstalling Tools 补充 在安装软件包的过程中遇到依赖问题无法安装，这是因为当前需要安装的软件包依赖其他软件包，而其他软件包在当前的源上找不到。我们可以添加更多的 Ubuntu 源，从而提供其他软件包的资源。\n例如使用清华大学的源，在 /etc/apt/sources.list 中添加如下语句：\ndeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ hirsute main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ hirsute-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ hirsute-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ hirsute-security main restricted universe multiverse 执行 sudo apt-get update 之后再下载软件包，即可正常进行。\nConfiguring Vim Vim 的 Recording 功能 Recording 功能可以帮助我们完成重复工作。以讲义中的示例为例，欲输出\n1 2 ... 100 只需依次按下 i1\u0026lt;ESC\u0026gt;q1yyp\u0026lt;C-a\u0026gt;q98@1 即可。\n按 q 再按下任意一个字符之后进入 Recording 模式。这里的字符相当于一个缓冲器名，表示接下来录制的这段动作将保存在这个缓冲器中，我们可以在不同的缓冲器中录制不同的动作。在示例中，动作被存入了缓冲器 1 中。\n接下来 yy 命令是复制光标所在行整行，p 命令是将剪贴板内容粘贴到当前光标下一行并且将光标移动到下一行。\u0026lt;C-a\u0026gt;/\u0026lt;C-x\u0026gt; 操作可以进行简单的算数运算，对整数进行+1/-1。\n再按一次 q 结束当前录制。想要使用之前的动作序列时，先直接按下需要执行的次数，然后按下 @ ，再按下指定的缓冲器名即可。本例中我们直接输入了1，在录制宏的过程中完成了2，因此只需要再执行98次。\nVim 的 Visual Block 模式 Visual Block 模式可以帮助我们对文本进行批量操作。以讲义中的示例为例，欲将下面片段每行左右对调\naaaaaaaaaaaaaaaaaaaaaaaaabbbbbbbbbbbbbbbbbbbbbbbbb cccccccccccccccccccccccccddddddddddddddddddddddddd eeeeeeeeeeeeeeeeeeeeeeeeefffffffffffffffffffffffff ggggggggggggggggggggggggghhhhhhhhhhhhhhhhhhhhhhhhh iiiiiiiiiiiiiiiiiiiiiiiiijjjjjjjjjjjjjjjjjjjjjjjjj 只需依次输入 gg\u0026lt;C-v\u0026gt;24l4jd$p 即可。\ngg 命令可以将光标移动到文本开头。按下 \u0026lt;C-v\u0026gt; 进入 Visual Block 模式。 24l4j 将光标向右移动24格之后再向下移动4格，从而选中了左边一整块所有字符。d 操作删除选中的部分，并将删除的内容放入剪贴板。$ 命令将光标移动到行末（不改变当前的 normal 模式）,p 粘贴，从而完成任务。\nGNU Diff Format 可以参照 这个文档 来详细了解 GNU diff format。\n注意：这种格式只是一种严谨规范地向他人描述修改内容的方法，并不是要将这些内容直接写入要修改的文件！\n补充 若使用讲义中的方法直接将 /etc/vim/vimrc 复制到 ~/.vimrc，我们在编辑保存的时候会遇到一些权限问题。\n使用 ls -l -a | grep vimrc 命令查看 ~/.vimrc 的详细信息，可以看到其权限信息为 -rw-r--r--，这说明除了创建者 root 之外别的用户对该文件没有写入的权限。我们可以用 sudo chmod 664 ~/.vimrc 命令将其权限修改为 -rw-rw-r-- 来解决问题。\nMore Exploration 思考题 消失的cd\n为什么上述基本命令除了 cd 之外都能找到它们的 manpage?\ncd 并不是一条指令，如果在终端中输入 type cd 我们会得到 “cd is a shell builtin”。\nThings Behind Scrolling\nWhy the original terminal cannot be scrolled? How does tmux make the terminals scrollable? How to implement a scroll bar?\n留坑。盲猜最基本的滚轮功能是滚一格向上/下移动 $x$ 行，欲实现滚轮需要将终端内的历史命令和输出保存下来。\n补充 正则表达式的最基本语法 [] 语法\n正则表达式 含义及其说明 oo oo [abcd]oo aoo/boo/coo/doo\n[] 表示匹配一个字符 [^ef]oo xoo，x不为e和f\n^ 是取反符号，且取反中括号内所有列出的字符。 行首行末匹配 ^ $\n正则表达式 含义及其说明 ^[^A-Z] 首字符不是大写字母的行\n注意 ^ 在中括号中表示取反，不在中括号中表示行首 \\.$ 以 . 结尾的行\n注意 . 有特殊含义，要用 \\ 转义。 ^$ 空白行 任意字符 .，重复字符 *\n正则表达式 含义及其说明 g..d 长度为4的以g开头d结尾的串\n. 表示“一定要有一个字符” ooo* 两个以及更多的o\n* 表示将之前的一个字符重复零次或若干次 go.*g 以go开头g结尾的单词，中间可以有任意的字符（也可以为空） [0-9][0-9]* 任意数字 限定次数 {}\n正则表达式 含义及其说明 o\\{2\\} o连续出现两次，即oo\n注意使用 {} 一定要转义 o\\{2,5\\} o出现两次到五次之间，即oo/ooo/oooo/ooooo go\\{2,\\}d 开头是g结尾是d,中间出现了两次及以上的o 扩展正则表达式语法\n正则表达式 含义及其说明 go+d 开头是g结尾是d，中间出现了一次及以上的o\n+ 表示前一个字符出现了若干次（与 * 的区别是非零） go?d gd或god\n? 表示前一个字符重复零次或一次 gd|god gd或god\n| 表示或 g(la|oo)d glad/good\n() 里可以罗列若干个串并用 | 分隔开 A(xyz)+B 开头是A结尾是B中间有一个或多个xyz\n()+ 表示括号中的群组重复一次或多次 Standard Streams In Computer Programming, standard streams are interconnected input and ouput communication channel between a computer program and its environment when it begins execution. (From Wikipedia)\n标准流包括三个：标准输入 (stdin, 0)，标准输出 (stdout, 1) 和标准错误 (stderr, 2)。默认情况下，标准输入是通过键盘输入，标准输出和标准错误都是直接打印在终端上通过屏幕显示。可以通过重定向 (redirection) 或管道 （pipeline）来修改标准流。此外，子进程继承父进程的标准流。\n关于 find 和 xargs 命令 在 Linux 入门教程中提到使用 find . | grep '\\.c$|\\.h$' | xargs wc -l 来统计代码的行数。笔者在本地直接使用该命令时报错：xargs: unmatched single quote。查阅资料得知这是因为文件名中有奇数个单引号。与此同时，文件名中的空格、斜杠等特殊字符也会导致识别错误。\n配合使用 find 命令的 -print0 参数和 xargs 命令的 -0 参数可以解决这个问题。它们的作用是用一个 null character 来代替空格分隔文件名，同时可以解决文件名中的空格，斜杠等问题。但我们发现 find . -print0 的结果送给 grep 无法正常地完成筛选。\n我们发现 find 命令自带文件名筛选功能。我们可以使用 -name '*.cpp' 这个选项来筛选出所有 .cpp 文件，这样使用命令\nfind . -name '*.cpp' -print0 | xargs -0 wc -l 可以完成所有 .cpp 文件的代码行数统计，要注意 -name 选项后的文件名并不支持完整的正则表达式语法，根据手册，它只支持 * ? 和 [] 语法。\n如果执意想使用 grep 命令的话，我们可以换一个思路来解决这个问题：给文件名加上双引号来解决特殊字符。\nfind . -printf '\u0026quot;%p\u0026quot;\\n' | grep '\\.cpp\u0026quot;$' | xargs wc -l -printf 参数后跟 %p 可以输出文件名，我们将所有的文件名用双引号括起来，加一个换行符，就可以让 find 在标准输出中将文件名带引号地分行输出，注意此时 grep 指令需要匹配行尾的 \u0026quot; 。\n/dev/null , /dev/zero 和 /dev/random /dev/null 是一个只写文件。如果使用 cat /dev/null 查看文件内容会得到空。通常可以通过将标准输出重定向到 /dev/null 的方法来吃掉你不想要的输出内容。虽然无法写入，但在写入时它会返回给你写入成功。\n/dev/zero 在读取时会提供无限的空字符。可以用来覆盖文件内容或产生特定大小的空文件。\ndev/random 在读取时会产生永不为空的随机字节数据流。\n对于这些特殊文件实现方式的一个简单解释是，例如 /dev/null ,当内核接收到对这个文件的请求时，不需要进行任何真实的硬件操作，直接按照API返回写入成功即可。\nMakefile Makefile最简单的一点语法：\n要生成的文件名:依赖文件列表 用于生成目标文件的命令序列 如果连续多次执行 make ，会得到信息 \u0026lsquo;xxx is up to date\u0026rsquo;。这是 make 程序智能管理的功能，如果目标文件已经存在且修改时间后于其依赖的所有文件，make 会认为这个文件已经编译过了，不需要重新编译。\n（即使这个文件并不是按照命令要求生成的，如在当前目录下有文件 hello.c 和 Makefile。Makefile 的内容如下：\nhello:hello.c gcc hello.c -o hello 此时用 touch hello 指令创建一个修改时间最新的 hello 空文件再执行 make ，仍然显示 ‘hello is up to date’。）\n使用语句 :PHONY xxx 可以将 xxx 变成一个伪目标，这样以后在执行 make xxx 时不会再检查文件 xxx 的新旧，而是直接执行 xxx 规则下的命令。\nGetting Source Code for PAs 思考题 What happened? You should know how a program is generated in the 程序设计基础 course. But do you have any idea about what happened when a bunch of information is output to the screen during make is executed?\n留坑。\n补充 Git使用 - 关于 SSH Key 的设置 如果想要向远程仓库提交修改，必须将本机的 SSH Key 添加到受信任的 SSH Key 列表中。\n如果本地没有 SSH Key，可以使用命令 ssh-keygen -t rsa -C \u0026quot;email\u0026quot; 命令来生成 SSH Key，其中 email 是在 git config --global user.email 中填写的邮箱。默认生成位置在 ~/.ssh 中。生成后将公钥 ~/.ssh/id_rsa.pub 中的内容填写到受信任 SSH Key 列表中即可。\n关于 make menuconfig 的报错 在 ics2021/nemu 下使用命令：make menuconfig，报错 bison: No such file or directory 。\n报错是因为缺少 bison 工具，安装即可。对于之后的 flex 工具也是亦然。\n注：当你缺少某项工具时，不一定会返回 command not found，也可能会返回 No such file or directory!\n关于软件安装的报错 在使用 apt-get install 安装软件时若出现形如以下的错误：\nE: Failed to fetch http://mirrors.tuna.tsinghua.edu.cn/ubuntu/pool/main/f/flex/flex_2.6.4-8_amd64.deb Connection timed out [IP: 2402:f000:1:400::2 80] E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing? 虽然可能是源中没有对应的 package，但 Connection timed out 也可能是因为网速不行，重新安装一次也许就可以解决。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aade78eb8532dd9428d8481a01e9babc","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-ics/pa/pa0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-ics/pa/pa0/","section":"notes","summary":"实验进度 我完成了所有安装任务，完成了必答题，并针对思考题和遇到的其他问题进行了资料搜索和思考。\n必答题 我按照实验要求编写了 hello.c 并编写 Makefile 文件进行编译，并且学习了 GDB 的使用。这些内容无法直接呈现，故省略。\n关于《提问的智慧》 我们从小被要求养成提问的习惯，提问被认为是有好奇心或者善于探索的象征，但我认为背后有思考的提问才是真正有价值的。《提问的智慧》中提及了大量的提问相关的 convention 和技巧，其核心原理都是思考。\n我曾在知乎上看到一句话：“道德是用来约束自己的，不是用来约束别人的。”这句话当时被用来说明你不能强求别人写给你看的题解像喂饭一样深入浅出。我觉得这句话用在提问上也一样合适。除非你花钱雇了一个人专职为你解答问题，否则别人解答你的问题是一种义务劳动。你没有权利浪费别人的时间，别人也没有义务去回答一些愚蠢的问题或者给你保姆级的教程。我总结了一些《提问的智慧》中我觉得比较精华的内容罗列如下：\n不要问一些直接 STFW/RTFM 就能轻松获得答案的知识性问题，他们通常具有 \u0026ldquo;xxx是什么？\u0026quot;“xxx怎么用” 等格式。 作为一个计算机界的后辈，你遇到的问题有极大的概率是已经有无数人遇到过的问题。一些经典的问题通常可以在 Stack Overflow 等知名平台上找到解答，所以你应该确保你的问题没有现成可查的解决方案。 你应该尽可能详细地刻画你的问题，比如写下你已经用过哪些方法但失败了，也可以贴一些截图。一方面，更详细的信息可以让别人更好地了解你的情况，提供帮助；另一方面，这可以体现你为了解决问题已经付出过你能力范围内的努力。 机器永远是对的，不要说“我觉得我的gcc有问题/我觉得我的电脑坏了”之类的话（这是我在帮助上“程序设计基础”课的同学解决问题时经常听到的话）。另外，你手上的源码有很大概率经过了很多人的验证，所以不要轻易宣布自己发现了 bug。 作为一个提问者你不能显得趾高气昂，在提问中适当使用委婉的词汇可以使你的态度更加诚恳，但也不用过度使用以至于语句冗余。 对于我们这样的初学者来说问题可能还没有领域之分，但在日后如果提出一些分类较细的问题，需要注意提问的平台是否合适。 总之，想要提出一个好的问题，你需要在遇到困难时先主动自己解决，尝试能力范围内可以使用的方法，并且在你的提问中展现这个过程。这样蕴含了你的思考的问题才是有价值的。","tags":null,"title":"PA0 - 世界诞生的前夜：开发环境配置","type":"docs"},{"authors":null,"categories":null,"content":"该入门实验的主要目的是熟悉 cool 语言的语法，为编译器编写打下基础。本实验的任务是用 cool 语言写一个简单的 stack machine，支持 int + s e d 五种操作。\nDesignation 由于 cool 语言中没有开数组的功能，所以笔者使用链表来模拟这个栈数据结构。插入操作是新建一个链表节点插在 head 前面，e 操作则是查看链表开头的若干个元素并执行相应操作。\nInteresting Bugs cool 是一个面向对象风格的语言，一开始笔者吃了不少苦头；而且 PA 提供的 cool 编译器报错信息很少，不方便知道到底发生了什么，只能自己猜测和摸索。\n笔者遇到的一个有意思的 bug 是在实现 class List 的某个 method 时，无法直接使用另一个 List 变量的 attribute。这是因为 cool 要求所有的 attribute 都是 private 的，method 是 public 的，因此如果想要访问某个变量的 attribute 要这样写：\nclass CLASS { attribute : Object; attribute() : Object { attribute }; }; 这样就可以通过 attribute() 方法来访问 attribute 属性。\nMiscellaneous 关于 cool 的一点吐槽 (README 要求的作业之一)：\n无法指定 private/public 的 attribute；\n没有逻辑运算符 (and/or) 导致有一些 if-else 语句不得不拆成两个写；\nif 结构必须是 if-then-else-fi，不能省略 else 分支；\n多行代码必须用大括号框起来，有一点丑 (不过这应该可以简化 parser 的设计)；\n……\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0d9180175f76fea706c40970ce8845ab","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/pa/pa0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/pa/pa0/","section":"notes","summary":"该入门实验的主要目的是熟悉 cool 语言的语法，为编译器编写打下基础。本实验的任务是用 cool 语言写一个简单的 stack machine，支持 int + s e d 五种操作。\nDesignation 由于 cool 语言中没有开数组的功能，所以笔者使用链表来模拟这个栈数据结构。插入操作是新建一个链表节点插在 head 前面，e 操作则是查看链表开头的若干个元素并执行相应操作。\nInteresting Bugs cool 是一个面向对象风格的语言，一开始笔者吃了不少苦头；而且 PA 提供的 cool 编译器报错信息很少，不方便知道到底发生了什么，只能自己猜测和摸索。\n笔者遇到的一个有意思的 bug 是在实现 class List 的某个 method 时，无法直接使用另一个 List 变量的 attribute。这是因为 cool 要求所有的 attribute 都是 private 的，method 是 public 的，因此如果想要访问某个变量的 attribute 要这样写：","tags":null,"title":"Stanford-CS143 PA0: Cool Programming","type":"docs"},{"authors":null,"categories":null,"content":"实验进度 我完成了所有的必答题，并针对选做题和思考题给出了自己的想法。\n必答题 程序是个状态机 点击 这里 跳转到解答。\n理解基础设施 有 450 次编译用于调试，假设只有 450 个 bug，那么总共需要 4500min = 75h 。简易调试器可以节约 50h 的时间。\nRTFM riscv32有哪几种指令格式?\n在 Volume I - 2.2 节可以查到 Base Instruction Formats, 在 Volume I -17.2 节中可以查到 Compressed Instruction Formats。在 Volume I - 26.3 节可以查到扩展 RISCV 的指令格式。\nLUI指令的行为是什么?\n在 Volume I 第 19 页可以查到 LUI 指令的行为。\nmstatus寄存器的结构是怎么样的?\n在 Volume II - 3.1.6 节可以查到 machine status register 的结构。\nShell命令 笔者使用了如下命令来统计所有非空行的代码行数：\nfind . -name \u0026quot;*[.c|.h]\u0026quot; | xargs grep ^. | wc -l 其中的正则表达式 ^. 用来识别开头至少有一个字符的行。\npa0结束时共有代码 19868 行，pa1结束时共有代码 20272 行。\nRTFM -Wall 选项会显示所有的 warning 信息，-Werror 会将所有 warning 视作 error 报错。使用这些编译选项可以尽早发现潜在的错误并强制报错，将 bug 消灭在 fault 的阶段。\n以下是我的自由报告内容，我在做实验的过程中详细记录了自己遇到的所有问题和查阅的所有资料。这些笔记按照章节排列，每章通常有两个部分：\n思考题：包含笔者针对思考题查阅的资料和我尝试给出的答案。 补充：这里的内容是没有在讲义中提及的问题，以及讲义中建议自学的东西。 在开始愉快的PA之旅之前 补充 关于 git status 追踪不到修改 在 ics2021 根目录下新建文件 touch test.cpp 后使用 git status 查看变化，发现 git 并没有追踪到这条变化。使用 git add a.cpp 命令后显示：\nThe following paths are ignored by one of your .gitignore files 这说明根目录的 .gitignore 文件忽略了该文件，打开 .gitignore 查看：\n*.* * !*/ !/nemu/* !/nexus-am/* !/nanos-lite/* !/navy-apps/* !Makefile !README.md !.gitignore !init.sh /fceux-am /am-kernels 查阅资料得知，.gitignore 文件的最基础语法包括：\n可以用正则表达式 [] ? * 等来匹配文件名 行开头使用 ! 表示不忽略该行匹配的文件 ics2001/a.cpp 被 *.* 捕捉，因此被 git 忽略了。为了验证我的思考，我在 ics2001/nemu 下创建了 a.cpp ，根据根目录下的 .gitignore 文件 /nemu 下的文件没有被忽略，但 git 仍然没有追踪到 a.cpp。\n我发现 /nemu 下也有 .gitignore 文件，该文件中的 *.* 捕捉了 a.cpp。查阅资料得知，当多个 .gitignore 文件发生冲突时，git 优先服从本地的文件而不是父文件夹的文件。\n关于添加环境变量 ccache 工具要求将 /usr/lib/ccache 添加到 PATH 中。笔者一开始直接在 ~/.bashrc 中添加了如下一行：\nexport PATH=/usr/lib/ccache 之后发现其他所有的命令都用不了了。事实上大部分命令都放在 /usr/bin 之下，这个路径默认保存在 PATH 中。如果向上文那样直接修改 PATH，会导致其他命令无法使用。\n在命令行中输入 export PATH=\u0026quot;/usr/bin:$PATH\u0026quot; 可以暂时将 /usr/bin 添加回 PATH，但终端关闭后会失效。此时打开 ~/.bashrc 将命令修改为\nexport PATH=/usr/lib/ccache:$PATH 后一切正常。这里的 : 是多个路径之间的分隔符，这条语句相当于在原本的 $PATH 内容之前加上 /usr/lib/ccache。\n（事实上仔细阅读 ccache 的文档可以发现它让你将路径 “perpend” 到 PATH 中，没让你直接修改……）\n开天辟地的篇章 必答题 从状态机视角理解程序运行 以上一小节中1+2+...+100的指令序列为例, 尝试画出这个程序的状态机.\n这个程序比较简单, 需要更新的状态只包括PC和r1, r2这两个寄存器, 因此我们用一个三元组(PC, r1, r2)就可以表示程序的所有状态, 而无需画出内存的具体状态. 初始状态是(0, x, x), 此处的x表示未初始化. 程序PC=0处的指令是mov r1, 0, 执行完之后PC会指向下一条指令, 因此下一个状态是(1, 0, x). 如此类推, 我们可以画出执行前3条指令的状态转移过程:\n(0, x, x) -\u0026gt; (1, 0, x) -\u0026gt; (2, 0, 0) -\u0026gt; (3, 0, 1) 请你尝试继续画出这个状态机, 其中程序中的循环只需要画出前两次循环和最后两次循环即可.\n完整的状态机如下：\n(0,x,x) -\u0026gt; (1,0,x) -\u0026gt; (2,0,0) -\u0026gt; (3,0,1) -\u0026gt; (4,1,1) -\u0026gt; (2,1,1) -\u0026gt; (3,1,2) -\u0026gt; (4,3,2) -\u0026gt; (2,3,2) -\u0026gt; ... -\u0026gt; (2,4851,98) -\u0026gt; (3,4851,99) -\u0026gt; (4,4950,99) -\u0026gt; (2,4950,99) -\u0026gt; (3,4950,100) -\u0026gt; (4,5050,100) -\u0026gt; (5,5050,100) -\u0026gt; (5,5050,100) -\u0026gt; ... 思考题 [二周目] 计算机可以没有寄存器吗？ 如果没有寄存器, 计算机还可以工作吗? 如果可以, 这会对硬件提供的编程模型有什么影响呢?\n就算你是二周目来思考这个问题, 你也有可能是第一次听到\u0026quot;编程模型\u0026quot;这个概念. 不过如果一周目的时候你已经仔细地阅读过ISA手册, 你会记得确实有这么个概念. 所以, 如果想知道什么是编程模型, RTFM吧.\n留坑，二周目再做。\nRTFSC 思考题 kconfig生成的宏与条件编译 我们已经在上文提到过, kconfig会根据配置选项的结果在 nemu/include/generated/autoconf.h中定义一些形如CONFIG_xxx的宏, 我们可以在C代码中通过条件编译的功能对这些宏进行测试, 来判断是否编译某些代码. 例如, 当CONFIG_DEBUG这个宏没有定义时, 调试相关的代码就无需进行编译.\n为了编写更紧凑的代码, 我们在nemu/include/debug.h中定义了一些专门用来对宏进行测试的宏. 例如IFDEF(CONFIG_DEVICE, init_device());表示, 如果定义了CONFIG_DEVICE, 才会调用init_device()函数; 而MUXDEF(CONFIG_DEBUG, \u0026quot;ON\u0026quot;, \u0026quot;OFF\u0026quot;)则表示, 如果定义了CONFIG_DEBUG, 则预处理结果为\u0026quot;ON\u0026quot;(\u0026quot;OFF\u0026quot;在预处理后会消失), 否则预处理结果为\u0026quot;OFF\u0026quot;.\n这些宏的功能非常神奇, 你知道这些宏是如何工作的吗?\n宏定义的基本格式为 #define A B，这里的 A 可以包含参数也可以不包含。在编译的过程中，程序中的 A 会被替换成 B。\n条件编译指类似于 #idef A #ifndef A 等，表示如果宏 A 有定义/无定义才会编译下面的代码，以 #endif 结尾。\n为什么全部都是函数? 阅读init_monitor()函数的代码, 你会发现里面全部都是函数调用. 按道理, 把相应的函数体在init_monitor()中展开也不影响代码的正确性. 相比之下, 在这里使用函数有什么好处呢?\n事实上，如果能确定这些代码块只会使用一次，那么将这些代码放进函数体，并在每块的开头用注释写上该部分的作用，也可以达到代码易阅读的效果；但阅读代码发现这些代码块在其他的函数体中也有使用，因此封装成函数可以减少代码量。从另一种角度，这样写 init_monitor() 函数内容更加清爽，可以更好地体现分层抽象。\n究竟要执行多久？ 在cmd_c()函数中, 调用cpu_exec()的时候传入了参数-1, 你知道这是什么意思吗?\ncpu_exec() 中的参数 n 代表的是 cpu 执行指令的次数。在 /nemu/src/cpu/cpu_exec.c 的源码中是这样写的\nfor (;n\u0026gt;0;n--) { ... } 因此传入参数 -1 可以使 cpu 不停地执行指令，直到遇到 nemu_trap 指令。\n参数的处理过程 另外的一个问题是, 这些参数是从哪里来的呢?\n这些参数来自命令行，是用户键入的。main() 函数自带的两个参数 int argc 和 char *argv[] 处理用户在命令行中键入的参数。argc 是参数的个数，char *argv[] 是指向参数的指针数组。parse_args() 中传递的参数就是这两个。\n[二周目] 潜在的威胁 \u0026ldquo;调用cpu_exec()的时候传入了参数-1\u0026rdquo;, 这一做法属于未定义行为吗? 请查阅C99手册确认你的想法.\n留坑，二周目再做。\n谁来指示程序的结束？ 在程序设计课上老师告诉你, 当程序执行到main()函数返回处的时候, 程序就退出了, 你对此深信不疑. 但你是否怀疑过, 凭什么程序执行到main()函数的返回处就结束了? 如果有人告诉你, 程序设计课上老师的说法是错的, 你有办法来证明/反驳吗? 如果你对此感兴趣, 请在互联网上搜索相关内容.\nmain() 函数是程序的入口，但 main () 函数也是被其他程序调用的。例如有一个可执行文件 test，在 shell 中输入 ./test 之后，shell 会 clone 一个子进程，执行\nexecve(\u0026quot;./test\u0026quot;,char * const argv[], char * const envp[]) execve 加载 ./test 并将参数一步步传递下去。从 ./test 的入口开始执行（ELF文件中的 _start()）, _start() 调用 __libc_start_main()。__libc_start_main() 中有一条\nint result = main (argc, argv, __environ MAIN_AUXVEC_PARAM); 从这里进入 main() 函数，main() 函数的返回值会存在 result 中，__libc_start_main() 会直接 exit(result) ，从而 main() 函数的返回值会被父进程捕捉到。\n执行完 ./test 后用 echo $\u0026gt; 指令可以打印 main() 函数的返回值。\n[二周目] 有始有终 对于GNU/Linux上的一个程序, 怎么样才算开始? 怎么样才算是结束? 对于在NEMU中运行的程序, 问题的答案又是什么呢?\n与此相关的问题还有: NEMU中为什么要有nemu_trap? 为什么要有monitor?\n留坑，二周目再做。\n补充 关于 $@ 和 $\u0026lt; $@ 代表目标文件，$\u0026lt; 代表第一个依赖文件，此外类似的字符还有 $^ 代表所有的依赖文件。\n关于 getopt 和 getopt_long 两者都是用于分析参数，不同的是 getopt 会忽略长参数（即由 -- 开头的参数，参数名字可以不止一个字符）而 getopt_long 不会。\nmonitor.c 中的源码如下\nconst struct option table[] = { {\u0026quot;batch\u0026quot; , no_argument , NULL, 'b'}, {\u0026quot;log\u0026quot; , required_argument, NULL, 'l'}, {\u0026quot;diff\u0026quot; , required_argument, NULL, 'd'}, {\u0026quot;port\u0026quot; , required_argument, NULL, 'p'}, {\u0026quot;help\u0026quot; , no_argument , NULL, 'h'}, {0 , 0 , NULL, 0 }, }; int o; while ( (o = getopt_long(argc, argv, \u0026quot;-bhl:d:p:\u0026quot;, table, NULL)) != -1) { switch (o) { case 'b': sdb_set_batch_mode(); break; case 'p': sscanf(optarg, \u0026quot;%d\u0026quot;, \u0026amp;difftest_port); break; case 'l': log_file = optarg; break; case 'd': diff_so_file = optarg; break; case 1: img_file = optarg; return optind - 1; default: printf(\u0026quot;Usage: %s [OPTION...] IMAGE [args]\\n\\n\u0026quot;, argv[0]); printf(\u0026quot;\\t-b,--batch run with batch mode\\n\u0026quot;); printf(\u0026quot;\\t-l,--log=FILE output log to FILE\\n\u0026quot;); printf(\u0026quot;\\t-d,--diff=REF_SO run DiffTest with reference REF_SO\\n\u0026quot;); printf(\u0026quot;\\t-p,--port=PORT run DiffTest with port PORT\\n\u0026quot;); printf(\u0026quot;\\n\u0026quot;); exit(0); } } getopt() 里有如下参数：int argc 表示要分析的选项个数，char *argv[] 是指向参数的选项数组。getopt() 有一个额外的变量 optind 记录当前已经分析到第几个选项。每调用一次，getopt() 会返回下一个选项剥去了 - 的结果 (optional character)，如果已经没有下一个选项则返回 -1。\ngetopt() 的参数 optstring 表示识别哪些选项。如果选项字符前有 : 的话表示该选项还有参数，getopt() 分析时会将该选项的参数保存在 optarg 变量中。\ngetopt() 在默认情况下会将 argv 数组中的选项重排，将那些不是选项的 args 放到数组的最后。有两种特殊的扫描方式可以无视这种默认：\noptstring 的首字母是 + ，表示遇到第一个非选项的 args 就退出 optstring 的首字母是 - ，表示处理所有的 args，如果遇到非选项的 args，返回的 optional character 是 1。可以看到代码中对于非选项的部分 (Case 1) 返回了 optind-1 ，转到异常处理。 switch 语句中没有判断 h ，因为 h 是 default 的情况。\n基础设施 思考题 如何测试字符串处理函数？ 你可能会抑制不住编码的冲动: 与其RTFM, 还不如自己写. 如果真是这样, 你可以考虑一下, 你会如何测试自己编写的字符串处理函数?\n如果你愿意RTFM, 也不妨思考一下这个问题, 因为你会在PA2中遇到类似的问题.\n笔者的一点思考是，在测试的时候一定要仔细考虑字符串行末的 \u0026lsquo;\\0\u0026rsquo; 问题。笔者在实现简易的表达式求值函数时，在 make_token 函数中使用 C语言自带的 strncpy 函数来将一个字符串的一部分拷贝进 tokens 数组中，但在测试时发现如果 p 过之后 x 再 p 会打印意想不到的结果。\n仔细阅读 strncpy 的手册，发现其中有这样一句话：\nWarning: If there is no null byte among the first n bytes of src, the string placed in dest will not be null-terminated. 这正好是笔者在复制 tokens 过程中遇到的情况。因为复制过来的字符串不带结束符，所以 strlen 函数不能准确给出字符串长度，从而出现错误。\n补充 RTFSC 技巧 如果遇到一个宏或者一个函数不知道该到哪里去找来源，可以使用 grep xxx -r 命令来寻找所有包含关键字 xxx 的文件。当然在使用了现代的IDE（如 vscode）后这方面的焦虑会少很多。\n关于在 nemu 中直接用 q 退出会报错 Error 1 在 nemu 的主程序 /nemu/src/nemu-main.c 中最后调用了函数 is_exit_status_bad()，该函数在 /nemu/src/utils/state.c 中，源码如下：\nint is_exit_status_bad() { int good = (nemu_state.state == NEMU_END \u0026amp;\u0026amp; nemu_state.halt_ret == 0) || (nemu_state.state == NEMU_QUIT); return !good; } 可以看到正常退出的两个条件\n程序运行结束且没有遇到任何非正常情况 执行了 quit 操作 判断执行 quit 操作的方法是 nemu_state.state == NEMU_QUIT，然而在框架代码中的 cmd_q() 中只有一行 return -1。这里的 return -1 只是用于给 sdb_mainloop() 传递信息使其结束，但没有做好标志信息的设置。所以修改 cmd_q() 为\nstatic int cmd_q() { nemu_state.state = NEMU_QUIT; return -1; } 再次编译后，即使在程序未运行结束时 quit 也不会收到报错。\n关于在 sdb.c 中使用访问内存函数报错 在扫描内存函数中，笔者使用 paddr.c 中定义的函数 guest_to_host() 函数来访问内存，但运行后显示\nerror: implicit declaration of function 'guest_to_host' 这是因为程序找不到该函数的定义，我们可以 #include \u0026lt;memory/paddr.c\u0026gt; 来解决这个问题。\n内置客户代码放在了哪里？ 跟着程序运行的过程 RTFSC 是一个不错的方法，不过更简单的是我们可以充分相信自己写的程序的正确性：直接在 nemu 文件夹内搜索打印出的内存信息。迅速定位到在 /nemu/src/isa/init.c 中的代码：\n0x800002b7, // lui t0,0x80000 0x0002a023, // sw zero,0(t0) 0x0002a503, // lw a0,0(t0) 0x0000006b, // nemu_trap 和打印得到的信息比对，我们可以看到 riscv 是一个小端机器。在 init_isa 函数中是通过\nmemcpy(gueset_to_host(RESET_VECTOR), img, sizeof(img)) 的方式将 img 中的代码拷贝进内存的。另外我们可以看到：内存中未初始化的部分是乱码。\n表达式求值 思考题 为什么printf()的输出要换行? 如果不换行, 可能会发生什么? 你可以在代码中尝试一下, 并思考原因, 然后STFW对比你的想法.\n留坑。\n[二周目] 为什么要使用无符号类型? 我们在表达式求值中约定, 所有运算都是无符号运算. 你知道为什么要这样约定吗? 如果进行有符号运算, 有可能会发生什么问题?\n留坑。一个想法是引入负数可能会在访存时发生意想不到的问题，但这个问题似乎可以通过访存前的判断来筛除。\n表达式生成器如何获得C程序的打印结果? 代码中这部分的内容没有任何注释, 聪明的你也许马上就反应过来: 竟然是个RTFM的圈套! 阅读手册了解API的具体行为可是程序员的基本功. 如果觉得去年一整年的程序员都白当了, 就从现在开始好好锻炼吧.\ngen-expr.c 中使用了如下几个值得借鉴的函数：\nsprintf(code_buf, code_format, buf) ，该函数用于将 buf 的内容填入到 code_format 的 \u0026ldquo;%s\u0026rdquo; 中，并将整段c语言代码的字符串放进 code_buf。 system()，用于执行一个命令，返回值是为该命令创建的子进程的返回值，如果不是 0 说明指令执行失败。 fopen/popen (\u0026quot;file\u0026quot;, \u0026quot;r\u0026quot;/\u0026quot;w\u0026quot;) 用于打开文件，后面的 r/w 指明是读取还是写入。根据 STFW 的结果，两者的区别在于 popen() 会 fork 一个子进程并建立管道连接（不懂，留坑）。经测试，第一处 fopen 如果换成 popen 会在写入时报错 Permission denied；第二处 popen 如果换成 fopen 则无法读到程序的输出结果。 补充 关于表达式生成 如果直接将生成的表达式喂给C语言，C语言会把常量当做整型参与运算，从而得到不正确的结果，如在下面的例子中\n(0 - 1) / 10 在 int 规则下结果为 0，赋给 unsigned 变量之后结果仍是0，而在 unsigned 规则下结果显然不为0。unsigned 可以看做 int 的一个值域右移的版本，在这个版本下做任何加减操作不会影响正确性，但做乘除操作时会发生问题。\n笔者的解决方案是：生成两个表达式，一个正常的表达式用于喂给 nemu，另一个表达式在每个常量后面添加一个 u，将常量转化为 unsigned 类型后再喂给C语言。\n笔者并不希望通过计算的方式来过滤除0的表达式，因此使用了一种比较无脑的暴力方法：\n笔者修改了生成表达式的 BNF 规范，在新规范中没有 \u0026lt;expr\u0026gt; / \u0026lt;expr\u0026gt; ，而是 \u0026lt;expr\u0026gt; / ((\u0026lt;expr\u0026gt;)*2+ 1)。无符号数可以看作做完所有操作以后对 $2^{32}$ 取模，由于模数是偶数，因此 \u0026lt;expr\u0026gt;*2+1 取模过后必然是一个奇数，这样可以保证除数非零。这样做的唯一缺陷是生成的除数不再是等概率分布的，不过在测试正确性的过程中除数分布的均匀无关紧要。\n空格的插入是容易的，只需要在 BNF 规范中添加一条：\u0026lt;expr\u0026gt; ::= \u0026quot; \u0026quot;\u0026lt;expr\u0026gt; 即可。\n在当前的随机生成方式下，生成长表达式的概率较小。如果想生成更多的表达式，可以修改随机到各个部分的概率，使 \u0026lt;expr\u0026gt; ::= \u0026lt;decimal number\u0026gt; | \u0026lt;heximal number\u0026gt; 的概率变小。或者设置一个下界，当表达式总长小于下界时不允许生成 \u0026lt;number\u0026gt;。\n控制表达式的长度不超过 buffer 的限制是容易的：我们在生成表达式的同时记录当前表达式的总长，当总长超过一个预警值时，强制新表达式只能生成常数即可。\n关于负数功能 笔者在 PA1 中实现了负数功能。负号的识别和指针解引用是类似的：如果一个 - 的前面是双目运算符，负号或者 ( 的话，那么当前的 - 就是负号（单目运算符）。\n在计算的过程中，如果一个表达式由负号开头，且后面的部分中没有“裸露在外”（即不被任何一对括号包裹）的双目运算符，则可以剥离这个负号递归计算，将得到的答案取负之后返回。\n监视点 思考题 温故而知新 框架代码中定义wp_pool等变量的时候使用了关键字static, static在此处的含义是什么? 为什么要在此处使用它?\nstatic 最重要的作用在于隐藏。带有 static 的变量以及函数不能在该文件以外的地方访问和使用。例如在 cpu-exec.c 文件中，我们要实现对所有监视点的扫描，但又不能直接访问 watchpoint.c 中的监视点池，因此我们可以在 watchpoint.c 中写一个函数实现这个功能，再通过在 cpu-exec.c 中调用这个非 static 的函数来完成任务。使用 static 可以保证本文件中的东西不会被外界污染，如果出现问题，可以在本文件中寻找 bug，降低了调试难度。\n你会如何测试你的监视点实现? 我们没有提供监视点相关的测试, 思考一下, 你会如何测试?\n当然, 对于实验来说, 将来边用边测也是一种说得过去的方法, 就看你对自己代码的信心了.\n笔者没有批量生成测试用例，而是针对监视点的各个功能设计了几种测试手段：\n每执行完一次操作都使用命令 info w 检查所有监视点是否正常。 使用表达式 w *0x80000000+1 ，检查指针解引用部分的正确性， 以及监视点遇到变化是否能暂停程序。 使用表达式 w $t0 / 5，检查寄存器访问部分的正确性（t0 是内置客户程序中唯一修改过的寄存器）。 检测 d 命令是否能实现，以及删除不存在的监视点是否可以报错。 尝试添加大于监视点池容量的监视点，检查是否能触发 assertion fail。 强大的GDB 如果你遇到了段错误, 你很可能会想知道究竟是哪一行代码触发了段错误. 尝试编写一个触发段错误的程序, 然后在GDB中运行它. 你发现GDB能为你提供哪些有用的信息吗?\n笔者尝试在 nemu 中输入指令 x 10 0x0。由于 riscv32 的地址从 0x80000000 开始，该命令在计算地址时会得到负数从而引发段错误。GDB 输出了以下信息：\nProgram received signal SIGSEGV, Segmentation fault. 0x0000555555562cfd in cmd_x () GDB 可以定位到引发段错误的函数 cmd_x()。\n[二周目] 如何提高断点的效率 如果你在运行稍大一些的程序(如microbench)的时候使用断点, 你会发现设置断点之后会明显地降低NEMU执行程序的效率. 思考一下这是为什么? 有什么方法解决这个问题吗?\n留坑。\n一点也不能长? x86的int3指令不带任何操作数, 操作码为1个字节, 因此指令的长度是1个字节. 这是必须的吗? 假设有一种x86体系结构的变种my-x86, 除了int3指令的长度变成了2个字节之外, 其余指令和x86相同. 在my-x86中, 上述文章中的断点机制还可以正常工作吗? 为什么\nx86架构支持使用8位的 int 指令来实现中断，其中 int3 为CPU所有，专门用于 debugger 的中断。它的原理是将 0xCC 换到对应指令的第一个字节。这样 CPU 在读取指令时遇到 0xCC 就会暂停程序的执行。之所以使用单字的指令，是因为这样不论设置断点的指令是单字、双字还是四字，我们都可以在本条指令内部完成 int3 的标记，不会写到下一条指令中。\n在本题中，如果使用2个字节的指令，则在对单字指令进行标记时会写到别的存储区域中，从而可能出错。\n随心所欲的断点 如果把断点设置在指令的非首字节(中间或末尾), 会发生什么? 你可以在GDB中尝试一下, 然后思考并解释其中的缘由.\n笔者学习了如何在指定的地址添加断点。对于一个输出 hello world 的简单C程序，用 gdb 运行后设置断点 b *main ，运行暂停后输入命令 disassemble，可以看到\n=\u0026gt; 0x0000555555555149 \u0026lt;+0\u0026gt;: endbr64 0x000055555555514d \u0026lt;+4\u0026gt;: push %rbp 0x000055555555514e \u0026lt;+5\u0026gt;: mov %rsp,%rbp 0x0000555555555151 \u0026lt;+8\u0026gt;: sub $0x10,%rsp 0x0000555555555155 \u0026lt;+12\u0026gt;: movl $0x1,-0xc(%rbp) 0x000055555555515c \u0026lt;+19\u0026gt;: movl $0x2,-0x8(%rbp) 0x0000555555555163 \u0026lt;+26\u0026gt;: mov -0xc(%rbp),%edx 0x0000555555555166 \u0026lt;+29\u0026gt;: mov -0x8(%rbp),%eax 0x0000555555555169 \u0026lt;+32\u0026gt;: add %edx,%eax 0x000055555555516b \u0026lt;+34\u0026gt;: mov %eax,-0x4(%rbp) 0x000055555555516e \u0026lt;+37\u0026gt;: mov -0x4(%rbp),%eax 0x0000555555555171 \u0026lt;+40\u0026gt;: mov %eax,%esi 0x0000555555555173 \u0026lt;+42\u0026gt;: lea 0xe8a(%rip),%rdi # 0x555555556004 0x000055555555517a \u0026lt;+49\u0026gt;: mov $0x0,%eax 0x000055555555517f \u0026lt;+54\u0026gt;: call 0x555555555050 \u0026lt;printf@plt\u0026gt; 0x0000555555555184 \u0026lt;+59\u0026gt;: mov $0x0,%eax 0x0000555555555189 \u0026lt;+64\u0026gt;: leave 0x000055555555518a \u0026lt;+65\u0026gt;: ret 我们可以看到每条汇编指令的地址。笔者设置了断点 b *main+55 ，该位置不在指令的首字节，继续运行后 GDB 没有检测到这个断点。笔者认为 GDB 检测断点的机制是每次取指译码时根据首字节是否是 0xCC 来判断是否有断点，因此将标志信息设置在非首字节是无法被识别的。\nNEMU的前世今生 你已经对NEMU的工作方式有所了解了. 事实上在NEMU诞生之前, NEMU曾经有一段时间并不叫NEMU, 而是叫NDB(NJU Debugger), 后来由于某种原因才改名为NEMU. 如果你想知道这一段史前的秘密, 你首先需要了解这样一个问题: 模拟器(Emulator)和调试器(Debugger)有什么不同? 更具体地, 和NEMU相比, GDB到底是如何调试程序的?\n留坑。笔者暂时认为调试器是可以接触底层的硬件和数据的，为程序员反馈信息的应用程序，NEMU 相当于内置了一个调试器的功能，其本身不只是应用程序，而是一整套虚拟机。\n补充 关于 sscanf 函数 笔者之前在处理指令中的常数时是通过一位一位读取并计算的方式来将其转换为 int 型的。在 RTFSC 的过程中发现 sscanf 函数可以简洁地实现这个功能。例如有 int 型变量 N，有存储着常数的字符串 arg，则可以通过 sscanf(arg, \u0026quot;%d\u0026quot;, \u0026amp;N) 来将 arg 的内容转换成整数存进 N。\nAddress Sanitizer 实现 use-after-free 检测的原理 留坑。\n如何阅读手册 必答题 尝试通过目录定位关注的问题 假设你现在需要了解一个叫selector的概念, 请通过i386手册的目录确定你需要阅读手册中的哪些地方. 即使你选择的ISA并不是x86, 也可以尝试去查阅这个概念.\n在 I386 手册的 5.1.3 节中可以找到和 selector 有关的内容。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a46e57d8c94068d4be2fd92a7c7cb917","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-ics/pa/pa1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-ics/pa/pa1/","section":"notes","summary":"实验进度 我完成了所有的必答题，并针对选做题和思考题给出了自己的想法。\n必答题 程序是个状态机 点击 这里 跳转到解答。\n理解基础设施 有 450 次编译用于调试，假设只有 450 个 bug，那么总共需要 4500min = 75h 。简易调试器可以节约 50h 的时间。\nRTFM riscv32有哪几种指令格式?\n在 Volume I - 2.2 节可以查到 Base Instruction Formats, 在 Volume I -17.","tags":null,"title":"PA1 - 开天辟地的篇章：最简单的计算机","type":"docs"},{"authors":null,"categories":null,"content":"Overview 该实验的目的是完成 cool compiler 的 lexical analysis 部分。课堂上讲解了用正则表达式描述词汇格式以及如何根据正则表达式生成 NFA，通过 NFA 转 DFA，再将 DFA 以二维表的形式存储下来。不过现在有成熟的工具可以完成正则表达式的 implementation，所以本实验中我们只需要考虑如何用正则表达式描述 cool 语言的词汇，不需要考虑自动机。\n笔者选择了 C++ 版本的实验。本实验中我们使用 flex 工具来完成正则表达式的 implementation。我们识别出一个 token 后需要向 flex 生成的 yylex() 函数返回 token 的编号 (在 cool-parse.h 中定义)，如果当前 token 有额外的语义信息 (比如字符串，bool const) 则需要在 coolyyval 这个 union 的相应字段中填写信息。\n顺利完成该实验的重要前提是仔细阅读官方提供的各种手册：\n阅读 flex manual 的前 10 个 section 以熟悉 flex 的语法。 阅读 cool manual 的第 10 章以及 Figure 1 以了解 cool 的语法规则。 阅读 PA1 的讲义，该讲义的逻辑不太清晰，各种对返回值的 specification 散落在讲义的各个角落，需要非常仔细地寻找。 Tokens cool 的编译器需要识别以下几类 token：\nInteger: 非空的由 0~9 构成的字符串。 Identifier: identifier 都是由小写/大写字母、数字和下划线构成的非空字符串。type identifier 要求第一个字符必须是小写字母，object identifier 要求第一个字符必须是大写字母。 Operator: 各种符号，除了 \u0026lt;= \u0026lt;- =\u0026gt; 三个多字符符号有专门的 token id，其余的符号直接返回 ascii 码。 Keyword: 关键字都有各自定义好的 token id。true 和 false 这两个关键字要求首字母必须小写，其余的关键字都是大小写不敏感的。 White space: 编译器需要根据 \\n 正确判断行号，并过滤 \\v \\r \\f \\t 几种空白字符。 String, Comments: 这两个类别比较复杂，下面专门讨论。 Comments 注释分为 inline comment 和 block comment 两种，写法大同小异。因为我们要吞掉注释中的所有字符，注释中字符的 action 和外面不一样，所以对于 comment 我们最好使用 flex 的 start condition 机制来识别。\n当遇到 (* 时，进入 COMMENT 状态，在 COMMENT 状态中，我们只需要特殊处理换行符和 \u0026lt;EOF\u0026gt;，其余的字符都可以直接吞掉。\nStrings 处理 string 我们最好也使用 start condition 机制。string 中有更多的限制，比如不能有 unescaped 的 \\n，不能有 \\0，不能有 \u0026lt;EOF\u0026gt;，以及要单独处理特殊字符等。\n注意手册中对 string 错误处理的要求：如果一个 string 中有多个错误，只返回第一个错误的相关信息；当一个 string 错误时，下一次扫描应当从这个 string 结束的地方开始 (unescaped \\n or \\\u0026quot;)。有的人选择先将整个 string 无脑识别并存储下来，然后对着 char 数组处理各种特殊字符和错误。笔者采取的做法是在遇到 ERROR 后再进入一个 \u0026lt;STR_ERROR\u0026gt; 的 start condition，在这种状态中不再字符处理和 error handling，一路扫到 string 的结束。\nMiscellaneous 这里列举一些易漏易错点：\n要注意识别没有 (* 匹配的单独的 *)，返回 unmatched *)。 在 string, comment 等状态中要返回 ERROR 时，不要忘了在返回前将 start condition 重置为 INITIAL，因为我们要完整地处理整个输入，遇到 ERROR 之后剩下的内容也不能摆烂。 , n 和 \\n 是不一样的。在 string 中单独出现的两个字符 (例如 \u0026ldquo;\\n\u0026rdquo;) 应当保留并合并成一个字符，真正的特殊字符是一个不可见字符。 \\ 之后再跟特殊字符 \\0 是一个容易忽略的情况。我们通常会对 \\0 设置一个 rule 识别，使用正则表达式处理转义字符，需要注意转义字符后面跟的字符也可能是 null character。 为了正确地获得 string 的行号，对于 unterminated 的 string 最好使用 yyless(0) 将 \\n 退回，让编译器在 INITIAL 的状态下处理这个换行符，否则 unterminated 的 string 的行号会大1。 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5e4c369faa3c2e4ecd2324666dd33d68","permalink":"https://kristoff-starling.github.io/notes/coursenotes/stanford-compiler/pa/pa1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/stanford-compiler/pa/pa1/","section":"notes","summary":"Overview 该实验的目的是完成 cool compiler 的 lexical analysis 部分。课堂上讲解了用正则表达式描述词汇格式以及如何根据正则表达式生成 NFA，通过 NFA 转 DFA，再将 DFA 以二维表的形式存储下来。不过现在有成熟的工具可以完成正则表达式的 implementation，所以本实验中我们只需要考虑如何用正则表达式描述 cool 语言的词汇，不需要考虑自动机。\n笔者选择了 C++ 版本的实验。本实验中我们使用 flex 工具来完成正则表达式的 implementation。我们识别出一个 token 后需要向 flex 生成的 yylex() 函数返回 token 的编号 (在 cool-parse.","tags":null,"title":"Stanford-CS143 PA1: Lexical Analysis","type":"docs"},{"authors":null,"categories":null,"content":"实验进度 我完成了所有的必答题，并针对选做题和思考题给出了自己的想法。\n必答题 程序是个状态机 点击 这里跳转到解答。\nRTFSC 点击 这里跳转到解答。\n程序如何运行 点击 这里跳转到解答。\n编译与链接 在nemu/src/engine/interpreter/rtl-basic.h中, 你会看到由static inline开头定义的各种RTL指令函数. 选择其中一个函数, 分别尝试去掉static, 去掉inline或去掉两者, 然后重新进行编译, 你可能会看到发生错误. 请分别解释为什么这些错误会发生/不发生? 你有办法证明你的想法吗?\n如果去掉 inline，编译时会报错：xxx defined but not used。这是因为 rtl.h 文件 include 了 rtl-basic.h ，但并没有使用这个函数，因此触发了 -Werror 编译选项。\n如果去掉 static，编译时不会报错。这是因为这里的函数被定义成了内联函数，函数内容被直接塞进了调用者的函数体中。如果我们用 objdump -d 命令去检查编译得到的汇编程序，我们会发现 rtl_xx 等一系列函数是不在其中的。\n如果同时去掉 static 和 inline，编译时会报错：multiple definition of xxx。此时再查看汇编程序可以发现 rtl_xx 在其中。因为 rtl_xx 同时出现在了 cpu-exec.o hostcall.o 和 decode.o 中，所以链接时会出错。这里一个值得关注的细节是：我们编写的函数 exec_addi 调用了 rtl_addi ，但在汇编代码中并没有这一条调用。可以看到 rtl_addi 的内容被直接贴进了 exec_addi 的函数体中。这应该是编译器针对 addi 这种极其简短的函数调用做出的一种优化。\n编译与链接2 在nemu/include/common.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问重新编译后的NEMU含有多少个dummy变量的实体? 你是如何得到这个结果的? 添加上题中的代码后, 再在nemu/include/debug.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问此时的NEMU含有多少个dummy变量的实体? 与上题中dummy变量实体数目进行比较, 并解释本题的结果. 修改添加的代码, 为两处dummy变量进行初始化:volatile static int dummy = 0; 然后重新编译NEMU. 你发现了什么问题? 为什么之前没有出现这样的问题? (回答完本题后可以删除添加的代码.) 笔者起初的做法是在 Makefile 中加入一些功能，使得在 make 可以将预编译的 *.i 文件同时输出到 /build 中，然后在 /build 中使用 grep \u0026quot;volatile static int dummy\u0026quot; -r | wc -l 命令统计个数，得到的答案是 33 个。\n但这个做法其实有一些问题，因为高级程序中定义的“变量”并不一定是实体，比如连续定义两个相同名字的未初始化全局变量，在符号表中只会出现一个。因此正确的方法应该是查看符号表。使用命令 readelf --symbols $NEMU_HOME/build/riscv32-nemu-interpreter | grep \u0026quot;dummy\u0026quot; | wc -l 命令，得到的结果是 33 个。\n此时 nemu 中仍然含有 33 个 dummy 变量的实体。这是因为 common.h 中 include 了 dubug.h ，且这是唯一一个 include debug.h 的地方，未初始化的相同名字的全局变量在符号表中只有一个实体。\n对变量进行初始化之后再编译，会报错：redefinition of dummy。这是因为赋了初值的全局变量会被认为是一个强符号。C 语言中不允许有两个相同的强符号被定义。而没有赋初值的变量是弱符号，语法上是可以重复定义的。\n了解 Makefile 请描述你在am-kernels/kernels/hello/目录下敲入make ARCH=$ISA-nemu 后, make程序如何组织.c和.h文件, 最终生成可执行文件am-kernels/kernels/hello/build/hello-$ISA-nemu.elf. (这个问题包括两个方面:Makefile的工作方式和编译链接的过程.) 关于Makefile工作方式的提示:\nMakefile中使用了变量, 包含文件等特性 Makefile运用并重写了一些implicit rules 在man make中搜索-n选项, 也许会对你有帮助 RTFM hello 中的 Makefile 内容比较简单：将 NAME 和 SRC 设置好，然后将 AM 中的 Makefile 全部贴进来。（虽然 AM 的 Makefile 相当复杂）\n事实上 SRC 有非常多：AM 中几乎每个文件夹下都有 Makefile，把这个文件夹下的 .c 文件搜刮进 SRC 中。\n按照正序，Makfile 大概做了如下一些大的事情：\n在 Makefile 中有\n$(DST_DIR)/%.o: %.c @mkdir -p $(dir $@) \u0026amp;\u0026amp; echo + CC $\u0026lt; @$(CC) -std=gnu11 $(CFLAGS) -c -o $@ $(realpath $\u0026lt;) 它会中所有的.c文件编译成.o文件放进目录DST_DIR中。这里DST_DIR是 AM 下的 build 目录。\n在 Makefile 中有\n$(LIBS): %: @$(MAKE) -s -C $(AM_HOME)/$* archive 它会把我们自己写的库函数（如 klib）打包成 archive。\n在 Makefile 中有\n$(IMAGE).elf: $(OBJS) am $(LIBS) @echo + LD \u0026quot;-\u0026gt;\u0026quot; $(IMAGE_REL).elf @$(LD) $(LDFLAGS) -o $(IMAGE).elf --start-group $(LINKAGE) --end-group 它会将所有的 .o 文件全部链接起来生成一个 .elf 文件。这里的 $(OBJS) 的生成方法不难：将 SRC 中所有的 .c 换成了 .o，加上相对应的路径前缀即可。\n在 nemu.mk 中有\nimage: $(IMAGE).elf @$(OBJDUMP) -d $(IMAGE).elf \u0026gt; $(IMAGE).txt @echo + OBJCOPY \u0026quot;-\u0026gt;\u0026quot; $(IMAGE_REL).bin @$(OBJCOPY) -S --set-section-flags .bss=alloc,contents -O binary $(IMAGE).elf $(IMAGE).bin 它使用 OBJCOPY 命令将 .elf 文件中的一些节做了修改，然后粘贴进了 .bin 文件中。\n在 nemu.mk 中有\nrun: image $(MAKE) -C $(NEMU_HOME) ISA=$(ISA) run ARGS=\u0026quot;$(NEMUFLAGS)\u0026quot; IMG=$(IMAGE).bin 它相当于在 $NEMU_HOME 目录下使用了命令 make ISA=riscv32 run ARGS=... IMG=...，这样就实现了将镜像加载到 nemu 上运行。\n以下是我的自由报告内容，我在做实验的过程中详细记录了自己遇到的所有问题和查阅的所有资料。这些笔记按照章节排列，每章通常有两个部分：\n思考题：包含笔者针对思考题查阅的资料和我尝试给出的答案。 补充：这里的内容是没有在讲义中提及的问题，以及讲义中建议自学的东西。 不停计算的机器 必答题 理解YEMU如何执行程序 YEMU可以看成是一个简化版的NEMU, 它们的原理是相通的, 因此你需要理解YEMU是如何执行程序的. 具体地, 你需要\n画出在YEMU上执行的加法程序的状态机 通过RTFSC理解YEMU如何执行一条指令 思考一下, 以上两者有什么联系?\n我们定义一个状态为 (PC, R[0], R[1], M[7], halt)，则状态机为：\n(0, x, x, 0, 0) -\u0026gt; (0, 33, x, 0, 0) -\u0026gt; (1, 33, x, 0, 0) -\u0026gt; (1, 33, 33, 0, 0) -\u0026gt; (2, 33, 33, 0, 0) -\u0026gt; (2, 16, 33, 0, 0) -\u0026gt; (3, 16, 33, 0, 0) -\u0026gt; (3, 49, 33, 0, 0) -\u0026gt; (4, 49, 33, 0, 0) -\u0026gt; (4, 49, 33, 49, 0) -\u0026gt; (5, 49, 33, 49, 0) -\u0026gt; (5, 49, 33, 49, 1) YEMU 执行指令的流程为：\n取指：将 $M[pc]$ 处的内容拿出来 译码：根据指令的各个字段判断指令到底想让计算机做什么 执行：位于 switch 代码段中，YEMU 支持的指令非常简单，只有寄存器赋值，加法，load/store 四种。 更新 PC 两者的联系在于：程序的两个状态之间的变化和指令的功能是一一对应的。\nRTFSC(2) 必答题 RTFSC 理解指令执行的过程 这一小节的细节非常多, 你可能需要多次阅读讲义和代码才能理解每一处细节. 根据往届学长学姐的反馈, 一种有效的理解方法是通过做笔记的方式来整理这些细节. 事实上, 配合GDB食用效果更佳.\n为了避免你长时间对代码的理解没有任何进展, 我们就增加一道必答题吧:\n请整理一条指令在NEMU中的执行过程.\n除了nemu/src/device和nemu/src/isa/$ISA/system之外, NEMU的其它代码你都已经有能力理解了. 因此不要觉得讲义中没有提到的文件就不需要看, 尝试尽可能地理解每一处细节吧! 在你遇到bug的时候, 这些细节就会成为帮助你调试的线索.\nfetch_decode_exec_updatepc() 函数分成三个部分：fetch_decode() 负责取指译码，s-\u0026gt;EHelper(s) 利用函数指针调用了译码后指令应该执行的函数。cpu-\u0026gt;pc=s-\u0026gt;dnpc 将 pc 指向下一条指令。\n取指 fetch_decode() 调用了 isa_fetch_decode()。isa_fetch_decode 会调用 instr_fetch() 把指令从内存中取出来。instr_fetch(*pc, len) 的更深内容和物理内存读写有关，此处不深究。特别的一点是它取出指令后会根据 len 更新 pc 的值（指向下一条指令）。\n译码 isa_fetch_decode() 将 instr_fetch() 的返回结果存储到 s-\u0026gt;instr.val 中。s 是一个 Decode 结构体类型，其中的 instr 是 ISADecodeInfo 类型。\n这里有一个有趣的代码细节是 nemu 为了抽象化不同 ISA 的差异，在顶层的代码中使用的是相同的类型名称，这些名称在底层才会分出区别，例如 ISADecodeInfo 类型的定义是\ntypedef concat(__GUEST_ISA__, _ISADecodeInfo) ISADecodeInfo; concat 函数的功能是将两个字符串拼接起来，从而实现了根据选择的 ISA 的不同定义不同的 ISADecodeInfo，将 ISA 的差异对上层抽象了。\n在本实验中 instr 自然是 riscv32_ISADecodeInfo 类型。该类型的定义可以在 isa-def.h 中查到，这是一个 union，给 instr.val 赋值之后，我们可以通过调用 union 中的各个变量来轻松获得指令的各个部分。\nnemu 调用了 table_main 函数来进行指令类型的确认，所有的 table 函数可以被看做一个巨大的 switch-case。这里面有两种类型的宏：\ndef_INSTR_IDTAB(\u0026quot;??????? ????? ????? ??? ????? xxxxx xx\u0026quot;, I/U/S/J/B/R , xxx); def_INSTR_TAB(\u0026quot;??????? ????? ????? ??? ????? xxxxx xx\u0026quot;, xxx) 第一种和第二种的区别在于第一种还会按照传送的指令类型对指令的寄存器和立即数进行解析。这种宏会返回一个执行函数的编号。类型确认的过程无非是一些位运算，这里主要再看寄存器和立即数的解析：\n为了进一步实现指令译码和操作数译码的解耦，nemu 还定义了译码操作数辅助函数，专门用于对立即数或寄存器进行译码。s 中有三个 Operand 类型的变量。Operand 类型的变量中有一个 union，分别是指向寄存器的指针，带符号立即数和无符号立即数，代表了寄存器类型/有符号立即数/无符号立即数。针对立即数的译码操作数辅助函数很简单，只要将值赋给 imm 即可。针对寄存器的则略微复杂一些：为了实现 riscv 中零号寄存器永远为0、不可写的特性，译码操作数辅助函数会对操作的读/写，和目标进行判断，以确保不会修改零号寄存器的内容 (is_write 参数只在寄存器中才会有作用）。\n所有的译码辅助函数都是可以通过调用译码操作数辅助函数来高效完成。这部分和手册可以形成高度的对应。\n执行 在 cpu-exec 中执行的代码很简单：就是调用 s 中存好的执行函数。形如 exec_xxx 的执行函数都是通过更加基本的 rtl 指令来实现功能。rtl 指令大多是调用了基于 c 语言的表达式运算来实现功能，少数的跳转指令稍微复杂一些。\n更新 pc 将 s-\u0026gt;dnpc 赋给 s，这里要注意 dnpc 和 snpc 的区别：snpc 仅仅指内存中该条指令的下一条指令（pc+4）位置，而 dnpc 保存了下一条真正要执行的指令的位置。在一些跳转指令中 snpc 和 dnpc 不一定相同。\n思考题 立即数背后的故事 框架代码通过instr_fetch()函数进行取指, 别看这里就这么一行代码, 其实背后隐藏着针对字节序的慎重考虑. 大部分同学的主机都是x86小端机, 当你使用高级语言或者汇编语言写了一个32位常数0x1234的时候, 在生成的二进制代码中, 这个常数对应的字节序列如下(假设这个常数在内存中的起始地址是x):\nx x+1 x+2 x+3 +----+----+----+----+ | 34 | 12 | 00 | 00 | +----+----+----+----+ 而大多数PC机都是小端架构(我们相信没有同学会使用IBM大型机来做PA), 当NEMU运行的时候,\nimm = instr_fetch(pc, 4); 这行代码会将34 12 00 00这个字节序列原封不动地从内存读入imm变量中, 主机的CPU会按照小端方式来解释这一字节序列, 于是会得到0x1234, 符合我们的预期结果.\nMotorola 68k系列的处理器都是大端架构的. 现在问题来了, 考虑以下两种情况:\n假设我们需要将NEMU运行在Motorola 68k的机器上(把NEMU的源代码编译成Motorola 68k的机器码) 假设我们需要把Motorola 68k作为一个新的ISA加入到NEMU中 在这两种情况下, 你需要注意些什么问题? 为什么会产生这些问题? 怎么解决它们?\n事实上不仅仅是立即数的访问, 长度大于1字节的内存访问都需要考虑类似的问题. 我们在这里把问题统一抛出来, 以后就不再单独讨论了.\n如果我们要将 NEMU 运行在 Motorola 68k 机器上，那么我们访问内存的指令就不能像现在这样将连续4个字节直接读入变量，因为 Motorola 68k 会按照大端方式来读取这4个字节。我们需要自己手写一个循环来按照小端方式处理数据。\n如果我们要在 NEMU 中加入 Motorola 68k 的 ISA，那么相似地，我们不能将连续4个字节直接读入变量，而是要手写一个循环按照大端方式处理数据。\n立即数背后的故事(2) mips32和riscv32的指令长度只有32位, 因此它们不能像x86那样, 把C代码中的32位常数直接编码到一条指令中. 思考一下, mips32和riscv32应该如何解决这个问题?\n可以设置两种加载立即数的指令：一种向高位加载，一种向低位加载。riscv32 中的 lui 指令可以实现向高位加载立即数的功能。mips指令集由于没有接触过，暂时留坑。\n为什么不需要 rtl_muls_lo 我们没有定义用于获取有符号数乘法结果低32位的RTL基本指令rtl_muls_lo, 你知道为什么吗?\nrtl_muls_lo 所需实现的功能与 rtl_mulu_lo 完全相同，本着不要让多个函数做同一件事情的原则，我们不需要 rtl_muls_lo。但有符号和无符号在高位的表现是不同的，因此两种 hi 我们都需要。\nRTL寄存器中值的生存期 在程序设计课上, 我们知道C语言中不同的变量有不同的生存期: 有的变量的值会一直持续到程序结束, 但有的变量却很快消亡. 在上述定义的RTL寄存器中, 其实也有不同的生存期. 尝试根据生存期给RTL寄存器分类.\n尽管目前这个分类结果并没有什么用处, 但其实将来在PA5中设计RTL优化方案的时候, 生存期的性质会给我们提供很大的优化机会.\n留坑，二周目再做。\n为什么执行了未实现指令会出现上述报错信息 RTFSC, 理解执行未实现指令的时候, NEMU具体会怎么做.\n在执行了未实现的指令时，译码的过程中无法匹配到任何一种 pattern，最终会返回一个 EXEC_ID_inv 宏，即不合法指令对应的执行函数的编号。这里的宏利用元编程和 enum 的方法写出了一种鲁棒性很强的代码，即使不断添加新指令也可以使得 EXEC_ID_inv 代表的编号是正确的。\n拿到 EXEC_ID_inv 后，执行函数赋为 g[idx]。在执行 g[idx] 时，执行的是 exec_inv，exec_inv() 函数调用了 rtl_hostcall 函数，并传入了 HOSTCALL_INV 参数（与正常退出的 HOSTCALL_EXIT 区分）。rtl_hostcall 函数接收到 HOSTCALL_INV 参数时，便会打印上述的报错信息。\n程序，运行时环境与AM 思考题 这又能怎么样呢 思考一下, 这样的抽象还会带来哪些好处呢? 你很快就会体会到这些好处了.\n这样的抽象有利于代码的移植：你甚至可以把别人的上层代码拿来直接用，即使你们使用不同的语言做了 nemu，只要 API 接口统一，上层的操作系统和用户程序就可以调用 API 直接运行。\n[二周目]为什么要有AM？ 操作系统也有自己的运行时环境. AM和操作系统提供的运行时环境有什么不同呢? 为什么会有这些不同?\n留坑。笔者暂时认为 AM 中的运行时环境更多是对硬件功能的直接抽象：比如可以访问外设，可以读写内存等。而操作系统中的运行时环境抽象层次更高，比如系统调用等等，是对 AM 运行时环境的进一步封装。之所以不同是因为他们所处的抽象层不同，服务的对象也不同。操作系统向应用程序暴露 API，自然不需要让应用程序知道硬件细节。AM 的运行时环境可以让操作系统更好地利用已有的硬件功能，可以做到架构和OS的解耦。\nmips32的分支延迟槽 为了提升处理器的性能, mips使用了一种叫分支延迟槽的技术. 采用这种技术之后, 程序的执行顺序会发生一些改变: 我们把紧跟在跳转指令(包括有条件和无条件)之后的静态指令称为延迟槽, 那么程序在执行完跳转指令后, 会先执行延迟槽中的指令, 再执行位于跳转目标的指令. 例如\n100: beq 200 101: add 102: xor ... 200: sub 201: j 102 202: slt 若beq指令的执行结果为跳转, 则相应的动态指令流为100 -\u0026gt; 101 -\u0026gt; 200; 若beq指令的执行结果为不跳转, 则相应的动态指令流为100 -\u0026gt; 101 -\u0026gt; 102; 而对于j指令, 相应的动态指令流为201 -\u0026gt; 202 -\u0026gt; 102.\n你一定会对这种反直觉的技术如何提升处理器性能而感到疑惑. 不过这需要你先了解一些微结构的知识, 例如处理器流水线, 但这已经超出了ICS的课程范围了, 所以我们也不详细解释了, 感兴趣的话可以STFW.\n但我们可以知道, 延迟槽技术需要软硬件协同才能正确工作: mips手册中描述了这一约定, 处理器设计者按照这一约定设计处理器, 而编译器开发者则会让编译器负责在延迟槽中放置一条有意义的指令, 使得无论是否跳转, 按照这一约定的执行顺序都能得到正确的执行结果.\n如果你是编译器开发者, 你将会如何寻找合适的指令放到延迟槽中呢?\n流水线CPU中如果分支预测失败，常见的做法是对各个流水段进行冲刷，然后将应该跳转到的PC送入流水线继续执行。flush 是一个代价很大的操作，会使流水线浪费很多个时钟周期，因此我们有两个方向可以努力：一个是尽可能减少 flush 的次数，也就是提高分支预测的成功率（动态分支预测 etc.），另一个是使流水线中执行的指令即使在分支预测错误的时候也可以保留，这就是mips中的延迟槽。\n至于分支延迟槽中应该放什么指令，最简单的自然是插入nop指令。这样正确性无疑可以得到保证，但性能不高：不论分支预测是否成功，执行这条nop指令都相当于没做事情，可以理解为流水线被阻塞了。\n以下是笔者的一些猜想：如果跳转和不跳转的接下来的几条指令中有完全相同的指令，自然可以将这条指令放到延迟槽中。这样不论走了哪个分支这条指令的执行都是有用的。当然，能否调整指令的顺序取决于指令之间的依赖关系。不过完全相同的指令很难找，我们可以利用寄存器的重命名技术，现将某条指令的结果放到一个备用的内存空间中，如果将来走这条分支，就将对应的寄存器名映射到这个地址上。\n指令名对照 AT\u0026amp;T格式反汇编结果中的少量指令, 与手册中列出的指令名称不符, 如x86的cltd, mips32和riscv32则有不少伪指令(pseudo instruction). 除了STFW之外, 你有办法在手册中找到对应的指令吗? 如果有的话, 为什么这个办法是有效的呢?\n笔者使用的一个方法是：直接将这条伪指令对应的机器代码二进制串放进手册里搜索。因为伪指令实际上也是通过普通指令完成功能的，所以可以搜索到对应的普通指令，从而确定伪指令的行为。\nstdarg是如何实现的? stdarg.h中包含一些获取函数调用参数的宏, 它们可以看做是调用约定中关于参数传递方式的抽象. 不同ISA的ABI规范会定义不同的函数参数传递方式, 如果让你来实现这些宏, 你会如何实现?\n笔者并没有去看 stdarg.h 的源码，但笔者用过宏 __VA_ARGS__，认为它背后的实现方式应该是一个链表，链表中的每个元素包含了参数的名称和参数指向的地址。\n补充 关于 riscv 的 jalr 指令 笔者在实现 jalr 指令的时候犯了一些错误，这个错误直到 PA3 才暴露出来，在此特地记录。jalr 指令的行为在手册中的定义如下：\nt=pc+4; pc=(x[rs1]+sext(offset))\u0026amp;~1; x[rd]=t 笔者起初认为这样的写法非常麻烦：为什么不把 pc+4 的值直接赋给 x[rd] ，而要搞出这么一个中间变量 t 呢？事实上这是因为指令中 rs1 和 rd 可能是一样的，如果在第一条指令就直接修改了 x[rd]，就可能也修改了 x[rs1]，从而第二条指令的结果就不对了。因此中间变量 t 的设置绝非是画蛇添足。\nISA 的手册经过了很多人的打磨，是非常简练的。每一条看似无用的语句一定都是充分考虑到了一些特殊情况无法删除才呈现在手册中的。因此最简单的保证正确的实现方法就是：手册说什么你就写什么。\n基础设施(2) 思考题 消失的符号 我们在am-kernels/tests/cpu-tests/tests/add.c中定义了宏NR_DATA, 同时也在add()函数中定义了局部变量c和形参a, b, 但你会发现在符号表中找不到和它们对应的表项, 为什么会这样? 思考一下, 什么才算是一个符号(symbol)?\n宏只是做了简单的字符串替换，在预处理阶段就会处理掉，显然不会进入符号表。局部变量和形式参数都是在栈上定义的，所以不在符号表中。只有全局变量、函数、静态全局变量、只读字符串等才会出现在符号表中。\n寻找\u0026quot;Hello World!\u0026quot; 在Linux下编写一个Hello World程序, 编译后通过上述方法找到ELF文件的字符串表, 你发现\u0026quot;Hello World!\u0026ldquo;字符串在字符串表中的什么位置? 为什么会这样?\n笔者先用命令 hd a.out 查看二进制文件并找到了 \u0026ldquo;Hello, World\\n\u0026rdquo; 字符串在文件中的偏移量，然后用 readelf -a a.out 命令查看了所有节，发现该字符串在只读数据节中。之所以在只读代码节中是因为这个字符串是理论上不应该被修改的。\n不匹配的函数调用和返回 如果你仔细观察上文recursion的示例输出, 你会发现一些有趣的现象. 具体地, 注释(1)处的ret的函数是和对应的call匹配的, 也就是说, call调用了f2, 而与之对应的ret也是从f2返回; 但注释(2)所指示的一组call和ret的情况却有所不同, call调用了f1, 但却从f0返回; 注释(3)所指示的一组call和ret也出现了类似的现象, call调用了f1, 但却从f3返回.\n尝试结合反汇编结果, 分析为什么会出现这一现象.\n这是一个非常有意思的问题，我们以注释(2)处的代码为例分析这一情况：\n注释(2)处显示，函数 f2 中调用了 f1 ，但没有从 f1 返回而是从 f0 返回的。使用 nemu 追踪 CPU 是如何从 f1 悄悄跳到 f0 的，发现了 f1 结尾处的如下汇编代码：\n80000090:\t00158593 addi\ta1,a1,1 80000094:\tfff50513 addi\ta0,a0,-1 80000098:\t00078067 jr\ta5 8000009c:\t00100513 li\ta0,1 800000a0:\t00008067 ret f1 的 C 语言原文如下：\nint f1(int n, int l) { if (l \u0026gt; lvl) lvl = l; rec ++; return n \u0026lt;= 0 ? 1 : func[0](n - 1, l + 1); }; 正是位于地址 0x80000098 处的指令 jr a5 从 f1 跳转到了 f0，也就是说其实我们的 ftrace 追踪漏了一次调用。这一跳转指令之所以会在追踪中被遗漏是因为它不符合标准的跳转指令的形式：标准的跳转指令一般都是 jal 或 jalr 指令，且存储 snpc 的寄存器按照 calling convention 应为 ra，以方便 return 回来以后从跳转指令的下一条开始继续执行。这里使用 jr a5 直接跳转，会导致从 f0 返回后其实没有回到 f1。\n这里之所以出现这样的情况是因为编译器对尾调用进行了优化。因为 f1 调用 f0 在 f1 的函数末尾，所以执行完 f0 返回之后 f1 会立即拿着 f0 的返回值再返回给 f2，所以不妨让 f0 直接返回 f2。这个优化在尾递归中会格外有用，不仅省去了一些指令，还可以重复利用栈帧，使得层数很深的尾递归也不会爆栈。\n冗余的符号表 在Linux下编写一个Hello World程序, 然后使用strip命令丢弃可执行文件中的符号表:\ngcc -o hello hello.c strip -s hello 用readelf查看hello的信息, 你会发现符号表被丢弃了, 此时的hello程序能成功运行吗?\n目标文件中也有符号表, 我们同样可以丢弃它:\ngcc -c hello.c strip -s hello.o 用readelf查看hello.o的信息, 你会发现符号表被丢弃了. 尝试对hello.o进行链接:\ngcc -o hello hello.o 你发现了什么问题? 尝试对比上述两种情况, 并分析其中的原因.\n第一种情况丢弃了符号表之后仍然可以正常运行，第二种情况丢弃了符号表后会报错：\n/usr/bin/ld: /usr/lib/gcc/x86_64-linux-gnu/10/../../../x86_64-linux-gnu/Scrt1.o: in function `_start': (.text+0x24): undefined reference to `main' 因为符号表被删除了，无法找到 main 函数的位置，所以链接失败。符号表的作用就是在链接的时候告诉外部模块本模块的各个函数、变量的地址，在已经生成好的可执行文件中，所有重定位已经完成，自然不再需要符号表；但如果在可重定位文件中删去了符号表，链接则会出问题。\n如何生成 native 的可执行文件 阅读相关Makefile, 尝试理解abstract-machine是如何生成native的可执行文件的.\nMakefile 中有一个变量 CROSS_COMPILE，在 native 下运行的时候这个变量没有赋值，所以 Makefile 不会使用交叉编译工具编译代码，而是用 native 的 gcc 和 binutils。\n奇怪的错误码 为什么错误码是1呢? 你知道make程序是如何得到这个错误码的吗?\n如果 main 函数正常退出，返回值会是0，否则返回值是1。make 程序捕捉 main 函数的返回值，并据此判断是否发生了错误，并将错误码呈现出来。\n这是如何实现的？ 为什么定义宏__NATIVE_USE_KLIB__之后就可以把native上的这些库函数链接到klib? 这具体是如何发生的? 尝试根据你在课堂上学习的链接相关的知识解释这一现象.\nklib 中编写的所有库函数都被条件编译 ifdef 框了起来，参与编译的条件为 !defined(__ISA_NATIVE__) || defined(__NATIVE_USE_KLIB))。如果 NATIVE_USE_KLIB 被注释了的话，在 native 下运行就不会有手写的库函数，native 会使用 glibc 的库函数。如果 NATIVE_USE_KLIB 没有被注释，在 native 下运行有手写的库函数，当手写函数与 glibc 库函数名称冲突时，优先链接用户手写的函数，这样就达到了使用 klib 的效果。\n匪夷所思的QEMU行为(有点难度) 在一些旧版的mips32-QEMU中, 仅在上述指令的PC值后12位为0xffc时, 才会进行指令打包. 这个打包条件看上去非常奇怪, 你知道可能的原因是什么吗?\n笔者没有使用 QEMU 进行 difftest，也不了解 mips 指令集，故留坑。\n捕捉死循环(有点难度) NEMU除了作为模拟器之外, 还具有简单的调试功能, 可以设置断点, 查看程序状态. 如果让你为NEMU添加如下功能\n当用户程序陷入死循环时, 让用户程序暂停下来, 并输出相应的提示信息\n你觉得应该如何实现? 如果你感到疑惑, 在互联网上搜索相关信息.\n从理论上证明某个程序会死循环是不可能的，因为这涉及到图灵停机问题：比如我写一个 check 哥德巴赫猜想的程序，如果我能判断它是否会死循环，我就证明了哥德巴赫猜想。\n笔者结合了网上的资料并自己思考了之后认为可以有如下的一些捕捉方法：\n在一个进程运行的同时用另一个进程来监视它的行为，如果该进程耗时过长就将其 kill。 死循环主要来自 do-while 和 for 循环。虽然无限递归从理论上也会死循环，但硬件的限制会使其通过爆栈的方式停下来。因此可以在编译是找到所有的 do-while 和 for 循环，向其中加入计数器，在循环执行次数超过了一个阈值后强行退出。 补充 关于 Difftest 笔者刚开始无法通过 spike 的 difftest，查看寄存器状态发现 t0 寄存器的值不正确。产生这个问题的原因是笔者在实现 jal/jalr 指令时使用了 t0 寄存器保存中间结果——这一行为虽然符合讲义中的调用约定，但由于 spike 没有相同的行为，所以报错了。事实上我们写的 nemu 并不是真正的“硬件”：我们根本不需要真的用寄存器来保存中间结果——我们有 C 语言，定义一个变量保存就可以了！框架代码中给的 rtl_j 函数似乎也使用了类似的手法（笔者没有调用框架代码给的 rtl_j 来实现跳转指令）\n输入输出 必答题 游戏是如何运行的 请你以打字小游戏为例, 结合\u0026quot;程序在计算机上运行\u0026quot;的两个视角, 来剖析打字小游戏究竟是如何在计算机上运行的. 具体地, 当你按下一个字母并命中的时候, 整个计算机系统(NEMU, ISA, AM, 运行时环境, 程序) 是如何协同工作, 从而让打字小游戏实现出\u0026quot;命中\u0026quot;的游戏效果?\n在主循环之间，打字小游戏做了一些绘制屏幕方面的准备工作。这些工作在 vedio_init 中，具体为\n读取窗口的宽和高。程序读取窗口大小通过读取 AM 提供的 AM_GPU_CONFIG 抽象寄存器实现。AM_GPU_CONFIG 抽象寄存器则通过访问 nemu 提供的 I/O 端口来获得这些参数。 将整个画布涂成紫色的。程序向画布输出颜色通过向 AM 提供的 AM_GPU_FBDRAW 抽象寄存器写入内容来实现。抽象寄存器会接收到开始绘制的位置的坐标，绘制内容数量，绘制的内容的 buffer，和一个是否立即同步的布尔变量。抽象寄存器的行为很简单，就是将对应的数据写到 nemu 的 I/O 端口中。nemu 的硬件会每隔一段时间检查是否有同步信号，如果有就将缓冲区的内容输出到屏幕上。 对各种字母的颜色做好设定。 打字小游戏的主循环是一个 while(1) {} ，在循环中会做这样一些事情：\ngame_logic_update：每次循环中都会根据和上次更新的时间差进行若干次游戏逻辑更新。这里程序调用时间函数会使用 AM 提供的抽象寄存器 AM_TIMER_UPTIME 来读取游戏已经开始的时间。AM中读取这个抽象寄存器的逻辑是访问 nemu 的时钟 I/O 端口。\n游戏逻辑更新中会定期生成一个新的字母，并且将每个字母根据其信息更新位置。关于字母，每个字母有如下一些参数：\nch：表示这个字母是啥，可以取 A-Z。 (x,y)：表示字母当前的位置。x 值是生成字母的时候随机的，y 值则会根据当前的时间不断更新。 v：表示字母单位时间移动的速度。正常情况下速度是正数，字母会往下落。当字母被击中的时候速度会变成负数，从而实现字母向上升的效果。如果速度为0，表示当前字母 miss 了。 t：这是一个计时器，用于当一个字母 miss 的时候，延迟 FPS 的时间后才会消失。 键盘读取：除非读取到 AM_KEY_NONE 表示当前没有按键，否则程序会一直在键盘读取的 while 循环中。这里程序收集键盘按键会使用 AM 提供的抽象寄存器 AM_INPUT_KEYBRD。AM_INPUT_KEYBRD 会访问 nemu 的键盘 I/O 端口，并根据得到的数据生成 keydown 和 keycode 两个参数。\n键盘读取分为以下两种情况：\n按下了 escape 键：调用 halt(0)，退出。 按下了是字母的键：调用 check_hit 函数检查是否确实击中了字母。check_hit 的行为比较简单：如果没有匹配到任何一个字母则更新 wrong，否则会将击中的字母的速度改成一个负值，从而一面实现字母被击中的标记，一面实现字母向上升的效果。 render ：这个函数负责更新屏幕。该函数会将字母原本所处位置的屏幕内容抹去（变成紫色），然后根据字母新的位置以及字母当前的状态（下落白色，miss红色，击中绿色）选择相应的 texture 作为 buffer 输出到对应位置。\n思考题 理解 volatile 关键字 也许你从来都没听说过C语言中有volatile这个关键字, 但它从C语言诞生开始就一直存在. volatile关键字的作用十分特别, 它的作用是避免编译器对相应代码进行优化. 你应该动手体会一下volatile的作用, 在GNU/Linux下编写以下代码:\nvoid fun() { extern unsigned char _end; // _end是什么? volatile unsigned char *p = \u0026amp;_end; *p = 0; while(*p != 0xff); *p = 0x33; *p = 0x34; *p = 0x86; } 然后使用-O2编译代码. 尝试去掉代码中的volatile关键字, 重新使用-O2编译, 并对比去掉volatile前后反汇编结果的不同.\n你或许会感到疑惑, 代码优化不是一件好事情吗? 为什么会有volatile这种奇葩的存在? 思考一下, 如果代码中p指向的地址最终被映射到一个设备寄存器, 去掉volatile可能会带来什么问题?\n_end 是一个变量，它的地址指向了数据段的第一个未使用的位置。\n在有 volatile 关键字的情况下，反汇编结果为：\n0000000000000000 \u0026lt;fun\u0026gt;: 0:\tf3 0f 1e fa endbr64 4:\tc6 05 00 00 00 00 00 movb $0x0,0x0(%rip) # b \u0026lt;fun+0xb\u0026gt; b:\t48 8d 15 00 00 00 00 lea 0x0(%rip),%rdx # 12 \u0026lt;fun+0x12\u0026gt; 12:\t66 0f 1f 44 00 00 nopw 0x0(%rax,%rax,1) 18:\t0f b6 02 movzbl (%rdx),%eax 1b:\t3c ff cmp $0xff,%al 1d:\t75 f9 jne 18 \u0026lt;fun+0x18\u0026gt; 1f:\tc6 05 00 00 00 00 33 movb $0x33,0x0(%rip) # 26 \u0026lt;fun+0x26\u0026gt; 26:\tc6 05 00 00 00 00 34 movb $0x34,0x0(%rip) # 2d \u0026lt;fun+0x2d\u0026gt; 2d:\tc6 05 00 00 00 00 86 movb $0x86,0x0(%rip) # 34 \u0026lt;fun+0x34\u0026gt; 34:\tc3 ret 可以看到这段指令和 C 语言程序的功能基本是一一对应的。\n在没有 volatile 关键字的情况下，反汇编结果为：\n0000000000000000 \u0026lt;fun\u0026gt;: 0:\tf3 0f 1e fa endbr64 4:\tc6 05 00 00 00 00 00 movb $0x0,0x0(%rip) # b \u0026lt;fun+0xb\u0026gt; b:\teb fe jmp b \u0026lt;fun+0xb\u0026gt; 指令发生了很大的变化。编译器发现 *p=0 之后进入了一个只有 *p=0xff 才会退出的循环，这期间没有任何对 p 的更改，所以认为这是一个死循环，直接将其缩减为了 jmp b ，并且砍掉了后面的所有内容。\n如果 p 指向的地址被映射到了一个设备寄存器，那么原本这个程序的功能可能是正确的：当检测到设备寄存器的值变为 0xff 后，依次向设备寄存器写入 0x33, 0x34 和 0x86。但编译优化之后，这个程序就完全变成了一个死循环。因此我们并不是什么时候都希望激进的编译优化：编译器有可能考虑不到外设的参与等情况。\n如何检测多个键同时被按下? 在游戏中, 很多时候需要判断玩家是否同时按下了多个键, 例如RPG游戏中的八方向行走, 格斗游戏中的组合招式等等. 根据键盘码的特性, 你知道这些功能是如何实现的吗?\n键盘码是一个8位二进制数，如果我们用32位整数来传递键盘码，就可以同时传递4个，可以用于检测多个键同时按下。\n神奇的调色板 现代的显示器一般都支持24位的颜色(R, G, B各占8个bit, 共有2^8*2^8*2^8约1600万种颜色), 为了让屏幕显示不同的颜色成为可能, 在8位颜色深度时会使用调色板的概念. 调色板是一个颜色信息的数组, 每一个元素占4个字节, 分别代表R(red), G(green), B(blue), A(alpha)的值. 引入了调色板的概念之后, 一个像素存储的就不再是颜色的信息, 而是一个调色板的索引: 具体来说, 要得到一个像素的颜色信息, 就要把它的值当作下标, 在调色板这个数组中做下标运算, 取出相应的颜色信息. 因此, 只要使用不同的调色板, 就可以在不同的时刻使用不同的256种颜色了.\n在一些90年代的游戏中(比如仙剑奇侠传), 很多渐出渐入效果都是通过调色板实现的, 聪明的你知道其中的玄机吗?\n在保持颜色索引不变的情况下，只要平滑地切换调色板就可以实现渐变。如果准备多套调色板，事实上我们可以使用远不止256种颜色。\nLiteNES 如何工作？ 另一个值得RTFSC的项目是LiteNES, 除了内置rom之外, 代码总数大约1500行. 关键是这个小巧玲珑的项目里面已经包含了一个完整的计算机系统: CPU, 内存, MMIO, 以及手柄(psg), 卡带(mmc)和图形处理器(ppu)这三个外设. 除了ppu的内部实现细节之外, 其余的部分你都已经有能力去理解了.\n有趣的是, LiteNES可以看成是NEMU和AM程序的融合. 尝试阅读LiteNES的代码, 理解LiteNES作为一个完整的计算机系统, 上述部件如何交互, 以及LiteNES作为一个AM程序, 如何通过AM提供的API来实现游戏效果. 我们提供 6502处理器(NES的CPU)以及 NES PPU(图形处理器)的资料供大家参考.\n留坑。\n补充 关于串口背后的原理 putch 仅仅执行了 outb(SERIAL_PORT,ch)，而 outb(SERIAL_PORT,ch) 仅仅将 *SERIAL_PORT 的值赋成了 ch，为什么就能同时通过标准错误流把信息输出在屏幕上呢？\n我们需要深入到汇编层面理解这段代码，putch 编译成汇编代码后仅有三句话：\nlui a5, 0xa0000 sb a0, 1016(a5) ret 第一句话装载立即数，结合第二句的 1016(a5) 定位到 SERIAL_PORT 指向的地址，第二句话就是真正的写入函数。虽然看上去仅仅是 store，但向 I/O 设备的 store 行为是更丰富的，在 nemu 中它会走过这样的流程：\n取指译码之后获取所有的信息，并分配好一个存储相关的执行函数。 运行执行函数，store 的执行函数会调用 paddr_write。 paddr_write 分析了一下要写入的地址，发现并不在内存中，而是在 I/O 区域，于是调用了 mmio_write。 mmio_write 分析了一下要写入的地址，发现是串口的地址，于是调用了 map_write ，并把串口的 IOMap 传了过去。 map_write 做了一些正确性检查之后，先调用了 host_write ，将 ch 这个数据写到了 SERIAL_PORT 地址，然后调用了串口的回调函数。 串口的回调函数是 serial_io_handler ，串口的回调函数默认是输出，否则会报错，在 is_write==true 的情况下回调函数会调用 serial_putc。 serial_putc 使用了 glibc 中的 putc(ch,stderr) 将字符输出到了标准错误流。 因此事实上虽然从高级语言层面 putch 中只有一个存储指令，但在汇编层面它既完成了存储又完成了输出。符合串口的 feature。\n疑问 如果 nemu 所有向屏幕输出的函数最终都是通过 putch 来实现，那么按理来说只需要申请一个字节大小的串口空间就可以了，为什么要 8 个字节呢？\n关于时钟硬件接口 框架代码中有一个小细节：只有在读取时钟的高32位的时候才会触发 nemu 重新读取当前时间。这意味着如果需要读取时间，一定要先读取高32位再读取低32位，顺序反过来就会出错。这样有一个好处：因为两次读取总是有时间差的，所以这样可以保证高32位和低32位来自同一个时刻。\n声卡 笔者完成了声卡的选做题。声卡的 I/O 相较于其他的会复杂一些，因为 nemu 的硬件部分的代码也需要自己实现。nemu 不是真正的“硬件”，要实现音频的输出还是得靠库函数。这里笔者根据讲义使用了 SDL 库。\n我们需要在 AM 中实现以下函数：\n__am_audio_config：读取声卡的状态，包括是否存在声卡 (cfg-\u0026gt;present)。 __am_audio_ctrl：告诉硬件一些基本的信息，如频率，频道，采样率等等。 __am_audio_status：读取缓冲区中还有的数据字节数。 __am_audio_play：向声卡的缓冲区写入数据。如果声卡的缓冲区不够，则应该轮询，直到缓冲区大小足够位置。 我们需要在 nemu 中做这样一些事情：\n在 audio 的回调函数 audio_io_handler 中完成初始化，包括向 SDL_AudioSpec 类型的变量中填写频率、频道、采样率，注册一个回调函数 audio_callback()，以及调用 SDL_InitSubSystem 和 SDL_OpenAudio 函数等。 完成 audio-sbuf 的回调函数 audio_sbuf_handler ，主要工作就是把 AM 送过来的数据放入缓冲队列。 完成 audio_callback()，SDL 会不定时索要一定量的数据，从当前缓冲区的队列头部取数据给 SDL。如果当前所剩数据量不够，应该再补充一些 0，以防出现噪音。 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"67eec276bde55606eff45faa36dcba26","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-ics/pa/pa2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-ics/pa/pa2/","section":"notes","summary":"实验进度 我完成了所有的必答题，并针对选做题和思考题给出了自己的想法。\n必答题 程序是个状态机 点击 这里跳转到解答。\nRTFSC 点击 这里跳转到解答。\n程序如何运行 点击 这里跳转到解答。\n编译与链接 在nemu/src/engine/interpreter/rtl-basic.h中, 你会看到由static inline开头定义的各种RTL指令函数. 选择其中一个函数, 分别尝试去掉static, 去掉inline或去掉两者, 然后重新进行编译, 你可能会看到发生错误. 请分别解释为什么这些错误会发生/不发生? 你有办法证明你的想法吗?\n如果去掉 inline，编译时会报错：xxx defined but not used。这是因为 rtl.h 文件 include 了 rtl-basic.","tags":null,"title":"PA2 - 简单复杂的机器: 冯诺依曼计算机系统","type":"docs"},{"authors":null,"categories":null,"content":"实验进度 我完成了所有的必答题，并针对选做题和思考题给出了自己的想法。\n必答题 理解上下文结构体的前世今生 点击 这里跳转到解答。\n理解穿越时空的旅程 点击 这里跳转到解答。\nhello程序是什么, 它从何而来, 要到哪里去 点击 这里跳转到解答\n仙剑奇侠传究竟如何运行 运行仙剑奇侠传时会播放启动动画, 动画里仙鹤在群山中飞过. 这一动画是通过navy-apps/apps/pal/repo/src/main.c中的PAL_SplashScreen()函数播放的. 阅读这一函数, 可以得知仙鹤的像素信息存放在数据文件mgo.mkf中. 请回答以下问题: 库函数, libos, Nanos-lite, AM, NEMU是如何相互协助, 来帮助仙剑奇侠传的代码从mgo.mkf文件中读出仙鹤的像素信息, 并且更新到屏幕上? 换一种PA的经典问法: 这个过程究竟经历了些什么? (Hint: 合理使用各种trace工具, 可以帮助你更容易地理解仙剑奇侠传的行为)\n程序的行为总体上是读出仙鹤的像素信息，然后不断更新到屏幕上并修改仙鹤的位置。在软件层面，程序会使用fseek 和 fread 库函数来定位和读取像素信息，使用SDL库函数来输出。fseek 和 fread 函数最终会使用lseek 和 read 系统调用，SDL库函数基于我们对系统调用进一步封装的NDL库实现，NDL库会使用系统调用 lseek 和 write 来实现像素的定位和写入（注意VGA被抽象成了文件，读写像素不需要专门的 I/O 相关函数。）lseek read 和 write 最终会调用 libos 中的 _read, _write 和 _lseek，传递对应的系统调用号和相关参数，使用 ecall 指令触发中断。\nNanos-lite 中会识别系统调用的类型，并调用 fs_read fs_write 和 fs_lseek 。fs_lseek 比较简单，只是修改文件当前的 offset，fs_read 会使用 /bin/pal 对应的读函数 ramdisk_read 来从“硬盘”中读取信息（事实上已经被加载到内存中）ramdisk_read 使用的是 AM 的函数 memcpy；fs_write 会使用 /dev/fb 文件对应的写函数 fb_write 。fb_write 会使用 AM 提供的 VGA 相关的抽象寄存器和一段像素空间来写入信息。\nAM 和 nemu 之间有一套内存 I/O 的映射规定，nemu 会根据这些 I/O 空间的信息进行硬件层面的修改。memcpy 是 klib 中的函数，可以直接访问 nemu 的大数组（内存），实现信息的读取。\n以下是我的自由报告内容，我在做实验的过程中详细记录了自己遇到的所有问题和查阅的所有资料。这些笔记按照章节排列，每章通常有两个部分：\n思考题：包含笔者针对思考题查阅的资料和我尝试给出的答案。 补充：这里的内容是没有在讲义中提及的问题，以及讲义中建议自学的东西。 最简单的操作系统 思考题 [二周目] 什么是操作系统？ 这可是个大问题, 我们也鼓励你学习完操作系统课程之后再回来重新审视它.\n留坑，二周目再填。目前笔者认为操作系统是直接与硬件接触的一个程序，它将硬件支持的功能封装成系统调用作为服务提供给上层应用程序，并负责上层应用程序之间的运行调度。\n补充 初次运行 nanos-lite 报错 初次运行 nanos-lite 显示程序访问了非法的地址，经过定位后发现 AM 中的 printf 没有实现 %p 打印指针的功能，触发了 UB。这为我们敲响了编写好的代码的警钟：如果函数的参数输入出现了“未定义“的行为，函数应该输出一些提示信息，从而快速定位问题。（例如此处就应该让 printf 报错，而不是通过非法的地址访问去寻找 fault）。\n穿越时空的旅程 必答题 理解上下文结构体的前世今生 你会在__am_irq_handle()中看到有一个上下文结构指针c, c指向的上下文结构究竟在哪里? 这个上下文结构又是怎么来的? 具体地, 这个上下文结构有很多成员, 每一个成员究竟在哪里赋值的? $ISA-nemu.h, trap.S, 上述讲义文字, 以及你刚刚在NEMU中实现的新指令, 这四部分内容又有什么联系?\n如果你不是脑袋足够灵光, 还是不要眼睁睁地盯着代码看了, 理解程序的细节行为还是要从状态机视角入手.\ntrap.S 文件的前半部分负责组织上下文结构体。这个上下文结构体作为函数的参数，保存在栈上。trap.S 的行为和正常的 C 程序调用函数前准备参数的过程是一样的。第一句\naddi sp, sp, -CONTEXT_SIZE 为 Context 结构体开辟了空间。接下来的\nMAP(REGS, PUSH) 利用了一点元编程技巧，其含义是将通用寄存器的值按顺序上栈。\n接下来还要将特权寄存器的值上栈。特权寄存器不能用 store 指令直接上栈，因此要先将其值保存到通用寄存器中再上栈。代码是如下6行：\ncsrr t0, mcause csrr t1, mstatus csrr t2, mepc sd t0, OFFSET_CAUSE(sp) sd t1, OFFSET_STATUS(sp) sd t2, OFFSET_EPC(sp) 在进入处理函数之前，最后一句话是\nmv a0, sp 根据 RISCV 的 calling convention，a0 寄存器保存了第一个参数的值。我们后面要调用的函数 __am_irq_handle 的参数是 Context *c，因此将当前的 sp 值传进 a0，进入函数后指针 c 就指向了在栈上保存的上下文结构体的首地址。\n这整个过程充分利用了 C 和汇编语言的紧密联系。\n理解穿越时空的旅程 从Nanos-lite调用yield()开始, 到从yield()返回的期间, 这一趟旅程具体经历了什么? 软(AM, Nanos-lite)硬(NEMU)件是如何相互协助来完成这趟旅程的? 你需要解释这一过程中的每一处细节, 包括涉及的每一行汇编代码/C代码的行为, 尤其是一些比较关键的指令/变量. 事实上, 上文的必答题\u0026quot;理解上下文结构体的前世今生\u0026quot;已经涵盖了这趟旅程中的一部分, 你可以把它的回答包含进来.\n别被\u0026quot;每一行代码\u0026quot;吓到了, 这个过程也就大约50行代码, 要完全理解透彻并不是不可能的. 我们之所以设置这道必答题, 是为了强迫你理解清楚这个过程中的每一处细节. 这一理解是如此重要, 以至于如果你缺少它, 接下来你面对bug几乎是束手无策.\nNanos-lite 调用 yield() 之后，执行了两条汇编指令（这两条汇编指令是用内联汇编的方式直接嵌入的）：\nasm volatile(\u0026quot;li a7, -1; ecall\u0026quot;); 其中第一条指令向 a7 寄存器写入 -1，a7 寄存器是约定中传递中断类型的寄存器。第二条指令 ecall 则是“中断”指令。\n在硬件层面，nemu 对 ecall 指令译码后，执行时会调用 isa_raise_intr 函数，该函数将 a7 寄存器传递的事件类型存放到 mcause 寄存器中，向 mepc 寄存器写入当前的 pc，然后将 pc 跳转到 mtvec 寄存器预先存好的一个地址开始执行。mtvec 中的地址是函数 __am_asm_trap 的地址，在 cte_init 中的\nasm volatile(\u0026quot;csrw mtvec, %0\u0026quot; : : \u0026quot;r\u0026quot;(__am_asm_trap)); 完成了 mtvec 内容的初始化。\n__am_asm_trap 函数在 trap.S 中定义，是用内联汇编写的。该函数首先组织上下文结构体，组织方式见上一道必答题。然后跳转进入处理函数 __am_irq_handle。函数 __am_irq_handle 会根据上下文结构体的内容打包出一个事件结构体 ev。根据上下文结构体中的 mcause 寄存器的值，可以识别事件的类型，如自陷事件的事件号为 -1。打包完事件结构体后，__am_irq_handle 会将上下文结构体和事件结构体一起传给处理函数。这个处理函数是在 cte_init 中传进来的 do_event。\ndo_event 函数检查事件结构体中的事件类型，当看到是 EVENT_YIELD 时，它判定这个中断没有必要重复，因此给 mepc 的值 +4，这个 +4 操作直接修改了上下文结构体中的 mepc 的保存值。\n这时进入 trap.S 的后半部分，后半部分将栈上保存的寄存器内容恢复，然后调用 mret 指令。在硬件层面，nemu 识别出 mret 指令后，直接将 pc 恢复为 mepc 的值。至此，时空穿越的旅程结束。\n思考题 [二周目] 特殊的原因？ 这些程序状态(x86的eflags, cs, eip; mips32的epc, status, cause; riscv32的mepc, mstatus, mcause)必须由硬件来保存吗? 能否通过软件来保存? 为什么?\n留坑，二周目再做。\n异常号的保存 x86通过软件来保存异常号, 没有类似cause的寄存器. mips32和riscv32也可以这样吗? 为什么?\nx86的寄存器比较复杂，有类似于EFLAGS等大量的功能专一的寄存器，这些寄存器的值也是可以上栈的。而 riscv32 中只有通用寄存器的值可以上栈，如果一定要用软件来保存异常号的话，则必须硬件和软件约定好使用一个通用寄存器来专门保存异常号，这在本质上已经和cause寄存器没有区别了。\n对比异常处理与函数调用 我们知道进行函数调用的时候也需要保存调用者的状态: 返回地址, 以及calling convention中需要调用者保存的寄存器. 而CTE在保存上下文的时候却要保存更多的信息. 尝试对比它们, 并思考两者保存信息不同是什么原因造成的.\n异常处理比函数调用更复杂一些：函数调用能保证 callee 的操作满足 calling convention，但中断之后会涉及更复杂的操作，比如特权级切换等，这个过程中每个寄存器的值都可能会被改写。为了保证恢复上下文时程序的状态机不会变，我们需要保存更多的信息。\n诡异的 x86 代码 x86的trap.S中有一行pushl %esp的代码, 乍看之下其行为十分诡异. 你能结合前后的代码理解它的行为吗? Hint: 程序是个状态机.\n这句话和 riscv 的 trap.S 中的 mv a0, sp 没有本质区别，都是在为即将执行的 __am_irq_handle 准备参数。这里的 esp 的内容就是上下文结构体的地址。\n从加4操作看CISC和RISC 事实上, 自陷只是其中一种异常类型. 有一种故障类异常, 它们返回的PC和触发异常的PC是同一个, 例如缺页异常, 在系统将故障排除后, 将会重新执行相同的指令进行重试, 因此异常返回的PC无需加4. 所以根据异常类型的不同, 有时候需要加4, 有时候则不需要加.\n这时候, 我们就可以考虑这样的一个问题了: 决定要不要加4的, 是硬件还是软件呢? CISC和RISC的做法正好相反, CISC都交给硬件来做, 而RISC则交给软件来做. 思考一下, 这两种方案各有什么取舍? 你认为哪种更合理呢? 为什么?\n我认为从抽象层的角度来看由软件处理是否+4更加合理，因为是否需要+4取决于中断的类型，而判断中断类型的是操作系统。因此软件判断中断类型后由软件决定这次中断是否需要再次执行。\nmips32延迟槽和异常 我们在PA2中提到, 标准的mips32处理器采用了分支延迟槽技术. 思考一下, 如果标准的mips32处理器在执行延迟槽指令的时候触发了异常, 从异常返回之后可能会造成什么问题? 该如何解决? 尝试RTFM对比你的解决方案.\nmips32引入了分支延迟槽，所以在遇到跳转指令且确实发生跳转时的指令执行流为：\n跳转指令 --\u0026gt; 分支延迟槽 --\u0026gt; 跳转的目标指令 如果在分支延迟槽指令处出现了异常陷入内核态处理，处理结束之后我们不能按照惯例回到分支延迟槽的 snpc 执行。因为在流水线 CPU 中，经过了异常处理程序之后，跳转指令早就不在 CPU 中了，如果进入 snpc 则无法跳转。所以我们应该将 pc 拨回到跳转指令，将跳转指令再次送入流水线，然后按照顺序再做一次分支延迟槽，这一次分支延迟槽不一定再会触发异常（比如前一次已经处理了缺页），然后就能正确跳转到目标指令继续执行。\n补充 关于 ecall 指令 ecall 指令没有任何参数，那么如何直到应该向 mcause 寄存器里写入哪种中断原因呢？RTFSC 或者查看 riscv-linux 的约定可以看到 ecall 指令利用 a7 寄存器来保存调用号。因此将 a7 的内容写入 mcause 即可。\n关于恢复上下文中的软件 +4 硬件恢复上下文的方法是在 mret 指令中将 dnpc 设置为 mpec+4，但按照讲义中所写，riscv 应该用软件恢复上下文。笔者刚开始尝试了写入一段内联汇编的代码，利用 csrr csrw 指令直接修改 mepc 的值，但失败了。经过分析发现处理完中断之后 trap.S 会根据上下文结构体 c 的内容来恢复上下文，所以即使中间修改了 mepc 的值，最后仍然会被恢复为没有 +4 的原始值。因此软件+4的方法非常简单：在 do_event 中的 EVENT_YIELD 部分，将 c-\u0026gt;mepc 直接 +4 即可。\n用户程序和系统调用 必答题 hello程序是什么, 它从何而来, 要到哪里去 我们知道navy-apps/tests/hello/hello.c只是一个C源文件, 它会被编译链接成一个ELF文件. 那么, hello程序一开始在哪里? 它是怎么出现内存中的? 为什么会出现在目前的内存位置? 它的第一条指令在哪里? 究竟是怎么执行到它的第一条指令的? hello程序在不断地打印字符串, 每一个字符又是经历了什么才会最终出现在终端上?\n由于此时还没有实现文件系统，所以 ramdisk.img 中只有 hello 程序。nanos-lite 中的内联汇编程序 resources.S 将 ramdisk.img 的内容加载到了内存中。resources.S 的内容如下：\n.section .data .global ramdisk_start, ramdisk_end ramdisk_start: .incbin \u0026quot;build/ramdisk.img\u0026quot; ramdisk_end: .section .rodata .globl logo logo: .incbin \u0026quot;resources/logo.txt\u0026quot; .byte 0 一个有意思的细节是 resources.S 中定义了全局变量 ramdisk_start 和 ramdisk_end ，这样在 C 程序中我们可以很方便地定位 ramdisk.img 被加载到了内存中的哪个位置。从硬件层面来说，由于现在还没有引入虚拟内存，ramdisk.img 被放在了地址 0x83000000 处，Makefile 的 LNK_ADDR 实现了这一点。\n在调用了 naive_uload 函数后，系统会进入 hello 程序的汇编代码（elf文件中有入口地址），hello程序输出字符的时候，会使用 write 系统调用（直接使用 write 或者通过 printf 库函数使用 write），nanos-lite 中的 fs_write 函数会使用 AM 提供的接口来输出（在实现了文件系统之后，fs_write 会直接使用 stdout 文件对应的写函数 serial_write）。\n思考题 堆和栈在哪里？ 我们提到了代码和数据都在可执行文件里面, 但却没有提到堆(heap)和栈(stack). 为什么堆和栈的内容没有放入可执行文件里面? 那程序运行时刻用到的堆和栈又是怎么来的? AM的代码是否能给你带来一些启发?\nAM 的作用就是在硬件层的基础上进行了一定程度的抽象，提供了运行时环境。堆和栈是一种必要的运行时环境（事实上就是 nemu 内存大数组的一部分），因此可执行文件中只需要刻画如何使用堆和栈，并不需要把堆和栈放在文件里。\n如何识别不同格式的可执行文件？ 如果你在GNU/Linux下执行一个从Windows拷过来的可执行文件, 将会报告\u0026quot;格式错误\u0026quot;. 思考一下, GNU/Linux是如何知道\u0026quot;格式错误\u0026quot;的?\n可执行文件的前几个字符是文件的魔数，用于标识文件的类型。GNU/Linux 在执行文件之前可以先检查魔数来判断这是否是一个 ELF 格式的可执行文件。\n冗余的属性？ 使用readelf查看一个ELF文件的信息, 你会看到一个segment包含两个大小的属性, 分别是FileSiz和MemSiz, 这是为什么? 再仔细观察一下, 你会发现FileSiz通常不会大于相应的MemSiz, 这又是为什么?\n该问题的解答见下一道思考题“为什么要清零”。\n为什么要清零？ 为什么需要将 [VirtAddr + FileSiz, VirtAddr + MemSiz) 对应的物理区间清零?\nSFTW 后发现这是一个非常有意思的问题。ELF 文件中的 Filesize 指的是这个段在 ELF 文件中占据的大小，而 Memsize 指的是这个段最终在内存中占据的大小。这两者之所以不一样是因为 .bss 节（未初始化变量）在 ELF 中是没有分配具体的空间的，只是一个占位符，但最终在运行状态下它们也需要被分配内存空间。\n将 [VirtAddr + FileSiz, VirtAddr + MemSiz] 对应的物理区间清零，相当于使得 .bss 中的变量的初值都为 0。我们在 C 语言程序中定义未初始化的全局变量，其默认初值为0，正是因为加载器在加载时将这一段内存置为了0。经过笔者的实验，如果将这一清空语句删除，运行程序将会触发段错误。 这篇回答对这个问题给出了较为详细的解释。\n系统调用的必要性 对于批处理系统来说, 系统调用是必须的吗? 如果直接把AM的API暴露给批处理系统中的程序, 会不会有问题呢?\nAM 的 API 只能负责完成相应的功能，而系统调用应该还具有统一调度各个程序对硬件的使用的功能。比如系统调用 read，为了安全性的考虑，它应该只能读取本用户程序相关的内存区域，不能访问别的用户程序的内存。这部分安全检查就应该由系统调用及其背后的操作系统来完成。AM 的 API 只是硬件功能的简单封装，无法实现这样的功能。\nRISC-V系统调用号的传递 如果你选择的是RISC-V, 你会发现它并不是通过a0来传递系统调用号. 事实上, 我们参考了RISC-V Linux的系统调用参数传递的约定: 即在RISC-V Linux上也是通过这个寄存器来传递系统调用号的. 你觉得RISC-V Linux为什么没有使用a0来传递系统调用号呢?\nRISC-V Linux 调用约定中使用 a7 来传递系统调用号，且规定系统调用最多有 6 个参数，存放在 a0~a5 中。我认为这样设计可能的目的是保持系统调用和函数调用在传递参数上的一致性。\n补充 检查 ELF 文件的魔数 我们知道ELF文件的开头都有一个特殊的魔数, 为了防止loader加载了一个非ELF格式的文件, 我们可以在loader中对魔数进行检查:\nassert(*(uint32_t *)elf-\u0026gt;e_ident == 0xBadC0de); 你需要把上述的0xBadC0de换成正确的魔数.\n别小看这个表面上很蠢的assert(), 当你哪天手抖不知道做了什么而又被它抓到的时候, 你就知道谢天谢地了.\nELF文件开头的四个字节是 7f 45 4c 46 ，注意到 riscv 是小端机，所以正确的魔数为 0x464c457f。\n检测 ELF 文件的ISA类型 你很有可能会因为疏忽, 从而让native的Nanos-lite来加载运行一个x86/mips32/riscv32的dummy. 从ISA规范的角度来说, 这种行为显然属于UB, 具体而言通常会发生一些难以理解的错误. 为了避免这种情况, 你可以在loader中检测ELF文件的ISA类型. 我们可以根据AM中定义的一些宏来筛选出预期的ISA类型，然后和ELF信息中的某个域进行对比, 如果发现要加载的ELF文件的ISA类型和预期不一致, 就报错. 如果你不知道AM中的宏在哪里定义, RTFSC. 如果你不知道应该和ELF中的哪个域进行对比, RTFM.\n当前可能需要用到的 ISA 应该只有 native 的 x86-64 和 nemu 的 riscv32，因此笔者使用了如下代码来定义宏 EXPECT_ISA：\n#if defined(__ISA_AM_NATIVE) # define EXPECT_TYPE EM_X86_64 #elif defined(__ISA_RISCV32__) # define EXPECT_TYPE EM_RISCV // 阅读 elf.h 中的宏可以找到 RISC-V 对应 EM_RISCV #else # error Unsupported ISA #endif ELF 文件中的 ISA 属性存放在 elf_header 的 e_machine 字段中。因此用一个 assert 语句进行比较即可。\n关于内存的读写 笔者曾经想了很久也不明白应该如何读写内存（因为在 AM 的 nemu 相关文件夹中没有找到 API）。后来想起来内存的读写作为一条架构无关的功能，放在了 klib 里面。因此直接调用 memset, memcpy 等即可。从 ELF 文件中读出来的 vaddr 虽然是变量，但里面存储的就是地址，直接将其转换成指针类型即可。\n关于跳转 编译器编译并生成可执行文件时，会寻找 start.S 并将其作为程序的入口。这个入口保存在了 elf header 的 e_entry 字段中，因此直接访问该字段即可。框架代码中有一个很好的细节：\n((void *)())entry) (); 它将保存有客户程序入口地址的变量 entry 强制转换成了一个函数指针。然后调用这个函数，相当于跳转到函数指针指向的地址，而这个地址就是 entry 原来存储的值。这一句代码用 C 的方式完成了汇编级别的跳转。\n关于返回值 为什么我使用了框架代码给定的宏 GPRx 来存储返回值，但堆区的实现还是失败了？\n检查框架代码可以发现，除了 GPR1 对应到了正确的 a7 以外，其他的都是错的！根据 riscv-linux 的 syscall 约定，我们应该将 GPR2~GPR4 对应到 a0~a2，返回寄存器 GPRx 对应到 a0，这样就可以正确地提供返回值了。\n文件系统 补充 关于 file-test 中文件读入的溢出问题 笔者起初认为进行读取操作时，读取的范围是不能超过本文件大小的，因此在读取的时候对 offset 和 len 进行了 assert，结果触发了 fail。\n笔者打印了每次读取的 len，发现 fscanf 是批量读取的：由于有一次读取在四千多的位置一下读取了 1024 个字符，所以触发了断言。\n笔者再次阅读了 read 系统调用的手册，发现其返回值理应是实际读取到的字符个数。处于安全性的考虑，一个应用程序不应该可以读取到别的用户程序的数据信息，所以如果在文件系统中剩余的数据不足给定的 len，则应该只将剩余的数据放入缓冲区，并返回真实的读取到的字符数。\n精彩纷呈的应用程序 思考题 比较 fixedpt 和 float fixedpt和float类型的数据都是32位, 它们都可以表示2^32个不同的数. 但由于表示方法不一样, fixedpt和float能表示的数集是不一样的. 思考一下, 我们用fixedpt来模拟表示float, 这其中隐含着哪些取舍?\nfixedpt 中每相邻的两个数之间的差都是 $2^{-8}$，而 float 在越小的数据范围下表示的精度越高。通常来说我们在表示大数的时候会对其小数点后的精度要求不那么高，也就是我们更在意数据的“相对误差”而不是“绝对误差”，在这一点上 float 会更加合理。\n神奇的fixedpt_rconst 阅读fixedpt_rconst()的代码, 从表面上看, 它带有非常明显的浮点操作, 但从编译结果来看却没有任何浮点指令. 你知道其中的原因吗?\n笔者暂时没有研究出来，留坑。\n神奇的LD_PRELOAD bmp-test需要打开一个路径为/share/pictures/projectn.bmp的文件, 但在Linux native中, 这个路径对应的文件并不存在. 但我们还是把bmp-test成功运行起来了, 你知道这是如何实现的吗? 如果你感兴趣, 可以在互联网上搜索LD_PRELOAD相关的内容.\nLD_PRELOAD 可以实现路径的重定向，PA4.1 的 busybox 也使用了相似的技术实现了将 shell 命令的地址重定向到 busybox 中的程序。具体内容尚未了解，留坑。\n仙剑奇侠传是如何工作的？ 我们在PA2中讨论过一个游戏的基本框架, 尝试阅读仙剑奇侠传的代码, 找出基本框架是通过哪些函数实现的. 找到之后, 可能会对你调试仙剑奇侠传带来一定的帮助. 虽然仙剑奇侠传的代码很多, 但为了回答这个问题, 你并不需要阅读大量的代码.\nPA2 中提到的一个游戏的基本框架大致为：\nwhile (1) { 等待新的一帧(); // AM_TIMER_UPTIME 处理用户按键(); // AM_INPUT_KEYBRD 更新游戏逻辑(); // TRM 绘制新的屏幕(); // AM_GPU_FBDRAW } 仙剑奇侠传中的 PAL_GameMain() 中的 while 循环大抵做了相似的工作：\nwhile (TRUE) { // // Do some initialization at game start. // if (gpGlobals-\u0026gt;fGameStart) { PAL_GameStart(); gpGlobals-\u0026gt;fGameStart = FALSE; } // // Load the game resources if needed. // PAL_LoadResources(); // // Clear the input state of previous frame. // PAL_ClearKeyState(); // // Wait for the time of one frame. Accept input here. // PAL_DelayUntil(dwTime); uint32_t now = SDL_GetTicks(); UpdateFPS(now); // // Set the time of the next frame. // dwTime = now + FRAME_TIME; // // Run the main frame routine. // PAL_StartFrame(); } PAL_LoadResources() 用于加载需要的游戏资源。PAL_ClearKeyState() 清空之后，PAL_DelayUntil() 会持续执行一段时间并接收设备的输入（主要使用了 SDL_Delay() 和 PAL_ProcessEvent()）。PAL_StartFrame() 用于更新游戏逻辑（比如根据输入来改变人物的位置）并绘制图像。\n仙剑奇侠传的脚本引擎 在navy-apps/apps/pal/repo/src/game/script.c中有一个PAL_InterpretInstruction()的函数, 尝试大致了解这个函数的作用和行为. 然后大胆猜测一下, 仙剑奇侠传的开发者是如何开发这款游戏的? 你对\u0026quot;游戏引擎\u0026quot;是否有新的认识?\n这个函数的行为有一点像一个 cpu：它拿到“指令”之后，会进行译码，执行，函数会返回下一条应该执行的“指令”的地址。\n仙剑的开发者在开发这款游戏的时候，可能发明了一款专用于 pal 的 ISA，然后所有和游戏相关的逻辑更新的操作都通过这个 ISA 支持的指令来完成。 游戏引擎其实就是一个虚拟机。如果我们认为 nemu 是真机的话，那么 pal 里的这个专门执行 pal-ISA 指令集的 \u0026ldquo;cpu\u0026rdquo; 就是游戏引擎；如果我们认为 native 是真机的话，笔者目前的 nemu 就是一个执行 riscv32-ISA 指令集的“游戏引擎”。\n不再神秘的秘技 网上流传着一些关于仙剑奇侠传的秘技, 其中的若干条秘技如下:\n很多人到了云姨那里都会去拿三次钱, 其实拿一次就会让钱箱爆满! 你拿了一次钱就去买剑把钱用到只剩一千多, 然后去道士那里, 先不要上楼, 去掌柜那里买酒, 多买几次你就会发现钱用不完了. 不断使用乾坤一掷(钱必须多于五千文)用到财产低于五千文, 钱会暴增到上限, 如此一来就有用不完的钱了 当李逍遥等级到达99级时, 用5~10只金蚕王, 经验点又跑出来了, 而且升级所需经验会变回初期5~10级内的经验值, 然后去打敌人或用金蚕王升级, 可以学到灵儿的法术(从五气朝元开始); 升到199级后再用5~10只金蚕王, 经验点再跑出来, 所需升级经验也是很低, 可以学到月如的法术(从一阳指开始); 到299级后再用10~30只金蚕王, 经验点出来后继续升级, 可学到阿奴的法术(从万蚁蚀象开始). 假设这些上述这些秘技并非游戏制作人员的本意, 请尝试解释这些秘技为什么能生效.\n笔者没有仔细玩过仙剑奇侠传，因此对其中的一些游戏机制不太了解。但是从上述的某些 bug 的现象中（比如第二个）可以推测有一些无符号数在下溢出之后直接变成了 UINT_MAX，从而导致问题。\n在 Navy 中运行 microbench 尝试把microbench编译到Navy并运行, 你应该会发现运行错误, 请尝试分析原因.\n笔者暂时还未实现 Navy 中的 AM，留坑。\n如何在 Navy 上运行 Nanos-lite? 既然能在Navy上运行基于AM的FCEUX, 那么为了炫耀, 在Navy上运行Nanos-lite也并不是不可能的. 思考一下, 如果想在Navy上实现CTE, 我们还需要些什么呢?\n我们需要支持 CTE 的中断机制。在 Nanos-lite 中有一些汇编操控特权寄存器的语句，这些语句直接与硬件交互。但现在 Navy-Nanos-lite 是在 Nanos-lite 上跑的，所以特权寄存器的一套机制需要有一种软的处理方案。\nRTFSC??? 机智的你也许会想: 哇塞, 下学期的oslab0我不就有优秀代码可以参考了吗? 不过我们已经对发布的代码进行了某种特殊的处理. 在沮丧之余, 不妨思考一下, 如果要你来实现这一特殊的处理, 你会如何实现? 这和PA1中的表达式求值有什么相似之处吗?\n观察 oslab0 的代码，我们基本可以确定代码的发布者对代码中的变量名，函数名等进行了替换，将其换成了冗长的不可读字符串。PA1 中用正则表达式匹配字符串的技术在这里可以派上用场。\n终极拷问 自古以来, 计算机系统方向的课程就有一个终极拷问:\n当你在终端键入./hello运行Hello World程序的时候, 计算机究竟做了些什么?\n你已经实现了批处理系统, 并且成功通过NTerm来运行其它程序. 尽管我们的批处理系统经过了诸多简化, 但还是保留了计算机发展史的精髓. 实现了批处理系统之后, 你对上述的终极拷问有什么新的认识?\n一个简单的流程如下：\n键入 ./hello 以后，shell 解析命令之后发现要运行 hello 文件（可执行程序），于是使用 execve 系统调用，将文件名 hello 和相应的参数，环境变量传进去。 陷入内核态之后，操作系统检查 hello 文件是否存在，是否有足够的访问权限等，如果有问题会返回相应的错误号。shell 如果发现 execve 系统调用返回，则会根据错误号报错。 如果一切正常，execve 系统调用不会返回。操作系统会为 hello 程序创建一个初始的上下文结构体，然后调度 hello 作为下一个执行的进程。（在 pa3 中暂时没有进程的概念，会直接使用 naive_uload 来加载 hello 并跳转到 entry 执行）。 hello 程序使用 printf 库函数打印字符串 \u0026ldquo;Hello, world!\\n\u0026rdquo;，printf 库函数的底层会使用 write 系统调用，陷入内核态之后，操作系统使用 write 系统调用相关的服务程序，向 stdout (屏幕) 输出字符。 补充 关于 convert.sh 的报错 直接运行 convert.sh 会报错\nattempt to perform an operation not allowed by the security policy `PDF' STFW后得知，只需将 /etc/ImageMagick-6/policy.xml 中的\n\u0026lt;policy domain=\u0026quot;coder\u0026quot; rights=\u0026quot;none\u0026quot; pattern=\u0026quot;PDF\u0026quot; /\u0026gt; 中的 \u0026quot;none\u0026quot; 改为 \u0026quot;read | write\u0026quot; 即可。\n关于仙剑奇侠传的红蓝颜色 笔者的仙剑奇侠传刚开始启动页面出现的是红色的旗子，游戏中的所有人物都是青色的脸庞。仔细阅读 SDL 部分的源码后发现，SDL 中对于 32 位颜色数据的解读和讲义中写的略有不同：正确的解读方法应该是 aabbggrr，和讲义中的相比正好红色和蓝色颠倒了。\n关于仙剑奇侠传的字幕黑框 笔者的仙剑奇侠传曾经出现所有有字幕的地方（比如人物的对话区域，以及“新的故事”“旧的回忆”的选择区域）全部是黑框的现象。仔细阅读 SDL 手册后发现 SDL_UpdateRect() 函数实现的有一些问题，导致一直在取屏幕左上角的一小块矩形来更新像素，那一部分恰好是黑色的。修正矩形区域的坐标后问题解决。\n仙剑奇侠传与 SDL_FillRect() SDL_FillRect() 的官方文档的描述是将画布中指定矩形区域的颜色都置为 color。其中的参数 color 是一个 32 位数。但仙剑奇侠传中是使用调色盘来表示颜色的，pixels 里存放的是颜色在调色盘中的索引，应该怎么将这个 color 赋过去呢？\n笔者起初以为仙剑中调用该函数时传入的 color 应该是 32 位的 aaggbbrr 格式的颜色，因此将调色盘中的所有颜色取出和 color 一一比对，但发现 color 并不一定在调色盘中。笔者尝试使用曼哈顿距离最小的颜色来代替 color，但效果很差。笔者又尝试了从调色盘中随机挑一个颜色，将 color 替换进去。这样虽然可以达到正确的效果，但存在一定的隐患。\n笔者在阅读了 pal 的源码之后，发现其中调用 SDL_FillRect() 的时候传递的 color 参数都是 8 位二进制数，明白其实传进去的就是颜色的调色盘索引，所以直接赋值即可。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e479e780bba6cd9c03779466bf928b59","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-ics/pa/pa3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-ics/pa/pa3/","section":"notes","summary":"实验进度 我完成了所有的必答题，并针对选做题和思考题给出了自己的想法。\n必答题 理解上下文结构体的前世今生 点击 这里跳转到解答。\n理解穿越时空的旅程 点击 这里跳转到解答。\nhello程序是什么, 它从何而来, 要到哪里去 点击 这里跳转到解答\n仙剑奇侠传究竟如何运行 运行仙剑奇侠传时会播放启动动画, 动画里仙鹤在群山中飞过. 这一动画是通过navy-apps/apps/pal/repo/src/main.c中的PAL_SplashScreen()函数播放的. 阅读这一函数, 可以得知仙鹤的像素信息存放在数据文件mgo.mkf中. 请回答以下问题: 库函数, libos, Nanos-lite, AM, NEMU是如何相互协助, 来帮助仙剑奇侠传的代码从mgo.mkf文件中读出仙鹤的像素信息, 并且更新到屏幕上? 换一种PA的经典问法: 这个过程究竟经历了些什么? (Hint: 合理使用各种trace工具, 可以帮助你更容易地理解仙剑奇侠传的行为)","tags":null,"title":"PA3 - 穿越时空的旅程: 批处理系统","type":"docs"},{"authors":null,"categories":null,"content":"实验进度 我完成了所有的必答题，并针对选做题和思考题给出了自己的想法。\n必答题 分时多任务的具体过程 请结合代码, 解释分页机制和硬件中断是如何支撑仙剑奇侠传和hello程序在我们的计算机系统(Nanos-lite, AM, NEMU)中分时运行的.\n这里主要叙述从 hello 用户程序切换到 pal 的过程。在抢占式多任务系统中，hello 相当于一个“恶意用户程序”，因为它不会主动使用 yield() 来让操作系统切换程序。但实现了时钟中断之后我们可以强制 hello 的挂起。\n每一条指令执行结束时，nemu 的 cpu_exec() 中都会调用 timer_interrupt() 函数来检查 CPU 的 INTR 引脚有没有被拉高。如果被拉高了说明有设备发出了中断请求（在 PA 中只有时钟中断请求），此时 CPU 会将 mstatus 寄存器的 MIE 位置零（防止中断嵌套），然后进入 nanos-lite 的中断/异常处理程序 trap.S。\n在 trap.S 中，nanos-lite 首先会将 sp 指针切换到 hello 用户进程的内核栈，在内核栈上保存 hello 进程的上下文，将 mscratch 和 c-\u0026gt;np 等信息设置好之后，进入 __am_irq_handle() 函数。\n在 __am_irq_handle() 函数中，nanos-lite 发现 mcause 寄存器中的事件编号是 0x80000007，于是标记该事件为时钟中断，调用 do_event() 函数。do_event() 函数中调用了 shedule() 函数，schedule() 函数将 current-\u0026gt;cp 指向刚才保存在 hello 内核栈上的 hello 上下文，将 current 指针指向 pal 进程的 pcb，并返回 pal 进程内核栈上的上下文结构体（该结构体可能是 context_uload() 时创建的初始结构体，也可能是前一次进程切换时保存的结构体）。__am_irq_handle() 函数最终会返回 pal 进程的上下文结构体。\n回到 trap.S 中以后，nanos-lite 会恢复 pal 进程的上下文，并且根据 c-\u0026gt;np 将栈指针从 pal 进程的内核栈移到 pal 进程的用户栈。执行完 mret 指令之后，nanos-lite 就切换到了 pal 的代码继续执行（mret 指令会将 mstatus 的 MIE 位重新打开，以接收中断）。\n理解计算机系统 尝试在Linux中编写并运行以下程序:\nint main() { char *p = \u0026quot;abc\u0026quot;; p[0] = 'A'; return 0; } 你会看到程序因为往只读字符串进行写入而触发了段错误. 请你根据学习的知识和工具, 从程序, 编译器, 链接器, 运行时环境, 操作系统和硬件等视角分析\u0026quot;字符串的写保护机制是如何实现的\u0026quot;. 换句话说, 上述程序在执行p[0] = 'A'的时候, 计算机系统究竟发生了什么而引发段错误? 计算机系统又是如何保证段错误会发生? 如何使用合适的工具来证明你的想法?\n字符串 \u0026ldquo;abc\u0026rdquo; 在编译的时候会被放入 ELF 文件的只读数据段，并在链接运行的时候位于只读代码段。高级语言中的 p[0] = 'A' 实际上是一次访存写入操作，对应的汇编代码为\n0000000000000000 \u0026lt;main\u0026gt;: 0: f3 0f 1e fa endbr64 4: 55 push %rbp 5: 48 89 e5 mov %rsp,%rbp 8: 48 8d 05 00 00 00 00 lea 0x0(%rip),%rax # f \u0026lt;main+0xf\u0026gt; f: 48 89 45 f8 mov %rax,-0x8(%rbp) 13: 48 8b 45 f8 mov -0x8(%rbp),%rax 17: c6 00 41 movb $0x41,(%rax) # p[0] = 'A' 1a: b8 00 00 00 00 mov $0x0,%eax 1f: 5d pop %rbp 20: c3 ret 执行到 \u0026lt;main+0x17\u0026gt; 这条指令时，硬件中的 MMU 会检查当前进程的权限是否可以访问这一内存区域。由于 \u0026ldquo;abc\u0026rdquo; 是只读数据，所以发生了越权行为。访问非法地址后 MMU 会修改一些特权寄存器的值记录信息，然后转到操作系统的异常处理程序。操作系统会向用户进程发送一个 SIGSEGV 信号，表示发生了段错误。用户进程收到 SIGSEGV 信号后的默认动作是终止程序运行，但它会生成一个核心文件以帮助调试，也就是所谓的 (core dumped 核心已转储)。\n我们可以在用户程序中注册一个信号处理函数来捕捉 SIGSEGV 信号，代码如下：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; void signal_handler(int signum) { if (signum == 11) printf(\u0026quot;Signal SIGSEGV captured\\n\u0026quot;); exit(0); } int main() { signal(SIGSEGV, signal_handler); char *p = \u0026quot;abc\u0026quot;; p[0] = 'A'; return 0; } 编译、运行该程序后不会报段错误，而会打印 Signal SIGSEGV captured 之后正常退出。这可以证明用户进程确实接收到了 SIGSEGV 信号。\n我们也可以通过 gdb 来检测 SIGSEGV 信号：在 gdb 中使用 layout asm 打开汇编代码，一条一条执行，在执行到 movb 语句时会显示 SIGSEGV 信号。\n为了看到操作系统执行该程序时经历的过程，我们可以用 strace 工具来查看执行 ./a.out 时使用的所有系统调用。（注意：strace 工具默认将信息输出到标准错误流，所以如果想用 less 工具来查看的话，需要先将输出重定向到标准输出流，使用命令 strace ./a.out 2\u0026gt;\u0026amp;1 | less。）\nexecve(\u0026quot;./a.out\u0026quot;, [\u0026quot;./a.out\u0026quot;], 0x7ffec38443f0 /* 67 vars */) = 0 brk(NULL) = 0x555ca9bfc000 arch_prctl(0x3001 /* ARCH_??? */, 0x7ffd43e30600) = -1 EINVAL (Invalid argument) access(\u0026quot;/etc/ld.so.preload\u0026quot;, R_OK) = -1 ENOENT (No such file or directory) openat(AT_FDCWD, \u0026quot;/etc/ld.so.cache\u0026quot;, O_RDONLY|O_CLOEXEC) = 3 newfstatat(3, \u0026quot;\u0026quot;, {st_mode=S_IFREG|0644, st_size=76978, ...}, AT_EMPTY_PATH) = 0 mmap(NULL, 76978, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fe701222000 close(3) = 0 openat(AT_FDCWD, \u0026quot;/lib/x86_64-linux-gnu/libc.so.6\u0026quot;, O_RDONLY|O_CLOEXEC) = 3 read(3, \u0026quot;\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u0026gt;\\0\\1\\0\\0\\0\\240\\206\\2\\0\\0\\0\\0\\0\u0026quot;..., 832) = 832 pread64(3, \u0026quot;\\6\\0\\0\\0\\4\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\u0026quot;..., 784, 64) = 784 pread64(3, \u0026quot;\\4\\0\\0\\0 \\0\\0\\0\\5\\0\\0\\0GNU\\0\\2\\0\\0\\300\\4\\0\\0\\0\\3\\0\\0\\0\\0\\0\\0\\0\u0026quot;..., 48, 848) = 48 pread64(3, \u0026quot;\\4\\0\\0\\0\\24\\0\\0\\0\\3\\0\\0\\0GNU\\0+H)\\227\\201T\\214\\233\\304R\\352\\306\\3379\\220%\u0026quot;..., 68, 896) = 68 newfstatat(3, \u0026quot;\u0026quot;, {st_mode=S_IFREG|0755, st_size=1983576, ...}, AT_EMPTY_PATH) = 0 mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fe701220000 pread64(3, \u0026quot;\\6\\0\\0\\0\\4\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\u0026quot;..., 784, 64) = 784 mmap(NULL, 2012056, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fe701034000 mmap(0x7fe70105a000, 1486848, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x26000) = 0x7fe70105a000 mmap(0x7fe7011c5000, 311296, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x191000) = 0x7fe7011c5000 mmap(0x7fe701211000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1dc000) = 0x7fe701211000 mmap(0x7fe701217000, 33688, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fe701217000 close(3) = 0 mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fe701032000 arch_prctl(ARCH_SET_FS, 0x7fe701221580) = 0 mprotect(0x7fe701211000, 12288, PROT_READ) = 0 mprotect(0x555ca947c000, 4096, PROT_READ) = 0 mprotect(0x7fe701267000, 8192, PROT_READ) = 0 munmap(0x7fe701222000, 76978) = 0 rt_sigaction(SIGHUP, {sa_handler=0x555ca947a189, sa_mask=[HUP], sa_flags=SA_RESTORER|SA_RESTART, sa_restorer=0x7fe701075040}, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, 8) = 0 --- SIGSEGV {si_signo=SIGSEGV, si_code=SEGV_ACCERR, si_addr=0x555ca947b01c} --- +++ killed by SIGSEGV (core dumped) +++ Segmentation fault (core dumped) 虽然笔者不能看懂所有的系统调用，但大概可以看到一些比较核心的步骤，比如使用 execve 系统调用转到 a.out 程序执行，中间的 mmap 系统调用试图访问了一些有着 MAP_DENYWRITE 属性的东西。最后发出了 SIGSEGV 信号，并给出了触发该信号的指令地址。\n以下是我的自由报告内容，我在做实验的过程中详细记录了自己遇到的所有问题和查阅的所有资料。这些笔记按照章节排列，每章通常有两个部分\n思考题：包含笔者针对思考题查阅的资料和我尝试给出的答案。 补充：这里的内容是没有在讲义中提及的问题，以及讲义中建议自学的东西。 多道程序 思考题 为什么需要使用不同的栈空间? 如果不同的进程共享同一个栈空间, 会发生什么呢?\n比如不同的进程可以互相修改别人的栈的内容，这样原先的进程就可能崩溃。\nmips32 和 riscv32 的调用约定 我们没有给出mips32和riscv32的调用约定, 你需要查阅相应的ABI手册. 当然, 你也可以自己动手实践来总结传参的规则.\n笔者选择的架构是 riscv32，所以在此简单地列举 riscv32 的调用约定：riscv32 使用寄存器来传递参数和返回值。a0 a1 a2 等寄存器分别存储了第一，第二，第三个参数，以此类推；a0 寄存器存储了返回值。\n一山不能藏二虎? 尝试把hello_fun()换成Navy中的hello:\n-context_kload(\u0026amp;pcb[0], (void *)hello_fun, NULL); +context_uload(\u0026amp;pcb[0], \u0026quot;/bin/hello\u0026quot;); context_uload(\u0026amp;pcb[1], \u0026quot;/bin/pal\u0026quot;); 你发现了什么问题? 为什么会这样? 思考一下, 答案会在下一阶段揭晓!\n程序触发了段错误。两个用户程序使用的是相同的用户栈，代码也会加载到同样的位置，它们会相互覆盖，从而导致错误。\n为什么少了一个const? 在main()函数中, argv和envp的类型是char * [], 而在execve()函数中, 它们的类型则是char *const []. 从这一差异来看, main()函数中argv和envp所指向的字符串是可写的, 你知道为什么会这样吗?\n根据 C99 手册中的规定：\nProgram Startup The parameters argc and argv and the strings pointed to by the argv array shall be modifiable by the program, and retain their last-stored values between program startup and program termination.\nSTFW 得出的结论是，这是一个历史遗留问题。早期的 C 语言没有 const，后来 C++ 为了兼容之前的 C 程序，也没有加上这个 const。有一些程序正是利用 argv[] 的可修改性进行工作的，例如：\n// print out all the arguments: while (--argc) std::cout \u0026lt;\u0026lt; *++argv \u0026lt;\u0026lt; std::endl; 此外，一些 UNIX API，比如 getopt，确实会修改 argv[] 的内容。但 argv[] 作为一个栈上的局部变量，在定义的时候加上 const 也是无伤大雅的。（stackoverflow 上的 这个回答比较详细）\n补充 调试心得 字符串的复制最好使用 strcpy 函数，它会帮你将字符串末尾的 \\0 也一并复制过去。如果想要使用 memcpy 来复制的话，长度一定要设置成 strlen(src)+1 ，否则会漏复制末尾的 \\0 从而导致奇怪的后果。\n关于用户程序参数的错误 笔者在实现了 nterm 的内建 shell 的参数传送功能之后，在使用命令 pal --skip 来跳过仙剑奇侠传的动画时发现无效。简单排查之后发现存储参数字符串的内存在一个奇特的时刻被改写了。仔细排查之后发现，这些参数字符串是被仙剑奇侠传用户程序改写的——这其中有一些机缘巧合：笔者在 nterm 中定义了一个数组来存放参数字符串，因此参数字符串的内容作为客户程序的一部分，在 nterm 运行时会被加载到 0x83000000 附近。笔者刚开始实现的 loader 函数在切换用户程序时，会先加载新的用户程序，再在用户栈中安放用户程序的参数，这导致 pal 程序在加载到 0x83000000 附近时直接覆盖了 nterm 中还没来得及拿出来的参数字符串。因此将这两个步骤换个顺序——先把参数字符串放到用户栈里，再加载程序即可。\n这个问题的发生归根结底在于不同的用户程序使用了同一段物理内存来进行工作。在实现了虚拟内存之后应该就不会有这个问题。\n关于添加 busybox 之后的错误 笔者在添加了busybox 用户程序之后，nanos-lite 直接崩溃。检查堆区的范围后发现，heap.start 此时已经到了 0x83000000 之后，因此加载用户程序时用户程序的代码会直接覆盖用户栈的内容。\n这说明 ramdisk.img 的大小的上限并不是 48MB，而是更小的一个阈值。因为 heap.start 考虑到一些对齐原因并不是紧贴着 ramdisk_end 设置的。\n笔者在 nslider 用户程序中删掉了几张图片，将 ramdisk.img 的大小降到 37MB 之后，恢复正常。\n虚实交错的魔法 思考题 [二周目] 实现基于PIE的loader 天下并没有免费的午餐, PIE之所以能做到位置无关, 其实是要依赖于程序中一个叫GOT(global offset table, 全局偏移量表)的数据结构. 要正确运行PIE, 加载器需要在加载程序的时候往GOT中填写正确的内容.\n有兴趣的同学可以让Nanos-lite的loader支持PIE, 当然这需要了解一些ELF相关的细节, 具体细节可以参考ABI手册.\n留坑，二周目再做。\n笔者虽然还没有实现基于 PIE 的 loader，但学习了一下动态加载的基本原理。以下面的程序为例：\nextern int foo; int func(void) { return foo; } 在 amd64 架构下，访问变量 foo 的核心语句是\nmov 0x200271(%rip), %rax # 200828 200828 处是 GOT 的一个表项：\nOffset Info Type Sym. Value Sym. Name + Addend [...] 000000200828 000400000006 R_X86_64_GLOB_DAT 0000000000000000 foo + 0 动态加载器在加载动态链接库时，会往 GOT 中填写相关的表项。\n在 i386 架构中没有类似 %rip 这样的寄存器，无法直接得知当前指令的位置，因此通常会使用类似于下面这样的略带 tricky 的代码：\n0000040c \u0026lt;function\u0026gt;: 40c: 55 push %ebp 40d: 89 e5 mov %esp,%ebp 40f: e8 0e 00 00 00 call 422 \u0026lt;__i686.get_pc_thunk.cx\u0026gt; 414: 81 c1 5c 11 00 00 add $0x115c,%ecx 41a: 8b 81 18 00 00 00 mov 0x18(%ecx),%eax 420: 5d pop %ebp 421: c3 ret 00000422 \u0026lt;__i686.get_pc_thunk.cx\u0026gt;: 422: 8b 0c 24 mov (%esp),%ecx 425: c3 ret 在 40f 处调用了一个函数 __i686.get_pc_thunk.cx\u0026gt;，这个函数将 call 的返回地址（也就是 414）保存到了 %ecx 寄存器中，从而变向实现了 get_pc 的功能。\n超越容量的界限 思考题 虚存管理中PIC的好处 我们之前提到, PIC的其中一个好处是可以将代码加载到任意内存位置执行. 如果配合虚存管理, PIC还有什么新的好处呢? (Hint: 动态库已经在享受这些好处了)\nPIC 的好处在于，我们不需要将 PIC 反复装进内存。比如第一个进程将动态库放进了内存，那么第二个进程如果也要用动态库，它只要找一下内存里有没有动态库的页面，如果有就将自己的页表中关于动态库的那项直接指向已有的动态库页面即可。\n理解分页细节 i386不是一个32位的处理器吗, 为什么表项中的基地址信息只有20位, 而不是32位? 手册上提到表项(包括CR3)中的基地址都是物理地址, 物理地址是必须的吗? 能否使用虚拟地址? 为什么不采用一级页表? 或者说采用一级页表会有什么缺点? 每个页的大小是 4KB，所以地址的低 12 位用来表示页内偏移，高 20 位用来指示页号。 物理地址是必须的，如果所有的东西都是虚拟地址，那我们就无法找到解析虚拟地址所需的信息。 采用一级页表的缺点在于：通常来说页表中的有效项是非常稀疏的。如果采用一级的线性页表，我们不得不将所有的页表内容放进内存，占用相当大的一块内存空间，但其实里面有大量的 0。如果采用二级页表，我们只需要将页目录的一个页和有内容的那些子页放进内存，这样就节省了内存空间。 空指针真的是\u0026quot;空\u0026quot;的吗? 程序设计课上老师告诉你, 当一个指针变量的值等于NULL时, 代表空, 不指向任何东西. 仔细想想, 真的是这样吗? 当程序对空指针解引用的时候, 计算机内部具体都做了些什么? 你对空指针的本质有什么新的认识?\n严格来说空指针并不是不指向任何东西，而是它指向一个不可以被访问的东西，如果试图对空指针解引用，会因为越权行为触发异常。\nmips32的TLB管理是否更简单? 有一种观点认为, mips32的分页机制更简单. 你认同吗? 尝试分别在现在, 以及完成这部分内容之后回答这个问题.\nmips32 将 TLB 管理完全交给软件，这使得在 PA 中我们不能省略 TLB 的实现，也必须要处理进程切换时产生的一系列一致性问题，在 PA 中完成 mips32 的分页机制更加麻烦。但实际中，硬件上维护 TLB 比软件上维护 TLB 要复杂，需要更多的门电路支持。mips32 的 TLB 管理将硬件的活交给软件，可以使硬件设计更为简单。\n内核映射的作用 对于x86和riscv32, 在protect()中创建地址空间的时候, 有一处代码用于拷贝内核映射:\n// map kernel space memcpy(updir, kas.ptr, PGSIZE); 尝试注释这处代码, 重新编译并运行, 你会看到发生了错误. 请解释为什么会发生这个错误.\n我们在从用户进程切换到内核线程的时候并没有切换 satp，因为对于任何一个用户进程来说，内核段都是恒等映射。但这就要求用户进程的页表里必须包含内核映射，不然内核区域的代码无法正确执行。\nNative 的 VME 实现 尝试阅读native的VME实现, 你发现native是如何实现VME的? 为什么可以这样做?\n留坑。\n可以在用户栈里面创建用户进程上下文吗? ucontext()的行为是在内核栈kstack中创建用户进程上下文. 我们是否可以对ucontext()的行为进行修改, 让它在用户栈上创建用户进程上下文? 为什么?\n目前来说是可以的，事实上除了创建的时候上下文在内核栈上，其他时候上下文都在用户栈上。但在用户栈上创建和保存上下文会遇到下面一道思考题涉及的问题。\n并发执行多个用户进程 让Nanos-lite加载仙剑奇侠传和hello这两个用户进程; 或者是加载NTerm和hello内核线程, 然后从NTerm启动仙剑奇侠传, 你应该会在运行的时候观察到错误. 尝试分析这一错误的原因, 并总结为了支持这一功能, 我们需要满足什么样的条件.\n这可以说是一周目最难的一道思考题了, 虽然我们会在PA4的最后给出分析, 喜欢挑战的同学仍然可以在这里尝试独立思考: 如果你能独立解决这个问题, 说明你对计算机系统的理解可以说是相当了得了.\n以前者为例，当我们想要从 pal 进程切换到 hello 进程的时候，我们首先会把 pal 进程的上下文保存在 pal 的用户栈上，然后陷入内核执行中断服务程序，注意我们在中断服务程序中进行的函数调用，局部变量定义等事情也一直是在 pal 的用户栈上做的。schedule() 将下一个进程切换到 hello，做完 __am_switch() 后，页表已经是 hello 进程的页表，和 pal 相关的所有虚存映射都不在该页表中。因此目前我们无法访问到保存在 pal 用户栈上的那些和中断服务程序相关的栈帧信息（比如返回地址），所以会发生段错误。\n补充 关于 mm_brk() 笔者在这里卡了相当长的时间，因为不太能理解讲义的内容。经过思考后大致明白了这个堆区的意思。用户程序申请的新 program-break 都是虚拟内存下的 pb。pcb 结构体中的 max_brk 存的也是虚拟内存下的 pb。如果当前申请的 pb 值超过了 max_brk，就申请一些新的物理内存页，将 [max_brk,pb) 中的内容映射到物理内存页中。想要获得当前进程的 max_brk，只要通过 current 指针访问当前进程的 pcb 即可。\n来自外部的声音 思考题 灾难性的后果(这个问题有点难度) 假设硬件把中断信息固定保存在某个内存地址(例如0x1000)的位置, AM也总是从这里开始构造上下文. 如果发生了中断嵌套, 将会发生什么样的灾难性后果? 这一灾难性的后果将会以什么样的形式表现出来? 如果你觉得毫无头绪, 你可以用纸笔模拟中断处理的过程.\n留坑。\n如何支持中断嵌套 思考一下, x86, mips32和riscv32的软硬件该分别如何协同, 来支持中断嵌套?\n留坑。\n中断和用户进程初始化 我们知道, 用户进程从Navy的_start开始运行, 并且在_start中设置正确的栈指针. 如果在用户进程设置正确的栈指针之前就到来了中断, 我们的系统还能够正确地进行中断处理吗?\n在实现内核栈切换之前，这会导致一些问题。因为 sp 还没指向正确的位置，无法在用户栈上保存上下文。但实现了内核栈切换之后不会有问题。因为我们总是可以将 sp 切换到进程的内核栈上保存上下文，中断处理结束之后再回到用户程序，继续设置正确的用户栈指针。\n用户态和栈指针 一般来说, 处理器的特权级也是一种状态. 我们是否可以通过栈指针的值来判断当前位于用户态还是内核态?\n通常来说是可以的，在 nanos-lite 中，我们可以检查 sp 指针是否位于用户栈（即小于 0x80000000）来判断进入 trap.S 时处于用户态还是内核态。但如果遇到上述思考题提到的那种“在设置好栈指针之前进入了中断”的情况，则不可以（因为在设置好栈指针前 sp 一定处于内核区，这会导致误判）。因此在上下文结构体中保存一个 np 状态是比较好的选择。\n系统的复杂性(3) 我们把CTE重入问题作为状态机视角的一个练习, 请你来尝试分析上述代码在CTE重入的情况下存在什么问题.\n上述代码在进入 __am_irq_handle(c) 的时候还没有对 pp 进行设置，比方将从用户态通过系统调用陷入内核态，此时 pp == USER，然后如果在系统调用中途发生了 CTE 重入，进入 __am_asm_trap 的时候，pp 仍然是 USER，会出错。\n为了预防 CTE 重入导致的上述问题，我们要提前设置好 pp。因为 CTE 重入一定是从 CTE 进入 CTE，而 CTE 一定在内核态，所以直接将 pp 设为 KERNEL 即可。\n临时寄存器的方案 同样是作为CTE的临时寄存器, mips32选择在GPR中分配出k0和k1, 而riscv32则是采用mscratch这个CSR寄存器. 这两种方案相比, 是否存在哪一种方案更优? 为什么?\n笔者认为没有明显的优劣。一个执行单一功能的通用寄存器和CSR没有太本质的区别。\n[二周目] Nanos-lite 与并发 bug 上文讨论并发的时候提到: 更一般地, 用户进程都会并发地执行系统调用, 操作系统还需要保证它们都能按照系统调用的语义正确地执行.\n我们在PA3中知道printf()会通过malloc()申请缓冲区, 而malloc()又可能会执行_sbrk(), 通过SYS_brk陷入内核; 在上一个阶段中, 我们实现了支持分页机制的mm_brk(), 在必要的时候它会通过new_page()申请一页. 而仙剑和hello用户进程都会调用printf(), 使得它们可能会并发执行SYS_brk. 思考一下, 目前Nanos-lite的设计会导致并发bug吗? 为什么?\n留坑。\n补充 关于时钟中断的软件+4 时钟中断和 yield 的处理过程几乎完全相同。但需要注意的是，yield 中 mepc 保存的是当前指令 (ecall) 的 pc，而时钟中断由于放在 CPU 循环的 updatepc 之后，所以 mepc 保存的是下一条指令的 pc。因此时钟中断在操作系统层面不需要+4。\n关于时钟中断的上下文正确创建方式 笔者最初在创建上下文的时候，将 mstatus 的 MIE 位和 PMIE 位都设置成 1，但这导致了段错误。经过排查发现，nanos-lite 在执行 trap.S 中的指令时响应了中断，导致上下文信息恢复了一半时发生了中断嵌套。\n正确的上下文创建方式应该是将 PMIE 置为1，MIE 置为 0。任何一个用户进程第一次被调度到的时候，一定是从 trap.S 的后半段开始的，没有给你关中断的机会。因此这时 MIE 一定要置为 0，否则一旦恢复 mstatus 就会发生中断嵌套。PMIE 置为 1 是为了保证在执行 mret 之后 MIE 可以接收 PMIE 的值变为 1，从而后续可以正常地响应中断。\n关于从 nterm 中执行其他程序时出错 笔者在实现了 execve 调用之后尝试从 nterm 中用命令 pal --skip 加载仙剑奇侠传并跳过片头动画，但触发了段错误。有效的 debug 路径如下：\n发现pc是在内核区跑飞的 --\u0026gt; 在指令序列中寻找pc对应的指令，发现位于context_uload里面 --\u0026gt; 使用在各个位置插入assert(0)的方法来定位出错的具体语句，发现在完成protect()，切换到新进程的用户栈上，准备将参数搬上用户栈时发生段错误 nterm 的参数解析写在内建 shell 中，笔者在实现内建 shell 时将参数搬到了 buildin-shell.c 文件中定义的数组里。这些数组在编译是位于 nterm 进程的数据段。在 context_uload() 中完成 protect() 后，satp 切换到了新进程的页表。新进程的页表中没有 nterm 用户栈的映射信息，因此保存在 nterm 数据段的参数是取不到的。强行取就会触发段错误。但是我们必须在页表切换到新进程之后才能开始保存参数，这似乎是一个两难的问题。\n笔者采取的解决方案是，进入 context_uload() 之后，先把所有的参数复制到内核代码创建的数组中，这些数组位于内核的数据段，是所有进程都可以访问的。这样切换到新进程的页表之后，再将已经保存在内核数据段的参数拷贝到新进程的用户栈上，就不会出问题了。\n关于反复加载 bird 用户程序时出错 笔者给 bird 程序绑定了 esc 键用于退出，但笔者发现如果退出时再次加载 bird 程序会触发段错误，有效的 debug 路径如下：\n发现pc是在用户区跑飞的 --\u0026gt; 使用strace打印执行过的所有系统调用 --\u0026gt; 发现最近一次使用的系统调用是sys_brk --\u0026gt; 检查sys_brk代码，思考第二次加载与第一次加载的不同 笔者发现关键点在于 max_brk 的维护上。loader 中将各个段加载到虚拟内存中，并根据加载的位置更新 max_brk。因此加载结束时 max_brk 总是能指向数据段之后第一个未被分配的地址。\nfor (int i = 0; i \u0026lt; ehdr-\u0026gt;e_phnum; i ++) if (phdr[i].p_type == PT_LOAD) { fs_lseek(fd, phdr[i].p_offset, SEEK_SET); fs_read(fd, data, phdr[i].p_filesz); uintptr_t _ed = memory_loader(\u0026amp;pcb-\u0026gt;as, phdr[i].p_vaddr, phdr[i].p_filesz, phdr[i].p_memsz); if (_ed \u0026gt; pcb-\u0026gt;max_brk) pcb-\u0026gt;max_brk = _ed; } 用当前 pcb 重新加载另一个用户进程时，一定要将 max_brk 清零，否则如果下一个进程的实际的 max_brk 小于前一个进程结束时的 brk，就会出现一段没有在页表中映射到的“真空地带”，在进程使用堆区的时候就会出发段错误。\n关于实现内核栈切换之后时钟中断无法与 yield() 并存 笔者在实现内核栈切换之后发现如果既有 yield() 又有时钟中断会出现段错误。有效的 debug 路径如下：\n发现pc是在内核区跑飞的 --\u0026gt; 使用itrace打印跑飞之前执行过的若干条指令 --\u0026gt; 发现在trap.S的代码执行了一半的时候又触发了时钟中断，出现了中断嵌套 经过对 trap.S 中代码的检查，发现了如下问题：\nSTORE t0, OFFSET_CAUSE(sp) STORE t1, OFFSET_STATUS(sp) STORE t2, OFFSET_EPC(sp) STORE t3, OFFSET_SP(sp) addi t0, sp, CONTEXT_SIZE csrr t1, mscratch xor t0, t0, t1 bnez t0, user_np addi t2, x0, KERNEL STORE t2, OFFSET_NP(sp) j continue user_np: addi t2, x0, USER STORE t2, OFFSET_NP(sp) # c-\u0026gt;np continue: # set mstatus.MPRV to pass difftest li a0, (1 \u0026lt;\u0026lt; 17) or t1, t1, a0 csrw mstatus, t1 最后一段有三条用于 pass difftest 的指令，这里的指令默认 t1 中仍然存储的是 STORE t1, OFFSET_STATUS(sp) 中的 mstatus 的值（在原本的 trap.S 的代码中它们是连在一起的）。但笔者现在在中间加入了一些判断状态的汇编语句，破坏了 t1 寄存器的值，当 t1 的值的 MIE 位正好是 1 的时候，执行完最后的 csrw mstatus, t1 就会神不知鬼不觉地打开中断，从而导致中断嵌套。\n修复的方法很简单：只要将 pass difftest 的三条语句移动到 STORE 的下面即可。\n关于实现内核栈切换之后无法通过 OJ 笔者在实现了内核栈切换之后发现无法通过 OJ 的 easy test。这是笔者调过的最痛苦的 \u0026ldquo;bug\u0026rdquo;，因为本地没有任何的错误，无法找到任何不对劲的地方，只能虚空调 bug。后来笔者通过在各个函数中加入 assert(0) 的方法来测试 OJ 到底是如何评测的，惊奇地发现 OJ 使用了 kcontext() 但没有使用 context_kload() ，即 OJ 只是创建了一个内核线程上下文，但没有使用进一步封装的 context_kload() 将其保存在某个具体的 pcb 的内核栈上。\n笔者默认创建上下文会调用更高层的 context_kload() ，不会绕过它直接调用底层的 kcontext() ，因此在实现时并没有在 kcontext() 中完成所有的上下文信息的设置，c-\u0026gt;sp 的设置被放在了 context_kload() 里面。因此单纯调用 kcontext() 获得的上下文结构体缺少了 c-\u0026gt;sp，栈切换时 sp 寄存器自然会跑飞。将这一初始化挪到 kcontext() 里面完成后即可通过 OJ。\n这一教训告诉我们必须仔细阅读讲义的 API 定义。讲义中关于 kcontext() API 的定义是：\n“其中kstack是栈的范围, entry是内核线程的入口, arg则是内核线程的参数. 你需要在kstack的底部创建一个以entry为返回地址的上下文结构(目前你可以先忽略arg参数), 然后返回这一结构的指针.”\n因此确实应在在 kcontext() 内完成所有创建工作。\n编写不朽的传奇 思考题 笔者尚未完成该章节的选做内容，故此部分的思考题暂时留坑。\n补充 关于使用 F1 F2 F3 切换时画面互相覆盖 由于没有用于调度窗口的进程，在进程切换的时候画面会互相覆盖，非常难看。笔者采用的暂时性的解决方案是在进程切换的时候强行刷新一次 VGA，将所有像素填成黑色。这个方案对于 bird，nterm 等整个屏幕都在不断更新的应用比较友好，但对于 pal，nslider 等没有变化的区域屏幕不会更新的应用不太友好——屏幕上没有更新的部分会一直是黑的，除非对应用进行操作使其刷新屏幕。笔者认为如果将整个屏幕的像素信息加入上下文，在恢复上下文的时候将整个画面恢复会有比较好的效果。但这样上下文结构体会极其臃肿。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"40d0202dbdc2113a3ba2cdc030ec7727","permalink":"https://kristoff-starling.github.io/notes/coursenotes/nju-ics/pa/pa4/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/notes/coursenotes/nju-ics/pa/pa4/","section":"notes","summary":"实验进度 我完成了所有的必答题，并针对选做题和思考题给出了自己的想法。\n必答题 分时多任务的具体过程 请结合代码, 解释分页机制和硬件中断是如何支撑仙剑奇侠传和hello程序在我们的计算机系统(Nanos-lite, AM, NEMU)中分时运行的.\n这里主要叙述从 hello 用户程序切换到 pal 的过程。在抢占式多任务系统中，hello 相当于一个“恶意用户程序”，因为它不会主动使用 yield() 来让操作系统切换程序。但实现了时钟中断之后我们可以强制 hello 的挂起。\n每一条指令执行结束时，nemu 的 cpu_exec() 中都会调用 timer_interrupt() 函数来检查 CPU 的 INTR 引脚有没有被拉高。如果被拉高了说明有设备发出了中断请求（在 PA 中只有时钟中断请求），此时 CPU 会将 mstatus 寄存器的 MIE 位置零（防止中断嵌套），然后进入 nanos-lite 的中断/异常处理程序 trap.","tags":null,"title":"PA4 - 虚实交错的魔法: 分时多任务","type":"docs"},{"authors":null,"categories":null,"content":"高中的时候，每天老师会给你布置一堆试卷，你什么也不用管只需要跟着老师的节奏走；但大学里，你很可能在课下根本找不到老师的踪影，大学课程的作业量通常不大，每天会有大量的空余时间不知道该做什么……因此进入大学后，大家一定要扭转自己的学习模式，做一个 self-motivated 的人。你应当学会为自己规划：应该看一些什么样的书，应当上一些什么样的网课，如果打算出国我是不是应当着手准备英语测试……学会 self-learning，你才能在大学中存活下来。\n上面的话是各个学科通用的，着眼于计算机这个学科，self-learning 有其独特的方法。计算机学科的一大特点在于技术更新极快——你学习的某项技术很可能是去年刚刚产生的，很多工具的使用也不会在教科书中写出。因此不同于学习数学物理时四处寻找好的教材，学习计算机一定要学会利用好强大的互联网。学习工具时，多找一找官方的文档 (Almost all official manuals are written in English, which again demonstrates the significance of proficiency in English.)，遇到疑难杂症时，多看一看有没有类似的问题解答可以参照……当你遇到问题第一反应是自己动手寻求解决方案而不是打开和“大腿”的QQ聊天框求救时，你便已经进步了很多。\n下面的话来自大家未来操作系统课程的老师：\nSearch the friendly(f**king) web.\nRead the friendly(f**king) manual.\n其中的 F 让它们更具传奇色彩。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5701697cbff4a99cfb7f3e162370110e","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/cser0/self-learning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/cser0/self-learning/","section":"courses","summary":"高中的时候，每天老师会给你布置一堆试卷，你什么也不用管只需要跟着老师的节奏走；但大学里，你很可能在课下根本找不到老师的踪影，大学课程的作业量通常不大，每天会有大量的空余时间不知道该做什么……因此进入大学后，大家一定要扭转自己的学习模式，做一个 self-motivated 的人。你应当学会为自己规划：应该看一些什么样的书，应当上一些什么样的网课，如果打算出国我是不是应当着手准备英语测试……学会 self-learning，你才能在大学中存活下来。\n上面的话是各个学科通用的，着眼于计算机这个学科，self-learning 有其独特的方法。计算机学科的一大特点在于技术更新极快——你学习的某项技术很可能是去年刚刚产生的，很多工具的使用也不会在教科书中写出。因此不同于学习数学物理时四处寻找好的教材，学习计算机一定要学会利用好强大的互联网。学习工具时，多找一找官方的文档 (Almost all official manuals are written in English, which again demonstrates the significance of proficiency in English.)，遇到疑难杂症时，多看一看有没有类似的问题解答可以参照……当你遇到问题第一反应是自己动手寻求解决方案而不是打开和“大腿”的QQ聊天框求救时，你便已经进步了很多。\n下面的话来自大家未来操作系统课程的老师：\nSearch the friendly(f**king) web.\nRead the friendly(f**king) manual.","tags":null,"title":"Self Learning","type":"docs"},{"authors":null,"categories":null,"content":"从某种角度来说，计算机领域的大牛多少有一点偏执——毕竟写代码的时候漏打一个符号便可能酿成大祸，所以学计算机的人总有点“强迫症”。退一步来说，即使你没有强迫症，写作文的时候歪七扭八、行间距不一、每个字都不一样大，开头时不时地忘记空两格……总不是件好事。\n你也许在书面助教的作业要求中注意到了 LaTeX 这个东西。$\\LaTeX$ 是一个高质量的排版系统，你可以通过编写代码生成文档的方式来精确地控制文档里的每一处细节，比如分隔线的粗细、图片的大小，页边距的宽窄等等，精度可以达到毫米。我们不强制要求大家使用 LaTeX 书写作业 (因为对于新手来说这可能会耗费很多的时间)，但我们仍然推荐你学习这项工具 (不出意外，你撰写毕业论文的时候是肯定会用到它的)。\n如果你认为 $\\LaTeX$ 太过麻烦，不妨尝试一下 Markdown。从原理上来说 Markdown 和 LaTeX 很不一样，但你可以简单地认为它们都是通过一些特殊的符号来生成具有格式，编排美观的文档 (助教博客中的大部分页面都是用 Markdown 书写的)。Markdown 比 LaTeX 简明很多，比如你可以通过 # 来生成各个级别的标题：\n这是二级标题 这是三级标题 可以通过 * 来生成列表：\n列表1 列表2 Markdown 同样支持丰富的数学符号：\n\\begin{align} f(n)=\\sum_{d|n}g(d)\\Longleftrightarrow g(n)=\\sum_{d|n}\\mu(d)f\\left(\\frac{n}{d}\\right). \\end{align} $$ \\begin{align} f(n)=\\sum_{d|n}g(d)\\Longleftrightarrow g(n)=\\sum_{d|n}\\mu(d)f\\left(\\frac{n}{d}\\right). \\end{align} $$\n我们强烈建议你至少掌握一些 Markdown 的基本语法，这可以帮助你将来迅速地写出一份还算美观的文档。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"be0ce6b9feb12c6c4963e17d53343cb5","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/cser0/typesetting/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/cser0/typesetting/","section":"courses","summary":"从某种角度来说，计算机领域的大牛多少有一点偏执——毕竟写代码的时候漏打一个符号便可能酿成大祸，所以学计算机的人总有点“强迫症”。退一步来说，即使你没有强迫症，写作文的时候歪七扭八、行间距不一、每个字都不一样大，开头时不时地忘记空两格……总不是件好事。\n你也许在书面助教的作业要求中注意到了 LaTeX 这个东西。$\\LaTeX$ 是一个高质量的排版系统，你可以通过编写代码生成文档的方式来精确地控制文档里的每一处细节，比如分隔线的粗细、图片的大小，页边距的宽窄等等，精度可以达到毫米。我们不强制要求大家使用 LaTeX 书写作业 (因为对于新手来说这可能会耗费很多的时间)，但我们仍然推荐你学习这项工具 (不出意外，你撰写毕业论文的时候是肯定会用到它的)。\n如果你认为 $\\LaTeX$ 太过麻烦，不妨尝试一下 Markdown。从原理上来说 Markdown 和 LaTeX 很不一样，但你可以简单地认为它们都是通过一些特殊的符号来生成具有格式，编排美观的文档 (助教博客中的大部分页面都是用 Markdown 书写的)。Markdown 比 LaTeX 简明很多，比如你可以通过 # 来生成各个级别的标题：\n这是二级标题 这是三级标题 可以通过 * 来生成列表：","tags":null,"title":"Typesetting","type":"docs"},{"authors":null,"categories":null,"content":"对于零基础的同学来说，键盘可能是十分陌生的。但大家既然选择了CS，计算机之于大家就应当相当于宝剑之于骑士，打字就应当像拿筷子吃饭一样熟练。如果你连\n应当如何通过键盘敲出下划线 _ ？\n这个问题都感到无从下手，那你一定要花一些功夫练习打字。\n打字这件事很像投篮。能把球投进篮筐的姿势都是好姿势，同理打得快、准确率高的姿势也都是好姿势。但我们还是建议初学者打好基础，学习正规的十指布局。我们认为一个合格的CSer应当拥有200+cpm (character per minute) 的打字速度。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ac6430c6d3c2f9c7e310fc09cd539769","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/cser0/typing/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/cser0/typing/","section":"courses","summary":"对于零基础的同学来说，键盘可能是十分陌生的。但大家既然选择了CS，计算机之于大家就应当相当于宝剑之于骑士，打字就应当像拿筷子吃饭一样熟练。如果你连\n应当如何通过键盘敲出下划线 _ ？\n这个问题都感到无从下手，那你一定要花一些功夫练习打字。\n打字这件事很像投篮。能把球投进篮筐的姿势都是好姿势，同理打得快、准确率高的姿势也都是好姿势。但我们还是建议初学者打好基础，学习正规的十指布局。我们认为一个合格的CSer应当拥有200+cpm (character per minute) 的打字速度。","tags":null,"title":"Typing","type":"docs"},{"authors":null,"categories":null,"content":"随着程序规模的扩大，你的 main() 函数可能变得越来越臃肿了。这时候使用函数将不同的模块分开书写，可以让程序变得条理清晰、简明易懂。例如下面是 OJ 习题 \u0026ldquo;环形矩阵\u0026rdquo; 的一段代码：\nint n; int a[100][100]; int main () { scanf(\u0026quot;%d\u0026quot;, \u0026amp;n); for (int k = 1; k \u0026lt;= (n + 1) / 2; k++) for (int i = k; i \u0026lt;= n + 1 - k; i++) for (int j = k; j \u0026lt;= n + 1 - k; j++) a[i][j] = k; for (int i = 1; i \u0026lt;= n; i++) { for (int j = 1; j \u0026lt;= n; j++) printf(\u0026quot;%4d\u0026quot;, a[i][j]); puts(\u0026quot;\u0026quot;); } return 0; } 读入、矩阵制作、输出三个步骤全部放在 main() 函数中显得有些冗长。我们可以根据功能将上述代码分成三个模块，每个模块写在一个单独的子函数里：\nint n; int a[100][100]; void input() { scanf(\u0026quot;%d\u0026quot;, \u0026amp;n); } void matrix_generation() { for (int k = 1; k \u0026lt;= (n + 1) / 2; k++) for (int i = k; i \u0026lt;= n + 1 - k; i++) for (int j = k; j \u0026lt;= n + 1 - k; j++) a[i][j] = k; } void print() { for (int i = 1; i \u0026lt;= n; i++) { for (int j = 1; j \u0026lt;= n; j++) printf(\u0026quot;%4d\u0026quot;, a[i][j]); puts(\u0026quot;\u0026quot;); } } int main () { input(); matrix_generation(); print(); return 0; } 由于这个程序比较简单，你可能会觉得这样写代码非常拖沓。但随着程序结构的进一步复杂化，你一定会发现将程序分功能分模块书写能帮助你理清思路，也方便 debug。\n代码风格\n对于初学者来说，养成良好的代码风格极其重要。一方面，条理清晰的代码看起来赏心悦目，方便自己 debug；另一方面，如果你将来与别人合作开发项目，良好的代码风格可以让他人快速理解你书写的模块，方便沟通交流。大家或许听说过一些类似于 “老程序员一走，整个项目就玩不转了，因为没人知道他写了什么” 的笑话，撇开工程复杂性的客观原因，这样的现象也说明很大一部分程序员的代码书写习惯极其糟糕。\n所以无论你是否有编程基础，请一定重视自己的代码风格。我们建议你至少在以下几个方面注意：\n合理的变量命名：不要使用无意义的 a b c _ __，而应该使用 arrayLength stuCount 等。有意义的变量名可以让你/他人立刻理解这个变量的用途。至于变量的命名格式，我们建议你搜索驼峰命名法。 合理的函数使用：不要将一大堆代码塞在一起。 合理书写注释，对程序的功能做一点解释。 合理的符号使用 (括号，换行符 etc.) 合理的缩进 …… 如果你感兴趣，你可以上网搜索 Google 的代码风格规范。\n最后是一个小笑话：\n世界上有两件最讨厌的事情，一个是写注释，一个是别人的代码不写注释。\n定义 函数的基本语法如下：\nint func(int a, float b, char c, ...) { } 其中\n第一个 int 指明了函数的返回值类型为 int。你当然可以选择别的类型，如果你的函数不需要返回值，可以用 void。 func 是函数的名称。这是你可以自由指定的部分。 (int a, float b, ...) 是函数的参数。你可以指定任意个数的参数，但每个参数都要有类型。 下面是一个简明的例子：\nint abs(int x) { int res = x \u0026gt;= 0 ? x : -x; return res; } int main () { int x = -1; x_abs = abs(x); // x_abs = 1 return 0; } 注意所有的子函数要写在 main 函数的上方 (这是 C/C++ 的要求)。如果你想要将子函数写在 main 函数的下方，需要在 main 函数之前先声明该子函数。声明简单来说就是将函数的定义抄一遍：\nint abs(int x); int main () { int x = -1; x_abs = abs(x); return 0; } int abs(int x) { int res = x \u0026gt;= 0 ? x : -x; return res; } 变量的作用域 有了函数的概念后我们就必须要区分“全局变量“和“局部变量”。顾名思义在函数内部定义的变量是局部变量，该变量只能在当前函数内使用。在所有函数外定义的变量是全局变量，该变量可以在任何函数中使用 (注：一个函数的参数也是该函数的局部变量)。下面是一个例子：\nint n = 0; void func() { printf(\u0026quot;%d\\n\u0026quot;, n); // 输出结果为 0。 printf(\u0026quot;%d\\n\u0026quot;, m); // 编译错误：m 是 main() 的局部变量，在 func() 中不可用。 } int main () { int n = 1, m = 2; printf(\u0026quot;%d\\n\u0026quot;, n); // 输出结果为 1，全局变量和局部变量重名优先使用局部变量。 } 按值传递和按引用传递 按值传递和按引用传递是函数中必须提及的另一个重要概念。很多初学者会疑惑：如果我在子函数中对参数的值做了改动，主函数里相应的变量会变吗？你可以做一个小实验探索这一点：\nvoid func(int x) { x = 2; } int main () { int x = 1; func(x); printf(\u0026quot;%d\\n\u0026quot;, x); // 输出结果为 1 } 事实证明子函数的改动不会影响主函数。这是因为 C/C++ 中函数变量参数的传递默认使用按值传递，即子函数的参数变量 x 和主函数的变量 x 是两个独立的主体，在函数调用时主函数的 x 的值会被复制到子函数的 x 中，在子函数中对 x 的所有改动都是针对这个“复印件”的，对原件没有影响。\n那么有没有办法可以让子函数直接修改主函数中的变量的值呢？ C++ 提供了引用变量的机制，一个例子如下：\nvoid func(int x, int \u0026amp;y) { x++; y++; } int main () { int x = 1, y = 1; func(x, y); printf(\u0026quot;%d %d\\n\u0026quot;, x, y); // 输出结果为 1 2 } 在这个例子中，x 是按值传递的，y 是按引用传递的 (注意函数参数前的 \u0026amp; 符号)。按引用传递可以理解为直接将原件交给了子函数，子函数的改动会影响主函数的值。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"bf40eb456eef4ee614fb8bb8d9689526","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/functions/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/functions/","section":"courses","summary":"随着程序规模的扩大，你的 main() 函数可能变得越来越臃肿了。这时候使用函数将不同的模块分开书写，可以让程序变得条理清晰、简明易懂。例如下面是 OJ 习题 \u0026ldquo;环形矩阵\u0026rdquo; 的一段代码：\nint n; int a[100][100]; int main () { scanf(\u0026quot;%d\u0026quot;, \u0026amp;n); for (int k = 1; k \u0026lt;= (n + 1) / 2; k++) for (int i = k; i \u0026lt;= n + 1 - k; i++) for (int j = k; j \u0026lt;= n + 1 - k; j++) a[i][j] = k; for (int i = 1; i \u0026lt;= n; i++) { for (int j = 1; j \u0026lt;= n; j++) printf(\u0026quot;%4d\u0026quot;, a[i][j]); puts(\u0026quot;\u0026quot;); } return 0; } 读入、矩阵制作、输出三个步骤全部放在 main() 函数中显得有些冗长。我们可以根据功能将上述代码分成三个模块，每个模块写在一个单独的子函数里：","tags":null,"title":"函数","type":"docs"},{"authors":null,"categories":null,"content":"很多时候我们需要根据某个条件决定去做事情1还是事情2,这就是分支。一个分支框架的格式如下：\nif (condition) { // your code } 它的意思是：如果 if () 括号中的条件成立，那么就执行大括号中的那些语句，否则跳过这些语句。此外，我们还可以添加 else 分支：\nif (condition) { // your code } else { // your code } 这时如果条件成立就执行紧接着的大括号中的语句，并跳过 else 下的语句；如果条件不成立就跳过紧接着的语句，直接执行 else 下的语句。一个额外的规则是：如果 \u0026ldquo;your code\u0026rdquo; 的地方你只需要写一条语句，你可以省略大括号对 (这样代码看上去更紧凑简洁)，不过如果你没有把握，加上大括号永远是最稳妥最正确的选择。\n我们来看一个简单的例子：输入两个数，如果它们的和是奇数就输出 \u0026ldquo;odd\u0026rdquo;，否则输出 \u0026ldquo;even\u0026rdquo;：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { int a, b, sum; std::cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; sum = a + b; if (sum % 2 == 1) std::cout \u0026lt;\u0026lt; \u0026quot;odd\u0026quot; \u0026lt;\u0026lt; '\\n'; else std::cout \u0026lt;\u0026lt; \u0026quot;even\u0026quot; \u0026lt;\u0026lt; '\\n'; return 0; } 这里需要对 if 的条件语句做一点说明：\n% 是取模符号，sum % 2 即计算变量 sum 除以 2 后的余数。 在 C++ 中我们要格外小心 == 和 = 的区别: == 是一个比较运算符，用来比较式子的左边和右边是否相等。其他的一些常用的比较运算符列举如下\n符号 意义 \u0026lt;= 小于等于 \u0026lt; 小于 \u0026gt;= 大于等于 \u0026gt; 大于 != 不等于 = 是赋值符号，比如在 sum = a + b; 中，将 a + b 的值赋给 sum。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"74bc57c6713cea8a7e36283b093daed4","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/branch/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/branch/","section":"courses","summary":"很多时候我们需要根据某个条件决定去做事情1还是事情2,这就是分支。一个分支框架的格式如下：\nif (condition) { // your code } 它的意思是：如果 if () 括号中的条件成立，那么就执行大括号中的那些语句，否则跳过这些语句。此外，我们还可以添加 else 分支：\nif (condition) { // your code } else { // your code } 这时如果条件成立就执行紧接着的大括号中的语句，并跳过 else 下的语句；如果条件不成立就跳过紧接着的语句，直接执行 else 下的语句。一个额外的规则是：如果 \u0026ldquo;your code\u0026rdquo; 的地方你只需要写一条语句，你可以省略大括号对 (这样代码看上去更紧凑简洁)，不过如果你没有把握，加上大括号永远是最稳妥最正确的选择。","tags":null,"title":"分支","type":"docs"},{"authors":null,"categories":null,"content":"一个最简单的 C++ 程序长成这样：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { // your code return 0; } 我们对这个程序的几个组成部分做一点说明：\n\u0026ldquo;include\u0026quot;一行使程序包含了一系列头文件 (header file), 头文件中定义了许多有用的函数，我们只有使用 include 包含这些头文件才能使用这些函数（头文件在安装环境时就有了，你暂时不需要关心它们在哪里以及是如何实现的，你只需要知道 include 这行几乎是必须要写的）。 int main () {} 称为 main 函数。每个程序都必须有 main 函数，当程序开始运行时，第一条执行的指令就是 main 函数的第一条指令。 return 0; 是一条语句，无论 main 函数中写了什么内容，最后一样都应当是 return 0;。 C++ 语法\n你的每条语句都必须以 ; 结尾。一行可以有多条语句，但每个语句后都要有 ;。\n使用 // 可以在 C++ 代码中书写注释 (comment)，注释类似于批注，其目的是让阅读代码的人更好地理解代码的意思，注释中的内容不会被执行。此外，如果你想书写一段多行的注释，可以使用如下方法：\n/* write your comments here write your comments here */ ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cbb55943d7dee727ea6d97be41afcfbb","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/framework/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/framework/","section":"courses","summary":"一个最简单的 C++ 程序长成这样：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { // your code return 0; } 我们对这个程序的几个组成部分做一点说明：\n\u0026ldquo;include\u0026quot;一行使程序包含了一系列头文件 (header file), 头文件中定义了许多有用的函数，我们只有使用 include 包含这些头文件才能使用这些函数（头文件在安装环境时就有了，你暂时不需要关心它们在哪里以及是如何实现的，你只需要知道 include 这行几乎是必须要写的）。 int main () {} 称为 main 函数。每个程序都必须有 main 函数，当程序开始运行时，第一条执行的指令就是 main 函数的第一条指令。 return 0; 是一条语句，无论 main 函数中写了什么内容，最后一样都应当是 return 0;。 C++ 语法","tags":null,"title":"基本框架","type":"docs"},{"authors":null,"categories":null,"content":"上一节的所有示例代码中我们定义的都是一维数组，一维数组顾名思义就是将所有的”小盒子“排成一排，用一个下标去索引它们。C/C++ 中可以定义各种维度的数组，比如你可以定义一个二维数组来存储方阵：\n#include \u0026lt;bits/stdc++.h\u0026gt; int a[100][100]; int main () { a[0][0] = 1; // 二维数组的每个维度都是从0开始编号的！ a[2][3] = 5; std::cout \u0026lt;\u0026lt; a[0][0] \u0026lt;\u0026lt; '\\n'; //输出结果为1 return 0; } 有了多维数组后，你会发现我们手里原有的线性的循环工具有点不够用了。但事实上我们可以用嵌套循环来轻松地对多维数组进行访问。下面的示例程序接受一个 $n$ 行 $m$ 列的包含整数的方阵作为输入，它会将其原封不动地打印出来 (假设 $n,m\\leq 100$)：\n#include \u0026lt;bits/stdc++.h\u0026gt; int a[100][100]; int main () { int row, col; std::cin \u0026gt;\u0026gt; row \u0026gt;\u0026gt; col; // input for (int i = 0; i \u0026lt; row; i++) { for (int j = 0; j \u0026lt; col; j++) { std::cin \u0026gt;\u0026gt; a[i][j]; } } // output for (int i = 0; i \u0026lt; row; i++) for (int j = 0; j \u0026lt; col; j++) { char suffix_char = ((j == col - 1) ? '\\n' : ' '); std::cout \u0026lt;\u0026lt; a[i][j] \u0026lt;\u0026lt; suffix_char; } } 从逻辑上来看嵌套循环也没什么“了不起”：以输出部分为例，对于每一个 $i=0,1,\\cdots,row-1$，循环变量 $j$ 都会从 $0$ 循环到 $col-1$，这样在内层循环的里面我们就可以按照 $(0,0)$, $(0,1)$,$\\cdots$, $(0, col-1)$, $(1, 0)$, $(1, 1)$, $\\cdots$ ,$(1, col-1)$, $(2, 0)$,$\\cdots$, $(row-1, 0)$, $\\cdots$, $(row-1, col-1)$ 的顺序去访问二维数组中的每个元素。\n这个代码中有一些细节值得讲解：\n在书写嵌套循环时，内层循环和外层循环应当使用不同的循环变量。如果你在内层循环中使用了和外层循环一样的变量，那么执行完内层循环后回到外层循环时，变量的值就乱了。不要小瞧这条看上去显而易见的结论，你们所有人大抵都会在过去、现在或将来犯一些类似下面的错误： for (int i = 0; i \u0026lt; n; i++) for (int j = 0; j \u0026lt; m; i++) 我们在给出两段双重循环的代码时特地使用了不同的括号风格，你可以借此机会对到底什么时候需要打大括号有更深入的理解：我们之前提到如果当前结构内部只有一条语句，for循环/if语句可以不打大括号；但更准确地说应该是如果只有“一块”一句，比如第二段双重循环的外层循环内部只有一个for循环这“一块”语句，所以可以省略大括号。还是那句话，如果你拿捏不准，把大括号写全永远是最稳妥的。 示例代码中出现了一个比较奇怪的语句：suffix_char = ((j == col - 1) ? '\\n' : ' ')。? : 被称为三目运算符，是 C/C++ 提供的一个语法机制。(a ? b : c) 的意思是如果 a 的值为真则返回 b，否则返回 c。上面的这一行代码等价于一个if语句： if (j == col - 1) suffix_char = '\\n'; else suffix_char = ' '; 可以看到合理使用三目运算符有助于使代码更加简洁。 运算符优先级\n你可能会疑惑：三目运算符的代码写成\nsuffix_char = (j == col - 1 ? '\\n' : ' '); 甚至是\nsuffix_char = j == col - 1 ? '\\n' : ' '; 可不可以呢？ 在坐等答案之前，你应该做的事情是把括号去掉并尝试运行程序，这是你自己通过试验寻求问题答案的途径。当然在这里我们会告诉你：上面两段代码是没有问题的，因为 C/C++ 中不同的符号存在优先级差异。正如算术中乘除法比加减法优先级高，C/C++内部也有一套严格的优先级金字塔。优先级相同的运算符优先计算左侧的；优先级不同的运算符优先计算等级高的。这个 链接 详细讲述了优先级的划分。\n下面展示一个更精巧的例子，它的作用是打印出一个字符三角形：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { int n; std::cin \u0026gt;\u0026gt; n; for (int i = 1; i \u0026lt;= n; i++) { for (int j = 0; j \u0026lt; i; j++) std:: cout \u0026lt;\u0026lt; '*'; std::cout \u0026lt;\u0026lt; '\\n'; } return 0; } 可以看到外层的循环变量是可以在内层循环体和循环条件中使用的。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3eb9f1b11d39ac785a2b5583355a19e3","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/nestedloop/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/nestedloop/","section":"courses","summary":"上一节的所有示例代码中我们定义的都是一维数组，一维数组顾名思义就是将所有的”小盒子“排成一排，用一个下标去索引它们。C/C++ 中可以定义各种维度的数组，比如你可以定义一个二维数组来存储方阵：\n#include \u0026lt;bits/stdc++.h\u0026gt; int a[100][100]; int main () { a[0][0] = 1; // 二维数组的每个维度都是从0开始编号的！ a[2][3] = 5; std::cout \u0026lt;\u0026lt; a[0][0] \u0026lt;\u0026lt; '\\n'; //输出结果为1 return 0; } 有了多维数组后，你会发现我们手里原有的线性的循环工具有点不够用了。但事实上我们可以用嵌套循环来轻松地对多维数组进行访问。下面的示例程序接受一个 $n$ 行 $m$ 列的包含整数的方阵作为输入，它会将其原封不动地打印出来 (假设 $n,m\\leq 100$)：","tags":null,"title":"嵌套循环","type":"docs"},{"authors":null,"categories":null,"content":"假设我们现在要计算 $1+2+3+4+5$，相信你已经有能力写出一段代码完成这个任务：\nint sum; sum = 1; sum = sum + 2; // 你也可以写 sum += 2; 它们的功能是一样的 sum = sum + 3; sum = sum + 4; sum = sum + 5; 但是这样的代码看起来未免有些笨拙，如果我们要计算 $1+2+\\cdots+100$，岂不是要写 100 行？当遇到这种需要大量重复做相同/相似操作的情况时，循环便能派上用场。while 循环的基本架构为：\nwhile (condition) { // your code here } 在进入循环体之前，程序会先检查括号中的条件是否成立，如果成立就执行大括号中的内容，执行完内容后程序会再次判断括号中的条件是否成立……直到某次执行完循环体后条件不成立了，while 循环才会退出，下面的流程图很好地诠释了 while 循环的执行过程：\ngraph TD s0[start] s1{while yes?} s2(body) s3(break) s0 --\u0026gt; s1 s1 --\u0026gt; |yes| s2 s2 --\u0026gt; s1 s1 --\u0026gt; |no| s3 有了 while 循环后，我们可以容易地解决下面的这个问题：输入一个整数 $n$，输出 $1+2+\\cdots+n$：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { int n, sum; std::cin \u0026gt;\u0026gt; n; sum = 0; while (n != 0) { sum += n; n--; // \u0026quot;n--\u0026quot; is equal to \u0026quot;n = n - 1\u0026quot; } std::cout \u0026lt;\u0026lt; sum \u0026lt;\u0026lt; '\\n'; return 0; } 上述 while 循环将判断条件放在开头，另有一种 do-while 循环框架将判断条件放在末尾：\ndo { // your code } while (condition); // 这里要加分号！ do-while 循环一定会先执行循环体再检查条件，其他的部分和 while 循环没有区别。\n除了 while 循环，for 循环也是一种常用的循环框架，不过 for 循环的格式相对复杂：\nfor (/* statement 1 */; /* statement 2 */; /* statement 3 */) { // your code } C++ 语言的 for 循环中有 3 条语句，其执行顺序非常微妙 (这是 C/C++ 经常被吐槽的一个点)。用流程图可以比较清楚地解释执行的顺序：\ngraph LR s0[start] s1(statement 1) s2{statement 2 yes?} s3(body) s4(statement 3) s5(break) s0 --\u0026gt; s1 s1 --\u0026gt; s2 s2 --\u0026gt; |yes| s3 s3 --\u0026gt; s4 s4 --\u0026gt; s2 s2 --\u0026gt; |no| s5 如果你觉得这个流程比较复杂，也可以暂时不那么仔细地理解它，毕竟 while 循环可以做到 for 循环能做到的所有事情。不过你可以记住的是：\nint i; for (i = 1; i \u0026lt;= n; i++) {} 这样一个 for 循环可以让变量 i 分别取 $1, 2, \\cdots, n$，然后退出循环。如果你把三条语句代入刚才的流程图，你会发现它确实是正确的。这样一个从 $1$ 枚举到 $n$ 的写法比 while 循环看上去简洁一些。\n我们给出两个使用 for 循环实现计算 $1+2+\\cdots n$ 的示例代码：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { int n, sum; std::cin \u0026gt;\u0026gt; n; for (int i = 1; i \u0026lt;= n; i++) // 如果你想在循环体内部临时使用一个变量，你可以选择像这样的定义方式 sum += i; // 别忘了单条语句可以不用{}包裹起来 std::cout \u0026lt;\u0026lt; sum \u0026lt;\u0026lt; '\\n'; return 0; } 如你所见，你可以在 for 循环中临时定义变量 i，这个变量 i 只可以在循环体中使用，在循环体以外你不能使用 i。\n这个 for 循环的写法是之前介绍的比较规整的写法，下面是一个长相比较特别的 for 循环：\nint main () { int n, sum; std::cin \u0026gt;\u0026gt; n; for ( ;n != 0; n--) sum = sum + n; std::cout \u0026lt;\u0026lt; sum \u0026lt;\u0026lt; '\\n'; return 0; } 如果你代入之前的流程图理解 for 循环执行的过程，你会发现这个写法比较像 while 循环的逻辑。事实上，之所以说 for 循环完全可以用 while 循环代替，是因为\nfor (s1; s2; s3) { // your code } 等价于\ns1; while (s2) { // your code s3; } ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1fa517a55138ecfac147e3557f1935e8","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/loop/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/loop/","section":"courses","summary":"假设我们现在要计算 $1+2+3+4+5$，相信你已经有能力写出一段代码完成这个任务：\nint sum; sum = 1; sum = sum + 2; // 你也可以写 sum += 2; 它们的功能是一样的 sum = sum + 3; sum = sum + 4; sum = sum + 5; 但是这样的代码看起来未免有些笨拙，如果我们要计算 $1+2+\\cdots+100$，岂不是要写 100 行？当遇到这种需要大量重复做相同/相似操作的情况时，循环便能派上用场。while 循环的基本架构为：","tags":null,"title":"循环","type":"docs"},{"authors":null,"categories":null,"content":" 为了解释清楚一些现象背后的原因，本文涉及一些超纲的计算机底层知识。这部分内容都在绿色的框内，如果你无法看懂可以直接跳过。等到大家学完了计算机系统基础 (ICS) 后自然就能理解这些话的含义。 有了循环之后，你很快就会发现简单地定义一个一个的变量有点“不够用”了，比如考虑如下问题：\n输入整数 $N$，然后输入 $N$ 个数的一个数列，将这个数列倒序输出。\n我们想要倒序输出，就说明我们在读取完数列的最后一个整数时，还要“记住”前面的 $N-1$ 个整数，所以我们每读取到一个整数都得将其保存在变量里，但我们在预先不知道数列长度的情况下怎么知道该定义多少个变量呢？这似乎陷入了死局。\n(在这里我们不考虑递归等技巧) 我们希望有一种语法，可以批量开一堆变量，而且最好能用下标去索引它们。在 C/C++ 中我们可以通过定义数组来实现这一点。我们先给出上面问题的一段示例代码：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { int n; std::cin \u0026gt;\u0026gt; n; int a[n]; for (int i = 0; i \u0026lt; n; i++) std::cin \u0026gt;\u0026gt; a[i]; for (int i = n - 1; i \u0026gt;= 0; i--) std::cout \u0026lt;\u0026lt; a[i] \u0026lt;\u0026lt; '\\n'; return 0; } 这里出现的新语法是 int a[n]。如果说 int 类型的变量是一个可以存放一个整数的小盒子，那么 int a[n] 就定义了 $n$ 个小盒子，每个小盒子都可以存放一个整数。值得注意的是，这里的“小盒子”是按照 $0,1,\\cdots, n-1$ 编号的。\nVariable-Length Array (VLA)\n在上面的例子中，我们定义的数组的长度依赖于我们输入的变量 $n$ 的值，也就是说，在程序开始运行之前，我们无法知道数组的具体长度。这种以变量作为长度的数组称为 variable-length array (VLA)。\nVLA 的微妙之处在于，编译器在不知道数组具体长度的情况下可能会在内存分配上犯难。C99 标准首次允许 VLA 的使用，但对其作出了诸多限制，比如不能使用 $\\mathbf{extern}$, $\\mathbf{static}$ 等关键字修饰。不同的编译器支持的标准也略有差异，例如 Visual Studio 使用的 msvc 编译器很可能会对上面的示例代码报错。\n如果你对这些内容感兴趣，可以上网查询更多的资料。\n如果上面关于 VLA 的内容你没有看懂，没有关系，一句话概括就是使用变量作为数组的长度“不太好”。我们的 OJ 题会对输入数据的范围作出严格的限制，你可以根据数据范围将数组开到足够大的一个固定长度。假设题目规定了 $N\\leq 1000$，那么一个不使用 VLA 的程序应该这样写：\n#include \u0026lt;bits/stdc++.h\u0026gt; int a[1000]; int main () { int n; std::cin \u0026gt;\u0026gt; n; for (int i = 0; i \u0026lt; n; i++) std::cin \u0026gt;\u0026gt; a[i]; for (int i = n - 1; i \u0026gt;= 0; i--) std::cout \u0026lt;\u0026lt; a[i] \u0026lt;\u0026lt; '\\n'; return 0; } 这里我们希望不加解释地做出一个规定：如果你要定义一个定长的数组，请将它定义在 main() 函数的外面。\n不行，我就是想知道为什么要这么规定\nC/C++ 的编译器需要负责将高级语言程序映射到具体的硬件上。对于数组这样的存储设施，编译器会将其映射到内存中的某块区域。如果你将数组定义在函数内部，编译器会将其安排在栈上；如果你将数组定义在全局 (函数外部)，编译器会将其安排在静态数据区。除非特别配置，一个程序的栈空间通常不是很大，如果在函数内部定义了过长的数组可能会导致栈溢出，栈溢出会导致不可预知的严重后果。\n如果你想亲手体验一下“栈溢出”，你可以尝试运行以下代码 (不要加任何编译优化)：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { char s[1 \u0026lt;\u0026lt; 25]; } 直接运行这段代码可能会获得段错误 (Segmentation Fault)。\n如果你没有看懂这段话，那就老老实实地遵守我们的规定吧。\n总有一些“完美主义者”觉得这样写代码十分令人不爽——如果 $N$ 远小于 1000，我们的代码岂不是无谓的多使用了很多资源？这里我们再介绍一种定义数组的方式，它在功能上和前面的几种是完全相同的：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { int n; std::cin \u0026gt;\u0026gt; n; int *a = new int [n]; for (int i = 0; i \u0026lt; n; i++) std::cin \u0026gt;\u0026gt; a[i]; for (int i = n - 1; i \u0026gt;= 0; i--) std::cout \u0026lt;\u0026lt; a[i] \u0026lt;\u0026lt; '\\n'; delete [] a; return 0; } int *a = new int [n] 的功能是定义一个长度为 $n$ 的数组，每个数组元素都是 int 类型，这个数组的名字叫做 a。我们在这里希望强调一点：如果你使用了new语法定义数组，请一定在你确定不会再使用该数组的时刻 (例如 return 0 之前) 使用delete释放它。\n我不写delete这一行好像也没报错啊？\n如果你是一个曾经学过算法竞赛的同学，你很可能已经养成了“随手new，从不delete”的习惯。我们在这里必须严肃地警告：这是一个非常危险的习惯！你之前写过的忘记 delete 的 OJ 程序之所以可以正常退出，是因为当 OJ 程序所在的进程被销毁时，操作系统会将进程申请的资源自动释放——换言之，操作系统帮你默默地做了 delete。没有及时释放申请的内存会导致内存泄漏 (memory leak)，如果将来你维护一个大型的项目，内存泄漏的累积很可能导致程序崩溃。\n如果你是一个计算机小白，恭喜你拥有了一个小小的优势：你没有经历过算法竞赛中各种糟糕的代码书写习惯的熏陶。从初学阶段开始严格遵守各种规范，你将自然而然地将书写安全、高质量、可读性强的代码作为一种本能。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"af58f0ca73f9f8e7cb1edc0d2c5c72b3","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/array/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/array/","section":"courses","summary":"为了解释清楚一些现象背后的原因，本文涉及一些超纲的计算机底层知识。这部分内容都在绿色的框内，如果你无法看懂可以直接跳过。等到大家学完了计算机系统基础 (ICS) 后自然就能理解这些话的含义。 有了循环之后，你很快就会发现简单地定义一个一个的变量有点“不够用”了，比如考虑如下问题：\n输入整数 $N$，然后输入 $N$ 个数的一个数列，将这个数列倒序输出。\n我们想要倒序输出，就说明我们在读取完数列的最后一个整数时，还要“记住”前面的 $N-1$ 个整数，所以我们每读取到一个整数都得将其保存在变量里，但我们在预先不知道数列长度的情况下怎么知道该定义多少个变量呢？这似乎陷入了死局。\n(在这里我们不考虑递归等技巧) 我们希望有一种语法，可以批量开一堆变量，而且最好能用下标去索引它们。在 C/C++ 中我们可以通过定义数组来实现这一点。我们先给出上面问题的一段示例代码：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { int n; std::cin \u0026gt;\u0026gt; n; int a[n]; for (int i = 0; i \u0026lt; n; i++) std::cin \u0026gt;\u0026gt; a[i]; for (int i = n - 1; i \u0026gt;= 0; i--) std::cout \u0026lt;\u0026lt; a[i] \u0026lt;\u0026lt; '\\n'; return 0; } 这里出现的新语法是 int a[n]。如果说 int 类型的变量是一个可以存放一个整数的小盒子，那么 int a[n] 就定义了 $n$ 个小盒子，每个小盒子都可以存放一个整数。值得注意的是，这里的“小盒子”是按照 $0,1,\\cdots, n-1$ 编号的。","tags":null,"title":"数组","type":"docs"},{"authors":null,"categories":null,"content":"如果你使用的是 Dev-cpp，将基本框架中的程序拷贝到代码区并按下 F11，你会发现程序已经可以成功地运行了！不过跳出的黑色窗口中没有任何内容——因为我们的 main 函数中什么都没写。我们现在来尝试输出一行 \u0026ldquo;hello world!\u0026quot;：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { std::cout \u0026lt;\u0026lt; \u0026quot;Hello World\u0026quot; \u0026lt;\u0026lt; '\\n'; // don't forget to add ';' at the end! return 0; } cout 是一个对象 (object)，作为初学者我们不需要知道对象是什么意思，一个好的理解方式是：你可以把 \u0026ldquo;cout\u0026rdquo; 想象成运行时蹦出的窗口，现在我们的任务是将要输出的内容喂给窗口，这里的 \u0026lt;\u0026lt; 就像箭头一样指明了数据的流向，“Hello World\u0026rdquo; 和代表换行符的 \u0026ldquo;\\n\u0026rdquo; 依次流入 \u0026ldquo;cout\u0026rdquo; 并被显示出来，这就是 cout 的用法，颇有象形文字的智慧。\nstd:: 这个前缀是什么意思？\nstd 是一个命名空间 (namespace)。对于初学者来说命名空间的概念太过复杂了，你可以把它当作“头文件”来理解：std 中有很多函数/对象/\u0026hellip;可以供我们使用。在使用它们时，为了让计算机知道这个函数/对象/\u0026hellip;来自于 std，我们要前面加上 std:: 这个前缀。\n一个自然的问题是：我们既然有一个 include 语句包含头文件，那么我们可不可以也用一条语句来“包含” std 从而避免每次使用 std 中的东西都要写 std:: 呢？答案是肯定的，我们可以这样写：\n#include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; 第二行的意思是：在整个程序中我都可以任意地使用 std 这个 namespace 的所有内容，不再需要 std:: 这个前缀。这样写固然方便，但我们仍然推荐新手养成不滥用 using namespace std; 的习惯，因为这样你能够更好地知道哪些函数是头文件中的，哪些函数是 std 中的，这对将来的编程学习很有好处。\n一个只能输出的程序没有意思，我们希望程序可以与人类交互，因此我们接下来考虑一个更复杂的例子：输入两个数，输出它们的和。我们直接给出示例代码：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { int a, b, sum; std::cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b; // don't forget the \u0026quot;std::\u0026quot; prefix! sum = a + b; std::cout \u0026lt;\u0026lt; sum \u0026lt;\u0026lt; '\\n'; return 0; } 这个程序颇为复杂，出现了很多新东西，我们来一一看：\n程序中的 a b sum 被称为变量 (variable)。变量可以被理解为一个“小盒子“，里面可以存放一个值。在使用变量前我们需要定义变量，定义的格式是 类型 变量名;，这里我们定义了 int 类型的变量，表示 a b sum 这三个“盒子”里只能存放整数。 cin 是用于输入的对象。有了 cout 的经验，cin 一行很好理解：我们还是将 \u0026ldquo;cin\u0026rdquo; 想象成黑色窗口，当我们输入了两个数字的时候，\u0026ldquo;cin\u0026rdquo; 需要将数据喂给变量，因此流符号的方向是 \u0026gt;\u0026gt;。 sum = a + b; 是一个赋值语句，它的含义是将 a 和 b 中的值加起来，存放到 sum 中，注意该操作不会影响 a 和 b 中的内容。 变量\n上述示例代码中定义的是 int 型的变量 (\u0026ldquo;int\u0026quot;是整数 integer 的缩写）。C++ 为我们提供了很多的变量类型，比如存储小数(浮点数）的 float 类型和 double 类型，存储更大的整数的 long long 类型，存储字符的 char 类型等等，你可以上网搜索这些类型的含义。\n除此之外，变量的命名看似自由，其实也有一定的约束条件，比如变量名的第一个字符不能是数字。如果你感兴趣，你也可以上网搜索相关的资料。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c854c8cdfcb821c5e43b471585efd925","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/io/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/io/","section":"courses","summary":"如果你使用的是 Dev-cpp，将基本框架中的程序拷贝到代码区并按下 F11，你会发现程序已经可以成功地运行了！不过跳出的黑色窗口中没有任何内容——因为我们的 main 函数中什么都没写。我们现在来尝试输出一行 \u0026ldquo;hello world!\u0026quot;：\n#include \u0026lt;bits/stdc++.h\u0026gt; int main () { std::cout \u0026lt;\u0026lt; \u0026quot;Hello World\u0026quot; \u0026lt;\u0026lt; '\\n'; // don't forget to add ';' at the end! return 0; } cout 是一个对象 (object)，作为初学者我们不需要知道对象是什么意思，一个好的理解方式是：你可以把 \u0026ldquo;cout\u0026rdquo; 想象成运行时蹦出的窗口，现在我们的任务是将要输出的内容喂给窗口，这里的 \u0026lt;\u0026lt; 就像箭头一样指明了数据的流向，“Hello World\u0026rdquo; 和代表换行符的 \u0026ldquo;\\n\u0026rdquo; 依次流入 \u0026ldquo;cout\u0026rdquo; 并被显示出来，这就是 cout 的用法，颇有象形文字的智慧。","tags":null,"title":"输入输出","type":"docs"},{"authors":null,"categories":null,"content":"递归对于初学者来说是一个非常头疼的概念。如果你觉得暂时无法理解，请不要灰心，因为正常的人类倾向于使用递推思考问题，即从一个 base case 出发从小往大推，而不是把一个大的问题逐渐拆解。但你必须逐渐习惯计算机世界中的这种将大任务拆成小任务解决的思想，大家后面会接触到的分治思想更是将这一点发挥到了极致。\n这篇讲义希望用一个故事把递归的思想讲明白。假设一个国家的国王有一个任务：计算 $1+2+\\cdots+100$。日理万机的国王肯定不会一个一个累加浪费时间，但他也没有聪明到能够发现高斯公式。幸运的是他有一批听话的大臣可以使用，于是他设计了一个这样的策略：\n让丞相去计算 $1+2+\\cdots +99$，等他把结果返回给我了，我只要计算这个结果+100，答案就出来了。\n丞相同样忙碌且数学天分不高，但幸运的是他也有一批手下可以召唤，于是他设计了一个同样的策略：\n找一个手下大臣去计算 $1+2+\\cdots +98$，等他把结果返回给我了，我只要计算这个结果+99，就能向国王交差了。\n这个王国的所有人都深谙资本主义压榨下属的套路 (bushi)，于是这个任务被一级一级传递下去，直到村长拿到 $1+2+3$ 时，把 $1+2$ 这个任务分配给了一个普通的村民。村民没有手下可以使用了，但幸运的是这个问题足够简单，他想都没想就机智地得到了答案 $3$ 并将结果返回给了村长。村长收到 $3$ 后计算出 $3+3=6$，又将结果返回给了镇长……一路下放的任务在收结果的过程中又被一路上传回去，最后国王收到了丞相的回复：$4950$，于是他完成了最后一步加法，$4950+100=5050$，并很高兴地宣称该任务圆满结束。\n这样的写法可能还不足以唤醒你在课堂上学习的递归“套路”。我们不妨写的更形式化一点：令 $F(n)$ 表示计算 $1+2+\\cdots +n$ 这个任务，那么国王的任务是计算 $F(100)$，丞相的任务是计算 $F(99)$……镇长的任务是计算 $F(4)$，村长的任务是计算 $F(3)$。不论这个参数是大是小，他们都采取了相同的战术： $$ F(n)=F(n-1)+n $$ 只有村民不一样，他的任务就是一个简单的加法。所以整个王国的策略可以被归纳为 $$ F(n)= \\begin{cases} 3\u0026amp;,n=2\\\\ F(n-1)+n\u0026amp;,n\\geq 3 \\end{cases} $$ 这就是递归的基本思想：如果一个大任务 (例如 $F(n)$) 可以被分解成一个性质相同但规模更小的任务 (例如 $F(n-1)$) 以及一些简单的额外运算 (例如 $+n$)，那么这个问题就非常适合用递归解决。我们可以为上面的递归加法写一个程序：\nint query_sum(int n) { if (n == 2) return 3; else return query_sum(n - 1) + n; } 该函数的执行过程和王国里任务下放再回收的过程完全相同：query_sum(100) 调用 query_sum(99) 等待其返回值，query_sum(99) 又调用了 query_sum(98)……从而形成了一个长长的调用链。query_sum(3) 调用 query_sum(2) 时，query_sum(2) 不需要再调用子函数，直接返回了结果，从而 query_sum(3) 执行完加法后也返回了结果，一层层返回结果，直到 query_sum(100) 返回。\n大家更加喜闻乐见的可能是小学/中学接触过的斐波那契数列： $$ fib_n= \\begin{cases} 0\u0026amp;, n=0\\\\ 1\u0026amp;, n=1\\\\ fib_{n-1}+fib_{n-2}\u0026amp;, n\\geq 2 \\end{cases} $$\n能够写出这种递推式的数列一定可以非常简明地用递归实现计算：\nint query_fib(int n) { if (n == 0) return 0; else if (n == 1) return 1; else return query_fib(n - 1) + query_fib(n - 2); } 这个例子比上一个例子稍稍复杂一些，因为它把一个大任务分解成了两个小任务，可以想象递归的调用会形成一个树状结构而不是链状结构。你可以自己用纸笔画一画 query_fib(5) 的递归调用过程，画完之后参考 这个链接 的动画进行比对。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"82091eade8d2de99a8e1f34ff8ef6e49","permalink":"https://kristoff-starling.github.io/courses/problemsolving22/c++0/recursion/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/problemsolving22/c++0/recursion/","section":"courses","summary":"递归对于初学者来说是一个非常头疼的概念。如果你觉得暂时无法理解，请不要灰心，因为正常的人类倾向于使用递推思考问题，即从一个 base case 出发从小往大推，而不是把一个大的问题逐渐拆解。但你必须逐渐习惯计算机世界中的这种将大任务拆成小任务解决的思想，大家后面会接触到的分治思想更是将这一点发挥到了极致。\n这篇讲义希望用一个故事把递归的思想讲明白。假设一个国家的国王有一个任务：计算 $1+2+\\cdots+100$。日理万机的国王肯定不会一个一个累加浪费时间，但他也没有聪明到能够发现高斯公式。幸运的是他有一批听话的大臣可以使用，于是他设计了一个这样的策略：\n让丞相去计算 $1+2+\\cdots +99$，等他把结果返回给我了，我只要计算这个结果+100，答案就出来了。\n丞相同样忙碌且数学天分不高，但幸运的是他也有一批手下可以召唤，于是他设计了一个同样的策略：\n找一个手下大臣去计算 $1+2+\\cdots +98$，等他把结果返回给我了，我只要计算这个结果+99，就能向国王交差了。\n这个王国的所有人都深谙资本主义压榨下属的套路 (bushi)，于是这个任务被一级一级传递下去，直到村长拿到 $1+2+3$ 时，把 $1+2$ 这个任务分配给了一个普通的村民。村民没有手下可以使用了，但幸运的是这个问题足够简单，他想都没想就机智地得到了答案 $3$ 并将结果返回给了村长。村长收到 $3$ 后计算出 $3+3=6$，又将结果返回给了镇长……一路下放的任务在收结果的过程中又被一路上传回去，最后国王收到了丞相的回复：$4950$，于是他完成了最后一步加法，$4950+100=5050$，并很高兴地宣称该任务圆满结束。\n这样的写法可能还不足以唤醒你在课堂上学习的递归“套路”。我们不妨写的更形式化一点：令 $F(n)$ 表示计算 $1+2+\\cdots +n$ 这个任务，那么国王的任务是计算 $F(100)$，丞相的任务是计算 $F(99)$……镇长的任务是计算 $F(4)$，村长的任务是计算 $F(3)$。不论这个参数是大是小，他们都采取了相同的战术： $$ F(n)=F(n-1)+n $$ 只有村民不一样，他的任务就是一个简单的加法。所以整个王国的策略可以被归纳为 $$ F(n)= \\begin{cases} 3\u0026amp;,n=2\\\\ F(n-1)+n\u0026amp;,n\\geq 3 \\end{cases} $$ 这就是递归的基本思想：如果一个大任务 (例如 $F(n)$) 可以被分解成一个性质相同但规模更小的任务 (例如 $F(n-1)$) 以及一些简单的额外运算 (例如 $+n$)，那么这个问题就非常适合用递归解决。我们可以为上面的递归加法写一个程序：","tags":null,"title":"递归","type":"docs"}]