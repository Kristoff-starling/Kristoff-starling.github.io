<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Networking: A Top-Down Approach | Yuyao Wang&#39;s Homepage</title>
    <link>https://kristoff-starling.github.io/posts/booknotes/network-topdown/</link>
      <atom:link href="https://kristoff-starling.github.io/posts/booknotes/network-topdown/index.xml" rel="self" type="application/rss+xml" />
    <description>Computer Networking: A Top-Down Approach</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 21 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Computer Networking: A Top-Down Approach</title>
      <link>https://kristoff-starling.github.io/posts/booknotes/network-topdown/</link>
    </image>
    
    <item>
      <title>Chapter 2: Application Layer</title>
      <link>https://kristoff-starling.github.io/posts/booknotes/network-topdown/ch02/</link>
      <pubDate>Fri, 21 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/booknotes/network-topdown/ch02/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#21-principles-of-network-applications&#34;&gt;2.1 Principles of Network Applications&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#211-network-application-architectures&#34;&gt;2.1.1 Network Application Architectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#212-processes-communicating&#34;&gt;2.1.2 Processes Communicating&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#client-and-server-processes&#34;&gt;Client and Server Processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#the-interface-between-the-process-and-the-computer-network&#34;&gt;The Interface Between the Process and the Computer Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#addressing-processes&#34;&gt;Addressing Processes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#213-transport-services-available-to-applications&#34;&gt;2.1.3 Transport Services Available to Applications&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#reliable-data-transfer&#34;&gt;Reliable Data Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#throughput&#34;&gt;Throughput&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#timing&#34;&gt;Timing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#security&#34;&gt;Security&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#214-transport-services-provided-by-the-internet&#34;&gt;2.1.4 Transport Services Provided by the Internet&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#tcp-services&#34;&gt;TCP Services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#udp-services&#34;&gt;UDP Services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#services-not-provided-by-internet-transport-protocols&#34;&gt;Services Not Provided by Internet Transport Protocols&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#215-application-layer-protocols&#34;&gt;2.1.5 Application-Layer Protocols&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#216-network-applications-covered-in-this-book&#34;&gt;2.1.6 Network Applications Covered in This Book&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#22-the-web-and-http&#34;&gt;2.2 The Web and HTTP&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#221-overview-of-http&#34;&gt;2.2.1 Overview of HTTP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#222-non-persistent-and-persistent-connections&#34;&gt;2.2.2 Non-Persistent and Persistent Connections&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#http-with-non-persistent-connections&#34;&gt;HTTP with Non-Persistent Connections&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#http-with-persistent-connections&#34;&gt;HTTP with Persistent Connections&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#223-http-message-format&#34;&gt;2.2.3 HTTP Message Format&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#http-request-message&#34;&gt;HTTP Request Message&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#http-response-message&#34;&gt;HTTP Response Message&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#224-user-server-interaction-cookies&#34;&gt;2.2.4 User-Server Interaction: Cookies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#225-web-caching&#34;&gt;2.2.5 Web Caching&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#the-conditional-get&#34;&gt;The Conditional GET&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#226-http2&#34;&gt;2.2.6 HTTP/2&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#http2-framing&#34;&gt;HTTP/2 Framing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#response-message-prioritization-and-server-pushing&#34;&gt;Response Message Prioritization and Server Pushing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#23-electronic-mail-in-the-internet&#34;&gt;2.3 Electronic Mail in the Internet&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#231-smtp&#34;&gt;2.3.1 SMTP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#232-mail-message-formats&#34;&gt;2.3.2 Mail Message Formats&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#233-mail-access-protocols&#34;&gt;2.3.3 Mail Access Protocols&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#24-dns---the-internets-directory-service&#34;&gt;2.4 DNS - The Internet&amp;rsquo;s Directory Service&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#241-services-provided-by-dns&#34;&gt;2.4.1 Services Provided by DNS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#242-overview-of-how-dns-works&#34;&gt;2.4.2 Overview of How DNS Works&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#a-distributed-hierarchical-database&#34;&gt;A Distributed, Hierarchical Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#dns-caching&#34;&gt;DNS Caching&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#243-dns-records-and-messages&#34;&gt;2.4.3 DNS Records and Messages&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#dns-message&#34;&gt;DNS Message&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#inserting-records-into-the-dns-database&#34;&gt;Inserting Records into the DNS Database&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#25-peer-to-peer-file-distribution&#34;&gt;2.5 Peer-to-Peer File Distribution&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#scalability-of-p2p-architecture&#34;&gt;Scalability of P2P Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#bittorrent&#34;&gt;BitTorrent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#26-video-streaming-and-content-distribution-networks&#34;&gt;2.6 Video Streaming and Content Distribution Networks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#261-internet-video&#34;&gt;2.6.1 Internet Video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#262-http-streaming-and-dash&#34;&gt;2.6.2 HTTP Streaming and DASH&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#263-content-distribution-networks&#34;&gt;2.6.3 Content Distribution Networks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#cdn-operation&#34;&gt;CDN Operation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#cluster-selection-strategies&#34;&gt;Cluster Selection Strategies&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#264-case-studies-netflix-and-youtube&#34;&gt;2.6.4 Case Studies: Netflix and YouTube&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#netflix&#34;&gt;Netflix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#youtube&#34;&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#27-socket-programming-creating-network-applications&#34;&gt;2.7 Socket Programming: Creating Network Applications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;21-principles-of-network-applications&#34;&gt;2.1 Principles of Network Applications&lt;/h2&gt;
&lt;p&gt;开发网络应用的核心是书写可以在不同的终端设备上运行的代码——值得注意的是我们不需要使我们的程序可以在 network core 中运行，因为 network core 中的 router/switch 根本没有应用层。&lt;/p&gt;
&lt;h3 id=&#34;211-network-application-architectures&#34;&gt;2.1.1 Network Application Architectures&lt;/h3&gt;
&lt;p&gt;需要注意的是 application architecture 和之前的 network architecture (即应用/传输/网络/链路/物理五层架构) 是不同的。&lt;strong&gt;应用架构 (application architecture)&lt;/strong&gt; 由软件开发者提出，用来描述一个网络应用应当以什么样的结构分布在各个终端设备上。现在最流行的两种应用架构是所谓的 client-server 架构和 P2P 架构。&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;客户机-服务器架构 (client-server architecture)&lt;/strong&gt; 中，有一台一直运作的主机称为&lt;strong&gt;服务器 (server)&lt;/strong&gt;，它的功能是为许许多多的其他主机，称为&lt;strong&gt;客户机 (client)&lt;/strong&gt;，提供服务。在 client-server 架构中，不同的客户机之间不会直接建立通讯，他们都只和服务器交互，服务器有一个固定且为大家所知的 IP 地址，客户机可以通过向该 IP 地址发送 packet 的方式与服务器建立通讯。&lt;/p&gt;
&lt;p&gt;通常在 client-server 应用中，一个服务器主机很难支撑繁重的业务，所以开发者一般会建立&lt;strong&gt;数据中心 (data center)&lt;/strong&gt;。数据中心里有大量的主机，它们合起来对外形成一个虚拟服务器。&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;点对点架构 (peer=to=peer/P2P architecture)&lt;/strong&gt; 中，我们不再有服务器和数据中心的概念。用户的主机之间直接建立联系，这种 pair 被称为&lt;strong&gt;同伴 (peer)&lt;/strong&gt;。P2P 的一大优势在于其 self-scalability，例如在一个 P2P 文件分享应用中，虽然每个用户索取文件会为网络带来 workload，但每个用户也会将自己的文件贡献给同伴，为网络增添服务能力。此外，P2P 节省了建设服务器等服务基础设施的钱财和精力。不过 P2P 高度去中心化的结构使其在安全性、可靠性等方面存在一定的挑战。&lt;/p&gt;
&lt;h3 id=&#34;212-processes-communicating&#34;&gt;2.1.2 Processes Communicating&lt;/h3&gt;
&lt;p&gt;这个 section 主要讨论位于不同终端设备的程序之间是如何交互的。根据操作系统的术语，事实上并不是程序在交互，而是进程在交互。两个进程处于两个不同终端设备的应用层，它们通过向网络发送报文的方式交换信息。&lt;/p&gt;
&lt;h4 id=&#34;client-and-server-processes&#34;&gt;Client and Server Processes&lt;/h4&gt;
&lt;p&gt;对于每一对通信的进程，我们通常将其中提供服务的进程称为 server，使用服务的进程称为 client。例如在 Web 应用中，网页浏览器是 client 进程，Web server 是 server 进程；在 P2P 文件共享中，下载文件的进程是 client 进程，上传文件的进程是 server 进程。事实上，在 P2P 中，很多情况下一个进程可能同时在上传和下载，但具体到一个固定的 pair 中时它要么是 server 要么是 client。&lt;/p&gt;
&lt;p&gt;关于 client side 和 server side 有一个更正式的定义：对于一对正在通信的进程来说，初始化通信会话的那个进程是 client，那个等待它人与自己连接并开启会话的进程是 server。&lt;/p&gt;
&lt;h4 id=&#34;the-interface-between-the-process-and-the-computer-network&#34;&gt;The Interface Between the Process and the Computer Network&lt;/h4&gt;
&lt;p&gt;应用层的 application 通过&lt;strong&gt;套接字 (socket)&lt;/strong&gt; 发送和接收消息。socket 是传输层向应用层提供的 API，它为应用层提供的保证是 application 只要向 socket 传输内容，下层的基础设施就会将内容传输到连接另外一端的 socket。应用开发者不能也不应该直接触碰底层的传输细节，他们只能通过选择传输协议和给定一些参数的方式来定制自己所需的服务。&lt;/p&gt;
&lt;h4 id=&#34;addressing-processes&#34;&gt;Addressing Processes&lt;/h4&gt;
&lt;p&gt;发送消息时发送方需要知道接收主机的 &lt;strong&gt;IP 地址 (IP address)&lt;/strong&gt;。此外，由于一个主机可以同时运行多个网络应用/进程，我们还需要一个方法来辨别接收消息的进程，这就是&lt;strong&gt;端口号 (port number)&lt;/strong&gt; 的功能。端口号有一些convention，比如 Web server 的端口号通常是 80，mail server 通常是 25 等等。&lt;/p&gt;
&lt;h3 id=&#34;213-transport-services-available-to-applications&#34;&gt;2.1.3 Transport Services Available to Applications&lt;/h3&gt;
&lt;p&gt;application 将消息发送到 socket 之后，下面的传输层协议就要负责将消息传到对面的 socket。大部分的网络提供多种传输协议，不同的协议在各项性能指标上存在差异，我们一般从 reliable data transfer, throughput, timing 和 security 四个维度来衡量一个传输协议。&lt;/p&gt;
&lt;h4 id=&#34;reliable-data-transfer&#34;&gt;Reliable Data Transfer&lt;/h4&gt;
&lt;p&gt;packet 在网络传输的过程中可能因为各种原因丢失，对于许多应用 (例如电子邮件、网络银行等)，丢失数据会造成严重的后果。如果一个协议可以保证一端发出的数据可以完整地被另一端接收，那么我们称该协议提供&lt;strong&gt;可靠数据传输 (reliable data transfer)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;对于一些 loss-tolerable 的应用，比如各种流媒体，它们就不必要选择提供可靠数据传输的协议。丢失一点数据可能只是造成一点画面失真而已，它们更在乎传输的流畅度。&lt;/p&gt;
&lt;h4 id=&#34;throughput&#34;&gt;Throughput&lt;/h4&gt;
&lt;p&gt;网络的拥塞程度会对传输的实际吞吐率产生很大的影响。有的传输协议可以向应用层提供 throughput 的保证，例如无论网络多么拥塞我都保证吞吐率不小于 $r$ bits/sec。这样的保证对于一些 bandwidth-sensitive application 及其重要。对于像电子邮件、文件传输这样的 elastic application，即时吞吐率的保证就无关紧要。&lt;/p&gt;
&lt;h4 id=&#34;timing&#34;&gt;Timing&lt;/h4&gt;
&lt;p&gt;类似于 throughput，传输协议也可以提供 timing 保证，例如保证一个 bit 在写入 socket 后可以在 $t$ sec 内传输到另一端的 socket。这种保证对即时应用十分重要。&lt;/p&gt;
&lt;h4 id=&#34;security&#34;&gt;Security&lt;/h4&gt;
&lt;p&gt;传输协议可以提供一些安全性的保证，例如在发送端对信息加密，接收端再对信息解密，这样中途即使被窃听也不会泄露用户隐私。&lt;/p&gt;
&lt;h3 id=&#34;214-transport-services-provided-by-the-internet&#34;&gt;2.1.4 Transport Services Provided by the Internet&lt;/h3&gt;
&lt;p&gt;因特网 (或者更一般地，TCP/IP 网络) 提供两种传输协议：TCP 和 UDP。当我们编写网络应用时，我们需要在这两个传输协议中做出选择。&lt;/p&gt;
&lt;h4 id=&#34;tcp-services&#34;&gt;TCP Services&lt;/h4&gt;
&lt;p&gt;TCP 协议为发送和接收双方提供如下服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Connection-oriented service: TCP 会让传输双方在开始正式传输信息之前先交换一些控制信息，这个过程被称为&lt;strong&gt;握手 (handshaking)&lt;/strong&gt;。完成握手后，两个进程的 socket 之间会建立起 &lt;strong&gt;TCP 连接 (TCP connection)&lt;/strong&gt;。这个 TCP connection 是双向的，即两个进程可以同时互发消息。消息传输完成后，进程必须销毁这个连接。&lt;/li&gt;
&lt;li&gt;Reliable data transfer service: TCP 保证一方发送的数据会不重复不以漏地传输到另一方，且接收消息的顺序和发送消息的顺序相同。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TCP 中还有一些拥塞控制机制，当发送方和接收方之间的网络过于拥塞时，TCP 会暂时挂起发送进程以缓解网络的拥塞程度。该机制并不是直接为通信进程服务的，而是为整个互联网提供的福利。&lt;/p&gt;
&lt;h4 id=&#34;udp-services&#34;&gt;UDP Services&lt;/h4&gt;
&lt;p&gt;UDP 是一个轻量级的传输协议，它只提供最少的能保证正常运转的服务。UDP 在开始通信之前不会握手；传输不具有可靠性，即不能保证发送的数据一定会被收到；此外，在 UDP 中发送的消息可能会乱序地到达接收方。UDP 中也没有拥塞控制机制，发送方可以以任何 (物理限制以内的) 速率把数据送出去。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Securing TCP&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;无论是 TCP 还是 UDP 都不会对数据进行任何加密，这使得用户数据在传输途中随时可能被窃取。因此互联网社区推出了 TCP 的一个增强服务：&lt;strong&gt;Transport Layer Security (TLS)&lt;/strong&gt;。有 TLS 增强的 TCP 除了可以提供 TCP 原有的所有服务，还可以提供一些安全服务，例如 encryption, data integrity, end-point authentication 等。&lt;/p&gt;
&lt;p&gt;值得注意的是 TLS 不是和 TCP, UDP 同一级别的传输协议，它只是一个“增强扩展包”。想要使用 TLS 需要在客户端和服务器端都安装 TLS 代码。TLS 提供一套和 TCP 几乎相同的 API 接口，用户把信息传输给 TLS socket 后，TLS 对数据做加密，然后传给 TCP socket，TCP 将数据传到另一端的 TCP socket 后，TCP 把加密数据传给 TLS，TLS 完成解密后将数据通过 TLS socket 提供给上层应用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;services-not-provided-by-internet-transport-protocols&#34;&gt;Services Not Provided by Internet Transport Protocols&lt;/h4&gt;
&lt;p&gt;值得注意的是无论是 TCP 还是 UDP 都没有提供 throughput 或 timing 的保证，但这并不意味着即时通讯软件无法在互联网中使用，因为应用的开发者尽可能保证了它们的产品在糟糕的网络环境下也能正常运转。&lt;/p&gt;
&lt;p&gt;大部分的网络应用 (例如电子邮件、文件传输、远程控制) 都采用 TCP 协议，因为 reliable data transfer 对它们来说非常重要。一些网络电话应用对数据丢失容忍度较高，可能会采取 UDP 协议来绕过 TCP 的拥塞控制和 packet overhead；但由于很多防火墙会拦截大部分的 UDP traffic，所以网络电话应用通常会把 TCP 当作 UDP 失效时的后备选项。&lt;/p&gt;
&lt;h3 id=&#34;215-application-layer-protocols&#34;&gt;2.1.5 Application-Layer Protocols&lt;/h3&gt;
&lt;p&gt;之前我们讨论的都是下层如何传输 message，但 message 本身的结构和内容也十分重要。&lt;strong&gt;应用层协议 (application-layer protocol)&lt;/strong&gt; 负责这一部分。通常来说应用层协议会定义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;message 的类型 (request/response etc.)；&lt;/li&gt;
&lt;li&gt;各种类型的 message 的语法、各个字段的语义；&lt;/li&gt;
&lt;li&gt;一系列规则，定义一个进程应该什么时候以什么方式发送 message。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们需要注意区分网络应用和应用层协议：后者只是前者的一个组成部分 (不过是很重要的一部分)。以网页为例，网页这个应用包含了文档的格式标准 (HTML)、网页浏览器、网页服务器，以及应用层协议。网页所采用的 HTTP 协议规定了浏览器和服务器交换数据的方式，只是网页这一应用的一个组成部分。&lt;/p&gt;
&lt;h3 id=&#34;216-network-applications-covered-in-this-book&#34;&gt;2.1.6 Network Applications Covered in This Book&lt;/h3&gt;
&lt;p&gt;本书讨论 5 个重要的应用：网页、电子邮件、目录服务、视频流和 P2P。&lt;/p&gt;
&lt;h2 id=&#34;22-the-web-and-http&#34;&gt;2.2 The Web and HTTP&lt;/h2&gt;
&lt;p&gt;在 20 世纪 90 年代初，因特网仍然只是一个研究员、学者、高校学生远程连接、传输数据的小圈子。但 World Wide Web 这一应用的出现让因特网火爆全球。网页最大的特点就是提供 on demand 的服务，用户可以在任意时刻获取信息，而不是像看电视，听收音机那样要在指定的时间守候。&lt;/p&gt;
&lt;h3 id=&#34;221-overview-of-http&#34;&gt;2.2.1 Overview of HTTP&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;超文本传输协议 (HyperText Transfer Protocol, HTTP)&lt;/strong&gt; 是网页使用的应用层协议，处在整个应用的核心位置。HTTP 分为客户端程序和服务端程序，这两个程序通过交换 HTTP message 通信，HTTP 定义了 message 的结构和消息交换的方式。&lt;/p&gt;
&lt;p&gt;首先介绍一些概念：一个 Web page (aka. document) 包含一系列的对象，一个对象就是一个可以通过 URL 索引的文件 (HTML, JPG, Javascript, CSS 等等)。Web page 包含的对象中有一个是 base HTML 文件，该文件通过 URL 去索引别的对象。每个 URL 都有 host name 和 path name 两个部分。例如&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://www.someSchool.edu/someDepartment/picture.gif
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;中 &lt;code&gt;www.someSchool.edu&lt;/code&gt; 是 host name，&lt;code&gt;/someDepartment/picture.gif&lt;/code&gt; 是 path name。&lt;/p&gt;
&lt;p&gt;HTTP 规定的 client-server 交互方式简单来说就是 client 向 server 发送 HTTP request，server 收到后向 client 发送 HTTP response。HTTP 使用 TCP 作为下层的传输协议，因此 TCP connection 建立后，在 client 眼中它只要把 HTTP request 发送到 socket，然后等一会儿这个“神奇的小门”就会把 HTTP response 呈现出来；在 server 眼中它只要从 socket 中取出 HTTP request，分析后把相关的数据用 socket 传回去即可。计算机网络的层状结构使得 HTTP 这样的顶层协议完全不需要担心数据丢失、重新发送等问题，这些细节都由 TCP 以及更下次层的协议栈搞定。&lt;/p&gt;
&lt;p&gt;服务器端不会存储任何的额外信息。例如如果 client 连续两次请求同一个文件，server 就会连续发两次，而不会智能地在第二次回复“你已经请求过这个文件了”。因此 HTTP 是一种&lt;strong&gt;无状态协议 (stateless protocol)&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;222-non-persistent-and-persistent-connections&#34;&gt;2.2.2 Non-Persistent and Persistent Connections&lt;/h3&gt;
&lt;p&gt;在许多网络应用中 client 和 server 之间会进行多次通信，于是一个需要思考的问题是应该为每一次通信建立一个 TCP connection 还是用一个 TCP connection 完成多次通信。前者被称为 &lt;strong&gt;non-persistent connection&lt;/strong&gt;，后者被称为 &lt;strong&gt;persistent connection&lt;/strong&gt;。这两者各有利弊，虽然 HTTP 默认 persistent，但 client/server 可以选择将其配置为 non-persistent。&lt;/p&gt;
&lt;h4 id=&#34;http-with-non-persistent-connections&#34;&gt;HTTP with Non-Persistent Connections&lt;/h4&gt;
&lt;p&gt;在 non-persistent 的连接中，client 向 server 索取一个页面 (base HTML + 10 JPG) 会经历如下的过程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;client 与 server 建立 TCP connection，并向 server 发送 HTTP request。&lt;/li&gt;
&lt;li&gt;server 接收到请求后，将相关的文件传输回去，并告诉 TCP 关闭连接 (连接不会直接关闭，会等 client 接收到文件再关闭)。&lt;/li&gt;
&lt;li&gt;client 接收到文件后 (此时 connection 正式关闭)，发现 HTML 文件中索引了 10 张图片，于是用 step1&amp;amp;2 的方式将 10 张图片拿到手。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到在 non-persistent connection 中，每个 TCP connection 只能传输一个对象。不过上述过程也有一些优化的空间，比如获取图片时 client-server 之间可以并行地开多个 connection 一起传输，这样可以节省时间。&lt;/p&gt;
&lt;p&gt;之前的描述中我们简化了建立连接的过程，事实上建立 TCP connection 有一定的 overhead。我们定义 &lt;strong&gt;round-trip time (RTT)&lt;/strong&gt; 为一个 packet 从 client 到 server 再回到 client 所需的时间，client 和 server 之间完成一个对象的传输需要经历“三步握手”—— client 向 server 发送一个 segment、server 回复一个 segment (此时连接建立)、client 向 server 发送 request，然后 server 将对象文件以流水线的方式通过 connection 发送回来。获取一个对象总共需要的时间为
$$
2\times RTT+\frac{Size(object)}{\text{server&amp;rsquo;s transmission rate}}
$$&lt;/p&gt;
&lt;h4 id=&#34;http-with-persistent-connections&#34;&gt;HTTP with Persistent Connections&lt;/h4&gt;
&lt;p&gt;建立 persistent connection 可以免去创建连接的 overhead，而且多次 request 可以用流水线的方式发送，不需要等前一个 request 得到 response 后再发送下一个，因此效率很高。&lt;/p&gt;
&lt;h3 id=&#34;223-http-message-format&#34;&gt;2.2.3 HTTP Message Format&lt;/h3&gt;
&lt;h4 id=&#34;http-request-message&#34;&gt;HTTP Request Message&lt;/h4&gt;
&lt;p&gt;一个 HTTP request message 的通用格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;method URL Version \r\n        // Request line
HeaderFieldName: value \r\n    /*                */
    ...                        /*  Header lines  */
HeaderFieldName: value \r\n    /*                */
\r\n
...                            /*               */
...                            /*  Entity body  */
...                            /*               */
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;request message 的第一行被称为 &lt;strong&gt;request line&lt;/strong&gt;，后续的若干行称为 &lt;strong&gt;header line&lt;/strong&gt;。下面是一个具体的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;GET /somedir/page.html HTTP/1.1
Host: www.someschool.edu
Connection: close
User-agent: Mozilla/5.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Request line 中，GET 是一个 method (最常用)，通常用于从服务器获取内容；URL 指定了服务器中文件的路径；Version 指定了 HTTP 版本。Header line 中，&lt;code&gt;Host&lt;/code&gt; 指定了主机地址；&lt;code&gt;Connection: close&lt;/code&gt; 表示建立一个 non-persistent 的连接，本次传输完成后就关闭；&lt;code&gt;User-agent&lt;/code&gt; 指定了客户端 (浏览器) 的版本，服务器可以根据版本返回更加适配的 message (比如同一个文件的不同版本)。除此之外还有很多的 header line 可以选择。&lt;/p&gt;
&lt;p&gt;GET 方法后面没有 entity body，但其他方法后面是可以有 entity body 的，例如 POST 方法通常用于填写网页中的表格，用户填写的内容就放在 entity body 中传给服务器。(注：值得一提的是事实上现在大部分的应用还是使用 GET 方法来传输填表结果，它们会把填写的内容放到 URL 里，比如填写了 apple 和 banana，那么 URL 就会形如 &lt;code&gt;www.somesite.com/fruitsearch?apple&amp;amp;banana&lt;/code&gt;。)&lt;/p&gt;
&lt;p&gt;除了 GET 和 POST，HEAD 方法和 GET 类似，但服务器不会返回请求的对象，通常用于 debugging；PUT 方法用于向服务器上传文件；DELETE 方法用于在服务器中删除文件。&lt;/p&gt;
&lt;h4 id=&#34;http-response-message&#34;&gt;HTTP Response Message&lt;/h4&gt;
&lt;p&gt;一个 HTTP request message 的通用格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;version StatusCode Phrase \r\n  // Status line
HeaderFieldName: value \r\n     /*                */
    ...                         /*  Header lines  */
HeaderFieldName: value \r\n     /*                */
\r\n
...                             /*               */
...                             /*  Entity body  */
...                             /*               */
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Response message 的第一行被称为 &lt;strong&gt;status line&lt;/strong&gt;，后续的若干行被称为 &lt;strong&gt;header line&lt;/strong&gt;。下面是一个具体的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-http&#34;&gt;HTTP/1.1 200 OK
Connection: close
Date: Tue, 18 Aug 2015 15:44:04 GMT
Server: Apache/2.2.3 (CentOS)
Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT
Content-Length: 6821
Content-Type: text/html
(data data data data data ...)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;括号中的 &lt;code&gt;(data data ...)&lt;/code&gt; 表示 entity body 的内容 (即 client 要的数据)。&lt;/p&gt;
&lt;p&gt;status line 中，&lt;code&gt;HTTP/1.1&lt;/code&gt; 表示了 protocol version，&lt;code&gt;200 OK&lt;/code&gt; 是 status code 和对应的状态描述。常见的 status code 如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;200 OK&lt;/code&gt;：请求成功。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;301 Moved Permanently&lt;/code&gt;：请求的资源已经被永久移除。该资源的新地址会在 header line 区域中以 &lt;code&gt;Location: ...&lt;/code&gt; 的形式给出。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;400 Bad Request&lt;/code&gt;：请求无法解析。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;404 Not Found&lt;/code&gt;：请求的东西不存在。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;505 HTTP Version Not Supported&lt;/code&gt;：HTTP 协议版本不支持。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;header line 中，比较有意思的一些 line 包括：&lt;code&gt;Connection: close&lt;/code&gt; 告诉 client 该消息传输完成后 TCP connection 就会被关闭；&lt;code&gt;Date:&lt;/code&gt; 中的日期指的是服务器接收到请求，将资源提取出来的时间 (而不是文件的创建时间)；&lt;code&gt;Content-Type&lt;/code&gt; 指明了返回文件的类型，文件的类型由该字段决定而不由其扩展名决定。&lt;/p&gt;
&lt;p&gt;浏览器的版本、类型，用户配置，以及当前本地是否有 cached 的对象旧版本……这些因素都会影响 client 发送 request 时包含哪些 header line，在服务器端影响因素是类似的。&lt;/p&gt;
&lt;h3 id=&#34;224-user-server-interaction-cookies&#34;&gt;2.2.4 User-Server Interaction: Cookies&lt;/h3&gt;
&lt;p&gt;我们之前提到 HTTP 是一个 stateless 的协议，但很多时候服务器希望能识别用户以及记录用户的状态，从而提供更好的服务/将一些用户写入黑名单。HTTP 使用 cookie 完成该功能。&lt;/p&gt;
&lt;p&gt;Cookie 技术包含 4 个组成部分：(1) HTTP response message 中的 cookie header line (2) HTTP request message 中的 cookie header line (3) 浏览器负责管理的本地 cookie file (4) 服务器端存储 cookie 相关信息的数据库。 Cookie 的工作流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假设一个新用户第一次访问某网站 (发送 request message)，该网站识别到这是一个新用户后，会在数据库中为该用户创建一个 cookie id、在数据库中存储一些用户相关的信息，并在 response message 中加入一条 cookie header line，格式为 &lt;code&gt;Set-cookie: cookie-id&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;浏览器处理 response message 发现形如 &lt;code&gt;Set-cookie&lt;/code&gt; 的 header line 后，会把该服务器分配的 cookie id 存入本地的一个 cookie file 中。&lt;/li&gt;
&lt;li&gt;之后这个用户如果再访问该网站，浏览器会检索 cookie file，发现有对应的 cookie id 则会以 &lt;code&gt;Cookie: cookie-id&lt;/code&gt; 的形式在 request message 中添加一个 cookie header line。服务器处理 request message 时则可以根据 cookie-id 在数据库中调取该用户相关的信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;尽管 Cookie 可以优化用户的上网体验，但其在隐私泄漏上的问题也使其倍受争议。&lt;/p&gt;
&lt;h3 id=&#34;225-web-caching&#34;&gt;2.2.5 Web Caching&lt;/h3&gt;
&lt;p&gt;Web cache (也称 proxy server) 通常由 ISP 购买和安装，其作用和计算机系统中的 cache 类似：当用户希望从真正的服务器获取文件时，它会和 proxy server 建立 TCP connection，proxy server 会首先检查自己本地有没有该文件，如果有就直接传回给用户，如果没有则会与真正的服务器建立一个 TCP connection，获取文件后一方面传回给用户，一方面在自己本地留一个副本以便后续用户直接取用。&lt;/p&gt;
&lt;p&gt;Web cache 有两点好处：一方面它与用户机器建立连接、传输数据的速度更快，可以优化用户的 delay；另一方面在一个小局域网中安装 web cache 可以防止大量的请求外溢到因特网中，从而减少因特网的流量压力，减少整个网络的 queuing delay 等等。&lt;/p&gt;
&lt;h4 id=&#34;the-conditional-get&#34;&gt;The Conditional GET&lt;/h4&gt;
&lt;p&gt;所有的类 cache 策略都要考虑数据一致性的问题。HTTP 协议提供了 conditional GET 这一机制来使 cache 完成和服务器的同步。具体来说，当 cache 希望确认自己手上的副本是否是最新版时，它会向真正的服务器发送一个 GET request，其中增加一个 header line：&lt;code&gt;If-modified-since: xxx&lt;/code&gt;。服务器检查本地文件的最后修改时间，如果正好匹配则会返回空消息告诉 cache 副本已是最新 (status code 为 &lt;code&gt;304 Not Modified&lt;/code&gt;)，否则会将新版本传回。&lt;/p&gt;
&lt;h3 id=&#34;226-http2&#34;&gt;2.2.6 HTTP/2&lt;/h3&gt;
&lt;p&gt;2015 年标准化的 HTTP/2 相较于 HTTP/1.1 的主要优势是它能够只使用一个 TCP connection 完成 response multiplexing。&lt;/p&gt;
&lt;p&gt;HTTP/1.1 默认使用 persistent TCP connection，即只使用一个 TCP connection 从一个服务器获取多个文件。这样的做法存在一个 &lt;strong&gt;Head of Line (HOL) blocking&lt;/strong&gt; 的问题：假设当前网页的第一个 object 是一个特别大的视频，后面跟着的是一堆小的 object，那么 HTTP/1.1 按顺序传输会导致在第一个 object 上花费很多时间，从而整个网页很久都完全显现不出来。为了绕过这个问题，HTTP/1.1 会开很多个 TCP connection 来并行传输。不过多个 TCP connection 会共享带宽，这使得网络应用会尽可能“多开一点” TCP connection 以占取更大份额的带宽 (比如两个应用各开一个，那么一人一半带宽，但如果有人恶意开了 10 个连接，他就能占据 10/11 的带宽)。&lt;/p&gt;
&lt;h4 id=&#34;http2-framing&#34;&gt;HTTP/2 Framing&lt;/h4&gt;
&lt;p&gt;HTTP/2 解决这个问题的方法类似于操作系统的分时多任务：在 HTTP/1.1 中一个 response message 没法拆开，但 HTTP/2 允许将一个大的 message 拆成若干个 frame，然后多个 message 轮流一人一个 frame 地传输，这样小 message 就可以很快地传完。&lt;/p&gt;
&lt;img src=&#34;https://kristoff-starling.github.io/img/top-down/HTTP1vs2-frame.png&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;该策略的技术难点是如何将大的 message 拆分。HTTP/2 里专门设计了一个 framing sub-layer，负责 message 的拆分和重组。&lt;/p&gt;
&lt;h4 id=&#34;response-message-prioritization-and-server-pushing&#34;&gt;Response Message Prioritization and Server Pushing&lt;/h4&gt;
&lt;p&gt;HTTP/2 在“分时多任务”的基础上支持一定程度的“用户自定义”，例如用户可以为各个 request 设置优先级、依赖关系等等。&lt;/p&gt;
&lt;p&gt;HTTP/2 的另一个特性是允许 server 对一个 request 返回多个 response。例如用户请求一个网页，服务器自动分析发现这个网页附带一些 object，就可以 response 时 push 一些额外的 object 给客户端，这样在用户发出 object 请求之前就返回文件，省去了一些延迟。&lt;/p&gt;
&lt;h2 id=&#34;23-electronic-mail-in-the-internet&#34;&gt;2.3 Electronic Mail in the Internet&lt;/h2&gt;
&lt;p&gt;电子邮件系统主要由三个部分组成：&lt;strong&gt;user agent&lt;/strong&gt;, &lt;strong&gt;mail server&lt;/strong&gt; 和&lt;strong&gt;简单邮件传输协议 (Simple Mail Transfer Protocol, SMTP)&lt;/strong&gt;。每个电子邮件用户都在自己的 mail server 上有自己的&lt;strong&gt;邮箱 (mailbox)&lt;/strong&gt;。user agent 可以理解为在用户主机上和自己的 mail server 交互，操控邮箱的软件。假设 Alice 给 Bob 发送邮件，首先 Alice 的 user agent 将邮件上传到 Alice 的邮箱中，然后 mail server 负责将邮件发送到 Bob 的 mail server (更准确地说，是将该邮件 append 到 &lt;strong&gt;message queue&lt;/strong&gt; 中，等待发送)，Bob 的 mail server 接收到邮件后将其存放在 Bob 的邮箱中。当 Bob 打开自己的 user agent 查看邮件时，user agent 将邮件内容从 mail server 上抓取下来。如果 Alice 的 mail server 迟迟无法发送成功，它在尝试多次后会删除这个 message 并向 Alice 返回发送失败。&lt;/p&gt;
&lt;p&gt;SMTP 协议负责的是不同 mail server 之间传输的部分。它使用 TCP 提供的 reliable data transfer service 传输邮件。SMTP 有 client 和 server 两个端，每个 mail server 既要运行 client 也要安装 server，它发送邮件时是 client，接收邮件时是 server。&lt;/p&gt;
&lt;h3 id=&#34;231-smtp&#34;&gt;2.3.1 SMTP&lt;/h3&gt;
&lt;p&gt;SMTP 是比 HTTP 古老得多的应用层协议。因此它有一些“过时的特征”，例如它要求整个 mail message 都要使用 7-bit 的 ASCII 码传输，这使得使用 SMTP 前后需要有 encoding/decoding 的额外步骤。&lt;/p&gt;
&lt;p&gt;SMTP 工作的基本流程为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mail server 将待发送的邮件放入 message queue 后，安装在 mail server 上的 SMTP 客户端发现有新邮件，于是根据其内容与目标地址建立 TCP connection，连接目标机器的 25 号端口。&lt;/li&gt;
&lt;li&gt;TCP connection 建立后双方会经过一个握手过程，该过程中双方会交换邮件的发送人、接收人等信息。&lt;/li&gt;
&lt;li&gt;握手完成后，正式开始邮件内容的传输。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是一个具体的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;S: 220 hamburger.edu
C: HELO crepes.fr
S: 250 Hello crepes.fr, pleased to meet you
C: MAIL FROM: &amp;lt;alice@crepes.fr&amp;gt;
S: 250 alice@crepes.fr ... Sender ok
C: RCPT TO: &amp;lt;bob@hamburger.edu&amp;gt;
S: 250 bob@hamburger.edu ... Recipient ok
C: DATA
S: 354 Enter mail, end with &amp;quot;.&amp;quot; on a line by itself
C: (data)
C: (data)
C: .
S: 250 Mesage accepted for delivery
C: QUIT
S: 221 hmburger.edu closing connection
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里所有的行都是 client/server 直接通过 TCP 传输的内容。client 在这里使用了 &lt;code&gt;HELO&lt;/code&gt; &lt;code&gt;MAIL FROM&lt;/code&gt; &lt;code&gt;RCPT TO&lt;/code&gt; &lt;code&gt;DATA&lt;/code&gt; &lt;code&gt;QUIT&lt;/code&gt; 等命令，server 对于每条命令都会返回 reply code 以及 (optional) 一些英文解释。&lt;/p&gt;
&lt;p&gt;值得注意的是 SMTP 使用 persistent TCP connection，即两个 mail server 之间可以通过一个 TCP connection 传输多封邮件。每封邮件的传输都从 &lt;code&gt;MAIL FROM&lt;/code&gt; 开始，到传输完数据后的 &lt;code&gt;.&lt;/code&gt; 结束。传输完所有邮件后 client 再使用 &lt;code&gt;QUIT&lt;/code&gt; 退出。&lt;/p&gt;
&lt;h3 id=&#34;232-mail-message-formats&#34;&gt;2.3.2 Mail Message Formats&lt;/h3&gt;
&lt;p&gt;SMTP 对邮件内容的格式也有一定的要求。一封邮件除了其主体内容外还有若干 header line，其中 &lt;code&gt;From&lt;/code&gt; 和 &lt;code&gt;To&lt;/code&gt; 这两个 header line 必须有，&lt;code&gt;Subject&lt;/code&gt; 等 header line 是可选的。一封典型的邮件内容如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;From: alice@crepes.fr
To: bob@hamburger.edu
Subject: Searching for the meaning of life.

(body) (body) (body) ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;需要注意的是之前提到的 &lt;code&gt;MAIL FROM&lt;/code&gt; &lt;code&gt;RCPT TO&lt;/code&gt; 和这里的 &lt;code&gt;From&lt;/code&gt; 和 &lt;code&gt;To&lt;/code&gt; 不一样：前者是两个 mail server 握手阶段使用的命令，后者是邮件本身内容的一部分。&lt;/p&gt;
&lt;h3 id=&#34;233-mail-access-protocols&#34;&gt;2.3.3 Mail Access Protocols&lt;/h3&gt;
&lt;p&gt;有人认为 Bob (接收者) 没有必要拥有一个额外的 mail server，他自己的终端设备就可以是 server，这样发送者直接把邮件发送到它的终端设备上就好。但一个问题是用户的终端设备并不一定一直处于联网状态 (比如没信号，或者没电关机了)，这样发送者就会发送失败。因此我们总是需要一台 24 小时待命的服务器负责接收邮件，Bob 在自己 available 的时候再去查看邮件。&lt;/p&gt;
&lt;p&gt;mail server 向 mail server 发送邮件使用 SMTP 协议，Alice (发送者) 向自己的 mail server 上传邮件也可以使用 SMTP 协议 (或者 HTTP) 协议，但在 Bob (接收者) 这一端，他不能使用 SMTP 协议，因为他需要的是一个 pull 操作，而 SMTP 是一个 push 协议。一般情况下，如果接收者使用网页版的 e-mail 或者手机应用，user agent 会使用 HTTP 协议来获取邮件；另外一种方式 (例如 Microsoft Outlook)，则是使用 &lt;strong&gt;Internet Mail Access Protocol (IMAP)&lt;/strong&gt; 协议来获取邮件。这两个协议都可以让 Bob 对位于 mail server 中的自己的邮箱里的内容进行访问、修改、标记等等。&lt;/p&gt;
&lt;h2 id=&#34;24-dns---the-internets-directory-service&#34;&gt;2.4 DNS - The Internet&amp;rsquo;s Directory Service&lt;/h2&gt;
&lt;p&gt;一台主机在网络中有多种”称呼方法“，最常见的 identifier 是 &lt;strong&gt;hostname&lt;/strong&gt;，例如 &lt;code&gt;www.facebook.com&lt;/code&gt;。hostname 对人类非常友好，但提供的信息有限，其不固定的长度也不便于路由器处理。因此网络实现中更普遍使用的 identifier 是 &lt;strong&gt;IP 地址 (IP address)&lt;/strong&gt;。IP 地址 (IPv4) 共占 4 个字节，用 4 个 &lt;code&gt;[0,256)&lt;/code&gt; 的整数表示。IP 地址有着严格的等级结构，就像 postal address 一样，越往后得到的信息越详细越细节。&lt;/p&gt;
&lt;h3 id=&#34;241-services-provided-by-dns&#34;&gt;2.4.1 Services Provided by DNS&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;域名系统 (domain name system, DNS)&lt;/strong&gt; 的主要任务是将 hostname 翻译成对应的 IP 地址。DNS 是一个应用层协议，在服务器端它有一群分布式的 DNS server 存储域名信息。DNS 协议基于 UDP 运行，默认端口号是 53。&lt;/p&gt;
&lt;p&gt;DNS 通常被 HTTP, SMTP 等其他应用层协议使用，例如 HTTP 协议想要发送 request message 时，会启动 DNS 应用的客户端，将域名发送给 DNS server，DNS server 返回对应的 IP 地址，然后 HTTP 通过 IP 地址建立 TCP connection。DNS 解析的步骤是通信过程的一个额外的 delay。&lt;/p&gt;
&lt;p&gt;除了域名解析，DNS 还提供以下的服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Host aliasing：一台有着比较复杂的 hostname 的机器还可以有一些更好记的别名。原本的 hostname 称为 &lt;strong&gt;canonical hostname&lt;/strong&gt;，别名则称为 alias hostname。DNS 提供将 alias hostname 翻译成 canonical hostname (以及 IP 地址) 的服务。&lt;/li&gt;
&lt;li&gt;Mail server aliasing：和 host aliasing 类似，mail server 也可以有更好记的别名，DNS 提供翻译服务。&lt;/li&gt;
&lt;li&gt;Load distribution：有很多网页背后会使用一群服务器来提供支持，每台服务器有各自的 IP 地址，但它们共享一个 hostname。当 DNS 解析这样的 hostname 时，它会返回一个 IP 地址的 list，不过每次请求它返回的结果都会 shift 一下，这是因为大部分的协议通常选择 list 的第一个 IP 地址发送请求，每次 shift 一下可以使得各个服务器均匀地承受流量。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;242-overview-of-how-dns-works&#34;&gt;2.4.2 Overview of How DNS Works&lt;/h3&gt;
&lt;p&gt;最简单的想法是使用一台 DNS server 处理所有的请求，可惜这样简单的设计至少有如下的一些问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A single point of failure：只要这台 DNS server 挂了，全球的 DNS 服务就都挂了。&lt;/li&gt;
&lt;li&gt;Traffic volume：这台服务器承受全球的 DNS request 的流量，会导致严重的 delay。&lt;/li&gt;
&lt;li&gt;Distant centralized database：地球上总有一些地区离这台服务器很远，这些地区使用 DNS 服务会有很高的 delay。&lt;/li&gt;
&lt;li&gt;Maintenance：这一台服务器需要大得惊人的容量来存储所有的 IP 地址，还需要不断更新。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，分布式成为了 DNS server 必须的选择。&lt;/p&gt;
&lt;h4 id=&#34;a-distributed-hierarchical-database&#34;&gt;A Distributed, Hierarchical Database&lt;/h4&gt;
&lt;p&gt;为了解决上面的问题，DNS 使用了大量的服务器，以 hierarchical 的方式组织起来分布在全世界。DNS 等级体系中共有三类服务器：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Root DNS server：全球共有 1000 多个，它们是 13 个不同的 root server 的复制，它们的主要任务是根据顶级域名提供对应的 TLD server 的 IP 地址。&lt;/li&gt;
&lt;li&gt;Top-level domain (TLD) server：每一个顶级域名——如 &lt;code&gt;com&lt;/code&gt; &lt;code&gt;org&lt;/code&gt; &lt;code&gt;net&lt;/code&gt; &lt;code&gt;edu&lt;/code&gt;，以及国家顶级域名——如 &lt;code&gt;us&lt;/code&gt; &lt;code&gt;cn&lt;/code&gt; &lt;code&gt;jp&lt;/code&gt; &lt;code&gt;fr&lt;/code&gt; 都各自有对应的 TLD server (或 server cluster)。它们的主要任务是根据下一级域名提供 authoritative server 的 IP 地址。&lt;/li&gt;
&lt;li&gt;Authoritative DNS server：每一个接入公网的组织都必须提供外界可访问的 DNS 记录，这些记录保存在组织的 authoritative DNS server 上。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了这三类服务器，还有一类服务器称为 &lt;strong&gt;local DNS server&lt;/strong&gt; (aka. default name server)，它不属于等级体系中但也非常重要，可以理解为主机使用 DNS 服务的 proxy server。&lt;/p&gt;
&lt;p&gt;一台主机通过 DNS 服务查询另一台主机的 IP 地址的过程大致如下图所示。该查询过程是 iterative + recursive 形式的。Local DNS server 作为 requesting server 的代表，顺序地向各个层级的 DNS server 发送请求，最终将结果返回给 requesting server。&lt;/p&gt;
&lt;img src=&#34;https://kristoff-starling.github.io/img/top-down/DNS-example1.png&#34; style=&#34;zoom:33%;&#34; /&gt;
&lt;p&gt;该查询过程也可以是 fully recursive 的，每一个服务器都把整个任务交给下一级服务器，并将最终结果返回给上一层服务器。&lt;/p&gt;
&lt;img src=&#34;https://kristoff-starling.github.io/img/top-down/DNS-example2.png&#34; style=&#34;zoom:33%;&#34; /&gt;
&lt;p&gt;可以看到不论是哪种顺序，在该例子中 requesting server 总是需要 8 次消息传输才能获得 IP 地址，效率不高。&lt;/p&gt;
&lt;h4 id=&#34;dns-caching&#34;&gt;DNS Caching&lt;/h4&gt;
&lt;p&gt;DNS caching 是减少 DNS 查询过程 delay 的一项关键技术。各个层级的 DNS server 内部都有 cache 维护hostname 到 IP 地址的映射表。这样如果有多次对同一个 hostname 的查询，DNS server 就不用把查询下放到底层的 authoritative server 而可以直接返回。不过由于 hostname 的 IP 地址是可以变的，通常 DNS server 两天就会 flush 一次 cache。&lt;/p&gt;
&lt;p&gt;Cache 中除了存储 hostname 的 IP 地址，还可以存储一些 DNS server 的 IP 地址，这样的好处是可以绕过上级 server 直接发送查询给下层 server。&lt;/p&gt;
&lt;h3 id=&#34;243-dns-records-and-messages&#34;&gt;2.4.3 DNS Records and Messages&lt;/h3&gt;
&lt;p&gt;各级 DNS server 完成了对分布式 DNS 数据库的抽象。DNS 数据库中存储的数据称为 &lt;strong&gt;resource record (RR)&lt;/strong&gt;。一条 RR 是一个四元组 &lt;code&gt;(Name, Value, Type, TTL)&lt;/code&gt;。其中 &lt;code&gt;TTL&lt;/code&gt; 表示该数据的生存周期，即服务器应该过多久将其从 cache 中 flush 掉。剩下的三个属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;若 &lt;code&gt;Type=A&lt;/code&gt;，则 &lt;code&gt;Name&lt;/code&gt; 是一个 hostname，&lt;code&gt;Value&lt;/code&gt; 是一个 IP 地址，A record 是 hostname-IP mapping。&lt;/li&gt;
&lt;li&gt;若 &lt;code&gt;Type=NS&lt;/code&gt;，则 &lt;code&gt;Name&lt;/code&gt; 是一个 domain，&lt;code&gt;Value&lt;/code&gt; 是保存了该 domain 下所有 host 地址的 authoritative server 的 hostname。NS record 用于指引 DNS server 继续深入 query chain。&lt;/li&gt;
&lt;li&gt;若 &lt;code&gt;Type=CNAME&lt;/code&gt;，则 &lt;code&gt;Name&lt;/code&gt; 是一个 alias hostname，&lt;code&gt;Value&lt;/code&gt; 保存了对应的 canonical hostname。CNAME record 用于 host aliasing 的翻译。&lt;/li&gt;
&lt;li&gt;若 &lt;code&gt;Type=MX&lt;/code&gt;，则 &lt;code&gt;Name&lt;/code&gt; 是一个 mail server 的别名，&lt;code&gt;Value&lt;/code&gt; 保存了对应的 canonical hostname。MX record 用于 mail server aliasing 的翻译。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果一个 DNS server 是某个 hostname 的 authoritative server，那么它里面会存储该 hostname 的 A record。如果一个 DNS server 不是某个 hostname 的 authoritative server，那么它会存储包括了该 hostname 的 domain 的 NS record，以及一条记录 NS record 中主机的 IP 地址的 A record。&lt;/p&gt;
&lt;h4 id=&#34;dns-message&#34;&gt;DNS Message&lt;/h4&gt;
&lt;p&gt;DNS message 的格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;Identification              Flags                       //
Number of questions         Number of answer RRs        //    12 bytes
Number of authority RRs     Number of additional RRs    //
----------------------------------------------------------------------
Questions 
(variable number of questions)   // Name, type field for a query
----------------------------------------------------------------------
Answers 
(variable number of RRs)         // RRs in response to query
----------------------------------------------------------------------
Authority
(variable number of RRs)         // Records for authoritative servers
----------------------------------------------------------------------
Additional information
(variable number of RRs)         // Additional info that may be used
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;query 和 reply message 有着相同的格式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;header section 共 12 个字节，由一系列的字段组成。第一个字段是 16 bit 的 identifier，reply message 的 identifier 是对应 query 的 identifier，这样 client 就可以把请求和回复对应上；Flag 字段包括指明这是 query 还是 reply 的 flag，DNS server 是否是 authoritative server 的 flag，要求是否使用 recursion 的 flag 等。此外还有 4 个计数的字段。&lt;/li&gt;
&lt;li&gt;question section 包含询问信息，主要有询问的 name 和 type。&lt;/li&gt;
&lt;li&gt;answer section 由 reply message 使用，包含一条或多条 resource record。&lt;/li&gt;
&lt;li&gt;authority section 包含其他 authoritative server 的 record。&lt;/li&gt;
&lt;li&gt;additional section 包含其他的有用信息，比如某些 canonical hostname 的 IP 地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;inserting-records-into-the-dns-database&#34;&gt;Inserting Records into the DNS Database&lt;/h4&gt;
&lt;p&gt;想要新建网站的人需要通过 registrar 获得域名且需要提供自己的 hostname 和 IP 地址，数据库管理员负责将数据录入数据库。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;DNS Vulnerabilities&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对 DNS 的攻击主要有以下几类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DDoS 攻击：历史上发生过两次重大的针对 DNS 的 DDoS 攻击：一次攻击针对所有的 root DNS server，由于 root server 有较好的保护机制，且大多数的 local DNS server 的 cache 可以绕过 root server 直接走下层，所以该攻击没有取得好的效果。另一次攻击针对 top-level domain DNS server，这次攻击就比较有效。&lt;/li&gt;
&lt;li&gt;man-in-the-middle attack：截获 DNS query，并返回一个虚假的 reply 给用户。&lt;/li&gt;
&lt;li&gt;DNS poisoning attack：和中间人攻击类似，不过这种攻击的目的是将 DNS server 将错误的信息写入 cache，直接污染数据库。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;25-peer-to-peer-file-distribution&#34;&gt;2.5 Peer-to-Peer File Distribution&lt;/h2&gt;
&lt;p&gt;前面章节介绍的所有应用都是 client-server 模式的，应用的正常运转需要一直处于运行状态的服务器。在 P2P 模式中，互相连接的 host 可以直接交互，节省了一些 overhead。&lt;/p&gt;
&lt;h3 id=&#34;scalability-of-p2p-architecture&#34;&gt;Scalability of P2P Architecture&lt;/h3&gt;
&lt;p&gt;考虑如下的一个简化的场景：有 $N$ 个节点需要服务器上的一个文件，该文件的大小为 $F$ bits。服务器上传的速度是 $u_s$，第 $i$ 台客户机下载的速度是 $d_i$，上传的速度是 $u_i$。&lt;/p&gt;
&lt;p&gt;在 client-server 架构中，没有人帮助服务器分发文件，所以 $N$ 个节点共 $NF$ bits 的数据都要由服务器自己上传。此外每个节点下载自己的文件需要时间。假设上传和下载可以并行地完成，令 $d_{min}=\min\{d_1,\cdots, d_n\}$，则
$$
D_{cs}\geq \max\left\{\frac{NF}{u_s},\frac{F}{d_{min}}\right\}
$$
在 P2P 架构中，一方面第一份文件需要服务器自己上传，一方面每个节点下载自己的文件需要时间，一方面每个节点在下载的同时也参与到上传中，后续的上传工作可以合力完成。所以
$$
D_{P2P}\geq \max\left\{\frac{F}{u_s},\frac{F}{d_{min}},\frac{NF}{u_s+\sum_{i=1}^nu_i}\right\}
$$
可以证明在精巧的设计下两个时间都可以达到下界。可以看到 client-server 模式下时间是关于 $N$ 的线性函数， P2P 模式下时间关于 $N$ 的函数上升速度缓慢且有极限，所以 P2P 模式的 scalability 更好。&lt;/p&gt;
&lt;h3 id=&#34;bittorrent&#34;&gt;BitTorrent&lt;/h3&gt;
&lt;p&gt;BitTorrent 是当下最流行的 P2P 文件分发协议之一。这里简单介绍一些 BitTorrent 的机理。在 BitTorrent 中参与一个文件 distribution 的 peer 的集合称为一个 torrent。每个 torrent 中都有一个节点称为 tracker，一个节点新加入 torrent 时会到 tracker 那里注册，tracker 会每隔一段时间检查每个节点是否还在 torrent 中并更新 active list。&lt;/p&gt;
&lt;p&gt;对于一个新加入的节点，tracker 会随机选择一些 peer 并将其 IP 地址发送给新节点，新节点会尝试和这些 peer 建立 TCP connection，成功建立 connection 的 peer 被称为 neighboring peer。由于 torrent 中随时会有节点退出也随时会有新节点加入，一个节点的 neighboring peer 集合是动态变化的。&lt;/p&gt;
&lt;p&gt;文件的共享以 chunk (256KB) 为单位。在任意时刻，一个节点手里会有该文件的某些 chunk，它的目标是收集自己还没有的其他 chunk，所以每隔一段时间节点会向自己的 neighbor 询问他们手里拥有哪些 chunk，并根据信息向一些 neighbor 发送索求 chunk 的申请。于是对于每个节点来说，它有两件事情需要考虑：一是应当先去索要哪些 chunk，二是如何应付别的节点发送过来的 request。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于第一个问题，BitTorrent 采取 &lt;strong&gt;rarest first&lt;/strong&gt; 的策略，即优先申请那些自己没有的，且在 neighbor 中出现次数最少的 chunk。这样的好处是可以让那些比较稀有的 chunk 迅速在网络中传播开来，提高文件分享的速率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于第二个问题，BitTorrent 采取了一个非常聪明的 trading algorithm，称为 tit-for-tat。每个节点会实时维护自己的所有 neighbor 向自己传输文件的速率 (每过 10s 刷新，更准确地说是在一个 time interval 内传输的数据量)，并选择排名前 4 高的节点向它们发送数据。排名前 4 的 neighbor 被称为 &lt;strong&gt;unchoked&lt;/strong&gt;。此外每过 30s 节点会随机选择一个自己的 neighbor 并向其发送数据 (不论其排名如何)，这个节点被称为 &lt;strong&gt;optimistically unchoked&lt;/strong&gt;。除了这 4+1 个 neighbor，剩下的 neighbor 都被称为 choked，它们无法获得该节点的数据。&lt;/p&gt;
&lt;p&gt;unchoked 和 optimistically unchoked 各自有道理。unchoked 的选择使得节点之间倾向于互相帮助互惠共利，同时一定程度上避免了一些只索取不付出的“吸血节点”来捣乱。optimistically unchoked 的选择可以理解为向一个“陌生”节点示好，尝试与其建立“外交关系”，如果陌生节点积极的予以反馈，那么这对节点就可能逐渐地将对方升级为自己的 top 4。此外，一个刚进入网络的节点手里没有任何 chunk，无法向外界提供数据，所以刚开始不可能成为任何节点的 top 4。optimistically unchoked 可以让这些萌新节点免费获得一些初始成本，帮助其快速融入网络。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;26-video-streaming-and-content-distribution-networks&#34;&gt;2.6 Video Streaming and Content Distribution Networks&lt;/h2&gt;
&lt;h3 id=&#34;261-internet-video&#34;&gt;2.6.1 Internet Video&lt;/h3&gt;
&lt;p&gt;Video 的本质是 sequence of images，其最显著的特点就是 high bit rate，因此视频会消耗大量存储，视频的传输会消耗大量的流量。当然，我们可以通过压缩技术来获得同一个视频的不同码率的版本，码率越高，视频质量越高，消耗资源也越大。&lt;/p&gt;
&lt;h3 id=&#34;262-http-streaming-and-dash&#34;&gt;2.6.2 HTTP Streaming and DASH&lt;/h3&gt;
&lt;p&gt;在 HTTP streaming 中，视频文件和普通的文件无异，有一个可以索引的 URL。client 可以通过 HTTP GET 指令来获取视频。由于视频较长获取较慢，通常客户端会准备一个 client application buffer，GET 指令不断获取数据存入 buffer，当 buffer 中的数据量超过一个阈值时，客户端程序就会开始播放——从 buffer 中抓取 video frame、解压、呈现在用户屏幕上。这样客户端就实现了边下载边观看。&lt;/p&gt;
&lt;p&gt;HTTP streaming 的一个问题是：无论当前用户的网络状况如何，它都只能获取固定码率的视频，因此网速不好时视频播放容易卡顿。&lt;strong&gt;动态自适应流媒体 (Dynamic Adaptive Streaming over HTTP, DASH)&lt;/strong&gt; 技术致力于缓解该问题。在 DASH 中一个视频会有多个不同码率的版本，以不同的 URL 存放在 server 中。此外 server 里有一个 &lt;strong&gt;manifest file&lt;/strong&gt; 提供了可选择的码率版本和对应的 URL。一个完整的视频被划分成了若干小的 chunk，client 首先会获取 manifest file，了解不同的码率版本，然后根据当前的网络状况选择一个合适的码率版本用 HTTP GET 获取一个 chunk，获取的过程中客户端同时收集本次获取的网速等信息，从而决定下一个 chunk 选哪个版本。这样，DASH 允许了 client 在多个不同版本的视频中自由切换。&lt;/p&gt;
&lt;h3 id=&#34;263-content-distribution-networks&#34;&gt;2.6.3 Content Distribution Networks&lt;/h3&gt;
&lt;p&gt;Content provider 需要建立 data center 来存储提供给用户的视频资源。正如 DNS server 只建一个有诸多弊端，如果服务商只建一个超大的 data center，就会有部分地区延时高、单点崩溃意味着全盘崩溃等问题。因此几乎所有的 video-streaming 公司都采用了 &lt;strong&gt;Content Distribution Network (CDN)&lt;/strong&gt;，建立一个分布式的服务器群，服务器的选址通常有如下两种策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Enter Deep：将服务器打入到 access network 内部，海量部署小服务器，尽可能靠近用户以减小用户的 delay 并提高 throughput。这种方式成本和后续维护的代价都比较高。&lt;/li&gt;
&lt;li&gt;Bring Home：建立数量较少规模较大的服务器，部署在 IXP 中。这种方式代价较低但用户体验也相对较差。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通常来说 CDN 不会让每台服务器都存储所有资源的副本，而是让服务器扮演 cache 的角色。如果用户索求的资源在当前服务器中没有，服务器会向上层做 pull request，得到后发送给用户的同时在自己本地留一个副本。&lt;/p&gt;
&lt;h4 id=&#34;cdn-operation&#34;&gt;CDN Operation&lt;/h4&gt;
&lt;p&gt;这里以一个例子讲述 CDN 的运行过程。假设 content provider 公司 NetCinema 使用了第三方 CDN 公司 KingCDN 的服务。NetCinema 的一个视频的 URL 是 &lt;code&gt;video.netcinema.com/abc&lt;/code&gt;，那么用户获取视频的流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用户访问该视频链接时，用户主机发出了一条关于 &lt;code&gt;vidio.netcinema.com&lt;/code&gt; 的 DNS request。&lt;/li&gt;
&lt;li&gt;用户的 Local DNS server (LDNS) 一层层访问到 NetCinema 公司的 authoritative server 并将其发送请求。authoritative server 注意到该域名的前缀是 &lt;code&gt;video&lt;/code&gt;，知道视频其实是交给 KingCDN 托管的，所以它返回了 KingCDN 的域名给用户的 LDNS，从而将用户 redirect 到 KingCDN。&lt;/li&gt;
&lt;li&gt;LDNS 收到了一个新域名，于是它再次发送 DNS query，一层层访问到了 KingCDN 的 authoritative server，authoritative server 会选择一个 CDN server 并将其 IP 地址返回给 LDNS。&lt;/li&gt;
&lt;li&gt;LDNS 将 IP 地址给用户后，用户主机与指定的 CDN server 建立 TCP connection 并获取视频。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;cluster-selection-strategies&#34;&gt;Cluster Selection Strategies&lt;/h4&gt;
&lt;p&gt;上述过程中有一步“选择一个 CDN server”，这其中很有讲究。CDN deployment 的核心便是 cluster selection strategy。CDN 的 authoritative server 接收到 LDNS 的 DNS query 时可以获知用户的 IP 地址，从而获得一些用户相关的信息。authoritative server 可以根据这些信息选择一个“最好“的 CDN server。&lt;/p&gt;
&lt;p&gt;最简单常用的一个策略是 &lt;strong&gt;geographically closest&lt;/strong&gt;。地理距离近通常意味着传输时间短，但这个策略有时不灵光——第一，地理距离短并不一定意味着 link 少；第二，有些用户的 LDNS 和终端设备之间可能隔了很远；第三，该策略完全没有考虑网络的动态状况。因此，除了该策略外 CDN 还可以通过一些 real-time measurement 来影响 CDN server 分配的决策。&lt;/p&gt;
&lt;h3 id=&#34;264-case-studies-netflix-and-youtube&#34;&gt;2.6.4 Case Studies: Netflix and YouTube&lt;/h3&gt;
&lt;h4 id=&#34;netflix&#34;&gt;Netflix&lt;/h4&gt;
&lt;p&gt;Netflix 的特色在于它有一个巨大的 Amazon cloud 处于核心位置，Amazon cloud 负责视频的处理，不同版本的生成，并将内容推送到 CDN server 中。由于 Netflix 建立了自己的 private CDN network，CDN operation 的步骤不像上一节那样有一个 redirect 的过程，Amazon cloud 可以直接指定 CDN server。此外，Netflix 使用的是 push cache，即 Amazon cloud 会在非高峰时间将内容主动推送到 CDN server 上，而不是让 CDN server 动态地在 cache miss 时索取。&lt;/p&gt;
&lt;h4 id=&#34;youtube&#34;&gt;YouTube&lt;/h4&gt;
&lt;p&gt;类似于 Amazon cloud，Google data center 会完成视频的处理，版本生成等工作。YouTube 也有自己的 private CDN network。和 Netflix 不同的地方在于：YouTube 使用 pull cache，以及 YouTube 不支持 DASH，只能让用户手动选择码率后使用 HTTP streaming。&lt;/p&gt;
&lt;h2 id=&#34;27-socket-programming-creating-network-applications&#34;&gt;2.7 Socket Programming: Creating Network Applications&lt;/h2&gt;
&lt;p&gt;略&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 1: Computer Networks and the Internet</title>
      <link>https://kristoff-starling.github.io/posts/booknotes/network-topdown/ch01/</link>
      <pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/booknotes/network-topdown/ch01/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#11-what-is-the-internet&#34;&gt;1.1 What Is the Internet&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#111-a-nuts-and-bolts-description&#34;&gt;1.1.1 A Nuts-and-Bolts Description&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#112-a-services-description&#34;&gt;1.1.2 A Services Description&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#113-what-is-a-protocol&#34;&gt;1.1.3 What Is a Protocol&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#12-the-network-edge&#34;&gt;1.2 The Network Edge&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#121-access-networks&#34;&gt;1.2.1 Access Networks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#home-access&#34;&gt;Home Access&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#enterprise-access&#34;&gt;Enterprise Access&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#wide-area-wireless-access&#34;&gt;Wide-Area Wireless Access&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#122-physical-media&#34;&gt;1.2.2 Physical Media&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#13-the-network-core&#34;&gt;1.3 The Network Core&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#131-packet-switching&#34;&gt;1.3.1 Packet Switching&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#store-and-forward-transmission&#34;&gt;Store-and-Forward Transmission&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#queuing-delays-and-packet-loss&#34;&gt;Queuing Delays and Packet Loss&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#forwarding-tables-and-routing-protocols&#34;&gt;Forwarding Tables and Routing Protocols&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#132-circuit-switching&#34;&gt;1.3.2 Circuit Switching&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#multiplexing-in-circuit-switched-networks&#34;&gt;Multiplexing in Circuit-Switched Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#packet-switching-versus-circuit-switching&#34;&gt;Packet Switching Versus Circuit Switching&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#133-a-network-of-networks&#34;&gt;1.3.3 A Network of Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#14-delay-loss-and-throughput-in-packet-switched-networks&#34;&gt;1.4 Delay, Loss, and Throughput in Packet-Switched Networks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#141-overview-of-delay-in-packet-switched-networks&#34;&gt;1.4.1 Overview of Delay in Packet-Switched Networks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#processing-delay&#34;&gt;Processing Delay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#queuing-delay&#34;&gt;Queuing Delay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#transmission-delay&#34;&gt;Transmission Delay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#propagation-delay&#34;&gt;Propagation Delay&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#comparing-transmission-and-propagation-delay&#34;&gt;Comparing Transmission and Propagation Delay&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#142-queuing-delay-and-packet-loss&#34;&gt;1.4.2 Queuing Delay and Packet Loss&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#packet-loss&#34;&gt;Packet Loss&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#143-end-to-end-delay&#34;&gt;1.4.3 End-to-End Delay&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#traceroute&#34;&gt;Traceroute&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#end-system-application-and-other-delays&#34;&gt;End System, Application, and Other Delays&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#144-throughput-in-computer-networks&#34;&gt;1.4.4 Throughput in Computer Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#15-protocol-layers-and-their-service-models&#34;&gt;1.5 Protocol Layers and Their Service Models&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#151-layered-architecture&#34;&gt;1.5.1 Layered Architecture&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#protocol-layering&#34;&gt;Protocol Layering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#application-layer&#34;&gt;Application Layer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#transport-layer&#34;&gt;Transport Layer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#network-layer&#34;&gt;Network Layer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#link-layer&#34;&gt;Link Layer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#physical-layer&#34;&gt;Physical Layer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#152-encapsulation&#34;&gt;1.5.2 Encapsulation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#16-networks-under-attack&#34;&gt;1.6 Networks Under Attack&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#put-malware-into-your-host-via-the-internet&#34;&gt;Put Malware into Your Host Via the Internet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#attack-servers-and-network-infrastructure&#34;&gt;Attack Servers and Network Infrastructure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#sniff-packets&#34;&gt;Sniff Packets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#masquerade-as-someone-you-trust&#34;&gt;Masquerade as Someone You Trust&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#17-history-of-computer-networking-and-the-internet&#34;&gt;1.7 History of Computer Networking and the Internet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;11-what-is-the-internet&#34;&gt;1.1 What Is the Internet&lt;/h2&gt;
&lt;h3 id=&#34;111-a-nuts-and-bolts-description&#34;&gt;1.1.1 A Nuts-and-Bolts Description&lt;/h3&gt;
&lt;p&gt;这里的 &amp;ldquo;nuts-and-bolts&amp;rdquo; 指介绍网络中一些基本的元素和组件。网络中用户使用的电脑、手机、手柄……等物品称为&lt;strong&gt;主机 (host)&lt;/strong&gt; 或&lt;strong&gt;终端设备 (end system)&lt;/strong&gt;。终端设备通过由&lt;strong&gt;通信线路 (communication links)&lt;/strong&gt; 和&lt;strong&gt;包交换机 (packet switches)&lt;/strong&gt; 组成的网络相互连接，不同的链路具有不同的 transmission rate，在链路上传送的数据是一份一份的，称为一个个&lt;strong&gt;包 (packet)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Packet switch 负责接收 packet 并将其转发到其他的链路上。最主要的两种 packet switch 就是&lt;strong&gt;路由器 (router)&lt;/strong&gt; 和&lt;strong&gt;链路层交换机 (link-layer switch)&lt;/strong&gt;，前者通常用于 network core，后者通常用于 access network。Packet-switched network 和日常生活中的交通运输网络很像：packet 就好比卡车上的货物，communication links 就好比高速公路，packet switch 就好比十字路口，end system 就好比仓库和大楼。&lt;/p&gt;
&lt;p&gt;终端设备需要通过&lt;strong&gt;因特网服务提供商 (Internet Service Provider, ISP)&lt;/strong&gt; 来接入网络。ISP 分为若干层级，彼此互联，形成网络。&lt;/p&gt;
&lt;p&gt;终端设备、包交换机等在网络中收发数据都要遵循相关的&lt;strong&gt;协议 (protocol)&lt;/strong&gt;。&lt;strong&gt;传输控制协议 (Transmission Control Protocol, TCP)&lt;/strong&gt; 和&lt;strong&gt;网络互联协议 (Internet Protocol, IP)&lt;/strong&gt; 是最重要的两个协议。IP 协议描述了 packet 的格式。&lt;/p&gt;
&lt;h3 id=&#34;112-a-services-description&#34;&gt;1.1.2 A Services Description&lt;/h3&gt;
&lt;p&gt;这个角度旨在说明计算机网络是由若干服务组成的：对于每个服务项目，你需要遵守它提出的 specification，这样你就可以享受它的若干服务。&lt;/p&gt;
&lt;p&gt;我们开发的网络游戏、社交软件等称为 distributed application，因为它们需要运行在多个终端设备上，这些终端设备需要彼此交换信息。终端设备通过套接字接口 (socket interface) 来连入互联网，socket interface 主要规定了程序应当如何发送数据 (比如格式)，就像邮局规定寄信需要装信封贴邮票一样。&lt;/p&gt;
&lt;h3 id=&#34;113-what-is-a-protocol&#34;&gt;1.1.3 What Is a Protocol&lt;/h3&gt;
&lt;p&gt;一个协议定义了两个通讯实体之间发送信息的格式和顺序，以及收到某些信息后应当采取的行动。&lt;/p&gt;
&lt;h2 id=&#34;12-the-network-edge&#34;&gt;1.2 The Network Edge&lt;/h2&gt;
&lt;p&gt;Hosts 有时可以细分成两类：客户端 (client) 和服务器 (server)。客户端就是电脑、手机等，服务器通常指更加强大的，存储和分发网页、视频等的机器。先在大多数的网页内容都存储在数据中心 (data center)。&lt;/p&gt;
&lt;h3 id=&#34;121-access-networks&#34;&gt;1.2.1 Access Networks&lt;/h3&gt;
&lt;p&gt;接入网络 (access network) 指将终端设备和第一个路由器物理地连接起来的网络。&lt;/p&gt;
&lt;h4 id=&#34;home-access&#34;&gt;Home Access&lt;/h4&gt;
&lt;p&gt;对于家庭来说，常见的 access network 有以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;电话线接入 (digital subscriber line, DSL)：电脑通过一个 DSL modem 连接到电话线上，DSL modem 负责将数字信号转换成可以在电话线上传输的高频模拟信号。电话线上不同的频率可以传输不同的信号。来自一个地区各家各户的信号会汇总到一个 digital subscriber line access multiplexer (DSLAM) 处，它负责将模拟信号转换回数字信号，并将信号转发到 Internet / telephone network 中。&lt;/p&gt;
&lt;p&gt;DSL 的上传速率和下载速率是不一样的，因此 DSL 被称为是一项非对称技术。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;电缆接入 (cable)：基本原理和 DSL 相同，电脑通过 cable modem 连接到电缆上，一个 cable modem termination system (CMTS) 负责和 DSLAM 相同的工作。&lt;/p&gt;
&lt;p&gt;cable network access 的一个显著特征是这是一个共享的传输介质，因此同一个时刻使用网络的人越多，实际的网速就会越低。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;光纤到户 (fiber to the home, FTTH)：从 central office 直接拉光纤到家里。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;5G：信号从服务商的 5G 基站通过无线的方式传输到家庭的 modem。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;enterprise-access&#34;&gt;Enterprise Access&lt;/h4&gt;
&lt;p&gt;企业/高校会部署一个 local area network (LAN) 作为接入网络，最常用的是以太网 (Ethernet)：多台终端设备通过 twisted-pair copper wire 连接到以太网交换机上，以太网交换机再连接到更大的因特网中。wireless LAN 应用的也很广泛。&lt;/p&gt;
&lt;h4 id=&#34;wide-area-wireless-access&#34;&gt;Wide-Area Wireless Access&lt;/h4&gt;
&lt;p&gt;电信公司花费了大量财力部署无线网络的基站。这种技术和 WiFi 不太一样，只要终端设备和基站距离在几千米之内就可以收到信号。&lt;/p&gt;
&lt;h3 id=&#34;122-physical-media&#34;&gt;1.2.2 Physical Media&lt;/h3&gt;
&lt;p&gt;略。&lt;/p&gt;
&lt;h2 id=&#34;13-the-network-core&#34;&gt;1.3 The Network Core&lt;/h2&gt;
&lt;p&gt;Network Core 是由链路和包交换机组成的网络，用于将各地的终端设备连接起来。&lt;/p&gt;
&lt;h3 id=&#34;131-packet-switching&#34;&gt;1.3.1 Packet Switching&lt;/h3&gt;
&lt;p&gt;在网络中不同的终端设备之间需要传递信息。长的信息会被切割成一块一块小的数据，这些块被称为&lt;strong&gt;包 (packet)&lt;/strong&gt;。包在 communication link 上的传输速度等于该 link 的 full transmission rate，即如果一个 $L$ bits 的包在一个 $R$ bits/s 的链路上传输，则需要 $L/R$ 秒。&lt;/p&gt;
&lt;h4 id=&#34;store-and-forward-transmission&#34;&gt;Store-and-Forward Transmission&lt;/h4&gt;
&lt;p&gt;绝大多数的 packet switches 采取&lt;strong&gt;存储转发传输 (store-and-forward transmission)&lt;/strong&gt;，这意味着交换机一定会在接收到整个 packet 之后才会开始将 packet 转发到下一条链路，不存在并行的一边接收一边转发的情况。&lt;/p&gt;
&lt;p&gt;假设每个包的大小都是 $L$ bits，每条链路的 transmission rate 都是 $R$ bits，那么&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$N$ 个包转发 1 次 (即 src 和 dst 之间只有一个 packet switch)，需要的时间是 $(N+1)\cdot L/R$，注意发送第二个包的时候，packet switch 可以并行地接收第二个包和转发第一个包。&lt;/li&gt;
&lt;li&gt;1 个包经过 $N$ 个 link (即 $N-1$ 个 packet switch)，需要的时间是 $N\cdot L/R$。&lt;/li&gt;
&lt;li&gt;$P$ 个包经过 $N$ 个 link，需要的时间是 $(P+N-1)\cdot L/R$。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;queuing-delays-and-packet-loss&#34;&gt;Queuing Delays and Packet Loss&lt;/h4&gt;
&lt;p&gt;每个 packet switch 上都连接了多个 link，对于每条 link，packet switch 都有一个&lt;strong&gt;输出缓冲区&lt;/strong&gt; (&lt;strong&gt;output buffer&lt;/strong&gt;, also called &lt;strong&gt;output queue&lt;/strong&gt;)，存放那些即将被发出去的包。如果一个新到来的包需要从某条 link 转发出去，但这条 link 正在转发别的包，那么这个新的包就要到该 link 的 output buffer 中等待。因此除了 store-and-forward delay，包在传输过程中还有&lt;strong&gt;排队延迟 (queuing delay)&lt;/strong&gt;，其长短取决于网络的拥塞程度。&lt;/p&gt;
&lt;p&gt;由于 buffer 的大小是有限的，有时候新来的包会发现 output buffer 已经满了，这时就会发生&lt;strong&gt;包丢失 (packet loss)&lt;/strong&gt;——要么新来的包被丢弃，要么 buffer 里的某一个其他正在等待的包被丢弃。&lt;/p&gt;
&lt;h4 id=&#34;forwarding-tables-and-routing-protocols&#34;&gt;Forwarding Tables and Routing Protocols&lt;/h4&gt;
&lt;p&gt;对于 packet switch 来说，收到一个包以后该选择哪一条 link 去转发是它主要关心的问题。在 Internet 中，每个终端设备都有一个 IP 地址。当 src 想要给 dst 发送消息时，它会将 dst 的 IP 地址写在 packet header 中。路途中的每个 router 会解析 IP 地址的一部分，根据本地的&lt;strong&gt;转发表 (forwarding table)&lt;/strong&gt; 决定沿着哪条链路继续传输。&lt;/p&gt;
&lt;p&gt;Internet 有一系列的&lt;strong&gt;路由协议 (routing protocol)&lt;/strong&gt;，这些协议用来自动生成各个路由器的转发表。一个路由协议可以根据全局的情况来统筹规划，比如设计一条大城市之间的最短转发路径。&lt;/p&gt;
&lt;h3 id=&#34;132-circuit-switching&#34;&gt;1.3.2 Circuit Switching&lt;/h3&gt;
&lt;p&gt;在网络中主要有两种传输数据的方式：packet switching 和 circuit switching。这一节主要介绍后者。在 circuit-switched 网络中，两个终端设备之间联络需要提前预定资源，一旦建立了 end-to-end connection 后，在两个设备通话期间，这条路径上预定的资源会被这两个设备独占，从而可以保证一个稳定的 transmission rate (注意：在 circuit switching 中传输速率和 link 的个数无关，即不再有所谓的 store-and-forward delay)。&lt;/p&gt;
&lt;h4 id=&#34;multiplexing-in-circuit-switched-networks&#34;&gt;Multiplexing in Circuit-Switched Networks&lt;/h4&gt;
&lt;p&gt;switches 之间由 link 连接，一个 link 中包含多个 circuit。circuit 上一般会采用&lt;strong&gt;频分复用 (frequency-division multiplexing, FDM)&lt;/strong&gt; 或&lt;strong&gt;时分复用 (time-division multiplexing, TDM)&lt;/strong&gt; 技术。前者指的是将频谱分成多个 band 给不同的人用，后者指的是将时间轴切分成多个时间片给不同的人用。&lt;/p&gt;
&lt;h4 id=&#34;packet-switching-versus-circuit-switching&#34;&gt;Packet Switching Versus Circuit Switching&lt;/h4&gt;
&lt;p&gt;Packet Switching 的劣势主要在于，由于存在不可预测的延迟，它不能保证即时服务的稳定性。但 packet switching 总体来说比 circuit switching 更高效，因为 packet switching 可以更动态、更灵活地分配资源。下面是两个例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假设 link 的传输速率是 1Mbps，有一些用户需要 100kbps 的传输速率。在 circuit switching 中，我们可以使用 TDM 技术，把 1s 分成 10 份，每个用户在 1s 中获取一个时间片，这样可以有 10 个用户同时使用网络。但在 packet switching 中，我们可以证明在每个客户每个时刻有 0.1 的概率 active 的情况下，即使有 35 个用户同时 active 也有 0.9996 的概率只有不超过 10 人 active，这样 packet switching 在几乎保证了用户需求的情况下支持了更多用户。&lt;/li&gt;
&lt;li&gt;假设 10 个用户有 9 个在休息，有一个在大量产生数据，那么在 circuit switching 中，有需求的用户仍然只能得到 1/10 的时间片，而在 packet switching 中，所有的传输资源都可以为唯一的活跃用户所用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现在的主流是向 packet switching 靠拢。&lt;/p&gt;
&lt;h3 id=&#34;133-a-network-of-networks&#34;&gt;1.3.3 A Network of Networks&lt;/h3&gt;
&lt;p&gt;我们之前讨论了 home network, enterprise network 等等，无数的终端设备连接到由电话公司、电缆公司、高校……搭建的 access ISP 上。这些 access ISP 之间也需要连接起来，形成一个 network of networks。&lt;/p&gt;
&lt;p&gt;现代的互联网格局大致如下图所示：&lt;/p&gt;
&lt;img src=&#34;https://kristoff-starling.github.io/img/top-down/NetworkHierarchy.png&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;整个互联网大致是一个三级格局：access ISP 连向 regional ISP，regional ISP 连向 Tier 1 ISP，底层的 ISP 可以连接多个上层 ISP，还可以跨级连接。处于下层的 ISP 连向上层是为了和别的 ISP 连通，因此下层的 ISP 是 customer，上层的 ISP 是 provider，customer 给 provider 付费，provider 提供服务。顶层的 Tier 1 ISP 全球只有几十个，通常是国家级的，它们彼此之间连接，保证网络的连通。&lt;/p&gt;
&lt;p&gt;在基本的 hierarchical 架构下还有如下的一些特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Points of presence (PoP)：PoP 是 provider network 里的一组路由器，负责和 customer 联络。&lt;/li&gt;
&lt;li&gt;customer 为了减少给 provider 付费，同级的 ISP 之间也可以自己建立通讯，这种方式称为 peer。有一些第三方公司建立了&lt;strong&gt;互联网交换中心 (Internet Exchange Point, IXP)&lt;/strong&gt;，为 peer 提供服务。这种机制也可以减轻上层 ISP 的通讯压力。&lt;/li&gt;
&lt;li&gt;有一些本应处于底层的 content provider (比如 Google)，由于自身实力过于雄厚，拥有无数的数据中心和服务器，所以建立了自己的私有网络。Google 和 Tier 1 ISP 建立联络以保证自己的内容可以发送给世界各地，它在各地也有一些 IXP 可以直接和底层的 ISP 建立联系 (从而不用付钱走别的 Tier 1 ISP)。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;14-delay-loss-and-throughput-in-packet-switched-networks&#34;&gt;1.4 Delay, Loss, and Throughput in Packet-Switched Networks&lt;/h2&gt;
&lt;h3 id=&#34;141-overview-of-delay-in-packet-switched-networks&#34;&gt;1.4.1 Overview of Delay in Packet-Switched Networks&lt;/h3&gt;
&lt;p&gt;在 packet 传输的过程中，它在每个节点都会受到一些 delay，最重要的四种 delay 是&lt;strong&gt;处理时延 (processing delay)&lt;/strong&gt;，&lt;strong&gt;排队时延 (queuing delay)&lt;/strong&gt;，&lt;strong&gt;发送时延 (transmission delay)&lt;/strong&gt; 和&lt;strong&gt;传播时延 (propagation delay)&lt;/strong&gt;，这些 delay 综合起来形成一个节点的 total nodal delay。&lt;/p&gt;
&lt;h4 id=&#34;processing-delay&#34;&gt;Processing Delay&lt;/h4&gt;
&lt;p&gt;processing delay 指的是处理 packet header 以及确定这个 packet 该如何转发所花费的时间。在高速路由器中 processing delay 通常以微秒计。&lt;/p&gt;
&lt;h4 id=&#34;queuing-delay&#34;&gt;Queuing Delay&lt;/h4&gt;
&lt;p&gt;queuing delay 指的是在路由器的 output buffer 上排队等待的时间，该 delay 和整个网络的拥塞程度有关。量级从微秒到毫秒不等。&lt;/p&gt;
&lt;h4 id=&#34;transmission-delay&#34;&gt;Transmission Delay&lt;/h4&gt;
&lt;p&gt;transmission delay 指的是把要传输的数据 push 到 link 上所花费的时间，量级从微秒到毫秒不等。&lt;/p&gt;
&lt;h4 id=&#34;propagation-delay&#34;&gt;Propagation Delay&lt;/h4&gt;
&lt;p&gt;propagation delay 指的是数据在 link 上传输所花费的时间，该 delay 和 link 的物理材质以及距离的远近有关，量级以毫秒计。&lt;/p&gt;
&lt;h4 id=&#34;comparing-transmission-and-propagation-delay&#34;&gt;Comparing Transmission and Propagation Delay&lt;/h4&gt;
&lt;p&gt;transmission delay 指的是把数据 push out 到 link 上的时间，它和 packet 的大小以及 link 的 transmission rate 有关。propagation delay 指的是数据在 link 上传播的时间，它主要和路途的距离有关。一个节点的总时延可以写为
$$
d_{nodal}=d_{proc}+d_{queue}+d_{trans}+d_{prop}
$$
通常来说 $d_{proc}$ 这一项总是可以忽略不计的，而其他几项在不同的场景下可能很小也可能很大。&lt;/p&gt;
&lt;h3 id=&#34;142-queuing-delay-and-packet-loss&#34;&gt;1.4.2 Queuing Delay and Packet Loss&lt;/h3&gt;
&lt;p&gt;queuing delay 是最复杂和有趣的一种时延，每个包的 queuing delay 可能都不一样 (比如两个包来到一个 router，先来的包可能没有 queuing delay，后来的包就可能要等一个包的时间)，因此我们在刻画 queuing delay 的时候通常采取一些统计量，比如 queuing delay 的平均值、方差、超过某个阈值的概率等等。&lt;/p&gt;
&lt;p&gt;queuing delay 的大小和当前的流量，link 的 transmission rate (transmission rate 大，push out 一个包就要更长的时间，排队的包就要等更久) 以及流量的特征 (arrive periodically/in burst) 等有关。我们这里考虑一个简单情形：对于一个 router，buffer 没有容量限制，包的到来速率是 $a$ 个/秒，每个包的大小都是 $L$ bits，即流量是 $La$ bits/s；link 的 transmission rate 是 $R$ bits/s，那么 $La/R$ 这个值从量纲上看是没有单位的，通常称为&lt;strong&gt;流量强度 (traffic intensity)&lt;/strong&gt;。(更一般的定义是 $\frac{\text{arrival rate of bits}}{\text{service rate of bits}}$。) 流量强度是衡量 queuing delay 的重要指标，如果 $La/R&amp;gt;1$，那么可想而知发送的速度比到来的速度满，久而久之 queuing delay 将趋向于无限，因此网络系统建设的一个黄金原则就是：保证 system 的 traffic intensity 不大于 1。&lt;/p&gt;
&lt;p&gt;当 $La/R\leq 1$ 时，研究表明如果将平均 queuing delay 看作关于流量强度的函数，则该函数呈指数型，因此稍稍减小流量强度就可能对 queuing delay 有很明显的改善。&lt;/p&gt;
&lt;h4 id=&#34;packet-loss&#34;&gt;Packet Loss&lt;/h4&gt;
&lt;p&gt;在实际生活中 router 的 buffer 大小是有限的，因此当流量强度趋向于 1 的时候 queuing delay 并不会趋向于无穷。当 buffer 满了的时候，router 会选择&lt;strong&gt;丢弃 (drop)&lt;/strong&gt; 新来的包，或者说新来的包&lt;strong&gt;丢失 (lost)&lt;/strong&gt; 了。衡量网络性能时，我们不仅会关注每个节点的 delay，还会关注发生包丢失的概率。通常情况下，为了保证数据的完整性，发生包丢失时，丢失的包会再次从 source 发出。&lt;/p&gt;
&lt;h3 id=&#34;143-end-to-end-delay&#34;&gt;1.4.3 End-to-End Delay&lt;/h3&gt;
&lt;p&gt;我们之前讨论的都是一个 router/节点上的延迟，在这个 section 中我们讨论 end-to-end 的延迟。假设从起点到终点一共有 $N-1$ 个 router，当前流量很少节点上不会发生 queuing delay，那么 end-to-end 的 delay 为
$$
d_{end-end}=N(d_{proc}+d_{trans}+d_{prop})
$$
这里前面的系数之所以是 $N$ 而不是 $N-1$ 是因为起点节点把 packet 发送到第一个 router 上也有一个一组处理+发送+传播。&lt;/p&gt;
&lt;h4 id=&#34;traceroute&#34;&gt;Traceroute&lt;/h4&gt;
&lt;p&gt;traceroute 是一个命令行工具，命令格式为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;traceroute hostname
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它的功能是从运行命令的主机向目标主机发送一系列的 special packet。包在传输过程中会经过一系列的 router，假设沿路一共有 $N$ 个 router，编号 1~N，那么我们的主机就会发送 $N+1$ 个包。当 router 接收到一个 special packet 时，它会返回一条包含自己的名字、地址等信息的简短消息，且不会把 special packet 继续转发下去。这样沿路的所有 router 以及目标主机都会收到一个 special packet 并把自己的信息传输回去，我们的主机就可以根据这些信息分析到每个节点的传输时长，delay 等。traceroute 会把这个过程做 3 次并取平均值。&lt;/p&gt;
&lt;p&gt;由于 queuing delay 的影响，路径上处在前面的节点的平均传输时长是有可能比后面的节点长的。&lt;/p&gt;
&lt;h4 id=&#34;end-system-application-and-other-delays&#34;&gt;End System, Application, and Other Delays&lt;/h4&gt;
&lt;p&gt;除了之前提到的 4 种 delay，网络系统中还有许多其他类型的 delay，比如多个设备接入 WiFi 时，需要遵守协议保证资源共享，从而形成 delay；再例如在因特网语音 (Voice over IP, VoIP) 中，消息的发送方必须要在包里填写上加密的语音信息，这一步时延被称为 media packetization delay。&lt;/p&gt;
&lt;h3 id=&#34;144-throughput-in-computer-networks&#34;&gt;1.4.4 Throughput in Computer Networks&lt;/h3&gt;
&lt;p&gt;除了 delay 和 packet loss，衡量网络系统的另一个重要指标就是 end-to-end 的吞吐率。在一场 end-to-end 的传输中，任意时刻的&lt;strong&gt;即时吞吐率 (instantaneous throughput)&lt;/strong&gt; 指的是该时刻接收端在 1s 内接受的 bit 量 (单位：bit/s)，类似的平均吞吐率则应用一段时间内接受的 bit 数除以时间长度。一个网络的吞吐率取决于整个网络的&lt;strong&gt;瓶颈链路 (bottleneck link)&lt;/strong&gt;，即 transmission rate 最小的链路。通常来说 access network 中的链路很有可能称为瓶颈 (因为 network core 中的一般都是高速链路)；如果有多条传输路径共享某一条链路，那么这个“独木桥”也很有可能成为瓶颈。&lt;/p&gt;
&lt;h2 id=&#34;15-protocol-layers-and-their-service-models&#34;&gt;1.5 Protocol Layers and Their Service Models&lt;/h2&gt;
&lt;h3 id=&#34;151-layered-architecture&#34;&gt;1.5.1 Layered Architecture&lt;/h3&gt;
&lt;p&gt;我们以人类坐飞机为例，整个流程大致如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;Ticket(purchase)                             Ticket(complain)
       |                                            |
 Baggage(check)                               Baggage(claim)
       |                                            |
  Gates(load)                                 Gates(unload)
       |                                            |
Runaway takeoff       Airplane routing       Runaway landing
                 -------------------------&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到整个系统的功能被分成了若干层。每个层都可以提供一些服务，这些服务包含两个方面：一是对来的旅客做一些操作，二是使用更下一层提供的服务 (不会跨层调用)。&lt;/p&gt;
&lt;p&gt;对于复杂系统来说，这种模块化的设计很有好处：每层只对上层提供一些 specification，这样某一层的 implementation 如果变了，只要保证 specification 不变，系统的其他部分就不需要改变。&lt;/p&gt;
&lt;h4 id=&#34;protocol-layering&#34;&gt;Protocol Layering&lt;/h4&gt;
&lt;p&gt;在网络系统中，网络的设计者设计了一些协议，每个协议属于一个 layer。对于一个 layer，我们关心它可以对上面的层提供的服务，即所谓的&lt;strong&gt;服务模型 (service model)&lt;/strong&gt;。一个 protocol layer 即可以用硬件实现，也可以用软件实现，也可以硬软结合，例如应用层的协议 (如 HTTP, SMTP) 通常是由终端设备中的软件实现的，而网络层的协议则通常是硬软结合实现的。一个值得注意的点是，正如全世界各地的每个机场都有值机点一样，一个协议是分布式地存在于网络系统中的各个设备上的。&lt;/p&gt;
&lt;p&gt;尽管 protocol layer 的思想有很多好处，但仍有一些观点反对 layering。layering 的一个潜在的缺点是有时候多个层不得不实现相同的功能模块；另一个潜在的缺点是有时候一些层不得不获取下一个层的信息，这打破了 layer separation。&lt;/p&gt;
&lt;p&gt;各个层的 protocol 合起来总称&lt;strong&gt;协议栈 (protocol stack)&lt;/strong&gt;。因特网的协议栈共有五个层：&lt;strong&gt;应用层 (application layer)&lt;/strong&gt;，&lt;strong&gt;传输层 (transport layer)&lt;/strong&gt;，&lt;strong&gt;网络层 (network layer)&lt;/strong&gt;，&lt;strong&gt;链路层 (link layer)&lt;/strong&gt; 和&lt;strong&gt;物理层 (physical layer)&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;application-layer&#34;&gt;Application Layer&lt;/h4&gt;
&lt;p&gt;网络应用和应用层协议处于应用层。常见的应用层协议有 HTTP, SMTP, FTP 等。我们日常可见的一些服务，比如在地址栏里输入 human-readable 的网址就可以访问网站，也是由应用层的 DNS 支持的。&lt;/p&gt;
&lt;p&gt;应用层的 packet 通常称为&lt;strong&gt;报文 (message)&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;transport-layer&#34;&gt;Transport Layer&lt;/h4&gt;
&lt;p&gt;在因特网中，传输层协议有两个：TCP 和 UDP，它们都可以传输应用层的报文。TCP 和 UDP 的不同点在于前者可以对 reliability, flow control, congestion control 提供一些保证。&lt;/p&gt;
&lt;p&gt;传输层的 packet 通常称为&lt;strong&gt;段 (segment)&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;network-layer&#34;&gt;Network Layer&lt;/h4&gt;
&lt;p&gt;网络层的 packet 通常称为数据报 (datagram)。source host 的传输层协议 (TCP/UDP) 会将要发送的 segment 和目标主机的地址传给网络层，网络层负责发送这些内容。&lt;/p&gt;
&lt;p&gt;网络层最重要的协议是 IP，它定义了 datagram 的每一个字段的内容以及终端设备和路由器应当如何处理这些字段。网络中的每个设备都要遵守 IP。除此之外，网络层中还有很多小的路由协议。&lt;/p&gt;
&lt;h4 id=&#34;link-layer&#34;&gt;Link Layer&lt;/h4&gt;
&lt;p&gt;网络层会为 datagram 的传输规划出一条经过若干路由器的路线，但网络层需要依靠链路层完成具体的传输。具体地，在某一个节点中，网络层会把 datagram 传给链路层，链路层把 datagram 传给另一个节点的链路层，另一个节点再把 datagram 上传给自己的网络层。常见的链路层协议有 Ethernet, WiFi 等。&lt;/p&gt;
&lt;p&gt;链路层的 packet 通常称为&lt;strong&gt;帧 (frame)&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;physical-layer&#34;&gt;Physical Layer&lt;/h4&gt;
&lt;p&gt;物理层的任务就是将 frame 里一个一个的 bit 从一个节点传输到另一个。根据不同的线材 (twisted-pair copper, single-mode fiber etc.)，物理层也有不同的协议。&lt;/p&gt;
&lt;h3 id=&#34;152-encapsulation&#34;&gt;1.5.2 Encapsulation&lt;/h3&gt;
&lt;p&gt;网络中不是所有的设备都 implement 了5层协议。所有的 host 都 implement 了5层，像交换机、路由器等可能只做了低下的两三层。&lt;/p&gt;
&lt;p&gt;数据传输过程中的一个重要的概念就是&lt;strong&gt;封装 (encapsulation)&lt;/strong&gt;。每一层都会从上面一层接收 packet，在 packet 前加上自己这一层相关信息的 header，然后打包发给下一层。在每一层 packet 都分为 header field 和 payload field 两部分，payload field 本质上就是上一层传下来的包。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Layer&lt;/th&gt;
&lt;th&gt;Packet&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Application&lt;/td&gt;
&lt;td&gt;$M$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Transport&lt;/td&gt;
&lt;td&gt;$H_t\space M$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Network&lt;/td&gt;
&lt;td&gt;$H_n\space H_t\space M$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Link&lt;/td&gt;
&lt;td&gt;$H_l\space H_n\space H_t\space M$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Physical&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;解析的过程正好相反：每一层把自己这层的 header 拔下来，根据 header 中的信息做一些操作，然后把剩下的 payload field 往上传。&lt;/p&gt;
&lt;h2 id=&#34;16-networks-under-attack&#34;&gt;1.6 Networks Under Attack&lt;/h2&gt;
&lt;p&gt;互联网最初建立时的目标用户是 ”a group of mutually trusting users&amp;quot;，但现在互联网变得非常庞大，其中的人不可能做到互相信赖。互联网最初的一套底层的设计不能推倒重来，所以就有了各种攻击手段和防御手段。&lt;/p&gt;
&lt;h3 id=&#34;put-malware-into-your-host-via-the-internet&#34;&gt;Put Malware into Your Host Via the Internet&lt;/h3&gt;
&lt;p&gt;网络上除了好的程序，还有一些&lt;strong&gt;恶意软件 (malware)&lt;/strong&gt;，它们会侵入设备并做一切可能的坏事。此外，成千上万的主机可能会被利用并构建成一个&lt;strong&gt;僵尸网络 (botnet)&lt;/strong&gt;，坏人利用 botnet 来免费为他们自己做事。大部分的恶意软件都具有自我复制的功能：一旦感染了一台设备，它就会顺着这台设备在互联网中的连接去感染别的设备，从而形成一个指数级的感染规模。&lt;/p&gt;
&lt;h3 id=&#34;attack-servers-and-network-infrastructure&#34;&gt;Attack Servers and Network Infrastructure&lt;/h3&gt;
&lt;p&gt;另一类常见的攻击手段是&lt;strong&gt;拒绝服务攻击 (denial-of-service, DoS attack)&lt;/strong&gt;。DoS 攻击顾名思义就是让某些 server 停止工作，通常分为三大类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vulnerability attack：利用应用或操作系统的弱点代码攻击，使系统崩溃。&lt;/li&gt;
&lt;li&gt;Bandwidth flooding：向目标主机传输大量的数据，使其应接不暇，无法接收其他的正常数据。&lt;/li&gt;
&lt;li&gt;Connection flooding：攻击者和目标主机建立大量的 TCP 连接，使其应接不暇，无法建立其他的正常连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里着重讨论一下 bandwidth flooding。有的时候一个 link 的 transmission rate 很高，用一台机器很难发送足够海量的数据，而且如果所有的垃圾数据都来自同一台机器，上游的 router 很容易监测到这种攻击并作出相应的防御。因此现在攻击者更倾向于使用&lt;strong&gt;分布式拒绝服务攻击 (distributed Dos, DDoS)&lt;/strong&gt;。攻击者控制一个有成千上万台僵尸机的 botnet 来向目标主机倾泄垃圾数据。&lt;/p&gt;
&lt;h3 id=&#34;sniff-packets&#34;&gt;Sniff Packets&lt;/h3&gt;
&lt;p&gt;坏人可能会在一个网络中放置一个被动的接受器，这个接受器可以将网络中传输的每个 packet 都复制一份，这样的被动接受器被称为&lt;strong&gt;包嗅探器 (packet sniffer)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;sniffer 可以被用来窃取用户的隐私信息，其由于它是完全被动的，不会向网络主动发送 packet，所以它很难被发现。预防 packet sniffer 的有效手段是对包的内容进行加密。&lt;/p&gt;
&lt;h3 id=&#34;masquerade-as-someone-you-trust&#34;&gt;Masquerade as Someone You Trust&lt;/h3&gt;
&lt;p&gt;在网络中，我们可以很容易地制作一个包含任意源地址，目标地址和内容的 packet。网络中的节点只会负责地帮助我们转发这个包，但不一定能检验这个包的真实性。这种向网络中发送包含虚假源地址的包的攻击手段被称为 &lt;strong&gt;IP 欺骗 (IP spoofing)&lt;/strong&gt;。通过 IP spoofing，我们可以在网络中伪装成另一个人与他人通信。&lt;/p&gt;
&lt;p&gt;为了防御 IP spoofing，我们需要在网络中添加 end-point authentication，即检验消息的源地址的真实性。&lt;/p&gt;
&lt;h2 id=&#34;17-history-of-computer-networking-and-the-internet&#34;&gt;1.7 History of Computer Networking and the Internet&lt;/h2&gt;
&lt;p&gt;略。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
