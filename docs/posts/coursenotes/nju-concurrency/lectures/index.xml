<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lectures | Academic</title>
    <link>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/</link>
      <atom:link href="https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/index.xml" rel="self" type="application/rss+xml" />
    <description>Lectures</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 04 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Lectures</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/</link>
    </image>
    
    <item>
      <title>Lecture 04: Declarative Semantics for Concurrency</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/lec04/</link>
      <pubDate>Tue, 04 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/lec04/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#execution-graph&#34;&gt;Execution Graph&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#concepts&#34;&gt;Concepts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#consistency-predicate&#34;&gt;Consistency Predicate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#sequential-consistency&#34;&gt;Sequential Consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#coherent-consistency&#34;&gt;Coherent Consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#releaseacquire-consistency&#34;&gt;Release/Acquire Consistency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#happen-before-and-cc11-memory-model&#34;&gt;Happen-before and C/C++11 Memory Model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;The basic procedure of declarative/axiomatic concurrency semantics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Define the notion of a program execution (generalization of an execution trace)&lt;/li&gt;
&lt;li&gt;Map a program to a set of executions&lt;/li&gt;
&lt;li&gt;Define a consistency predicate on executions&lt;/li&gt;
&lt;li&gt;Semantics = the set of consistent executions of a program&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exception: &amp;ldquo;catch-fire&amp;rdquo; semantics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;catch-fire&amp;rdquo; semantics are those existing at least one &amp;ldquo;bad&amp;rdquo; consistent execution, which implies undefined behavior. (mainly appear in C/C++)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;execution-graph&#34;&gt;Execution Graph&lt;/h2&gt;
&lt;p&gt;The vertices stands for the events in the program. There are 4 event types: read, write, update, fence. The edges represents relations between events. There are two relation types: program order &lt;code&gt;po&lt;/code&gt; (also called sequenced-before, &lt;code&gt;sb&lt;/code&gt;), and reads-from, &lt;code&gt;rf&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;concepts&#34;&gt;Concepts&lt;/h3&gt;
&lt;p&gt;$\fbox{Definition}$ (label) A label has one of the following forms:
$$
R\space x\space v_r\qquad W\space x\space v_w\qquad U(x\space v_r\space v_w)\qquad F
$$
where $x\in \text{Loc}$ and $v_r,v_w\in \text{Val}$.&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ (event) An event is a triple $\langle id, i, l\rangle$ where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$id\in \mathbb N$ is an event identifier.&lt;/li&gt;
&lt;li&gt;$i\in \text{Tid}\cup {0}$ is a thread identifier.&lt;/li&gt;
&lt;li&gt;$l$ is a label.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: the thread identifier &amp;ldquo;0&amp;rdquo; is used for some initial statements that don&amp;rsquo;t belong to any specific thread.&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ (execution graph) An execution graph is a tuple $\langle E, po,rf\rangle$, where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$E$ is a finite set of events.&lt;/li&gt;
&lt;li&gt;$po$ (program order) is a partial order on $E$.&lt;/li&gt;
&lt;li&gt;$rf$ (reads-from) is a binary relation on $E$ such that
&lt;ul&gt;
&lt;li&gt;For every $\langle w,r\rangle\in rf$:
&lt;ul&gt;
&lt;li&gt;$\text{type}(w)\in {W,U},\text{type}(r)\in {R, U}$&lt;/li&gt;
&lt;li&gt;$\text{loc}(w)=\text{loc}(r)$&lt;/li&gt;
&lt;li&gt;$val_w=val_r$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$rf^{-1}$ is a function, i.e., every read operation can read from only one write.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\fbox{Definition}$ (sequential) An execution graph $G$ is called sequential if&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\text{tid}(a)=0$ for every $a\in G.E$.&lt;/li&gt;
&lt;li&gt;$G.po$ is a total order on $G.E$.&lt;/li&gt;
&lt;li&gt;$G.rf=\emptyset$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A sequential graph can be constructed from commands by the following rules:&lt;/p&gt;
&lt;p&gt;Silent:
$$
\frac{c,s\overset{\epsilon}{\to}c&amp;rsquo;,s&amp;rsquo;}{c,s,G\Rightarrow c&amp;rsquo;,s&amp;rsquo;,G}
$$
Non-silent:
$$
\frac{c,s\overset{l}{\to}c&amp;rsquo;,s&amp;rsquo;\qquad a=\langle n,0,l\rangle\qquad n\notin {\text{id}(b)|b\in G.E}}{c,s,G\Rightarrow c&amp;rsquo;,s&amp;rsquo;,Add(a,G)}
$$
where $Add(a,G)$ yields an execution graph $G&amp;rsquo;$ givens by&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$G&amp;rsquo;.E=G.E\cup {a}$&lt;/li&gt;
&lt;li&gt;$G&amp;rsquo;.po=G.po\cup (G.E\times {a})$&lt;/li&gt;
&lt;li&gt;$G&amp;rsquo;.rf=G.rf$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$G$ is an execution graph of a command &lt;code&gt;c&lt;/code&gt; with a final store &lt;code&gt;s&lt;/code&gt; if $c,s_0,G_\emptyset\Rightarrow^*\mathbf{skip},s,G$.&lt;/p&gt;
&lt;h3 id=&#34;consistency-predicate&#34;&gt;Consistency Predicate&lt;/h3&gt;
&lt;p&gt;The restriction of execution graph is quite loose. Given a program, we can draw a huge number of execution graphs satisfying the requirements above, but not all of them are reasonable. Therefore our goal is to define some consistency rules to specify &amp;ldquo;valid&amp;rdquo; execution graphs.&lt;/p&gt;
&lt;p&gt;Let $X$ be some consistency predicate. We say an outcome $O$ is allowed for a program $P$ under $X$ if there exists an execution graph $G$ such that $G$ is X-consistent and $G$ belongs to $P$ with outcome $O$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Exception: &amp;ldquo;catch-fire&amp;rdquo; semantics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;or if there exists an execution graph $G$ such that $G$ is X-consistent, $G$ is an execution graph of $P$ and $G$ is &amp;ldquo;bad&amp;rdquo;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$\fbox{Definition}$ (completeness) An execution graph $G$ is called complete if $codom(G.rf)=G.R$, i.e., every read reads from some write.&lt;/p&gt;
&lt;h2 id=&#34;sequential-consistency&#34;&gt;Sequential Consistency&lt;/h2&gt;
&lt;p&gt;$\fbox{Definition}$ (SC-consistent, Lamport) Let $sc$ be a total order of $G.E$, $G$ is called SC-consistent wrt (with respect to) $sc$ if&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If $\langle a,b\rangle\in G.po$, $\langle a, b\rangle \in sc$.&lt;/li&gt;
&lt;li&gt;If $\langle a, b\rangle\in G.rf$, then $\langle a,b\rangle\in sc$ and there does not exist $c\in G.W_{loc(b)}$ such that $\langle a,c\rangle\in sc$ and $\langle c,b\rangle\in sc$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes: the first condition requires that program order should be consistent with the $sc$ total order. The second condition requires that a read should read from a write prior to it and there shouldn&amp;rsquo;t be another write (on the same location) between them, i.e., read from the latest write.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s an alternative version of SC-consistency:&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ (modification order) $mo$ is called a modification order for an execution graph $G$ if $mo=\bigcup_{x\in \text{Loc}}mo_x$, where each $mo_x$ is a total order on $G.W_x$.&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ (SC-consistent, alternative) An execution graph $G$ is called SC-consistent if the following hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$G$ is complete.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There exists a modification order $mo$ for $G$ such that $G.po\cup G.rf\cup mo\cup rb$ is acyclic.&lt;/p&gt;
&lt;p&gt;Here $rb\triangleq (G.rf^{-1};mo) -{id}$. The &amp;ldquo;;&amp;rdquo; operator means that if there exists $\langle a,c\rangle\in G.rf^{-1}$ and $\langle c,b\rangle\in mo$, then $\langle a,b\rangle\in rb$. The ${id}$ is used to filter out some dummy relations generated by $U$ (an operation $U$ reads from another write $W$ and $W\to U$ is also in $mo$.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\fbox{Theorem}$ The two SC definitions are equivalent.&lt;/p&gt;
&lt;p&gt;Proof:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Lamport SC $\Rightarrow$ alternative SC&lt;/strong&gt;: We&amp;rsquo;ve got an total order $sc$ which includes $po$ and $rf$, so we only need to construct $mo$. We let $mo\triangleq [W_x]; sc; [W_x]$. (Here $[W_x]$ is a tricky way of representing the starting node should belong to $G.W_x$.). Since $mo\subseteq sc$, we only need to proof that $rb$ won&amp;rsquo;t generate circle with $sc$. Suppose the opposite, then the execution graph should be like&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
W1 --&amp;gt;|rf| R
W1 --&amp;gt;|mo| W2
W2 --&amp;gt;|sc| R
R --&amp;gt;|rb| W2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which contradicts the property of $sc$ in Lamport SC&amp;rsquo;s definition.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;alternative SC $\Rightarrow$ Lamport SC&lt;/strong&gt;: We&amp;rsquo;ve got $po,rf,mo$. Let $sc$ be a total order satisfying $po\cup rf\cup mo\cup rb\subseteq sc$. ($po\cup rf\cup mo\cup rb$ is acyclic, so it&amp;rsquo;s reasonable.) We need to prove that the total order $sc$ satisfies the second property in the definition. Suppose the opposite, i.e., there exists $\langle a,b\rangle, \langle a,c\rangle, \langle c,b\rangle\in sc$ and $\langle a,b\rangle\in rf,c\in G.W_{loc(b)}$, it&amp;rsquo;s easy to discover that $b\overset{rb}{\to}c$ (the graph is the same as above), so $\langle b,c\rangle\in sc$, which contradicts the fact that $sc$ is an total order.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;coherent-consistency&#34;&gt;Coherent Consistency&lt;/h2&gt;
&lt;p&gt;SC with interleaving semantics is (relatively) human-friendly, but it&amp;rsquo;s expensive to implement SC on hardware. What&amp;rsquo;s more, SC prohibits various optimization that are sound for sequential code. What most hardware guarantee and compilers preserve is &amp;ldquo;SC-per-location&amp;rdquo; (aka. coherence)&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ (coherent) an execution graph $G$ is coherent if the following hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$G$ is complete.&lt;/li&gt;
&lt;li&gt;For every location $x$, there exists a total order $sc_x$ satisfying the Lamport SC&amp;rsquo;s properties.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A few alternative definitions of coherence are shown below:&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ an execution graph $G$ is called coherent if the following hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$G$ is complete.&lt;/li&gt;
&lt;li&gt;There exists a modification order $mo$ such that $G.po|_{loc}\cup G.rf\cup mo\cup rb$ is acyclic.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note: $rf, mo,rb$ are naturally &amp;ldquo;per-location&amp;rdquo;, here the notation $G.po|_{loc}$ means that we only consider program order edges on the same location.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s have a loot at some prohibited patterns:&lt;/p&gt;
&lt;p&gt;No future read:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
S1(Rx) --&amp;gt; |po| S2(Wx)
S2 -.-&amp;gt; |rf|S1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RMW-1 (can be triggered by an &lt;code&gt;CAS(x, 1, 1)&lt;/code&gt; instruction):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
S1(Ux) -.-&amp;gt;|rf| S1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;coherence-ww/rw/wr/rr:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
S1(Wx) --&amp;gt; |po| S2(Wx) -.-&amp;gt;|mo| S1
S3(Wx) -.-&amp;gt; |rf| S4(Rx) --&amp;gt; |po| S5(Wx) -.-&amp;gt; |mo| S3
S6(Wx) -.-&amp;gt; |mo| S7(Wx) --&amp;gt; |po| S8(Rx)
S6 -.-&amp;gt; |rf| S8
S9(Wx) -.-&amp;gt;|rf| S10(Rx) --&amp;gt; |po| S11(Rx)
S12(Wx) -.-&amp;gt;|rf| S11
S12(Wx) -.-&amp;gt;|mo| S9
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: with $rb$ edges, these graphs will have cycles.&lt;/p&gt;
&lt;p&gt;RMW-2:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
S1(Wx) -.-&amp;gt; |rf| S2(Ux) -.-&amp;gt; |mo| S1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Atomicity:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
S1(Wx) -.-&amp;gt;|mo| S2(Wx) -.-&amp;gt;|mo| S3(Ux)
S1 -.-&amp;gt;|rf| S3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This pattern illustrates that RMW event may only read from the immediate $mo$-predecessor - it has synchronization.&lt;/p&gt;
&lt;p&gt;It can be proved that the bad patterns above cover all the cases of invalid execution graphs, so&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ an execution graph $G$ is coherent if $G$ is complete and there exists a modification order $mo$ satisfying:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$rf;po$ is irreflexive (no-future-read)&lt;/li&gt;
&lt;li&gt;$mo;po$ is irreflexive (coherence-ww)&lt;/li&gt;
&lt;li&gt;$mo;rf;po$ is irreflexive (coherence-rw)&lt;/li&gt;
&lt;li&gt;$rf^{-1};mo;po$ is irreflexive (coherence-wr)&lt;/li&gt;
&lt;li&gt;$rf^{-1};mo;rf;po$ is irreflexive (coherence-rr)&lt;/li&gt;
&lt;li&gt;$rf$ is irreflexive (RMW-1)&lt;/li&gt;
&lt;li&gt;$mo;rf$ is irreflexive (RMW-2)&lt;/li&gt;
&lt;li&gt;$rf^{-1};mo;mo$ is irreflexive (RMW-atomicity)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;releaseacquire-consistency&#34;&gt;Release/Acquire Consistency&lt;/h2&gt;
&lt;p&gt;COH is often too weak. For example, the common implementation of spinlock fails to work in COH since the variables used in the lock have no relation with the variables used in the critical section:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;lock(l):                          unlock(l):
    r := 0                            l := 0
    while not r do
        r := CAS(l, 0, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;Initially: x = y = 0;
lock(l);        ||  lock(l);
x = 1;          ||  y = 1;
a = y; /* 0 */  ||  b = x; /* 0 */       // store buffering is allowed even with spinlock!
unlock(l);      ||  unlock(l);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In addition, COH also doesn&amp;rsquo;t support message passing:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;Initially: x = y = 0;
x = 42;  ||  a = y;
y = 1;   ||  while (!a) a = y;          // Message passing: y = 1 ==&amp;gt; x = 42 is expected.
         ||  b = x; // 0                // b = 0 is allowable in COH!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The lesson we can learn from these examples is that the $rb$ relation in one variable should influence the global program order, i.e., $rb$ should serve as a synchronization. This leads to the RA memory model:&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ (RA-consistent) an execution graph $G$ is RA-consistent if it&amp;rsquo;s complete and there exists a modification order $mo$ such that $(po\cup rf)^+|_{loc}\cup mo\cup rb$ is acyclic.&lt;/p&gt;
&lt;p&gt;The subtle difference between $po|&lt;em&gt;{loc}\cup rf$ and $(po\cup rf)^+|&lt;/em&gt;{loc}$ is that the latter allow $rf$ relation on one location to connect events on other locations. Let&amp;rsquo;s check it on message passing example:&lt;/p&gt;
&lt;p&gt;COH on &lt;code&gt;x&lt;/code&gt; : allowed&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
S1(x=0) --&amp;gt;|po| S2(x=42)
S1 -.-&amp;gt; |mo| S2
S1 --&amp;gt; |po| S3(b=x // 0?)
S1 -.-&amp;gt; |rf| S3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RA on &lt;code&gt;x&lt;/code&gt; : not allowed&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
S1(x=0) --&amp;gt; |po| S2(x=42) --&amp;gt; |&amp;quot;(po,rf)+&amp;quot;| S3(y=1)
S1 --&amp;gt; |po| S4(a=y // 1)
S3 --&amp;gt;|&amp;quot;(po,rf)+&amp;quot;| S4
S4 --&amp;gt; |&amp;quot;(po,rf)+&amp;quot;| S5(b=x // 0?)
S1 -.-&amp;gt; |rf| S5
S5 -.-&amp;gt; |rb| S2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In RA,  the $rf$ relation between &lt;code&gt;y=1&lt;/code&gt; and &lt;code&gt;a=y&lt;/code&gt; serves as a bridge that connects &lt;code&gt;x=42&lt;/code&gt; and &lt;code&gt;b=x&lt;/code&gt;. In this situation If &lt;code&gt;b=x&lt;/code&gt; reads from &lt;code&gt;x=0&lt;/code&gt;, the $rb$ edge generated will cause a cycle.&lt;/p&gt;
&lt;h2 id=&#34;happen-before-and-cc11-memory-model&#34;&gt;Happen-before and C/C++11 Memory Model&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ve already known that according to the strength, COH&amp;lt;RA&amp;lt;SC, but there&amp;rsquo;s still some room between COH and RA: in the message passing example, we only need the $rf$ relation on &lt;code&gt;y&lt;/code&gt; to have the synchronization effect and we don&amp;rsquo;t care about &lt;code&gt;x&lt;/code&gt;. The idea is that we can introduce access modes on variables:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;x =(rlx) 42;  ||  a = y(rlx)
y =(rel) 1;   ||  while (!a) a = y;
              ||  a = y(acq)
              ||  b = x(rlx)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each memory access has a mode:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reads: $\text{rlx}$ or $\text{acq}$.&lt;/li&gt;
&lt;li&gt;Writes: $\text{rlx}$ or $\text{rel}$.&lt;/li&gt;
&lt;li&gt;RMWs: $\text{rlx}$ or $\text{acq}$ or $\text{rel}$ or $\text{acq-rel}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The strength order can be represented as the following graph:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
S1(rlx) --&amp;gt; S2(acq)
S1 --&amp;gt; S3(rel)
S2 --&amp;gt; S4(acq-rel)
S3 --&amp;gt; S4
S1 --&amp;gt; S4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And we do synchronization only on $\text{rel/acq}$:
$$
\begin{align}
G.sw&amp;amp;\triangleq [W^{\supseteq\text{rel}}];G.rf;[R^{\supseteq \text{acq}}]\\
G.hb&amp;amp;\triangleq (G.po\cup G.sw)^+
\end{align}
$$
Here $W^{\supseteq \text{rel}}$ means the set of write events that have access mode not weaker than $\text{rel}$.&lt;/p&gt;
&lt;p&gt;$\fbox{Definition}$ (C11 Consistency) an execution graph $G$ is C11-consistent if $G$ is complete and there exists a modification order $mo$ such that $hb_{loc}\cup rf\cup mo\cup rb$ is acyclic.&lt;/p&gt;
&lt;p&gt;Note: the definition of RA-consistency doesn&amp;rsquo;t need to additionally include $rf$ because the transitive closure $(po\cup rf)^+$ has include all the information in $rf$. However, in C11-consistency $hb_{loc}$ only consider $rf$ edges between &amp;ldquo;strong&amp;rdquo; r/w/rmw events so we still need to include $rf$.&lt;/p&gt;
&lt;p&gt;The full C/C++11 memory model is more general in that it includes more access modes and fences.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 03: Operational Semantics for Concurrency</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/lec03/</link>
      <pubDate>Tue, 20 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/lec03/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#a-simple-concurrent-programming-language&#34;&gt;A Simple Concurrent Programming Language&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#basic-setup&#34;&gt;Basic Setup&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#thread-subsystem&#34;&gt;Thread Subsystem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#storage-subsystem&#34;&gt;Storage Subsystem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#linking-the-two&#34;&gt;Linking the Two&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#the-thread-subsystem&#34;&gt;The Thread Subsystem&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#thread-local-steps&#34;&gt;Thread Local Steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#lifting-to-concurrent-programs&#34;&gt;Lifting to Concurrent Programs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#sc-storage-subsystem&#34;&gt;SC Storage subsystem&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#linking-the-thread-and-storage-subsystems&#34;&gt;Linking the Thread and Storage Subsystems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#x86s-tso-storage-subsystem&#34;&gt;x86&amp;rsquo;s TSO Storage Subsystem:&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#linking-the-thread-and-storage-subsystem&#34;&gt;Linking The Thread and Storage Subsystem&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#exercise-pso-storage-system&#34;&gt;Exercise: PSO Storage System&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;a-simple-concurrent-programming-language&#34;&gt;A Simple Concurrent Programming Language&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Basic domains:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Registers: $r\in \text{Reg}$.&lt;/li&gt;
&lt;li&gt;Memory locations: $x\in \text{Loc}$.&lt;/li&gt;
&lt;li&gt;Values (including 0): $v\in \text{Val}$.&lt;/li&gt;
&lt;li&gt;Thread identifiers: $i\in \text{Tid}=\{1,\cdots,N\}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Expressions and commands&lt;/strong&gt; (here all commands are atomic):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;e ::= r | v | e +(-*/) e | ...

c ::= skip | if e then c else c | while e do c |
      c ; c (sequential) | r := e | r := x (read) | x := e (write)
      r := FAA(x, e) | r := CAS(x, e, e) | fence
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;FAA means &amp;ldquo;fetch-and-add&amp;rdquo;, &lt;code&gt;r = FAA(x, e)&lt;/code&gt; will do&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;r = x;
x += e;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;atomically.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CAS means &amp;ldquo;compare-and-set/swap&amp;rdquo;, &lt;code&gt;r = CAS(x, er, ew)&lt;/code&gt; will do&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;r = x;
if (r == er) {
    x = ew;
    r = 1;
}
else
    r = 0;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;atomically.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;fence&lt;/code&gt; only takes effect under WMM. It forces previous writes to be propagated into memory.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Programs:&lt;/strong&gt; $P:Tid\to Cmd$, written as $P=c_1||c_2||\cdots ||c_N$.&lt;/p&gt;
&lt;h2 id=&#34;basic-setup&#34;&gt;Basic Setup&lt;/h2&gt;
&lt;p&gt;Different memory models usually share the same thread behaviors while have different implementation on the read/write side. Therefore we decompose the system into thread subsystem and storage subsystem and set an &amp;ldquo;virtual&amp;rdquo; interface between them.&lt;/p&gt;
&lt;h3 id=&#34;thread-subsystem&#34;&gt;Thread Subsystem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;thread local step: $(c,s)\overset{l}{\to}(c&amp;rsquo;,s&amp;rsquo;)$,&lt;/li&gt;
&lt;li&gt;Lift them to program steps: $(P,S)\overset{i,l}{\to}(P&amp;rsquo;,S&amp;rsquo;)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;storage-subsystem&#34;&gt;Storage Subsystem&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It&amp;rsquo;s memory-model-dependent.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Describe the effect of memory accesses and fences.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$M\overset{i:l}{\to}M&amp;rsquo;$.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;linking-the-two&#34;&gt;Linking the Two&lt;/h3&gt;
&lt;p&gt;Either the thread or the storage subsystem make an internel step, i.e., $\epsilon$, or they make matching $i:l$ steps. The transformation is denoted as $P,S,M\Rightarrow P&amp;rsquo;,S&amp;rsquo;,M&amp;rsquo;$.&lt;/p&gt;
&lt;h2 id=&#34;the-thread-subsystem&#34;&gt;The Thread Subsystem&lt;/h2&gt;
&lt;h3 id=&#34;thread-local-steps&#34;&gt;Thread Local Steps&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Store:&lt;/strong&gt; $s:\text{Reg}\to \text{Val}$ (initially $s_0\triangleq \lambda r.0$).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;State:&lt;/strong&gt; $(c,s)\in \text{Command}\times \text{Store}$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transitions:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$\mathbf{skip}$:
$$
\frac{}{\mathbf{skip};c,s\overset{\epsilon}{\to}c,s}
$$&lt;/p&gt;
&lt;p&gt;Sequential:&lt;/p&gt;
&lt;p&gt;$$
\frac{c_1,s\overset{l}{\to}c_1&amp;rsquo;,s&amp;rsquo;}{c_1;c_2,s\overset{l}{\to}c_1&amp;rsquo;,c_2,s&amp;rsquo;}
$$&lt;/p&gt;
&lt;p&gt;Register operations:
$$
\frac{s&amp;rsquo;=s[r\mapsto s(e)]}{\text{r:=e},s\overset{\epsilon}{\to}\mathbf{skip},s&amp;rsquo;}
$$
Memory read:
$$
\frac{l=R(x, v)}{\text{r:=x},s\overset{l}{\to}\mathbf{skip},s[r\to v]}
$$
Here $l=R(x, v)$ means that we read from the memory and $M[x] = v$.&lt;/p&gt;
&lt;p&gt;Memory write:
$$
\frac{l=W(x, s(e))}{\text{x:=e,s}\overset{l}{\to}\mathbf{skip},s}
$$
$\mathbf{if}$-$\mathbf{then}$-$\mathbf{else}$ branch:
$$
\frac{s(e)\neq 0}{\mathbf{if}\space e\space \mathbf{then}\space c_1\space \mathbf{else}\space c_2,s\overset{\epsilon}{\to}c_1,s}
$$&lt;/p&gt;
&lt;p&gt;$$
\frac{s(e)= 0}{\mathbf{if}\space e\space \mathbf{then}\space c_1\space \mathbf{else}\space c_2,s\overset{\epsilon}{\to}c_2,s}
$$&lt;/p&gt;
&lt;p&gt;$\mathbf{while}$ loop:
$$
\frac{}{\mathbf{while}\space e\space \mathbf{do}\space c,s\overset{\epsilon}{\to}\mathbf{if}\space e\space\mathbf{then}\space (c;\mathbf{while}\space e\space \mathbf{do}\space c)\space \mathbf{else}\space \mathbf{skip},s}
$$
Fetch-and-add:
$$
\frac{l=U(x, v, v + s(e))}{\text{r:=}\mathbf{FAA}(x,e),s\overset{l}{\to}\mathbf{skip},s[r\to v]}
$$
Here we define a new way to interact with memory: &lt;code&gt;U&lt;/code&gt; (update).  &lt;code&gt;U(x, vr, vw)&lt;/code&gt; means that we fetch $v_r$ from $M[x]$ and write $v_w$ to $M[x]$.&lt;/p&gt;
&lt;p&gt;Compare-and-swap:
$$
\frac{l=R(x, v)\quad v\neq s(e_r)}{\text{r:=}\mathbf{CAS}(x, e_r,e_w),s\overset{l}{\to}\mathbf{skip},s[r\to 0]}
$$&lt;/p&gt;
&lt;p&gt;$$
\frac{l=U(x, s(e_r), s(e_w))}{\text{r:=}\mathbf{CAS}(x, e_r,e_w),s\overset{l}{\to}\mathbf{skip},s[r\to 1]}
$$&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s worth noticing that when compare-and-swap fails, it acts as a normal read operation (&amp;ldquo;R&amp;rdquo; instead of &amp;ldquo;U&amp;rdquo;)&lt;/p&gt;
&lt;p&gt;Fence:
$$
\frac{}{\mathbf{fence},s\overset{F}{\to}\mathbf{skip},s}
$$
For WMM, when the memory receives &amp;ldquo;F&amp;rdquo;, it will do particular operations.&lt;/p&gt;
&lt;h3 id=&#34;lifting-to-concurrent-programs&#34;&gt;Lifting to Concurrent Programs&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;State:&lt;/strong&gt; $(P,S)\in\text{Program}\times (\text{Tid}\to \text{Store})$. (initially $(P,S_0)$, where $S_0\triangleq \lambda i.s_0$)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transitions:&lt;/strong&gt;
$$
\frac{P(i),S(i)\overset{l}{\to}c,s}{P,S\overset{i:l}{\mapsto}P[i\to c],S[i\mapsto s]}
$$&lt;/p&gt;
&lt;h2 id=&#34;sc-storage-subsystem&#34;&gt;SC Storage subsystem&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Machine state:&lt;/strong&gt; $M:\text{Loc}\to\text{Val}$ (initially $M_0\triangleq \lambda x.0$).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transitions:&lt;/strong&gt;
$$
\frac{l=W(x, v)}{M\overset{i:l}{\to}M[x\mapsto v]}
$$&lt;/p&gt;
&lt;p&gt;$$
\frac{l=R(x, v)\quad M[x]=v}{M\overset{i:l}{\to}M}
$$&lt;/p&gt;
&lt;p&gt;$$
\frac{l=U(x,v_r,v_w)\quad M[x]=v_r}{M\overset{i:l}{\to}M[x\mapsto v_w]}
$$&lt;/p&gt;
&lt;p&gt;$$
\frac{l=F}{M\overset{i:l}{\to}M}
$$&lt;/p&gt;
&lt;p&gt;(&lt;code&gt;fence&lt;/code&gt; doesn&amp;rsquo;t take effect in SC memory model.)&lt;/p&gt;
&lt;h3 id=&#34;linking-the-thread-and-storage-subsystems&#34;&gt;Linking the Thread and Storage Subsystems&lt;/h3&gt;
&lt;p&gt;Silent:
$$
\frac{P,S\overset{i:\epsilon}{\to}P&amp;rsquo;, S&amp;rsquo;}{P,S,M\Rightarrow P&amp;rsquo;,S&amp;rsquo;,M}
$$
Non-silent:
$$
\frac{P,S\overset{i:l}{\to}P&amp;rsquo;,S&amp;rsquo;\quad M\overset{i:l}{\to}M&amp;rsquo;}{P,S,M\Rightarrow P&amp;rsquo;,S&amp;rsquo;,M&amp;rsquo;}
$$
An outcome $O:\text{Tid}\to\text{Store}$ is allowed for a program $P$ under SC if there exists $M$ such that
$$
P,S_0,M_0\Rightarrow^* \mathbf{skip}||&amp;hellip;||\mathbf{skip},O,M.
$$&lt;/p&gt;
&lt;h2 id=&#34;x86s-tso-storage-subsystem&#34;&gt;x86&amp;rsquo;s TSO Storage Subsystem:&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Machine states:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A memory $M:\text{Loc}\to\text{Val}$&lt;/li&gt;
&lt;li&gt;A function $B:\text{Tid}\to (\text{Loc},\text{Val})^*$ assigning a &lt;strong&gt;store buffer&lt;/strong&gt; to every thread. Here a pair $(x, v)$ stands for a write. The most recent write appears at the left most position of the write sequence.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Initially, $M_0\triangleq \lambda x.0$,$B_0=\lambda i.\epsilon$).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transitions:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Write (only to the thread-local buffer):
$$
\frac{l=W(x, v)}{M,B\overset{i:l}{\to}M,B[i\mapsto (x,v)\cdot B(i)]}
$$
Propagate (flush the least recent operation in the buffer to the memory):
$$
\frac{B(i)=b\cdot (x,v)}{M,B\overset{i:\epsilon}{\to}M[x\mapsto v],B[i\mapsto b]}
$$
Read
$$
\frac{l=R(x,v)\quad B(i)=(x_n,v_n)\cdot\ldots\cdot(x_1,v_1)\quad M[x_1\mapsto v_1]\cdots[x_n\mapsto v_n] (x)=v}{M,B\overset{i:l}{\to}M,B}
$$
Notice that during a read, the buffer won&amp;rsquo;t be flushed into the memory.&lt;/p&gt;
&lt;p&gt;RMW (read-modify-write):
$$
\frac{l=U(x,v_r,v_w)\quad B(i)=\epsilon \quad M(x)=v_r}{M,B\overset{i:l}{\to}M[x\mapsto v_w],B}
$$
The condition $B(i)=\epsilon$ indicates that RMW will automatically synchronize the state. Notice that in $\mathbf{CAS}$, if the comparison failed, $\mathbf{CAS}$ would act as a normal &amp;ldquo;read&amp;rdquo; operation and in TSO no synchronization would be conducted.&lt;/p&gt;
&lt;p&gt;Fence:
$$
\frac{l=F\quad B(i)=\epsilon}{M,B\overset{i:l}{\to}M,B}
$$
Fence is used as forced synchronization.&lt;/p&gt;
&lt;h3 id=&#34;linking-the-thread-and-storage-subsystem&#34;&gt;Linking The Thread and Storage Subsystem&lt;/h3&gt;
&lt;p&gt;Silent thread:
$$
\frac{P,S\overset{i:\epsilon}{\to}P&amp;rsquo;,S&amp;rsquo;}{P,S,M,B\Rightarrow P,S&amp;rsquo;,M,B}
$$
Silent storage:
$$
\frac{M,B\overset{i:\epsilon}{\to}M&amp;rsquo;,B&amp;rsquo;}{P,S,M,B\Rightarrow P,S,M&amp;rsquo;,B&amp;rsquo;}
$$
Non silent:
$$
\frac{P,S\overset{i:l}{\to}P&amp;rsquo;,S&amp;rsquo;\qquad M,B\overset{i:l}{\to}M&amp;rsquo;,B&amp;rsquo;}{P,S,M,B\Rightarrow P&amp;rsquo;,S&amp;rsquo;,M&amp;rsquo;,B&amp;rsquo;}
$$
The definition of allowed outcome is similar to that of SC.&lt;/p&gt;
&lt;h2 id=&#34;exercise-pso-storage-system&#34;&gt;Exercise: PSO Storage System&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Partial Store Ordering (PSO)&lt;/em&gt; is a WMM similar to TSO, but it does not guarantee that stores to different locations propagate to the main memory in the order they were issued. In particular, it allows the following weak behavior:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;Initially, x = y = 0;
x = 1;  ||  a = y; // 1
y = 1;  ||  b = x; // 0;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(1) Operational semantics for PSO:&lt;/p&gt;
&lt;p&gt;We only need to redefine the propagate rule in TSO:
$$
\frac{B(i)=b&amp;rsquo;\cdot(x,v)\cdot b\qquad b=(x_t,v_t)\cdot\ldots\cdot(x_1,v_1),\forall 1\leq i\leq t,x_i\neq x}{M,B\overset{i:\epsilon}{\to}M[x\mapsto v],B[i\mapsto b&amp;rsquo;\cdot b]}
$$
(2) store-store fence:&lt;/p&gt;
&lt;p&gt;In the thread subsystem:
$$
\frac{}{\mathbf{ssfence};c,s\overset{SSF}{\to}\mathbf{skip};c,s}
$$
In the storage subsystem:&lt;/p&gt;
&lt;p&gt;SSF rule: add a special mark into the buffer array:
$$
\frac{}{M,B\overset{SSF}{\to}M,B[i\mapsto F\cdot B(i)]}
$$
Propagation rule needn&amp;rsquo;t be changed because our conditions implicitly require that there&amp;rsquo;s no store-store fence before the target operation. But we need an additional rule to move away &amp;ldquo;F&amp;rdquo; marks:
$$
\frac{B(i)=b\cdot F}{M,B\overset{i:\epsilon}{\to}M&amp;rsquo;,B[i\mapsto b]}
$$
(3) Show that programs containing store-store fences between every two writes have the same outcomes under TSO and PSO:&lt;/p&gt;
&lt;p&gt;TSO and PSO differ only in their propagation rules. If there is a store-store fence between every two writes, it&amp;rsquo;s easy to prove that at any point, the buffer of arbitrary thread should be in the form of $(x_n,v_n)\cdot F\cdot \ldots \cdot F\cdot (x_2,v_2)\cdot F\cdot (x_1,v_1)$. Therefore at any point the propagation rule in PSO can only choose the least recent operation in the buffer to propagate, which makes it completely the same as TSO&amp;rsquo;s propagation rule.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 02: Happens-before Memory Model</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/lec02/</link>
      <pubDate>Tue, 13 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/lec02/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#the-need-of-weak-memory-model&#34;&gt;The Need of Weak Memory Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#design-criteria&#34;&gt;Design Criteria&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#happened-before-memory-model-hmm&#34;&gt;Happened-before Memory Model (HMM)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#example-store-buffering&#34;&gt;Example: Store Buffering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#example-out-of-thin-air-read&#34;&gt;Example: Out-of-thin-Air Read&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#example-independent-reads-of-independent-writes-iriw&#34;&gt;Example: Independent Reads of Independent Writes (IRIW)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#example-hmm---no-drf-guarantee&#34;&gt;Example: HMM - No DRF guarantee.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Memory models define which reads see which writes. Sequential Consistency (SC) model is the simplest memory model: several threads&amp;rsquo; executions are interleaved (interleaving semantics), every read fetches the most recent write (full visibility).&lt;/p&gt;
&lt;h2 id=&#34;the-need-of-weak-memory-model&#34;&gt;The Need of Weak Memory Model&lt;/h2&gt;
&lt;p&gt;SC mode prohibits many optimizations, e.g. store buffering&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;Initially: x = y = 0;
x = 1;   ||   y = 1;
r1 = y;  ||   r2 = x;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;r1 = r2 = 0&lt;/code&gt; is impossible in SC model. However, compilers are unaware of concurrency and may adjust the order of statements, which violates SC model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;r1 = y;   #1 ||   y = 1;   #2
x = 1     #4 ||   r2 = x;  #3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;SC model is inconsistent with the current compiler &amp;amp; architecture implementations. That&amp;rsquo;s why we need weak memory models, which allow more behaviors.&lt;/p&gt;
&lt;h2 id=&#34;design-criteria&#34;&gt;Design Criteria&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Usability&lt;/strong&gt;: DRF guarantee. DRF programs should have the same behaviors as in SC model. DRF stands for Data-Race-Freedom. A data race occurs when we have two concurrent conflicting operations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Conflicting: two operations both access the same memory location and at least one is a write.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Concurrent: two operations are not ordered by &amp;ldquo;happens-before&amp;rdquo;. Here &amp;ldquo;happens-before&amp;rdquo; varies under different memory models. In SC, &amp;ldquo;happens-before&amp;rdquo; means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Program order: statement $S_1$ appears before $S_2$.&lt;/li&gt;
&lt;li&gt;Synchronization-with: lock - unlock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Implementability&lt;/strong&gt;: WMM cannot be too strong. It should be compatible with the mainstream compilers/architecture design:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allow common optimization techniques.&lt;/li&gt;
&lt;li&gt;Allow standard compilation schemes to major modern architectures.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That is, for an arbitrary code $C$, let $WMM(C)$ be the set of possible behaviors of $C$ under WMM, $Compiler(C)$ be the set of possible behaviors after compilation, $Compiler(C)\subseteq WMM(C)$ should hold.&lt;/p&gt;
&lt;p&gt;However, WMM cannot be too week either. e.g., type-safety and security guarantee shall be preserved.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Compiler Optimization Can Be Smart&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s difficult to put forward a good WMM because optimizations are complex. For example,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;r1 = x;               ||  y = 2;
r2 = x;               ||  x = r3;
if (r1 == r2) y = 2;  ||
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code can be optimized like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;y = 2;        // reorder
r1 = x;
r2 = r1;      // reduce memory access
if (true);    // &amp;quot;r2 = r1&amp;quot; guarantees (r1 == r2)
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;happened-before-memory-model-hmm&#34;&gt;Happened-before Memory Model (HMM)&lt;/h2&gt;
&lt;p&gt;Program execution: a set of events, and some orders between them.&lt;/p&gt;
&lt;p&gt;Happened-before order is the transitive closure of po (program order) and sw (synchronize-with). In HMM, a read can see&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The most recent write that happens before it.&lt;/li&gt;
&lt;li&gt;A write that has no happens-before relation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In WMM, we consider declarative semantics, i.e., instead of constructing the execution, we firstly do assumptions on the result of reads, then we draw execution graph and check whether the result is reasonable.&lt;/p&gt;
&lt;h3 id=&#34;example-store-buffering&#34;&gt;Example: Store Buffering&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
S1(x=y=0) --&amp;gt; S2(x=1) --&amp;gt; S3(r1=y // 0?)
S1 --&amp;gt; S4(y=1) --&amp;gt; S5(r2=x // 0?)
S5 -.-&amp;gt; S1
S3 -.-&amp;gt; S1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Assumption: &lt;code&gt;r1 = r2 = 0&lt;/code&gt;, we find that &lt;code&gt;x = y = 0&lt;/code&gt; is the most recent write that happens before &lt;code&gt;r1 = y&lt;/code&gt; and &lt;code&gt;r2 = x&lt;/code&gt;. Therefore the assumption is reasonable.&lt;/p&gt;
&lt;h3 id=&#34;example-out-of-thin-air-read&#34;&gt;Example: Out-of-thin-Air Read&lt;/h3&gt;
&lt;p&gt;Out-of-thin-air (OOTA) read means that the result is completely unreasonable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;Initially: x = y = 0;
r1 = x; | r2 = y;
y = r1; | x = r2;
assumption: r1 = r2 = 42;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
S1(x=y=0) --&amp;gt; S2(r1=x // 42?) --&amp;gt; S3(y=42)
S1 --&amp;gt; S4(r2=y // 42?) --&amp;gt; S5(x=42)
S2 -.-&amp;gt; S5
S4 -.-&amp;gt; S3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another understanding:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Speculation: &lt;code&gt;r2&lt;/code&gt; should be 42, which means that &lt;code&gt;y&lt;/code&gt; needs to be 42.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;r2&lt;/code&gt; equals 42, then in thread #2 &lt;code&gt;x&lt;/code&gt; will be 42.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;x&lt;/code&gt; equals 42, then in thread #1 &lt;code&gt;r1&lt;/code&gt; will be 42.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;r1&lt;/code&gt; equals 42, then in thread #1 &lt;code&gt;y&lt;/code&gt; will be 42. -&amp;gt; cycle formed, justified!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OOTA reads should be prohibited, otherwise malicious inputs may challenge the safety of programming languages. Java&amp;rsquo;s JMM spare great efforts to eliminate OOTA from HMM, resulting in JMM&amp;rsquo;s complexity, and JMM may generate some surprising behaviors.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;JMM&amp;rsquo;s Suprising Behaviors - Example&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;C1;       ||                 lock I    ||
lock I;   ||  C3;    ===&amp;gt;        C1;   ||  C3;
    C2;   ||                     C2;   ||
unlock I; ||                 unlock I; ||
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Adding more synchronization may increase behaviors!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;C1;  ||  C2  ||  C3;   ===&amp;gt;   C1;  ||  C3;
                              C2;  ||
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Inlining threads may increase behaviors!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;example-independent-reads-of-independent-writes-iriw&#34;&gt;Example: Independent Reads of Independent Writes (IRIW)&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;Initially: x = y = 0;
x = 1; || r1 = x; || r3 = y; || y = 1;
       || r2 = y; || r4 = x; ||
Assumption: r1 = 1, r2 = 0, r3 = 1, r4 = 0;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The assumption means that thread #2 shows &lt;code&gt;x=1&lt;/code&gt; happens before &lt;code&gt;y=1&lt;/code&gt; while thread #3 shows &lt;code&gt;y=1&lt;/code&gt; happens before &lt;code&gt;x=1&lt;/code&gt;, which is impossible in SC.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
S1(x=y=0) --&amp;gt; S2(x=1)
S1 --&amp;gt; S3(r1=x // 1?) --&amp;gt; S6(r2=y // 0?)
S1 --&amp;gt; S4(r3=y // 1?) --&amp;gt; S7(r4=x // 0?)
S1 --&amp;gt; S5(y=1)
S3 -.-&amp;gt; S2
S4 -.-&amp;gt; S5
S6 -.-&amp;gt; S1
S7 -.-&amp;gt; S1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, In HMM, it&amp;rsquo;s allowed.&lt;/p&gt;
&lt;h3 id=&#34;example-hmm---no-drf-guarantee&#34;&gt;Example: HMM - No DRF guarantee.&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;Initially: x = y = 0;
r1 = x;       ||  r2 = y;
if (r1 != 0)  ||  if (r2 != 0)
    y = 42;   ||      x = 42;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In SC, since both &lt;code&gt;if&lt;/code&gt; statements yield false, the two threads have no data race and the program satisfies DRF property. However, in HMM, &lt;code&gt;r1 = r2 = 42&lt;/code&gt; is possible, demonstrating that HMM doesn&amp;rsquo;t have DRF guarantee:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
S1(x=y=0) --&amp;gt; S2(r1=x // 42?) --&amp;gt; |if pass|S3(y=42)
S1 --&amp;gt; S4(r2=y // 42?) --&amp;gt; |if pass|S5(x=42)
S4 -.-&amp;gt; S3
S2 -.-&amp;gt; S5
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 01: Introduction</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/lec01/</link>
      <pubDate>Tue, 06 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-concurrency/lectures/lec01/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#implementations-of-concurrent-programs&#34;&gt;Implementations of Concurrent Programs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#problem-with-concurrency&#34;&gt;Problem with Concurrency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#model-summary&#34;&gt;Model Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#programmers-view&#34;&gt;Programmers View&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#memory-model&#34;&gt;Memory Model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#store-buffering&#34;&gt;Store Buffering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#load-buffering&#34;&gt;Load Buffering&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#wmm-for-high-level-languages&#34;&gt;WMM for High-Level Languages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;implementations-of-concurrent-programs&#34;&gt;Implementations of Concurrent Programs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Python:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import threading
def func():
    ...
if __name__ == &#39;__main__&#39;:
    t = threading.Thread(target=func,args=...)
    t.start()
    t.join()
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Java: use &amp;ldquo;Runnable&amp;rdquo; module&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;C++: use &lt;code&gt;&amp;lt;thread&amp;gt;&lt;/code&gt; header file.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some programming languages use message-passing mechanism instead of sharing memory, such as Go. But we can use the same abstraction.&lt;/p&gt;
&lt;h2 id=&#34;problem-with-concurrency&#34;&gt;Problem with Concurrency&lt;/h2&gt;
&lt;p&gt;Interleaving semantics means that the execution is non-deterministic, which is difficult for bug detection and reproduction.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;void thread_function() {
    for (int i = 0; i &amp;lt; 100; i++)
        std::cout &amp;lt;&amp;lt; &amp;quot;new thread&amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &#39;\n&#39;;
}
int main () {
    std::thread t(thread_function);
    for (int i = 0; i &amp;lt; 100; i++)
        std::cout &amp;lt;&amp;lt; &amp;quot;main thread&amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &#39;\n&#39;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we use &lt;code&gt;&amp;lt;&amp;lt;&lt;/code&gt; to  concatenate multiple outputs, the printing is not thread-safe and the example code results in interleaving outputs.&lt;/p&gt;
&lt;p&gt;The simplest solution to this is to use locks (synchronization operations):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;std::mutex mu;
void shared_output(std::string msg, int i) {
    std::lock_guard&amp;lt;std::mutex&amp;gt; guard(mu);
    std::cout &amp;lt;&amp;lt; msg &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &#39;\n&#39;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;model-summary&#34;&gt;Model Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Multiple threads&lt;/li&gt;
&lt;li&gt;Single shared memory&lt;/li&gt;
&lt;li&gt;Objects live in memory&lt;/li&gt;
&lt;li&gt;Unpredictable asynchronous delays.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;programmers-view&#34;&gt;Programmers View&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Parallel composition, shared memory &amp;amp; interleaving semantics&lt;/li&gt;
&lt;li&gt;Lock &amp;amp; synchronization operations&lt;/li&gt;
&lt;li&gt;Concurrent objects (e.g. implementation of locks) and their clients&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;memory-model&#34;&gt;Memory Model&lt;/h2&gt;
&lt;p&gt;In computing, a memory model describes the interactions of threads through memory and their shared use of data.&lt;/p&gt;
&lt;p&gt;When we write codes, we use sequential consistency (SC) model to understand it. However:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No multiprocessor implements SC.&lt;/li&gt;
&lt;li&gt;Modern compilers may invalidate the order.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each hardware has its own memory model. Theses models are called &lt;strong&gt;weak/relaxed memory model&lt;/strong&gt;. (Here the &amp;ldquo;weak&amp;rdquo; means that practical memory model may have more &amp;ldquo;unexpected&amp;rdquo; behavior.)&lt;/p&gt;
&lt;h3 id=&#34;store-buffering&#34;&gt;Store Buffering&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;Initially: x = y = 0;
x = 1;   |   y = 1;
r1 = y;  |   r2 = x;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;rsquo;s possible that &lt;code&gt;r1 = r2 = 0&lt;/code&gt; ! (e.g. in X86.)&lt;/p&gt;
&lt;p&gt;X86&amp;rsquo;s TSO memory model:&lt;/p&gt;
&lt;img src=&#34;https://kristoff-starling.github.io/img/x86-TSO.png&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;When we write data to the memory, the processor puts the data to the buffer and updates the buffer to the memory later. Each processor&amp;rsquo;s buffer is invisible to other processors.&lt;/p&gt;
&lt;p&gt;A possible execution leading to &lt;code&gt;r1 = r2 = 0&lt;/code&gt; is shown as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;x = 1&lt;/code&gt; in T1 (write to buffer)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;y = 1&lt;/code&gt; in T2 (write to buffer)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;r1 = y&lt;/code&gt; in T1 (no &lt;code&gt;y&lt;/code&gt; in T1&amp;rsquo;s buffer, read from memory, get 0)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;r2 = x&lt;/code&gt; in T2 (no &lt;code&gt;x&lt;/code&gt; in T2&amp;rsquo;s buffer, read from memory, get 0)&lt;/li&gt;
&lt;li&gt;Update buffers to memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;load-buffering&#34;&gt;Load Buffering&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;Initially: x = y = 0;
r1 = x;  ||  r2 = y;
y = 1;   ||  x = 1;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;rsquo;s possible that &lt;code&gt;r1 = r2 = 1&lt;/code&gt; ! (e.g. in ARM)&lt;/p&gt;
&lt;h2 id=&#34;wmm-for-high-level-languages&#34;&gt;WMM for High-Level Languages&lt;/h2&gt;
&lt;p&gt;For programmers, if they write code that satisfies DRF property, the compilers and processors guarantee SC behavior.&lt;/p&gt;
&lt;p&gt;We should embrace WMM since it&amp;rsquo;s part of the reality. Furthermore, many programs don&amp;rsquo;t rely on the strict SC model to ensure correctness.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
