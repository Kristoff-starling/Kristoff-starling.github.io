<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lectures | Yuyao Wang&#39;s Homepage</title>
    <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/</link>
      <atom:link href="https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/index.xml" rel="self" type="application/rss+xml" />
    <description>Lectures</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 13 Dec 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Lectures</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/</link>
    </image>
    
    <item>
      <title>Lecture 01: Introduction</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec01/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec01/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;关于计算机信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 &lt;code&gt;uname -a&lt;/code&gt; 命令可以查看操作系统，时间，硬件架构等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;what-is-operating-system&#34;&gt;What is Operating System?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Operating system is responsible for makeing it easy to run programs, allowing programs to share memory and interact with devices.  - OSTEP&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;操作系统：“管理软硬件资源，为程序提供服务”的东西。&lt;/p&gt;
&lt;h3 id=&#34;eniac&#34;&gt;ENIAC&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;逻辑门：真空电子管。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;存储器：延迟线内存，类似于“小丑扔球”的技巧，将数据不断地扔进延迟线，拿出来以后经过放大器再扔进延迟线。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;输入输出：打一针/将纸带挪动一下。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不需要操作系统。能运行程序就不错了，不需要“管理程序的程序”。&lt;/p&gt;
&lt;h3 id=&#34;1950s-computer&#34;&gt;1950s Computer&lt;/h3&gt;
&lt;p&gt;更快更小的逻辑门 (晶体管)，更大的内存 (磁芯内存)，更丰富的 I/O 设备。因为 I/O 设备速度严重低于处理器速度，所以中断机制出现。更多的人使用通用计算机，他们希望使用 API，而不是直接使用硬件。因此诞生了 FORTRAN 编程语言。&lt;/p&gt;
&lt;p&gt;1950s 的操作系统：管理多个程序依次排队运行的库函数和调度器。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算机非常贵非常少，多个用户排队使用计算机。
&lt;ul&gt;
&lt;li&gt;很多程序卡片 $\rightarrow$ OS $\rightarrow$ 硬件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;操作 (operate) 任务 (job) 的系统 (system)
&lt;ul&gt;
&lt;li&gt;批处理系统：程序自动切换 (换卡) + 提供库函数 API&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1960s-computer&#34;&gt;1960s Computer&lt;/h3&gt;
&lt;p&gt;更大的内存，更多的高级语言 (COBOL, BASIC etc.) &amp;hellip; 我们可以将多个程序同时放到程序里。但计算机中只有一个 CPU。&lt;/p&gt;
&lt;p&gt;1960s 的操作系统：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;传统的执行流：A on CPU (30s) $\rightarrow$ A on device (5min) $\rightarrow$ A on CPU (30s) B on CPU (30s)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;理想的执行流：&lt;/p&gt;
&lt;p&gt;CPU: 		A on CPU(30s) $\rightarrow$ OS 调度 $\rightarrow$ B on CPU (30s) 		$\rightarrow$ OS 调度 $\rightarrow$ A on CPU&lt;/p&gt;
&lt;p&gt;Device:						                       	$\rightarrow$ A on device (5min)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这就是多道程序 (multiprogramming)。为了防止恶意程序对别的程序和操作系统本身的破坏，我们还需要对每个程序的运行有一个好的隔离机制。&lt;/p&gt;
&lt;p&gt;多道程序在程序使用设备时发生切换。在引入时钟中断后，操作系统成为计算机的霸主：操作系统决定谁来运行。&lt;/p&gt;
&lt;h3 id=&#34;1970s-computer&#34;&gt;1970s+ Computer&lt;/h3&gt;
&lt;p&gt;计算机空前发展，与今天已无大异。&lt;/p&gt;
&lt;p&gt;分时系统趋于成熟，UNIX 诞生，奠定现代操作系统的形态。&lt;/p&gt;
&lt;h3 id=&#34;today&#34;&gt;Today&lt;/h3&gt;
&lt;p&gt;操作系统：虚拟化硬件资源，为应用程序提供服务。&lt;/p&gt;
&lt;p&gt;面对的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更复杂的处理器和内存：非对称多处理器， Non-uniform Memory Access etc.。&lt;/li&gt;
&lt;li&gt;更多的设备和资源。&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 02: Programs on Operating Systems</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec02/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec02/</guid>
      <description>&lt;h2 id=&#34;digital-logic&#34;&gt;Digital Logic&lt;/h2&gt;
&lt;p&gt;数字电路：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;状态：寄存器中保存的值；&lt;/li&gt;
&lt;li&gt;初始状态：RESET；&lt;/li&gt;
&lt;li&gt;迁移：组合逻辑电路下计算寄存器下一个周期的值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;example-seven-seg&#34;&gt;Example: Seven-seg&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// logisim.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;

#define REGS_FOREACH(_)  _(X) _(Y)
#define OUTS_FOREACH(_)  _(A) _(B) _(C) _(D) _(E) _(F) _(G)
#define RUN_LOGIC        X1 = !X &amp;amp;&amp;amp; Y; \
                         Y1 = !X &amp;amp;&amp;amp; !Y; \
                         A  = (!X &amp;amp;&amp;amp; !Y) || (X &amp;amp;&amp;amp; !Y); \
                         B  = 1; \
                         C  = (!X &amp;amp;&amp;amp; !Y) || (!X &amp;amp;&amp;amp; Y); \
                         D  = (!X &amp;amp;&amp;amp; !Y) || (X &amp;amp;&amp;amp; !Y); \
                         E  = (!X &amp;amp;&amp;amp; !Y) || (X &amp;amp;&amp;amp; !Y); \
                         F  = (!X &amp;amp;&amp;amp; !Y); \
                         G  = (X &amp;amp;&amp;amp; !Y); 

#define DEFINE(X)   static int X, X##1;
#define UPDATE(X)   X = X##1;
#define PRINT(X)    printf(#X &amp;quot; = %d; &amp;quot;, X);

int main() {
  REGS_FOREACH(DEFINE);
  OUTS_FOREACH(DEFINE);
  while (1) { // clock
    RUN_LOGIC;
    OUTS_FOREACH(PRINT);
    REGS_FOREACH(UPDATE);
    putchar(&#39;\n&#39;);
    fflush(stdout);
    sleep(1);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;数字电路永远是根据当前状态机的状态确定次态，循环往复。上述程序用两个寄存器 X,Y 实现了七段数码管 0 $\rightarrow$ 1 $\rightarrow$ 2 循环更新的功能 (注：这段代码使用了一些 X-macros 技巧，使得我们无需对每个寄存器写相同的代码，值得学习。)&lt;/p&gt;
&lt;p&gt;搭配上一个简单的 python 程序，我们便可以在终端中打印这个七段数码管：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# seven-seg.py
import fileinput
 
TEMPLATE = &#39;&#39;&#39;
\033[2J\033[1;1f
     AAAAAAAAA
    FF       BB
    FF       BB
    FF       BB
    FF       BB
     GGGGGGGGG
    EE       CC
    EE       CC
    EE       CC
    EE       CC
     DDDDDDDDD
&#39;&#39;&#39; 
BLOCK = {
    0: &#39;\033[37m░\033[0m&#39;, # STFW: ANSI Escape Code
    1: &#39;\033[31m█\033[0m&#39;,
}
VARS = &#39;ABCDEFG&#39;

for v in VARS:
    globals()[v] = 0
stdin = fileinput.input()

while True:
    exec(stdin.readline())
    pic = TEMPLATE
    for v in VARS:
        pic = pic.replace(v, BLOCK[globals()[v]]) # &#39;A&#39; -&amp;gt; BLOCK[A], ...
    print(pic)
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;关于该 python 程序的一些注解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;exec(stdin.readline())&lt;/code&gt; 用于将读入的内容直接当作 python 语句执行。由于之前的 C 程序在一行中用 &lt;code&gt;;&lt;/code&gt; 将多个变量赋值分开，符合 python 语法，因此可以直接作为 python 程序中的变量赋值语句。&lt;/li&gt;
&lt;li&gt;BLOCK[] 数组中存储了两种颜色：37 号是白色，31 号是红色。这里使用了 ANSI Escape Code，具体格式可以参考
&lt;a href=&#34;https://kristoff-starling.github.io/2022/02/18/ANSI%20Escape%20Code%20-%20Quick%20Manual/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这篇文章&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;programs-code-perspective&#34;&gt;Programs: Code Perspective&lt;/h2&gt;
&lt;p&gt;C 程序也是状态机：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;状态：堆+栈；&lt;/li&gt;
&lt;li&gt;初始状态：main() 的第一条语句；&lt;/li&gt;
&lt;li&gt;迁移：执行一条简单语句。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从更 low-level 的角度而言，C 程序的状态机描述如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;状态：全局变量+栈帧的列表 (每个栈帧里有一个 PC 表示当前执行到哪里)；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;初始状态：&lt;code&gt;main(argc, argv)&lt;/code&gt;；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;迁移：执行 top stack frame 中 PC 处的语句，PC++。&lt;/p&gt;
&lt;p&gt;函数的调用本质上就是新建一个栈帧放在栈帧列表的顶部，然后跳转到该栈帧中的第一条指令；函数的返回本质上就是将顶部的栈帧 pop 掉。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;example-hanoi-nr&#34;&gt;Example: Hanoi-nr&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// hanoi-nr.c
typedef struct {
  int pc, n;
  char from, to, via;
} Frame;

#define call(...) ({ *(++top) = (Frame) { .pc = 0, __VA_ARGS__ }; })
#define ret()     ({ top--; })
#define goto(loc) ({ f-&amp;gt;pc = (loc) - 1; })

void hanoi(int n, char from, char to, char via) {
  Frame stk[64], *top = stk - 1;
  call(n, from, to, via);
  for (Frame *f; (f = top) &amp;gt;= stk; f-&amp;gt;pc++) {
    switch (f-&amp;gt;pc) {
      case 0: if (f-&amp;gt;n == 1) { printf(&amp;quot;%c -&amp;gt; %c\n&amp;quot;, f-&amp;gt;from, f-&amp;gt;to); goto(4); } break;
      case 1: call(f-&amp;gt;n - 1, f-&amp;gt;from, f-&amp;gt;via, f-&amp;gt;to);   break;
      case 2: call(       1, f-&amp;gt;from, f-&amp;gt;to,  f-&amp;gt;via);  break;
      case 3: call(f-&amp;gt;n - 1, f-&amp;gt;via,  f-&amp;gt;to,  f-&amp;gt;from); break;
      case 4: ret();                                    break;
      default: assert(0);
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;switch-case 结构相当于给递归代码编上了“行号”。每个栈帧中的 PC 表示当前层函数执行到了第几行。&lt;/p&gt;
&lt;h2 id=&#34;programs-binary-perspective&#34;&gt;Programs: Binary Perspective&lt;/h2&gt;
&lt;p&gt;从二进制的角度，程序仍然是状态机。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;状态：寄存器，内存……&lt;/li&gt;
&lt;li&gt;迁移：执行一条指令&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果整个程序的行为是确定的，状态机应该长成一条直线：$(M_0,R_0)\rightarrow (M_1,R_1)\rightarrow\cdots$ 。如果引入了一些 non-deterministic 的元素，比如 &lt;code&gt;rdrand&lt;/code&gt; 指令 (读取一个硬件随机数到寄存器中)，那么状态机会有分叉。但无论如何，这是一个有限状态机 (内存、寄存器数量是有限的)，如果只有计算指令，有限步之后我们必然会回到一个经历过的状态。我们无法实现输入输出，甚至是停止程序。&lt;/p&gt;
&lt;p&gt;因此，程序中有一条特殊的指令：&lt;code&gt;syscall&lt;/code&gt;。程序将自己的状态机 $(M,R)$ 交给操作系统，任其修改，最终操作系统返回一个状态机 $(M&amp;rsquo;,R&amp;rsquo;)$，程序继续执行。因此程序=计算+syscall+计算+syscall+……&lt;/p&gt;
&lt;h3 id=&#34;example-a-smallest-hello-world&#34;&gt;Example: A smallest &amp;ldquo;Hello, world&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;我们想象中的最小函数：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void _start() {
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;直接运行会得到 SIGSEGV。使用 GDB 对汇编代码进行调试：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;0x401000 &amp;lt;_start&amp;gt;       endbr64                                            
0x401004 &amp;lt;_start+4&amp;gt;     push   %rbp                                        
0x401005 &amp;lt;_start+5&amp;gt;     mov    %rsp,%rbp                                   
0x401008 &amp;lt;_start+8&amp;gt;     nop                                                
0x401009 &amp;lt;_start+9&amp;gt;     pop    %rbp                                        
0x40100a &amp;lt;_start+10&amp;gt;    ret  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行 &lt;code&gt;ret&lt;/code&gt; 指令时发生错误，因此 &lt;code&gt;ret&lt;/code&gt; 的本质是将 %rax 的值赋给 PC，而此时 %rax 的值是一个非法的地址。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;用户程序只能解决“计算”的问题，因此我们甚至无法结束程序。我们必须借助系统调用才能使程序正常运行起来。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;# minimal.S
#include &amp;lt;sys/syscall.h&amp;gt;

.globl _start
_start:
  movq $SYS_write, %rax   # write(
  movq $1,         %rdi   #   fd=1,
  movq $st,        %rsi   #   buf=st,
  movq $(ed - st), %rdx   #   count=ed-st
  syscall                 # );

  movq $SYS_exit,  %rax   # exit(
  movq $1,         %rdi   #   status=1
  syscall                 # );

st:
  .ascii &amp;quot;\033[01;31mHello, OS World\033[0m\n&amp;quot;
ed:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;前半段程序负责打印：将系统调用号 SYS_write 和输出对象，输出内容等参数放到 x86-64 制定的寄存器中，然后使用 syscall 指令；后半段负责退出。&lt;/p&gt;
&lt;p&gt;使用 &lt;code&gt;gcc -c minimal.S &amp;amp;&amp;amp; ld minimal.S &amp;amp;&amp;amp; ./a.out&lt;/code&gt; 命令，可以得到红色加粗的 &amp;ldquo;Hello, OS World&amp;rdquo;。&lt;/p&gt;
&lt;h2 id=&#34;switching-between-perspectives&#34;&gt;Switching between Perspectives&lt;/h2&gt;
&lt;p&gt;记源代码为 $S$，汇编代码为 $S$，则编译器就是一个函数：$S=compile(S)$。&lt;/p&gt;
&lt;p&gt;从状态机的视角来看，编译 (优化) 的正确性 (soundness) 的含义是：两个状态机的可观测行为完全一致。因此在保证整体语义不变的前提下，编译器可以自由地调整语句顺序，合并语句，删除无用语句等。&lt;/p&gt;
&lt;h3 id=&#34;example-compile-optimization&#34;&gt;Example: Compile Optimization&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void foo(int g)
{
    g++;
    g++;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;开启 &lt;code&gt;-O1&lt;/code&gt; 优化后，得到的汇编代码为&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0000000000000000 &amp;lt;foo&amp;gt;:
   0:	f3 0f 1e fa          	endbr64 
   4:	c3                   	ret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;编译器直接将 &lt;code&gt;g++&lt;/code&gt; 删除了，因为没有返回，这两句话没有作用。&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;extern int g;
void foo(int x)
{
    g++;
  	g++;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;汇编代码为&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0000000000000000 &amp;lt;foo&amp;gt;:
   0:	f3 0f 1e fa          	endbr64 
   4:	83 05 00 00 00 00 02 	addl   $0x2,0x0(%rip)        # b &amp;lt;foo+0xb&amp;gt;
   b:	c3                   	ret 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;因为 g 是外部变量，所以这里对 g 的操作是有意义的，但连续的两次 +1 可以用一次 +2 来代替。&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;extern int g;
void foo(int x)
{
    g++;
	asm volatile(&amp;quot;nop&amp;quot; : : &amp;quot;r&amp;quot;(x));
  	g++;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;汇编代码为&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0000000000000000 &amp;lt;foo&amp;gt;:
   0:	f3 0f 1e fa          	endbr64 
   4:	90                   	nop
   5:	83 05 00 00 00 00 02 	addl   $0x2,0x0(%rip)        # c &amp;lt;foo+0xc&amp;gt;
   c:	c3                   	ret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这说明编译器可以调整语句的顺序，然后将两个 +1 合并成一个 +2。&lt;/p&gt;
&lt;p&gt;但我们有手段可以让编译器无法进行这个合并：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;extern int g;
void foo(int x)
{
    g++;
	asm volatile (&amp;quot;nop&amp;quot; : : &amp;quot;r&amp;quot;(x) : &amp;quot;memory&amp;quot;);
    g++;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;汇编代码为&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0000000000000000 &amp;lt;foo&amp;gt;:
   0:	f3 0f 1e fa          	endbr64 
   4:	83 05 00 00 00 00 01 	addl   $0x1,0x0(%rip)        # b &amp;lt;foo+0xb&amp;gt;
   b:	90                   	nop
   c:	83 05 00 00 00 00 01 	addl   $0x1,0x0(%rip)        # 13 &amp;lt;foo+0x13&amp;gt;
  13:	c3                   	ret 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;中间插入的内联汇编语句使用了 memory clobber，其意思是告诉编译器这些内联汇编代码可能会任意读取、修改内存内容，因此编译器在调整语句顺序时，不能超过这个 asm block。这句话就像一堵墙一样挡在中间，使得两处 +1 无法被合并。&lt;/p&gt;
&lt;p&gt;该手法在操作系统的锁机制中有重要的应用 (避免编译器将 critical section 中的语句优化到外面，导致 race condition)。&lt;/p&gt;
&lt;h2 id=&#34;programs-os-perspective&#34;&gt;Programs: OS Perspective&lt;/h2&gt;
&lt;p&gt;操作系统眼中的程序：程序=计算+syscall+计算+syscall+…… 程序只能通过操作系统允许的方式来访问操作系统掌控的资源，从而操作系统掌握了计算机的“霸权”。&lt;/p&gt;
&lt;h3 id=&#34;example-entering-a-program&#34;&gt;Example: Entering a Program&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;一个 C 程序执行的第一条指令在哪里？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最合理的方法：用 gdb 打开可执行文件，然后用 &lt;code&gt;starti&lt;/code&gt; 指令定位到第一条汇编指令，发现在 &lt;code&gt;/lib64/ld-linux-x86-64.so.2&lt;/code&gt; 中。这是一个加载器，加载器负责跳转到 &lt;code&gt;__start()&lt;/code&gt; 执行。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;凭什么不能是 rtfm.so?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 readelf 工具，可以看到在可执行文件中说明了&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[Requesting program interpreter: /lib64/ld-linux-x86-64.so.2]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果我们直接对 a.out 进行修改，将 ld-linux-x86-64.so.2 字段改为 rtfm.so，再创建一个从 rtfm.so 到 ld-linux-x86-64.so.2 的链接，我们就真的可以实现用我们制定的 rtfm.so 来加载程序。&lt;/p&gt;
&lt;p&gt;&lt;u&gt;计算机系统不存在玄学，一切都建立在确定的机制上。&lt;/u&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在执行 main() 函数之前，程序经历了很多的过程，使用了很多的系统调用，用 strace 工具可以查看这些系统调用(注：strace 会输出到标准错误，重定向时要注意)。 C 语言还支持在进入 main() 函数之前和之后做事情：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// hello-goodbye.c
#include &amp;lt;stdio.h&amp;gt;

__attribute__((constructor)) void hello() {
  printf(&amp;quot;Hello, World\n&amp;quot;);
}

// See also: atexit(3)
__attribute__((destructor)) void goodbye() {
  printf(&amp;quot;Goodbye, Cruel OS World!\n&amp;quot;);
}

int main() {
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip: 利用 Vim 来整理不易阅读的输入内容&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;strace 输出的内容杂乱难读，利用 vim 对其进行整理可以帮助我们阅读。常用的整理命令可以有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;:%! grep [-v] word&lt;/code&gt; 筛选出包含 word 的行 (-v 参数可以反向筛选)。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;:%s/, \r /g&lt;/code&gt; 将所有的 &lt;code&gt;,&lt;/code&gt; 替换为换行符。人类倾向于阅读行数多但每行都很短的内容。&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 03: Multiprocessor Programming</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec03/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec03/</guid>
      <description>&lt;p&gt;并发：一个计算机程序被分成了若干个部分，在不改变程序最终运行结果的情况下，这些部分被乱序地执行。并发执行的多个部分会共享资源。&lt;/p&gt;
&lt;h2 id=&#34;state-machine&#34;&gt;State Machine&lt;/h2&gt;
&lt;p&gt;在单线程视角中，C 程序的状态机包括全局变量，堆区，栈帧列表等。全局变量和堆区的内容是全局的，是所有函数共享的，理应作为共享资源；栈帧中的变量都是局部变量，栈帧与栈帧之间独立性较强，可以交给多个线程。&lt;/p&gt;
&lt;p&gt;多线程视角下的状态机：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全局变量，堆区等全局共享资源；&lt;/li&gt;
&lt;li&gt;若干个栈帧链，每条栈帧链属于一个线程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在并发程序中，每一步的结果都是 non-deterministic 的，它的状态转移图是长成这样的：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;stateDiagram
	state1: (g, T1, T2)
	state1 --&amp;gt; state2: 线程T1执行
	state1 --&amp;gt; state3: 线程T2执行
	state2: (g&#39;,T1&#39;,T2)
	state3: (g&#39;,T1,T2&#39;)
	state2 --&amp;gt; state4: 线程T1执行
	state2 --&amp;gt; state5: 线程T2执行
	state3 --&amp;gt; state6: 线程T1执行
	state3 --&amp;gt; state7: 线程T2执行
	state4: ……
	state5: ……
	state6: ……
	state7: ……
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;simplified-thread-api&#34;&gt;Simplified Thread API&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// thread.h
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdatomic.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;

#define NTHREAD 6400
enum { T_FREE = 0, T_LIVE, T_DEAD, };
struct thread {
  int id, status;
  pthread_t thread;
  void (*entry)(int);
};

struct thread tpool[NTHREAD], *tptr = tpool;

void *wrapper(void *arg) {
  struct thread *thread = (struct thread *)arg;
  thread-&amp;gt;entry(thread-&amp;gt;id);
  return NULL;
}

void create(void *fn) {
  assert(tptr - tpool &amp;lt; NTHREAD);
  *tptr = (struct thread) {
    .id = tptr - tpool + 1,
    .status = T_LIVE,
    .entry = fn,
  };
  pthread_create(&amp;amp;(tptr-&amp;gt;thread), NULL, wrapper, tptr);
  ++tptr;
}

void join() {
  for (int i = 0; i &amp;lt; NTHREAD; i++) {
    struct thread *t = &amp;amp;tpool[i];
    if (t-&amp;gt;status == T_LIVE) {
      pthread_join(t-&amp;gt;thread, NULL);
      t-&amp;gt;status = T_DEAD;
    }
  }
}

__attribute__((destructor)) void cleanup() {
  join();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;thread.h&lt;/code&gt; 是对 C 库 pthreads 的进一步封装。其中的一些关键函数和代码解读如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;create(fn)&lt;/code&gt; ：创建一个新的线程并立即执行，该线程的入口函数是 fn。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;函数 fn 的定义为 &lt;code&gt;void fn(int tid)&lt;/code&gt;，其中 tid 为线程号，从 1 开始编号。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从状态机的角度来看，create() 的语义是在状态机中新开了一个链表，这个链表只有一个 fn 函数的栈帧。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;原理：pthread_create() 函数的声明为&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 start_routine 是新线程第一个执行的函数，arg 是给 start_routine 传入的参数，attr 设置为 NULL 表示按照默认方式创建线程。&lt;code&gt;thread.h&lt;/code&gt; 中传入的 start_routine 是 wrapper，wrapper 中的语句 &lt;code&gt;thread-&amp;gt;entry(thread-&amp;gt;id)&lt;/code&gt; 以线程号为参数，调用了 fn 函数。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;join()&lt;/code&gt;：&lt;code&gt;join()&lt;/code&gt; 是线程中的“等待”，和进程中的 wait() 有一点相似。&lt;code&gt;join()&lt;/code&gt; 的语义相当于在调用该函数的线程中加入了一条死循环语句：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;while (其他线程未结束);
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;假设当前有三个线程 T1,T2,T3，T1 中调用了 &lt;code&gt;join()&lt;/code&gt;，则之后的状态机如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;stateDiagram
    state1:(T1(join),T2,T3)
    state1 --&amp;gt; state1: 线程 T1 执行
    state1 --&amp;gt; state2: 线程 T2 执行
    state1 --&amp;gt; state3: 线程 T3 执行
    state2:(T1(join), T2(end), T3)
    state3:(T1(join), T2, T3(end))
    state2 --&amp;gt; state2: 线程 T1 执行
    state2 --&amp;gt; state4: 线程 T3 执行
    state3 --&amp;gt; state3: 线程 T1 执行
    state3 --&amp;gt; state4: 线程 T2 执行
    state4: (T1,T2(end),T3(end))
    note right of state4
        T2,T3 线程均结束，T1 死循环解除
    end note
    state4 --&amp;gt; state5
    state5: ……
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;原理：join() 中主线程会遍历线程数组，调用 pthread_join() 函数等待它们一一结束，将其状态设置为 T_DEAD，然后返回。pthread_join() 函数的声明为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int pthread_join(pthread_t thread, void **retval);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当前函数会等待 thread 线程执行结束 (若 thread 已经结束就直接返回)，如果 retval 指针不为空，就将 thread 线程的退出状态指针填写到 retval 中。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 include 了 &lt;code&gt;threads.h&lt;/code&gt; 的情况下，main() 函数执行结束后，所有新创建的线程会被自动释放。该功能是由 &lt;code&gt;thread.h&lt;/code&gt; 中的 clean_up() 函数实现的 (添加了 &lt;code&gt;__attribute__((destructor))&lt;/code&gt; 的函数会在 main() 函数返回之后被执行)。clean_up() 额外调用了一次 join()，&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;concurrent-programming-introduction&#34;&gt;Concurrent Programming: Introduction&lt;/h2&gt;
&lt;p&gt;全局的变量会被各个线程共享，我们可以写一个程序来证明这一点：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// shm-test.c
#include &amp;quot;thread.h&amp;quot;

int x;

void Thello(int tid)
{
	usleep(tid * 100000);
	printf(&amp;quot;Hello world from thread #%c\n&amp;quot;, &amp;quot;0123456789ABCDEF&amp;quot;[x++]);
}

int main ()
{
	x = 1;
	for (int i = 0; i &amp;lt; 10 ; i++)
		create(Thello);
	return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该程序的输出结果为&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Hello world from thread #1
Hello world from thread #2
Hello world from thread #3
Hello world from thread #4
Hello world from thread #5
Hello world from thread #6
Hello world from thread #7
Hello world from thread #8
Hello world from thread #9
Hello world from thread #A
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，某一个线程对全局变量 x 的修改在别的线程是可见的。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我们可以写一个小程序来探测每个线程的栈空间大小：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// stack-probe.c
#include &amp;quot;thread.h&amp;quot;

__thread char *base, *cur; // thread-local variables
__thread int id;

// objdump to see how thread-local variables are implemented
__attribute__((noinline)) void set_cur(void *ptr) { cur = ptr; }
__attribute__((noinline)) char *get_cur()         { return cur; }

void stackoverflow(int n) {
  set_cur(&amp;amp;n);
  if (n % 1024 == 0) {
    int sz = base - get_cur();
    printf(&amp;quot;Stack size of T%d &amp;gt;= %d KB\n&amp;quot;, id, sz / 1024);
  }
  stackoverflow(n + 1);
}

void Tprobe(int tid) {
  id = tid;
  base = (void *)&amp;amp;tid;
  stackoverflow(0);
}

int main() {
  setbuf(stdout, NULL);
  for (int i = 0; i &amp;lt; 4; i++) {
    create(Tprobe);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该代码中有一些值得注意的细节：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;程序的主要思想是使用一个死递归，由于函数的参数作为局部变量总是放在栈上，所以可以通过查看参数 n 的地址来获得大致的栈顶位置。触发段错误之后，根据输出信息大致判断栈的大小。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;加入了 &lt;code&gt;__thread&lt;/code&gt; 声明的变量是线程局部变量 (thread-local variables)，每个线程都单独拥有线程局部变量，对线程局部变量的修改操作彼此互不影响。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;__attribute__((noinline))&lt;/code&gt; 字段可以使函数不会被內联到函数内部，这有助于我们使用 &lt;code&gt;objdump&lt;/code&gt; 工具反汇编可执行文件以观测线程局部变量的实现方式。&lt;code&gt;stack-probe.o&lt;/code&gt; 的反汇编结果中 set_cur() 函数的汇编代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0000000000000196 &amp;lt;set_cur&amp;gt;:
 196:   f3 0f 1e fa             endbr64 
 19a:   55                      push   %rbp		
 19b:   48 89 e5                mov    %rsp,%rbp        # 创建新的栈帧
 19e:   48 89 7d f8             mov    %rdi,-0x8(%rbp)		
 1a2:   48 8b 45 f8             mov    -0x8(%rbp),%rax  # 将第一个参数的值放入rax
 1a6:   64 48 89 04 25 00 00    mov    %rax,%fs:0x0     # 将rax的值赋给cur
 1ad:   00 00 
 1af:   90                      nop
 1b0:   5d                      pop    %rbp
 1b1:   c3                      ret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到 &lt;code&gt;%fs:0x0&lt;/code&gt; 代表的就是线程局部变量 cur 的地址。%fs 是 x86-64 的一个段寄存器，使用 %fs 将引用线程的 glibc TLS (thread local storage)。这里的偏移量之所以是 0 是因为还没有重定位，重定位之后每个变量都会有一个不同的 offset。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据程序的输出结果，可以看出每个线程栈大小为 8192K=8M。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip: Unix Philosophy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于有多个线程并发输出，该程序的输出结果非常杂乱，为处理之前大致如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;...
Stack size of T1 &amp;gt;= 8128 KB
Stack size of T3 &amp;gt;= 8064 KB
Stack size of T4 &amp;gt;= 6208 KB
Stack size of T2 &amp;gt;= 7616 KB
Stack size of T3 &amp;gt;= 8128 KB
[1]    46916 segmentation fault (core dumped)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以利用命令行的 sort 工具来整理输出结果。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./stack-probe | sort -nk 6
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中参数 &lt;code&gt;-n&lt;/code&gt; 表示比较时将字符串转换成数值进行比较 (如果不加这个参数，那些九百多的三位数会被排在作后)，&lt;code&gt;-k&lt;/code&gt; 表示选择第几列进行比较，后面的数字 6 指定了数值的那一列。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;如何修改线程栈的大小？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在执行程序前，使用命令 &lt;code&gt;ulimit -s SIZE&lt;/code&gt; 来修改栈大小。SIZE 的单位是 KB。修改完之后，使用 &lt;code&gt;stack-probe.c&lt;/code&gt; 程序进行检测可以看到线程栈大小改变了。&lt;/p&gt;
&lt;p&gt;(注：关闭终端后该改变会失效。)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;concurrent-programming-atomicity&#34;&gt;Concurrent Programming: Atomicity&lt;/h2&gt;
&lt;p&gt;考虑以下程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// sum.c
#include &amp;quot;thread.h&amp;quot;

#define N 100000000

long sum = 0;

void Tsum() {
  for (int i = 0; i &amp;lt; N; i++) {
    sum++;
  }
}

int main() {
  create(Tsum);
  create(Tsum);
  join();
  printf(&amp;quot;sum = %ld\n&amp;quot;, sum);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;两个线程各对全局变量 sum 进行 N 次 +1 操作，理论上应该得到结果 200000000，但运行该程序每次都会得到远小于 200000000 的各不相同的结果。导致这个结果的原因是&lt;strong&gt;原子性的丧失&lt;/strong&gt;：“程序 (甚至是一条指令) 独占处理器运行“的基本假设在现代多处理器系统上不再成立。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip: Unix Philosophy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们想多观测几次 &lt;code&gt;sum.c&lt;/code&gt; 程序的输出，但重复执行 &lt;code&gt;./sum&lt;/code&gt; 太低效了。好的方法是现场写一个 shell 脚本：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;while true; do ./sum; done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注：在一行内写 shell 脚本需要注意不同语句之间要用分号隔开。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;考察 Tsum() 函数的汇编结果，其中 sum++ 这条核心语句被编译成了 3 条汇编指令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;1a7:   48 8b 05 00 00 00 00    mov    0x0(%rip),%rax        # 1ae &amp;lt;Tsum+0x18&amp;gt;
1ae:   48 83 c0 01             add    $0x1,%rax
1b2:   48 89 05 00 00 00 00    mov    %rax,0x0(%rip)        # 1b9 &amp;lt;Tsum+0x23&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;0x0(%rip)&lt;/code&gt; 是变量 sum 的地址，由于还没有重定位，所以偏移量还没有填入。sum 的值会先被放入 %rax，然后 %rax +1，然后 %rax 的值被写回 sum。假设当前两个线程在并发地执行这段代码，轮流执行，则执行情况如下表 (设 sum 的初值为 s) ：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Thread1&lt;/th&gt;
&lt;th&gt;Thread2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;%rax in CPU1 = s&lt;/td&gt;
&lt;td&gt;%rax in CPU2 = s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;%rax in CPU1 = s+1&lt;/td&gt;
&lt;td&gt;%rax in CPU2 = s+1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;sum = s+1&lt;/td&gt;
&lt;td&gt;sum = s+1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;可以看到 +1 操作被吞掉了一次。两个线程在并发地对同一个内存地址进行读写，打破了 invariant，从而导致并发 bug。&lt;/p&gt;
&lt;p&gt;解决这个问题的方法是用锁将这几句代码包裹起来，强制两个线程串行地执行。&lt;/p&gt;
&lt;h2 id=&#34;concurrent-programming-order&#34;&gt;Concurrent Programming: Order&lt;/h2&gt;
&lt;p&gt;如果对 &lt;code&gt;sum.c&lt;/code&gt; 进行 -O1 和 -O2 优化，我们会得到不同的结果：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在 -O1 优化下，编译器会分析出函数的目的是 sum+=N，并使用 Reg = sum, Reg += N, sum = Reg 三条指令实现。因为 race condition，两次 sum = Reg 重复写入，所以 -O1 优化下输出结果为 100000000。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;-O2 优化更为彻底，直接使用一条指令&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;48 81 05 01 2e 00 00    addq   $0x5f5e100, 0x0(%rip)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;来完成。至少“看上去”获得了正确的结果 200000000。(Visibility 一节会再分析这种情况)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外一个例子是：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;extern int done;

int main ()
{
    while (!done);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;的汇编代码是 (-O2 优化)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0000000000000000 &amp;lt;main&amp;gt;:
   0:   f3 0f 1e fa             endbr64 
   4:   8b 05 00 00 00 00       mov    0x0(%rip),%eax        # a &amp;lt;main+0xa&amp;gt;
   a:   85 c0                   test   %eax,%eax
   c:   75 02                   jne    10 &amp;lt;main+0x10&amp;gt;
   e:   eb fe                   jmp    e &amp;lt;main+0xe&amp;gt;
  10:   31 c0                   xor    %eax,%eax
  12:   c3                      ret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它实际上被翻译成了&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;if (!done) while(1);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;编译器无法考虑到多线程的可能，它认为在执行 &lt;code&gt;while (!done)&lt;/code&gt; 的过程中当前程序是不可能被打断的。从状态及的角度来考虑，编译器只要保证最终结果的一致性 (语义一致性)，是可以随意修改指令的顺序 (甚至是指令本身) 的，这给并发编程带来了困难。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;使上述代码能够被正确地编译，一种方法是在循环中加上 memory barrier：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;while (!done) asm volatile(&amp;quot;&amp;quot; ::: &amp;quot;memory&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;memory barrier 相当于告诉编译器：这里可能发生任意的对内存的修改，所以编译器不再有对 done 的值保持不变的假设。&lt;/p&gt;
&lt;p&gt;另一种方法是&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;extern int volatile done;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它也可以保证 C 语义和汇编语义的一致性。&lt;/p&gt;
&lt;h2 id=&#34;concurrent-programming-visibility&#34;&gt;Concurrent Programming: Visibility&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// mem-ordering.c
#include &amp;quot;thread.h&amp;quot;

int x = 0, y = 0;

atomic_int flag;
#define FLAG atomic_load(&amp;amp;flag)
#define FLAG_XOR(val) atomic_fetch_xor(&amp;amp;flag, val)
#define WAIT_FOR(cond) while (!(cond)) ;

 __attribute__((noinline))
void write_x_read_y() {
  int y_val;
  asm volatile(
    &amp;quot;movl $1, %0;&amp;quot; // x = 1
    &amp;quot;movl %2, %1;&amp;quot; // y_val = y
    : &amp;quot;=m&amp;quot;(x), &amp;quot;=r&amp;quot;(y_val) : &amp;quot;m&amp;quot;(y)
  );
  printf(&amp;quot;%d &amp;quot;, y_val);
}

 __attribute__((noinline))
void write_y_read_x() {
  int x_val;
  asm volatile(
    &amp;quot;movl $1, %0;&amp;quot; // y = 1
    &amp;quot;movl %2, %1;&amp;quot; // x_val = x
    : &amp;quot;=m&amp;quot;(y), &amp;quot;=r&amp;quot;(x_val) : &amp;quot;m&amp;quot;(x)
  );
  printf(&amp;quot;%d &amp;quot;, x_val);
}

void T1(int id) {
  while (1) {
    WAIT_FOR((FLAG &amp;amp; 1));
    write_x_read_y();
    FLAG_XOR(1);
  }
}

void T2() {
  while (1) {
    WAIT_FOR((FLAG &amp;amp; 2));
    write_y_read_x();
    FLAG_XOR(2);
  }
}

void Tsync() {
  while (1) {
    x = y = 0;
    __sync_synchronize(); // full barrier
    usleep(1);            // + delay
    assert(FLAG == 0);
    FLAG_XOR(3);
    // T1 and T2 clear 0/1-bit, respectively
    WAIT_FOR(FLAG == 0);
    printf(&amp;quot;\n&amp;quot;); fflush(stdout);
  }
}

int main() {
  create(T1);
  create(T2);
  create(Tsync);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对该程序的一些关键代码解读如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tsync 是一个控制线程。它负责将一个开关变量 flag 的第一位和第二位拉高。flag 的第一位供 T1 线程使用，第二位供 T2 线程使用。等待 T1 和 T2 线程均完成操作后，Tsync 会进行下一次循环，Tsync 的设置保证了 T1 和 T2 总是能”同时“开始运行。&lt;/li&gt;
&lt;li&gt;T1 和 T2 线程会写入 x/y 并读取 y/x，完成操作后将 flag 的对应位拉低。我们在內联汇编代码中已经加入了 memory fence 保证编译器会按照顺序编译我们的代码。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;按理来说，根据执行顺序的不同，我们可能会获得 x=0 y=1，x=1 y=0，x=1 y=1 三种结果，但不可能获得 x=0 y=0。但事实上输出结果中确实有 (0,0)。我们还可以运行很多次，然后统计每种输出出现的频数。这里再次利用了 Unix Philosophy:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./mem-ordering | head -n 100000 | sort | uniq -c
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;head&lt;/code&gt; 命令用于取开头的若干行，用 &lt;code&gt;sort&lt;/code&gt; 排序后，&lt;code&gt;uniq -c&lt;/code&gt; 可以去重并统计每种输出出现的次数。可以看到 (0,0) 是最多的，(0,1) 比 (1,0) 稍多一些 (这是由于两个线程的不对称性)，(1,1) 没有。&lt;/p&gt;
&lt;p&gt;现代处理器会将指令分解成更小的“微指令” $\mu op$，这意味着处理器也是一个“编译器”。处理器会维护一个微指令池，其中记录了微指令之间的依赖关系以及出现顺序关系，并在不影响 eventual memory consistency 的情况下调整微指令的执行顺序，多个处理器之间的即时可见性丧失。&lt;/p&gt;
&lt;p&gt;在本例中，由于对 x 变量地址读取的 cache miss，处理器可能会先取出下一条指令的 $\mu op$ 来做：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;     # &amp;lt;-----------+
movl $1, (x)   #   |
movl (y), %eax # --+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;因此，输出结果中出现了 $x=y=0$ 的情况。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;解决这个问题只能从硬件的角度入手。比如可以使用 full barrier &lt;code&gt;__sync_synchronize()&lt;/code&gt; ，(在內联汇编中，可以直接使用 &lt;code&gt;mfence&lt;/code&gt; 指令)，或者使用原子指令。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 04: Understanding Concurrent Programs</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec04/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec04/</guid>
      <description>&lt;p&gt;互斥 (mutual exclusion)：保证两个线程不能同时 (并发) 执行一段代码。&lt;/p&gt;
&lt;p&gt;对于 &lt;code&gt;sum.c&lt;/code&gt; ，我们希望添加两个魔法函数 lock() 和 unlock()，使得魔法函数中间的代码具有互斥性：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;void Tsum()
{
	for (int i = 0; i &amp;lt; N; i++)
	{
+		lock();
		sum++;
+		unlock();
	}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一个失败的尝试：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define LOCK   1
#define UNLOCK 0
void critical_section()
{
retry:
    if (locked != UNLOCK)   //*
        goto entry;
    locked = LOCK;          //**
    
    // critical section
    
    locked = UNLOCK;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从状态机的角度：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;stateDiagram
	state1: T1-L*, T2-L*
	state1 --&amp;gt; state2: 线程T1执行
	state1 --&amp;gt; state3: 线程T2执行
	state3: ……
	state2: T1-L**, T2-L*
	state2 --&amp;gt; state4: 线程T1执行
	state2 --&amp;gt; state5: 线程T2执行
	state4: ……
	state5: T1-L**, T2-L**

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到存在一个状态，T1 和 T2 同时获得了锁。该方法失败的根本原因是：我们读锁状态的操作和写锁状态的操作无法原子地执行。&lt;/p&gt;
&lt;h2 id=&#34;peterson-algorithm&#34;&gt;Peterson Algorithm&lt;/h2&gt;
&lt;p&gt;理解并发的最好方法就是用物理世界中的东西作类比：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对共享内存的写：往黑板上贴便签条&lt;/li&gt;
&lt;li&gt;对共享内存的读：看黑板 (其实不同于人类，计算机的“读”只能看到一个“历史状态”)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;假设 Alice 和 Bob 想上厕所，为了不一起进入厕所，他们制定了如下协议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alice 想上厕所，于是举起了自己的旗子 (step1，相当于 STORE 一个共享的变量)，然后将 Bob (对方) 的名字写在厕所门上 (step2，也相当于 STORE 一个共享变量)；如果 Bob 想上厕所也是同理。注意厕所门上的名字是可以覆盖的。&lt;/li&gt;
&lt;li&gt;Alice 检查门上的名字和厕所 (step3)，Alice 可以进入厕所当且仅当 Bob 没有举旗子，或者门上的名字是自己的。&lt;/li&gt;
&lt;li&gt;Alice 上完厕所后，把自己的旗子放下来 (step4)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们讨论几种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alice 检查的时候，如果 Bob 没举旗子，说明 Bob 还不想上厕所，那 Alice 可以上厕所。&lt;/li&gt;
&lt;li&gt;如果 Bob 也举旗子了，那结果是：先举旗子的人可以先进入厕所，因为后举旗子的人会把先举旗子的人的名字贴在门上，覆盖了先贴的人的内容。&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个完备的证明方法是画状态机。我们设置状态机 $(PC_1, PC_2, x, y, turn,status)$，六个状态分别表示 T1/T2 执行到第几行，T1/T2 的旗子有没有举起来，当前厕所门上写的是谁的名字，以及当前厕所状态。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://kristoff-starling.github.io/img/njuos-lec06.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt;
&lt;p&gt;我们还可以写一个小程序验证 Peterson：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define BARRIER __sync_synchronize()	
void critical_section() {
  long cnt = atomic_fetch_add(&amp;amp;count, 1);
  int i = atomic_fetch_add(&amp;amp;nested, 1) + 1;
  if (i != 1) {
    printf(&amp;quot;%d threads in the critical section @ count=%ld\n&amp;quot;, i, cnt);
    assert(0);
  }
  atomic_fetch_add(&amp;amp;nested, -1);
}

int volatile x = 0, y = 0, turn;

void TA() {
  while (1) {
    x = 1;                   BARRIER;
    turn = B;                BARRIER; // &amp;lt;- this is critcal for x86
    while (1) {
      if (!y) break;         BARRIER;
      if (turn != B) break;  BARRIER;
    }
    critical_section();
    x = 0;                   BARRIER;
  }
}

void TB() {
  while (1) {
    y = 1;                   BARRIER;
    turn = A;                BARRIER;
    while (1) {
      if (!x) break;         BARRIER;
      if (turn != A) break;  BARRIER;
    }
    critical_section();
    y = 0;                   BARRIER;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 critical_section() 中，代码主要做的事情是操作一个共享变量，如果某个时刻 &lt;code&gt;nested == 2&lt;/code&gt;，说明两个线程同时进入了临界区域，则报错。&lt;/p&gt;
&lt;p&gt;由于现代编译器和多处理器会调整语句顺序/乱序执行……所以我们在每条语句后面添加一条 &lt;code&gt;__sync_synchronize()&lt;/code&gt; 来保证编译按照顺序进行，且多处理器之间具有可见性。事实证明，如果去掉 BARRIER 会发生错误。&lt;/p&gt;
&lt;h2 id=&#34;model-checker&#34;&gt;Model Checker&lt;/h2&gt;
&lt;p&gt;我们希望用程序自动画出状态机。
&lt;a href=&#34;https://kristoff-starling.github.io/files/model-checker.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;model-checker.py&lt;/a&gt; 帮助我们完成了这项工作，其中用到的 python 语言机制较多，暂时留坑。我们可以用 &lt;code&gt;model-checker.py&lt;/code&gt; 中编写的装饰器来编写多个线程，
&lt;a href=&#34;https://kristoff-starling.github.io/files/peterson-flag.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;peterson-flag.py&lt;/a&gt; 是一个示例。使用命令 &lt;code&gt;python3 model-checker.py xxx.py&lt;/code&gt; 可以输出状态机的所有节点和转移关系。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;model-checker.py&lt;/code&gt; 主要利用了 python generator 的机制来快速获得进程的状态机。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def numbers(init=0, step=1):
    n = init
    while True:
        n += step
        yield n

g = numbers()
h = numbers(100, 200)
print(g, h)

print(g.__next__())
print(g.__next__())
print(h.__next__())
print(g.__next__())
print(h.__next__())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该程序输出结果为&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;generator object numbers at 0x7f0a75b4fcf0&amp;gt; &amp;lt;generator object numbers at 0x7f0a759f9ba0&amp;gt;
1
2
300
3
500
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;虽然 numbers() 里面是一个死循环，但执行 numbers() 还是可以退出，这得益于 &lt;code&gt;yield&lt;/code&gt; 语句，yield 的功能类似于操作系统的调度，它会主动让出执行流。&lt;code&gt;g.__next__()&lt;/code&gt; 语句可以从被打断处重新进入，继续执行函数直到遇到下一次 yield。如果我们在每一条语句后面都加上一个 yield，让 yield 后面返回所有的线程局部变量，我们就获得了函数每执行一步之后的状态机。&lt;/p&gt;
&lt;p&gt;Model checker 将验证程序正确性的问题转化成了一个图论问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Safety (线程是否互斥)：从初始状态出发，是否存在到红色 (互斥失败) 节点的路径？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图搜索&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Liveness：是否从任意黑色 (没有人执行临界区域代码) 状态出发，总能在有限步内到达蓝色/绿色 (有一个线程执行临界区域代码) 节点？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这等价于只考虑图中的黑色节点，是否存在环。只要对黑色节点的导出子图求 SCC 即可。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 05: Concurrent Programming: Mutex</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec05/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec05/</guid>
      <description>&lt;p&gt;从 high level 来看，我们希望实现如下的结构体和 API：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typdef struct
{
    ...
}lock;
void lock(lock *lk);
void unlock(lock *lk);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;若 lock() 函数返回，说明获得了这个锁，别的进程会停在 lock() 里直到获得锁的人调用了 unlock()。&lt;/p&gt;
&lt;p&gt;实现互斥的根本困难：不能同时读写共享内存。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;load 的时候不能 store，且看完之后眼睛立刻闭上，看到的都是过去的东西；&lt;/li&gt;
&lt;li&gt;store 的时候不能 load，贴字条的时候不知道覆盖了什么。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spin-lock&#34;&gt;Spin Lock&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;“解决一个问题有两种方法：一个是分析问题、提出算法、实现解决，一个是解决提出问题的人。“ —— jyy&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们希望硬件支持一条“瞬间完成读和写”的指令：“请所有人闭眼，然后我睁开眼看一眼，并做一个操作&amp;quot;。&lt;/p&gt;
&lt;h3 id=&#34;x86-lock-prefix&#34;&gt;x86: Lock Prefix&lt;/h3&gt;
&lt;p&gt;以 lock 为前缀的指令支持原子操作。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// sum-atomic.c
#include &amp;quot;thread.h&amp;quot;

#define N 100000000

long sum = 0;

void Tsum() {
  for (int i = 0; i &amp;lt; N; i++) {
    asm volatile(&amp;quot;lock addq $1, %0&amp;quot;: &amp;quot;+m&amp;quot;(sum));
  }
}

int main() {
  create(Tsum);
  create(Tsum);
  join();
  printf(&amp;quot;sum = %ld\n&amp;quot;, sum);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由于这里的 +1 操作使用了原子指令，所以程序总能得到 2N 的输出。&lt;/p&gt;
&lt;p&gt;此外，一条非常好用的原子指令是 xchg，它可以原子地将一个数值和一个内存地址上的值交换。用 C 语言封装后的形式可以是：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int xchg(volatile int *addr, int newval) {
  int result;
  asm volatile (&amp;quot;lock xchg %0, %1&amp;quot;
    : &amp;quot;+m&amp;quot;(*addr), &amp;quot;=a&amp;quot;(result) : &amp;quot;1&amp;quot;(newval)); //xchg默认原子，即使不加前缀lock也可以
  return result;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;借助 &lt;code&gt;xchg&lt;/code&gt; 指令，我们可以轻松地实现一个自旋锁：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int lock = 0;
void lock() {while (xchg(&amp;amp;lock, 1));}
void unlock() {xchg(&amp;amp;lock, 0);}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在硬件层面，硬件可以保证所有的带 lock 的指令可以排出一个全序，且原子指令相关的内存都会被提前做好 (内存的可见性)。但这其中有很多技术细节，比如多核的 Cache 之间的一致性是 x86 的噩梦 (一旦某个 CPU 要获得所，其他所有 CPU 核的 L1 Cache 都要上锁)。&lt;/p&gt;
&lt;h3 id=&#34;risc-v-lrsc&#34;&gt;RISC-V: LR/SC&lt;/h3&gt;
&lt;p&gt;原子指令内部的本质是三个步骤：load(), exec(), store()。RISC-V 提供了 load-reserved/store-conditional (LR/SC) 机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LR: 在共享内存上打一个标记，如果出现中断、别的线程写入等情况，这个标记会消失。&lt;/li&gt;
&lt;li&gt;exec()：在寄存器上做一些自己的事情&lt;/li&gt;
&lt;li&gt;SC：如果共享内存上的标记还在，则 store。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里给出一个用于自旋锁的 compare-and-swap (旧值等于某个值才将新值与其交换) 函数的实现，用这个函数实现自旋锁在轮询时可以比 xchg 少一次写入操作：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// C语言语义
int cas(int *addr, int cmp_val, int new_val)
{
    int old_val = *addr;
    if (old_val == cmp_val) {*addr = new_val;return 0;}
    else return 1;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;cas:
	lr.w t0, (a0)		# 获得旧值，并对(a0)打标记
	bne t0, a1, fail	# 如果 old_val != cmp_val 则跳转到 fail
	sc.w t0, a2, (a0)	# 如果标记还在，将a2写入(a0)，t0存储标记存在情况
	bnez t0, cas		# 如果标记被冲刷了，说明出现race condition，回到cas重做
	jr ra
fail
	li a0, 1
	jr ra
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果有两个线程同时希望获得锁，第一个线程执行完 sc.w 后，第二个线程的标记被冲刷，从而第二个线程执行 sc.w 后 t0=1，无法获得锁。&lt;/p&gt;
&lt;p&gt;LR/SC 机制不仅可以实现锁，还可以让每个线程知道锁的拥堵情况。&lt;/p&gt;
&lt;h2 id=&#34;sleep-lock&#34;&gt;Sleep Lock&lt;/h2&gt;
&lt;p&gt;自旋锁的性能缺陷：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果多个线程同时争抢锁，并行/并发的程序会因为自旋锁变得串行。除了进入临界区域的线程，其他的线程都在空转。&lt;/li&gt;
&lt;li&gt;如果持有自旋锁的线程被调度走了，那么所有的线程都进不去了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自旋锁的理想使用场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;临界区几乎不拥堵。&lt;/li&gt;
&lt;li&gt;持有自旋锁时禁止执行流切换 - 这件事对于应用程序来说太危险了，因此自旋锁一般用于操作系统内核中的并发数据结构 (临界区很短)。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;如果锁被占用，待在原地等待锁被释放是一件不太聪明的事情 (尤其是要等很长时间的时候)，我们希望一个线程在等待锁的时候可以被暂时挂起，让出 CPU，等到锁被释放时再唤醒等锁进程。&lt;/p&gt;
&lt;p&gt;C 语言代码是做不到 ”让出 CPU 的&amp;quot;，因此我们需要两个系统调用：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;syscall(SYSCALL_lock, &amp;amp;lk);		// 试图获得lk，如果失败则当前进程被挂起
syscall(SYSCALL_unlock, &amp;amp;lk);	// 释放lk，并唤醒正在等待lk的进程
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;操作系统的工作是维护这个锁和等待锁的进程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果有线程尝试获得锁，且锁处于空闲状态，就把锁给他。&lt;/li&gt;
&lt;li&gt;如果有线程尝试获得锁但锁已经被取走了，则将当前线程加入等待锁的队列，并将其挂起。&lt;/li&gt;
&lt;li&gt;如果有线程释放了锁，就检查等待锁的队列中是否有线程，如果有则将锁交给下一位 (唤醒它)，如果没有则锁的状态为空闲。&lt;/li&gt;
&lt;li&gt;操作系统使用自旋锁保证自己对队列的操作是原子的。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip: GDB Usage&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 GDB 调试多线程时，如果直接使用 next 命令，所有的线程都会向后走一步。为了更好地观测程序行为，我们可以使用 &lt;code&gt;set scheduler-lock on&lt;/code&gt; 命令来打开线程锁，之后再使用 next 命令就只有当前线程会向前走一步。我们可以通过 &lt;code&gt;info threads&lt;/code&gt; 来查看线程信息，通过 &lt;code&gt;thread id&lt;/code&gt; 来切换当前调试的线程为 id。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;futex&#34;&gt;Futex&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;自旋锁有更快的 fast path：如果获得锁成功，可以立刻进入临界区；但如果没有获得锁，则要浪费 CPU 时钟周期。&lt;/li&gt;
&lt;li&gt;睡眠锁有更快的 slow path: 如果没有获得锁，可以执行线程切换；但在能获得锁的情况下，也需要执行系统调用陷入内核。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们希望发明一种锁，对于 fast path，只需要一条原子指令就可以获得锁，对于 slow path，可以通过系统调用 yield。这就是 Futex = spin + mutex。&lt;/p&gt;
&lt;p&gt;我们可以利用 model checker 来确认 futex 的正确性：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Futex
	locked, waits = &#39;&#39;, &#39;&#39;

    def tryacquire(self):
        if not self.locked:
            # Test-and-set (cmpxchg)
            # Same effect, but more efficient than xchg
            self.locked = &#39;🔒&#39;
            return &#39;&#39;
        else:
            return &#39;🔒&#39;

    def release(self):
        if self.waits:
            self.waits = self.waits[1:]		  # 将队首元素踢出队列 &amp;lt;=&amp;gt; 将编号为队首元素的线程唤醒
        else:
            self.locked = &#39;&#39;

    @thread
    def t1(self):
        while True:
            if self.tryacquire() == &#39;🔒&#39;:     # User
                self.waits = self.waits + &#39;1&#39; # Kernel
                while &#39;1&#39; in self.waits:      # Kernel
                    pass
            cs = True                         # User
            del cs                            # User
            self.release()                    # Kernel

    @thread
    def t2(self):
        while True:
            if self.tryacquire() == &#39;🔒&#39;:
                self.waits = self.waits + &#39;2&#39;
                while &#39;2&#39; in self.waits:
                    pass
            cs = True
            del cs
            self.release()
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip: 强大的 model checker&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;我们的 model checker 的原理是：对于有装饰器 thread 修饰的函数，在每条语句后添加 yield。因此我们可以轻松地实现一个原子的操作：只要将操作写成一个函数，并在一行内调用这个函数即可。再例如，xchg 原子操作在我们的 model checker 中可以很简单地写为&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x, y = y, x
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;线程函数中的语句&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;while &#39;1&#39; in self.waits:
    pass
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;并不是内核的真正行为：内核会切换走去执行别的线程。但从这个正在等待的线程的视角，内核在做和自己无关的事等价于内核在自己这里轮询。因此我们精巧地模拟出了内核的正确行为。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 06: Concurrent Programming: Synchronization</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec06/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec06/</guid>
      <description>&lt;p&gt;线程同步：在某个时间点共同达到互相已知的状态。(每个线程都有可能做自己的某个耗时很长的工作)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nnpy：等我洗完头就吃饭/等我打完游戏就吃饭。&lt;/li&gt;
&lt;li&gt;“先到先等”的同步机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;producer-consumer-problem&#34;&gt;Producer-Consumer Problem&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void Tproducer() {while (1) puts(&amp;quot;(&amp;quot;);}
void Tconsmuer() {while (1) puts(&amp;quot;)&amp;quot;);}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们希望生成合法的括号序列，且括号序列嵌套深度不超过给定值 $n$：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;producer: 序列深度小于 $n$ 才能打印；&lt;/li&gt;
&lt;li&gt;consumer: 序列深度大于等于 1 才能打印。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以用一个队列来维护任务池，producer 将任务放到队尾，consumer 从队头取任务。取和放的操作都要在锁的保护下进行。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// pc.c
#include &amp;quot;thread.h&amp;quot;
#include &amp;quot;thread-sync.h&amp;quot;

int n, count = 0;
mutex_t lk = MUTEX_INIT();

void Tproduce() {
  while (1) {
retry:
    mutex_lock(&amp;amp;lk);
    if (count == n) {
      mutex_unlock(&amp;amp;lk);
      goto retry;
    }
    count++;
    printf(&amp;quot;(&amp;quot;);
    mutex_unlock(&amp;amp;lk);
  }
}

void Tconsume() {
  while (1) {
retry:
    mutex_lock(&amp;amp;lk);
    if (count == 0) {
      mutex_unlock(&amp;amp;lk);
      goto retry;
    }
    count--;
    printf(&amp;quot;)&amp;quot;);
    mutex_unlock(&amp;amp;lk);
  }
}

int main(int argc, char *argv[]) {
  assert(argc == 2);
  n = atoi(argv[1]);
  setbuf(stdout, NULL);
  for (int i = 0; i &amp;lt; 8; i++) {
    create(Tproduce);
    create(Tconsume);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip: 如何证明这个模型是正确的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们可以编写一个压力测试：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import sys

limit = int(sys.argv[1])
count, n = 0, 100000
while True:
for ch in sys.stdin.read(n):
  if ch == &#39;(&#39;: count += 1
  if ch == &#39;)&#39;: count -= 1
  assert 0 &amp;lt;= count &amp;lt;= limit
print(f&#39;{n} Ok.&#39;)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;指定较深层次的括号，每检查 100000 个括号输出一个 OK 信息。&lt;/p&gt;
&lt;p&gt;我们还可以用 model checker 证明该模型的正确性：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# pc.py
class ProducerConsumer:
  locked, count, log, = &#39;&#39;, 0, &#39;&#39;

  def tryacquire(self):
      self.locked, seen = &#39;🔒&#39;, self.locked
      return seen == &#39;&#39;

  def release(self):
    self.locked = &#39;&#39;

  @thread
  def tp(self):
      while True:
         while not self.tryacquire(): pass
         if not self.count == 1:
           break
         self.release()
      self.log, self.count = self.log + &#39;(&#39;, self.count + 1
      self.release()

  @thread
  def tc1(self):
      while True:
         while not self.tryacquire(): pass
         if not self.count == 0:
           break
         self.release()
      self.log, self.count = self.log + &#39;)&#39;, self.count - 1
      self.release()

  @thread
  def tc2(self):
      while True:
         while not self.tryacquire(): pass
         if not self.count == 0:
           break
         self.release()
      self.log, self.count = self.log + &#39;)&#39;, self.count - 1
      self.release()

  @marker
  def mark_negative(self, state):
      count = 0
      for ch in self.log:
         if ch == &#39;(&#39;: count += 1
         if ch == &#39;)&#39;: count -= 1
         if count &amp;lt; 0: return &#39;red&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用命令 &lt;code&gt;python model-checker.py pc.py | grep red&lt;/code&gt; 可以快速检查是否有红色节点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;conditional-variable&#34;&gt;Conditional Variable&lt;/h2&gt;
&lt;p&gt;轮询地等待条件成立太浪费事件了。我们希望在条件不满足的时候进入睡眠状态，然后条件可能满足的时候把我唤醒，于是有了条件变量 (注：这个思想和睡眠锁类似，但等待的对象不一样。睡眠锁等待的是空锁的出现，而条件变量是在获得锁之后，等待关键变量相关的条件可能成立的时机)。&lt;/p&gt;
&lt;p&gt;条件变量最基本的 API 有：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int pthread_cond_wait(pthread_cond_t *cv, pthread_mutex_t *lk);
int pthread_cond_signal(pthread_cond_t &amp;amp;cv);
int pthread_cond_broadcast(ptread_cond_t &amp;amp;cv);
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;wait() 函数传入一个条件变量和一个互斥锁，调用时要求线程持有该锁。wait() 会将这个互斥锁释放掉，然后睡眠该线程。等到有别的线程调用 signal() 或 broadcast() 来唤醒这个条件变量有关的线程时，wait() 会重新获得互斥锁，并继续执行下去。&lt;/li&gt;
&lt;li&gt;signal() 和 broadcast() 的作用都是唤醒在条件变量 cv 上睡眠的线程。两者的不同是 signal() 只挑一个线程唤醒，broadcast() 会唤醒所有 cv 上的线程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;条件变量的正确使用方式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;mutex_lock(&amp;amp;lk);
while (!cond) {
    cond_wait(&amp;amp;cv, &amp;amp;lk);
}
assert(cond);

// do some job.
// if job is unrelated to critical variables, mutex lock can be released.

/* if other threads&#39; cv may be satisfied */
cond_broadcast(&amp;amp;cv);
/* ------------------------------------- */
mutex_unlock(&amp;amp;lk);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;有几点需要说明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;while (!cond)&lt;/code&gt; 写成 &lt;code&gt;if (!cond)&lt;/code&gt; 是一个常见的错误。比如当前有一个 Tproducer 和两个 Tconsumer，那么可能出现 Tproducer 打印完 &lt;code&gt;(&lt;/code&gt;  后唤醒了第一个 Tconsumer，然后第一个 Tconsumer 打印完 &lt;code&gt;)&lt;/code&gt; (此时已经不能再打印 &lt;code&gt;)&lt;/code&gt; ) 后唤醒了第二个 Tconsumer。如果是 &lt;code&gt;if (!cond)&lt;/code&gt; ，第二个 Tconsumer 被唤醒了之后无法再进行条件检查，从而又打出一个 &lt;code&gt;)&lt;/code&gt; 导致错误。&lt;/p&gt;
&lt;p&gt;使用 &lt;code&gt;while (!cond)&lt;/code&gt; 保证了跳出 while 循环后 cond 一定是成立的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 &lt;code&gt;cond_broadcast(&amp;amp;cv)&lt;/code&gt; 而不是 &lt;code&gt;cond_signal(&amp;amp;cv)&lt;/code&gt; 可以避免一些“死锁”情况，例如在没有多余的任务时，若干个 consumer 互相 signal 导致任务无法进行下去。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tproducer 完成任务后从唤醒一个睡在 comsumer-cv 上的线程，Tconsumer 完成任务后唤醒一个睡在 producer-cv 上的线程。为什么这个模型不对？&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class ProducerConsumer:
    locked, count, log, waitp, waitc = &#39;&#39;, 0, &#39;&#39;, &#39;&#39;, &#39;&#39;

    def tryacquire(self):
        self.locked, seen = &#39;🔒&#39;, self.locked
        return seen == &#39;&#39;

    def release(self):
        self.locked = &#39;&#39;

    @thread
    def tp(self):
        for _ in range(2):
            while not self.tryacquire(): pass # mutex_lock()

            if self.count == 1:
                # cond_wait
                _, self.waitp = self.release(), self.waitp + &#39;1&#39;
                while &#39;1&#39; in self.waitp: pass
                while not self.tryacquire(): pass

            self.log, self.count = self.log + &#39;(&#39;, self.count + 1
            self.waitc = self.waitc[1:] # cond_signal
            self.release() # mutex_unlock()

    @thread
    def tc1(self):
        while not self.tryacquire(): pass

        if self.count == 0:
            _, self.waitc = self.release(), self.waitc + &#39;2&#39;
            while &#39;2&#39; in self.waitc: pass
            while not self.tryacquire(): pass

        self.log, self.count = self.log + &#39;)&#39;, self.count - 1

        self.waitp = self.waitp[1:]
        self.release()

    @thread
    def tc2(self):
        while not self.tryacquire(): pass

        if self.count == 0:
            _, self.waitc = self.release(), self.waitc + &#39;3&#39;
            while &#39;3&#39; in self.waitc: pass
            while not self.tryacquire(): pass

        self.log, self.count = self.log + &#39;)&#39;, self.count - 1

        self.waitp = self.waitp[1:]
        self.release()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 model checker 对该算法进行分析。下面的这种情形会导致问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tc2 首先运行，获得锁之后发现 &lt;code&gt;count == 0&lt;/code&gt; ，于是释放锁并睡眠在 consumer-cv 上。&lt;/li&gt;
&lt;li&gt;Tp 运行，获得锁之后打印左括号，&lt;code&gt;count += 1&lt;/code&gt; ，唤醒了线程 Tc2，然后释放了锁。&lt;/li&gt;
&lt;li&gt;Tc2 被唤醒了以后并没有获得锁，而是 Tc1 抢先获得了锁，打印了右括号，&lt;code&gt;count -= 1&lt;/code&gt;，然后释放了锁。&lt;/li&gt;
&lt;li&gt;Tc2 获得了锁。但此时 Tp 生产的资源已经被 Tc1 用掉了，Tc2 因为没有使用 while 判断 count，所以直接打印了右括号，&lt;code&gt;count -= 1&lt;/code&gt;，错误发生。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;只要是可以多线程的工作，都可以使用上面的模板来进行并行加速。通常来说，如果一个任务要分成若干个“层“，每”层“内的任务之间互相独立，我们就可以利用多线程加速每一层的运算 (但层与层之间的依赖关系是无法多线程加速的)。&lt;/p&gt;
&lt;h3 id=&#34;example-fish&#34;&gt;Example: fish&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;使用打印 &lt;code&gt;&amp;lt;&lt;/code&gt; &lt;code&gt;&amp;gt;&lt;/code&gt; 和 &lt;code&gt;_&lt;/code&gt; 的三个线程连续输出小鱼。鱼的形态有两种：&lt;code&gt;&amp;lt;&amp;gt;&amp;lt;_&lt;/code&gt; 和 &lt;code&gt;&amp;gt;&amp;lt;&amp;gt;_&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用万能的条件变量。我们要搞清楚的事情是：这三个线程应该在什么条件下可以输出？我们画出状态机：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;stateDiagram
	s1: A(&#39;&#39;)
	s1 --&amp;gt; s2: &#39;&amp;lt;&#39;
	s1 --&amp;gt; s3: &#39;&amp;gt;&#39;
	s2: B(&#39;&amp;lt;&#39;)
	s3: C(&#39;&amp;gt;&#39;)
	s2 --&amp;gt; s4: &#39;&amp;gt;&#39;
	s4: D(&#39;&amp;lt;&amp;gt;&#39;)
	s3 --&amp;gt; s5: &#39;&amp;lt;&#39;
	s5: E(&#39;&amp;gt;&amp;lt;&#39;)
	s4 --&amp;gt; s6: &#39;&amp;lt;&#39;
	s5 --&amp;gt; s6: &#39;&amp;gt;&#39;
	s6: F(&#39;&amp;lt;&amp;gt;&amp;lt;&#39; or &#39;&amp;gt;&amp;lt;&amp;gt;&#39;)
	s6 --&amp;gt; s1: &#39;_&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们只要在程序中维护当前到达的状态机顶点，然后根据状态机的出边决定某个线程是否可以打印即可。还需要注意的一点是：打印 &lt;code&gt;&amp;lt;&lt;/code&gt; &lt;code&gt;&amp;gt;&lt;/code&gt; &lt;code&gt;_&lt;/code&gt; 的线程可能各有很多个。从状态机当前节点出发，只能有一个可行字符线程打印。因此还需要一个变量控制当前是否已经有线程在打印途中。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// fish.c
#include &amp;quot;thread.h&amp;quot;
#include &amp;lt;string.h&amp;gt;

#define LENGTH(arr) (sizeof(arr) / sizeof(arr[0]))

enum { A = 1, B, C, D, E, F, };

struct rule {
  int from, ch, to;
};

struct rule rules[] = {
  { A, &#39;&amp;lt;&#39;, B },
  { B, &#39;&amp;gt;&#39;, C },
  { C, &#39;&amp;lt;&#39;, D },
  { A, &#39;&amp;gt;&#39;, E },
  { E, &#39;&amp;lt;&#39;, F },
  { F, &#39;&amp;gt;&#39;, D },
  { D, &#39;_&#39;, A },
};
int current = A, quota = 1;

pthread_mutex_t lk   = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t  cond = PTHREAD_COND_INITIALIZER;

int next(char ch) {
  for (int i = 0; i &amp;lt; LENGTH(rules); i++) {
    struct rule *rule = &amp;amp;rules[i];
    if (rule-&amp;gt;from == current &amp;amp;&amp;amp; rule-&amp;gt;ch == ch) {
      return rule-&amp;gt;to;
    }
  }
  return 0;
}

void fish_before(char ch) {
  pthread_mutex_lock(&amp;amp;lk);
  while (!(next(ch) &amp;amp;&amp;amp; quota)) {
    // can proceed only if (next(ch) &amp;amp;&amp;amp; quota)
    pthread_cond_wait(&amp;amp;cond, &amp;amp;lk);
  }
  quota--;
  pthread_mutex_unlock(&amp;amp;lk);
}

void fish_after(char ch) {
  pthread_mutex_lock(&amp;amp;lk);
  quota++;
  current = next(ch);
  assert(current);
  pthread_cond_broadcast(&amp;amp;cond);
  pthread_mutex_unlock(&amp;amp;lk);
}

const char roles[] = &amp;quot;.&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;___&amp;quot;;

void fish_thread(int id) {
  char role = roles[id];
  while (1) {
    fish_before(role);
    putchar(role); // can be long; no lock protection
    fish_after(role);
  }
}

int main() {
  setbuf(stdout, NULL);
  for (int i = 0; i &amp;lt; strlen(roles); i++)
    create(fish_thread);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个 &lt;code&gt;fish.c&lt;/code&gt; 写的非常漂亮。它完全复刻了状态机的思想，维护了可行的转移条件。变量 quota 保证了只有一个线程“出手”打印。&lt;/p&gt;
&lt;p&gt;还值得注意的一点是，&lt;code&gt;putchar(role)&lt;/code&gt; 这个操作和控制状态机转移的关键变量 current 和 quota 无关。且 I/O 操作理论上速度较慢。这样的工作是可以放在锁外面进行的 (事实上，由于 quota 的控制，这个操作并没有起到明显的优化效果)。&lt;/p&gt;
&lt;p&gt;我们可以对其进行压力测试：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# fish-check.py
import sys

n, count = 100000, 0
while True:
    animal = str(sys.stdin.read(4))
    assert animal == &#39;&amp;lt;&amp;gt;&amp;lt;_&#39; or animal == &#39;&amp;gt;&amp;lt;&amp;gt;_&#39;
    count += 1
    if count == n:
        print(f&#39;{n} OK.&#39;)
        count = 0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;semaphore&#34;&gt;Semaphore&lt;/h2&gt;
&lt;p&gt;在上述的括号打印问题中，我们使用互斥锁来保护我们对 count 变量的更新操作。一个想法是：可不可以不止一个锁，而是有 $n$ 个手环。手环数量不能超过上限，producer 可以生产手环，consumer 必须领到手环才能做事情？这种维护了“一堆手环”的锁就是信号量。&lt;/p&gt;
&lt;p&gt;下面的 python 代码描述了信号量的行为建模：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# sem.py
class Semaphore:
    token, waits = 1, &#39;&#39;

    def P(self, tid):
        if self.token &amp;gt; 0:
            self.token -= 1
            return True
        else:
            self.waits = self.waits + tid
            return False

    def V(self):
        if self.waits:
            self.waits = self.waits[1:]
        else:
            self.token += 1

    @thread
    def t1(self):
        self.P(&#39;1&#39;)
        while &#39;1&#39; in self.waits: pass
        cs = True
        del cs
        self.V()

    @thread
    def t2(self):
        self.P(&#39;2&#39;)
        while &#39;2&#39; in self.waits: pass
        cs = True
        del cs
        self.V()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;变量 token 维护了资源 (手环) 的数量。P() 用于获取手环，如果当前有剩余的手环就领走，并进入临界区域；如果当前没有剩余的手环就进入等待序列。V() 用于归还手环。如果当前有正在等待的人，就直接将手环交给它 (wait list 队首元素弹出)，如果没有就归还给 kernel (token++)。&lt;/p&gt;
&lt;p&gt;C 语言的线程库为我们提供了信号量的相关 API:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int sem_init(sem_t *sem, int pshared, unsigned int value);
int sem_wait(sem_t *sem);
int sem_post(sem_t *sem);
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;sem_init() 用于初始化一个信号量，&lt;code&gt;pshared == 0&lt;/code&gt; 表示该信号量只在当前进程的线程之间共享；&lt;code&gt;pshared == 1&lt;/code&gt; 表示该信号量可以跨进程共享。value 表示信号量的初始值 (游泳馆的最大手环个数)。&lt;/li&gt;
&lt;li&gt;sem_wait() 和 sem_post() 等价于之前的 P() 和 V()，用于领取手环和归还手环。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;利用这些 API 我们可以非常轻巧地实现之前的括号打印任务：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// pc-sem.c
#include &amp;quot;thread.h&amp;quot;
#include &amp;quot;thread-sync.h&amp;quot;

sem_t fill, empty;

void producer() {
  while (1) {
    P(&amp;amp;empty);
    printf(&amp;quot;(&amp;quot;);
    V(&amp;amp;fill);
  }
}

void consumer() {
  while (1) {
    P(&amp;amp;fill);
    printf(&amp;quot;)&amp;quot;);
    V(&amp;amp;empty);
  }
}

int main(int argc, char *argv[]) {
  assert(argc == 2);
  SEM_INIT(&amp;amp;fill, 0);
  SEM_INIT(&amp;amp;empty, atoi(argv[1]));
  for (int i = 0; i &amp;lt; 8; i++) {
    create(producer);
    create(consumer);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通常来说，信号量在”一单位资源“明确的情况下比较好用 (比如这里的“一单位资源”就是指一个尚未匹配的左括号)，在有些场景下使用信号量很难写出正确的并发程序。此外，信号量的 V() 函数是可以在“没有领取手环”的时候“凭空”“变出一个手环“上交的，因此使用时必须格外小心。&lt;/p&gt;
&lt;h2 id=&#34;dining-philosophers-problem&#34;&gt;Dining Philosophers Problem&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;五个哲学家围成一桌吃饭。每两个人之间有一把叉子 (一共五把)，哲学家只有同时拿到左边和右边的叉子才能吃饭。如何维护这件事情？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这件事情不是很好明确“一单位资源“：一把叉子既是某位哲学家的“右叉子”，又是某位哲学家的“左叉子”，如果我们对每把叉子维护一个信号量，写入如下程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// philosopher.c
#include &amp;quot;thread.h&amp;quot;
#include &amp;quot;thread-sync.h&amp;quot;

#define N 5
sem_t locks[N];

void Tphilosopher(int id) {
  int lhs = (N + id - 1) % N;
  int rhs = id % N;
  while (1) {
    P(&amp;amp;locks[lhs]);
    printf(&amp;quot;T%d Got %d\n&amp;quot;, id, lhs + 1);
    P(&amp;amp;locks[rhs]);
    printf(&amp;quot;T%d Got %d\n&amp;quot;, id, rhs + 1);
    V(&amp;amp;locks[lhs]);
    V(&amp;amp;locks[rhs]);
  }
}

int main(int argc, char *argv[]) {
  for (int i = 0; i &amp;lt; N; i++) {
      SEM_INIT(&amp;amp;locks[i], 1);
  }
  for (int i = 0; i &amp;lt; N; i++) {
    create(Tphilosopher);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行一小会儿就会卡住。此时每个哲学家都抓着自己左手边的叉子，它们都想得到右叉子，但都得不到。因为都得不到，他们也不会放下自己手中的叉子。这就是死锁。如果把每把叉子想象成图中的节点，哲学家们对叉子的需求序列 (先要左叉子，再要右叉子) 就构成了一个环。如果锁依赖关系中有环，就可能出现死锁。&lt;/p&gt;
&lt;p&gt;当然我们可以用万能的条件变量来正确实现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;mutex_lock(&amp;amp;mutex);
while (!(avail[lhs] &amp;amp;&amp;amp; avail[rhs])) {
  wait(&amp;amp;cv, &amp;amp;mutex);
}
avail[lhs] = avail[rhs] = false;
mutex_unlock(&amp;amp;mutex);

mutex_lock(&amp;amp;mutex);
avail[lhs] = avail[rhs] = true;
broadcast(&amp;amp;cv);
mutex_unlock(&amp;amp;mutex);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该段代码与之前相比的区别在于，哲学家总是看到左右叉子都有再同时拿起，吃完了就会放下。不会出现之前方法中的哲学家拿到一把叉子再等另一把叉子，自己手里的叉子也不给别人用的情况。&lt;/p&gt;
&lt;p&gt;系统中另一种常见的处理生产者-消费者模型的方法是 master-slave：我们安排一个服务员来维护所有的叉子，所有的哲学家都通过与服务员通信的方法来向服务员索要叉子/让服务员把叉子取走。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void Tphilosopher(int id) {
  send_request(id, EAT);
  P(allowed[id]); // waiter 会把叉子递给哲学家
  philosopher_eat();
  send_request(id, DONE);
}

void Twaiter() {
  while (1) {
    (id, status) = receive_request();
    if (status == EAT) { ... }
    if (status == DONE) { ... }
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 07: Concurrent Programming: Real World</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec07/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec07/</guid>
      <description>&lt;h2 id=&#34;high-performance-computing&#34;&gt;High Performance Computing&lt;/h2&gt;
&lt;p&gt;HPC: 解决需要 massive computation 的任务。&lt;/p&gt;
&lt;p&gt;基本思路：计算图会分成若干层，每层会有很多要计算的节点。将每层的任务先分配到机器，机器里再分配到线程 (两级分解)，并行计算这些节点后，用一个 &amp;ldquo;join()&amp;rdquo; 汇总一下 (涉及线程、机器、共享内存之间的通信)。&lt;/p&gt;
&lt;p&gt;HPC 可以实现的原因：数据的局部性。例如我们想利用 HPC 进行一团气体的运动模拟，那么我们可以将立方体容器内的气体切分成很多块，每个线程管一块。每个线程管理的气体绝大部分的运动都是本地的，我们只需要处理少部分的相邻块的气体分子交换即可。&lt;/p&gt;
&lt;h3 id=&#34;example-mandelbrot-set&#34;&gt;Example: Mandelbrot Set&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// mandelbrot.c
#include &amp;quot;thread.h&amp;quot;
#include &amp;lt;math.h&amp;gt;

int NT;
#define W 6400
#define H 6400
#define IMG_FILE &amp;quot;./mandelbrot.ppm&amp;quot;

static inline int belongs(int x, int y, int t) {
  return x / (W / NT) == t;
}

int x[W][H];
int volatile done = 0;

void display(FILE *fp, int step) { 
  static int rnd = 1;
  int w = W / step, h = H / step;
  // STFW: Portable Pixel Map
  fprintf(fp, &amp;quot;P6\n %d %d 255\n&amp;quot;, w, h);
  for (int j = 0; j &amp;lt; H; j += step) {
    for (int i = 0; i &amp;lt; W; i += step) {
      int n = x[i][j];
      int r = 255 * pow((n - 80) / 800.0, 3);
      int g = 255 * pow((n - 80) / 800.0, 0.7);
      int b = 255 * pow((n - 80) / 800.0, 0.5);
      fputc(r, fp); fputc(g, fp); fputc(b, fp);
    }
  }
}

void Tworker(int tid) {
  for (int i = 0; i &amp;lt; W; i++)
    for (int j = 0; j &amp;lt; H; j++)
      if (belongs(i, j, tid - 1)) {
        double a = 0, b = 0, c, d;
        while ((c = a * a) + (d = b * b) &amp;lt; 4 &amp;amp;&amp;amp; x[i][j]++ &amp;lt; 880) {
          b = 2 * a * b + j * 1024.0 / H * 8e-9 - 0.645411;
          a = c - d + i * 1024.0 / W * 8e-9 + 0.356888;
        }
      }
  done++;
}

void Tdisplay() {
  float ms = 0;
  while (1) {
    FILE *fp = popen(&amp;quot;viu -&amp;quot;, &amp;quot;w&amp;quot;); assert(fp);
    display(fp, W / 256);
    pclose(fp);
    if (done == NT) break;
    usleep(1000000 / 5);
    ms += 1000.0 / 5;
  }
  printf(&amp;quot;Approximate render time: %.1lfs\n&amp;quot;, ms / 1000);

  FILE *fp = fopen(IMG_FILE, &amp;quot;w&amp;quot;); assert(fp);
  display(fp, 2);
  fclose(fp);
}

int main(int argc, char *argv[]) {
  assert(argc == 2);
  NT = atoi(argv[1]);
  for (int i = 0; i &amp;lt; NT; i++) {
    create(Tworker);
  }
  create(Tdisplay);
  join();
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这段代码使用一些数学手法画出一幅清晰度很高，非常美观的分形图。代码中有一些有意思的小工具：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tdisplay 线程中使用了 viu 命令行工具，它可以将一张图片以较低的分辨率打印在终端上，这可以在让我们看到图像生成的大致过程。我们可以看到该程序将画面切分成了多个部分，每个线程控制一个。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tdisplay 线程最终将像素信息输出到了一个 ppm (portable pixel map) 文件中。对于 C 语言来说，这是一种非常方便的输出图像的方式：只需要在文件开头输出&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;P6
W H COLOR // 宽，高，颜色数
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后一行一行地将每个点的 RGB 值输出即可。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data-center&#34;&gt;Data Center&lt;/h2&gt;
&lt;p&gt;多副本情况下的低延迟、高可靠性问题。这其中存在一些互相矛盾的点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Availability - 数据在 data center 应该有多个副本，这样如果某个副本坏了，数据不会丢失。此外，为了各地地人可以快速读取，服务器会把本地城市 data center 的数据直接返回。&lt;/li&gt;
&lt;li&gt;Consistency - ”我在南京屏蔽我妈，我妈在广州也要响应这个屏蔽。” 不能因为图快而不同步地直接读取本地副本。&lt;/li&gt;
&lt;li&gt;Partition Tolerance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这门课的问题：如何在一台计算机上既可能高效地处理并行请求？&lt;/p&gt;
&lt;p&gt;我们的工具：线程、协程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程：可以在操作系统的调度算法下进行切换，但线程切换很“重”：需要保存上下文，需要陷入内核 (privilege level 的改变)……&lt;/li&gt;
&lt;li&gt;协程：更轻量级的并发 (只要遵守 calling convention，切换时不需要保存那么多寄存器，不需要进操作系统)，但只有执行 co_yield() 才会切换，如果某个线程执行了很慢的 I/O 系统调用，剩下的协程就都在摸鱼。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;goroutine&#34;&gt;Goroutine&lt;/h3&gt;
&lt;p&gt;Go 是一门专门服务系统编程的语言。go 支持所谓的 goroutine: 在概念上它是线程，但它是使用类似于协程的原理实现的。每个 CPU 上只有一个线程，但这个线程下有多个 goroutine，每个 CPU 上有一个 Go worker 负责调度这些 goroutine。goroutine 切换的方式和协程相似，因此非常轻量级。对于某些会导致阻塞的系统调用 (如 sleep, rand)，go 会将他们改成 non-blocking 的版本，如果需要陷入内核进行长时间操作，它就会 yield 到另一个 goroutine 执行。这样，goroutine 将操作系统和 CPU 都利用到了100%。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Example from &amp;quot;The Go Programming Language&amp;quot;

package main

import (
  &amp;quot;fmt&amp;quot;
  &amp;quot;time&amp;quot;
)

func main() {
  go spinner(100 * time.Millisecond)
  const n = 45
  fibN := fib(n) // slow
  fmt.Printf(&amp;quot;\rFibonacci(%d) = %d\n&amp;quot;, n, fibN)
}

func spinner(delay time.Duration) {
  for {
    for _, r := range `-\|/` {
      fmt.Printf(&amp;quot;\r%c&amp;quot;, r)
      time.Sleep(delay)
    }
  }
}

func fib(x int) int {
  if x &amp;lt; 2 { return x }
  return fib(x - 1) + fib(x - 2)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在主函数中，我们使用 &lt;code&gt;go spinner&lt;/code&gt; 创建了一个新的 goroutine。该程序可以一边计算 Fibinacci 数列，一边在 spinner 协程中打印旋转的进度条。&lt;/p&gt;
&lt;p&gt;绝大部分的并发问题都可以通过生产者-消费者模型来解决。Go 语言封装了生产者-消费者队列，提供了用于 goroutines 之间通信的 API：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

var stream = make(chan int, 10)
const n = 4

func produce() {
  for i := 0; ; i++ {
    fmt.Println(&amp;quot;produce&amp;quot;, i)
    stream &amp;lt;- i
  }
}

func consume() {
  for {
    x := &amp;lt;-stream
    fmt.Println(&amp;quot;consume&amp;quot;, x)
  }
}

func main() {
  for i := 0; i &amp;lt; n; i++ {
    go produce()
  }
  consume()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;make(chan int, 10)&lt;/code&gt; 定义了一个通道，并规定了其最大容量 (最大容量为 0 的 channel 可以用来同步)。生产者通过 &lt;code&gt;stream &amp;lt;- i&lt;/code&gt; 往队列里面加东西，消费者通过 &lt;code&gt;x := &amp;lt;-stream&lt;/code&gt; 从队列里面取东西。其内部的锁，睡眠等细节问题全部对程序员透明。&lt;/p&gt;
&lt;h2 id=&#34;web-20&#34;&gt;Web 2.0&lt;/h2&gt;
&lt;p&gt;在网页这种计算量、并发量都不大的场景下，我们使用的模型是单线程+事件模型。事件按照顺序执行，具有原子性 (减少了发生并发 bug 的可能)，遇到耗时的 API 就立刻返回 (结束一个事件)。&lt;/p&gt;
&lt;p&gt;为了代码的可维护性，描述流图的语言正在发展。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 08: Concurrent Bugs and Confrontation</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec08/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec08/</guid>
      <description>&lt;p&gt;Bug 多的根本原因：软件是需求在计算机世界的投影，人类世界的很多性质在编程语言中丧失了。&lt;/p&gt;
&lt;h2 id=&#34;defensive-programming&#34;&gt;Defensive Programming&lt;/h2&gt;
&lt;p&gt;一个好的策略是添加很多的 assert()，assert() 的核心意义在于将程序的需求表达出来。&lt;/p&gt;
&lt;p&gt;assert() 虽然不一定能写得对，但如果 assert() 和代码出错的概率是独立的，那么写 assert() 就使得程序出错的概率降低了一个数量级。&lt;/p&gt;
&lt;h2 id=&#34;concurrent-bugs&#34;&gt;Concurrent Bugs&lt;/h2&gt;
&lt;h3 id=&#34;deadlock&#34;&gt;Deadlock&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;一个中断相关的死锁&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void os_run()
{
 spin_lock(&amp;amp;lk);
 spin_lock(&amp;amp;xxx);
 spin_unlock(&amp;amp;xxx); //------+
}					   //  	   |
					   //	   | Interrupt
void on_interrupt()	   //	   |
{					   //	   |
 spin_lock(&amp;amp;lk); // &amp;lt;-------+
 ...
 spin_unlock(&amp;amp;lk);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上锁的时候要关中断，且锁出现嵌套的时候，需要一个计数器来维护嵌套层数，只有完全无锁的时候才能开中断 (释放锁的时候不能莽开中断)。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;AA-deadlock：某个线程在试图获得自己已经获得的锁。这很容易检测出来。在编程的时候理应多使用如下的防御性编程：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;if (holding(lk)) panic();
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ABBA-deadlock：进程在互相等待别人的锁。lock-ordering 是一种好的防御方法：系统中所有的锁必须排出一个无环的拓扑序。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;model checker 可以可视化地帮我们检查是否有死锁。如果某个节点所有的出边都指向自己，这就是一个陷入死锁的状态。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-race&#34;&gt;Data Race&lt;/h3&gt;
&lt;p&gt;两个线程在同一时间访问同一个地址，且至少有一个是写。之所以被称为“竞争”是因为运行的结果取决于“谁跑赢了”。&lt;/p&gt;
&lt;h3 id=&#34;atomicity-violation-av--order-violation-ov&#34;&gt;Atomicity Violation (AV) &amp;amp; Order Violation (OV)&lt;/h3&gt;
&lt;p&gt;TOCTTOU (time of check to time of use)：某段代码通常会检查某个条件 (time to check)，然后在认为这个条件的成立是 invariant 的情况下对其进行某种操作 (time of use)，但如果其他程序在中间插入做了某个改变 invariant 的操作，就会产生 bug。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                       TIME		
/home/abc/mailbox       |
a symbolic link?        |
      |                 |   Delete /home/abc/mailbox
      |                 |
      | No              |   Create symbolic link
      |                 |   ~/mailbox, pointing to 
      |                 |   /etc/passwd
Append the new message  |
to /home/abc/mailbox    |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在上述过程中，如果攻击者利用 TOC 和 TOU 之间的窗口期将 &lt;code&gt;/home/abc/mailbox&lt;/code&gt; 指向某个非法的文件 (打破了 kernel 之前检查的条件)，kernel 就可能会给普通用户 root 权限。&lt;/p&gt;
&lt;h2 id=&#34;bugs-confrontation&#34;&gt;Bugs Confrontation&lt;/h2&gt;
&lt;h3 id=&#34;lockdep&#34;&gt;Lockdep&lt;/h3&gt;
&lt;p&gt;我们可以为每把锁一个全局唯一的 allocation site。在所有获得锁/释放锁的时间点记录一份日志，然后对日志进行分析 (观察上锁顺序)，如果对于某两把锁 $x,y$，我们能观测到 $x\rightsquigarrow y\and y\rightsquigarrow x$，则检测出了可能的死锁。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// lock-site.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;

typedef struct lock {
  int locked;
  const char *site;
} lock_t;

#define STRINGIFY(s) #s
#define TOSTRING(s)  STRINGIFY(s)
#define LOCK_INIT() \
  ( (lock_t) { .locked = 0, .site = __FILE__ &amp;quot;:&amp;quot; TOSTRING(__LINE__), } )

lock_t lk1 = LOCK_INIT();
lock_t lk2 = LOCK_INIT();

void lock(lock_t *lk) {
  printf(&amp;quot;LOCK   %s\n&amp;quot;, lk-&amp;gt;site);
}

void unlock(lock_t *lk) {
  printf(&amp;quot;UNLOCK %s\n&amp;quot;, lk-&amp;gt;site);
}

struct some_object {
  lock_t lock;
  int data;
};

void object_init(struct some_object *obj) {
  obj-&amp;gt;lock = LOCK_INIT();
}

int main() {
  lock(&amp;amp;lk1);
  lock(&amp;amp;lk2);
  unlock(&amp;amp;lk1);
  unlock(&amp;amp;lk2);

  struct some_object *obj = malloc(sizeof(struct some_object));
  assert(obj);
  object_init(obj);
  lock(&amp;amp;obj-&amp;gt;lock);

  lock(&amp;amp;lk2);
  lock(&amp;amp;lk1);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面的 &lt;code&gt;lock-site.c&lt;/code&gt; 提供了一种简单的为每个锁提供唯一 allocation site 的方法，其中的一些宏定义值得学习。&lt;/p&gt;
&lt;h3 id=&#34;sanitizer&#34;&gt;Sanitizer&lt;/h3&gt;
&lt;p&gt;运行时的动态检查。AddressSanitizer 可以检查内存访问的 bug (监控所有的内存访问)，ThreadSanitizer 可以检查数据竞争 (内存访问 + lock/unlock)，此外还有 UBSanitizer, MemorySanitizer 等。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// uaf.c
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;

int main() {
  int *ptr = malloc(sizeof(int));
  *ptr = 1;
  free(ptr);
  *ptr = 1;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上述程序存在 use-after-free 问题。在编译时加入 &lt;code&gt;-fsanitize=address&lt;/code&gt;，运行程序时，我们可以得到丰富的报错信息。&lt;/p&gt;
&lt;h3 id=&#34;lightweight-tools&#34;&gt;Lightweight Tools&lt;/h3&gt;
&lt;h4 id=&#34;stack-canary&#34;&gt;Stack Canary&lt;/h4&gt;
&lt;p&gt;在栈顶和栈底设置一些存储了特殊值的内存单元 (金丝雀) 并定期检查这些单元。如果这些单元被修改了，说明发生了栈溢出。我们只需很短的代码就可以完成 stack canary：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define MAGIC 0x55555555
#define BOTTOM (STK_SZ / sizeof(u32) - 1)
struct stack { char data[STK_SZ]; };

void canary_init(struct stack *s) {
  u32 *ptr = (u32 *)s;
  for (int i = 0; i &amp;lt; CANARY_SZ; i++)
    ptr[BOTTOM - i] = ptr[i] = MAGIC;
}

void canary_check(struct stack *s) {
  u32 *ptr = (u32 *)s;
  for (int i = 0; i &amp;lt; CANARY_SZ; i++) {
    panic_on(ptr[BOTTOM - i] != MAGIC, &amp;quot;underflow&amp;quot;);
    panic_on(ptr[i] != MAGIC, &amp;quot;overflow&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们有时在 windows 中会看到的 &amp;ldquo;烫烫烫&amp;rdquo; 等字，其实是 stack canary 在 GB2312 编码下的结果：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;未初始化栈: &lt;code&gt;0xcccccccc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;未初始化堆: &lt;code&gt;0xcdcdcdcd&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;对象头尾: &lt;code&gt;0xfdfdfdfd&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;已回收内存: &lt;code&gt;0xdddddddd&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以用&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(b&#39;\xcc&#39; * 80).decode(&#39;gb2312&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查看使用未初始化栈时得到的内容 (烫烫烫)。&lt;/p&gt;
&lt;h4 id=&#34;lightweight-lockdep&#34;&gt;Lightweight Lockdep&lt;/h4&gt;
&lt;p&gt;很多情况下，我们可以在自旋锁自旋次数过多的时候直接报警，然后利用 GDB 的 backtrace 功能观察是否真的发生了死锁。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int spin_cnt = 0;
while (xchg(&amp;amp;locked, 1)) {
  if (spin_cnt++ &amp;gt; SPIN_LIMIT) {
    printf(&amp;quot;Too many spin @ %s:%d\n&amp;quot;, __FILE__, __LINE__);
  }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 09: State Machine of OS</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec09/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec09/</guid>
      <description>&lt;h2 id=&#34;bare-metal--software&#34;&gt;Bare-metal &amp;amp; Software&lt;/h2&gt;
&lt;p&gt;数字电路本身就是一个巨大的状态机。硬件厂商会保证 CPU reset 后处理器处在一个确定的状态，各个单元的固定的值会写在手册中。以 x86 为例，手册规定了 CPU reset 后 rip 的值会是 0xfff0，EFLAGS 的值为 0x2，当前硬件运行在 16-bit 模式中，不响应中断。&lt;/p&gt;
&lt;p&gt;CPU 只是一个周而复始的取值译码执行的东西，因此它马上会做的事情就是取出 0xfff0 处的指令并执行。0xfff0 处通常是一个跳转指令，PC 会跳转到固件代码执行。固件 (Firmware) 是硬件厂商写死在一块 ROM 上的代码，常见的固件程序有 BIOS 和 UEFI 两种，后者更加现代机制更加复杂，这里简介 Legacy BIOS 的过程：&lt;/p&gt;
&lt;p&gt;BIOS 的主要工作是扫描各个硬盘/U盘/软盘……然后将第一个可引导的设备的第一个扇区 (512B) 加载到地址 0x7c00 处。可引导的设备的第一个扇区会遵循主引导记录 (Master Boot Record, MBR) 的格式。如果我们使用命令&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;cat executable-x86_64-qemu | head -c 512 | xxd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查看一个镜像文件的前 512 个字节，我们可以看到其末尾一定是 0x55aa。这是 MBR 的结束标志。&lt;/p&gt;
&lt;p&gt;此时硬件仍然工作在 16-bit 模式上。规定 &lt;code&gt;CS:IP=0x7c00&lt;/code&gt; ，即 &lt;code&gt;(R[CS]&amp;lt;&amp;lt;4) | R[IP] == 0x7c00&lt;/code&gt; ，其他没有任何约束。Firmware 执行结束后，PC 跳转到 0x7c00 执行，刚刚加载过来的是 Legacy boot (boot loader)，它负责完成操作系统的加载：初始化栈和堆区，为 main() 传递参数等等。&lt;/p&gt;
&lt;h2 id=&#34;code-firmware&#34;&gt;Code: Firmware&lt;/h2&gt;
&lt;p&gt;QEMU 是一个全系统模拟器，我们可以通过 GDB 远程连接的方式来调试 QEMU，从而观测各个时刻的系统状态。&lt;/p&gt;
&lt;p&gt;一个启动 QEMU 并使用 GDB 监听的脚本如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

qemu-system-x86_64 \
  -smp 1\
  -S -s\
  -drive format=raw,file=amgame-x86_64-qemu &amp;amp;
pid=$!

gdb -x remote.gdb ; kill -9 $!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;qemu-system-x86_64&lt;/code&gt; 启动了一个 x86-64 架构的 QEMU 模拟器，之后的各个选项和参数的意义如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-smp 1&lt;/code&gt; 指定了 QEMU 模拟单核 CPU。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-S&lt;/code&gt; 选项表示让 QEMU 停止在 CPU reset 后的第一条指令上。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-s&lt;/code&gt; 选项是 &lt;code&gt;-gdb tcp::1234&lt;/code&gt; 的简写，表示在端口 1234 打开一个 gdbserver。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-drive format=raw,file=amgame-x86_64-qemu&lt;/code&gt; 告诉了 QEMU 用于引导的设备。这里笔者使用了 Lab0 中 amgame 的镜像。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;gdb 的 &lt;code&gt;-x&lt;/code&gt; 选项后面可以跟一个脚本，表示在启动 gdb 之后自动运行后面的脚本。笔者在脚本中只做了一行配置：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;target remote localhost:1234
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;表示连接到 gdbserver。之前我们给运行 QEMU 的进程分配了一个进程号，现在用 &lt;code&gt;kill -9 $!&lt;/code&gt; 可以在退出 gdb 之后帮我们自动杀死 QEMU 的进程。&lt;/p&gt;
&lt;p&gt;运行这个脚本，我们可以看到 QEMU 停在了 CPU reset 后的初始状态。使用 &lt;code&gt;i r&lt;/code&gt; 命令打印寄存器信息，可以看到 &lt;code&gt;rip = 0xfff0&lt;/code&gt;，&lt;code&gt;eflags = 0x2&lt;/code&gt; 等，符合手册的约定。此时如果使用命令 &lt;code&gt;x/16xb 0x7c00&lt;/code&gt; 查看地址 0x7c00 附近的内存内容，可以看到全部是 0 (注：&lt;code&gt;x&lt;/code&gt; 是打印，&lt;code&gt;16&lt;/code&gt; 是打印 16 个 byte，&lt;code&gt;x&lt;/code&gt; 是按照十六进制打印，&lt;code&gt;b&lt;/code&gt; 是将各个 byte 分开)。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0x7c00:	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00
0x7c08:	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;想要监控 BIOS 的行为，我们可以用命令 &lt;code&gt;wa *0x7c00&lt;/code&gt; 在这个地址上打一个断点，然后 continue，该地址的值出现变化时 GDB 会停下并通知我们。&lt;/p&gt;
&lt;p&gt;当前系统仍处于 16 位模式，因此需要用 cs 和 rip 两个寄存器来定位指令的位置。使用 &lt;code&gt;x/i ($cs * 16 + $rip)&lt;/code&gt; 查看当前指令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0xfa591:	rep insl (%dx),%es:(%edi)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这是一条内存拷贝指令，刚开始可以看到 &lt;code&gt;%es:(%edi) == 0x7c00&lt;/code&gt; ，随着 repeat 的推进，&lt;code&gt;(%edi)&lt;/code&gt; 的值逐渐变大。如果再查看 0x7c00 附近的内容，可以看到 MBR 正在被逐渐搬入：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0x7c00:	0xfa	0x31	0xc0	0x8e	0xd8	0x8e	0xc0	0x8e
0x7c08:	0xd0	0xb8	0x01	0x4f	0xb9	0x12	0x01	0xbf
0x7c10:	0x00	0x40	0xcd	0x10	0x00	0x00	0x00	0x00
0x7c18:	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;state-machine-of-os&#34;&gt;State Machine of OS&lt;/h2&gt;
&lt;p&gt;Firmware 和 boot loader 共同完成了操作系统的加载。进入 C 代码后，操作系统将完全遵循 C 语言的形式语义（当然，调用 AbstractMachine API 的部分是对 C 语言形式语义的补充）。&lt;/p&gt;
&lt;p&gt;AbstractMachine 对 C 程序语义的扩展主要是以下几个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TRM + MPE
&lt;ul&gt;
&lt;li&gt;完全等同于多线程。将整个系统的状态机从一条链变成多条链，之后的执行将是 non-deterministic 的。&lt;/li&gt;
&lt;li&gt;IOE API 相当于库函数。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CTE
&lt;ul&gt;
&lt;li&gt;允许创建多个执行流。&lt;/li&gt;
&lt;li&gt;yield() 会主动切换，中断会被动切换。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;VME
&lt;ul&gt;
&lt;li&gt;创建一个“经过地址翻译的执行模式”。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;整个系统的状态机大致可以看成如下过程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://kristoff-starling.github.io/img/njuos-lec09.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;code-abstractmachine&#34;&gt;Code: AbstractMachine&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Unix Philosophy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Makefile 中的变量的定义可能散落在世界各处，因此静态地读 Makefile 效果可能不好。好的方式是直接观测 Makefile 做了怎样的事情。这里提供一套命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make mainargs=HelloOS run -nB \
| grep -ve &#39;^\(\#\|echo\|mkdir\|make\)&#39; \
| sed &amp;quot;s#$AM_HOME#\$AM_HOME#g&amp;quot; \
| sed &amp;quot;s#$PWD#.#g&amp;quot; \
| vim -
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;make 的 &lt;code&gt;-n&lt;/code&gt; 选项可以只输出执行的命令而不真正执行，&lt;code&gt;-B&lt;/code&gt; 选项可以忽略已经编译好的内容从头编译。&lt;/li&gt;
&lt;li&gt;grep 用于筛选，&lt;code&gt;-v&lt;/code&gt; 选项表示反向筛选，&lt;code&gt;-e&lt;/code&gt; 表示使用正则表达式匹配。&lt;/li&gt;
&lt;li&gt;sed 可以作替换，这里将冗长的路径名替换成了短的。&lt;/li&gt;
&lt;li&gt;vim - 命令可以将输出导入到 vim 中查看。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 vim 中使用 &lt;code&gt;:%s/ /\r  /g&lt;/code&gt; 可以将空格改为换行，从而提高可读性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;通过观察 Makefile 的输出结果，我们可以看到它是如何创建镜像文件以及传输命令行参数的：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;( cat $AM_HOME/am/src/x86/qemu/boot/bootblock.o;
  head -c 1024 /dev/zero; 
  cat ./build/threados-x86_64-qemu.elf )
&amp;gt; ./build/threados-x86_64-qemu
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;bootblock.o&lt;/code&gt; 是主引导记录。&lt;code&gt;head -c 1024 /dev/zero&lt;/code&gt; 取出了 1024B 的 \0。&lt;code&gt;threados-x86_64-qemu.elf&lt;/code&gt; 是我们之前编译、链接得到的 elf 文件。将这三者拼接起来输出到文件 &lt;code&gt;threados-x86_64-qemu&lt;/code&gt; 中，就制作好了镜像文件。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;( echo -n HelloOS; ) | dd if=/dev/stdin of=./build/threados-x86_64-qemu 
 bs=512 count=2 seek=1 conv=notrunc status=none
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;参数 HelloOS 被输出后，dd 指定 input file 为 stdin，output file 为我们刚刚制作的镜像，将参数写到了第二个扇区里 (即 MBR 后面紧跟着的扇区)。&lt;/p&gt;
&lt;p&gt;之前我们用 GDB 调试了固件将 MBR 加载到 0x7c00 的过程，现在我们可以继续用 GDB 调试 OS booter 的运行过程。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;没有 OS booter 的符号表怎么办？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;仔细阅读 AbstractMachine 的 Makefile，我们发现 &lt;code&gt;bootblock.o&lt;/code&gt; 就是主引导记录，它的生成过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;gcc -static -m32 -fno-pic -g -Os -nostdlib -Ttext 0x7c00 -I$AM_HOME/am/src -o bootblock.o start.S main.c&lt;/code&gt;，该命令编译 &lt;code&gt;am/src/x86/qemu/boot/&lt;/code&gt; 目录下的 &lt;code&gt;main.c&lt;/code&gt; 和 &lt;code&gt;start.S&lt;/code&gt; 并链接成一个 &lt;code&gt;bootblock.o&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;为了生成带有调试信息的二进制文件，我们应当加入 &lt;code&gt;-g&lt;/code&gt; 选项。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;python genboot.py bootblock.o&lt;/code&gt; 对 &lt;code&gt;bootblock.o&lt;/code&gt; 做了进一步的修改，阅读 &lt;code&gt;genboot.py&lt;/code&gt; ：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os, sys, pathlib, subprocess

f = pathlib.Path(sys.argv[1])
try:
    objcopy = os.getenv(&#39;CROSS_COMPILE&#39;, &#39;&#39;) + &#39;objcopy&#39;
    data = subprocess.run(
        [objcopy, &#39;-S&#39;, &#39;-O&#39;, &#39;binary&#39;, &#39;-j&#39;, &#39;.text&#39;, f, &#39;/dev/stdout&#39;],
        capture_output=True).stdout
    assert len(data) &amp;lt;= 510
    data += b&#39;\0&#39; * (510 - len(data)) + b&#39;\x55\xaa&#39;
    f.write_bytes(data)
except:
    f.unlink()
    raise
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它的主要工作是用 objcopy 工具将 &lt;code&gt;bootblock.o&lt;/code&gt; 中的关键内容拷贝出来，&lt;code&gt;-S&lt;/code&gt; 选项表示丢弃重定位信息，符号信息，调试信息等不需要的内容；&lt;code&gt;-j .text&lt;/code&gt; 表示只保留代码节。拷贝出来后在字节流的后面补上若干 0，最后加上 0x55aa，以形成一个 MBR。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了获得符号表，笔者做了如下修改：将第一步生成的 &lt;code&gt;bootblock.o&lt;/code&gt; 备份一份重命名为 &lt;code&gt; boot-sym.o&lt;/code&gt; 用于加载符号表，并在 gdb 启动时的自动化脚本中添加：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;symbol-file /path/to/boot-sym.o
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;在 GDB 中打断点 &lt;code&gt;wa ($rip != 0x7c00)&lt;/code&gt; (或者 &lt;code&gt;b _start&lt;/code&gt;) 即可定位到 OS booter。此时机器仍然处于 16 位模式，GDB 不支持 16 位的调试，打印出来的汇编命令会出现错误。我们可以在 &lt;code&gt;$AM_HOME/am/src/x86/qemu/boot/start.S&lt;/code&gt; 中找到对应的指令。可以看到在执行了不多的几条指令后，PC 跳转到了函数 start32。start32 执行了几条简单的指令后跳转到了 load_kernel()。(在 load_kernel() 中终于可以用 layout src 调试了)&lt;/p&gt;
&lt;p&gt;load_kernel() 和 nanos-lite 中的 loader() 功能类似：将 elf 文件中的各个段拷贝到内存的指定地址 0x8000，并跳转到入口函数启动内核。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;Elf32_Ehdr *elf32 = (void *)0x8000;
Elf64_Ehdr *elf64 = (void *)0x8000;
int is_ap = boot_record()-&amp;gt;is_ap;

if (!is_ap) {
    // load argument (string) to memory
    copy_from_disk((void *)MAINARG_ADDR, 1024, -1024);
    // load elf header to memory
    copy_from_disk(elf32, 4096, 0);
    if (elf32-&amp;gt;e_machine == EM_X86_64) {
      load_elf64(elf64);
    } else {
      load_elf32(elf32);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这段代码调用 copy_from_disk() 将 mainargs 以及 elf 文件从 disk 中拷贝出来，再调用 load_elf() 将其加载到 0x8000 位置。在执行 if 之前通过 &lt;code&gt;p *elf64&lt;/code&gt; 查看 0x8000 附近的内容，可以看到各个字段全部为空。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(gdb) p *elf64
$1 = {e_ident = &#39;\000&#39; &amp;lt;repeats 15 times&amp;gt;, e_type = 0, e_machine = 0,
  e_version = 0, e_entry = 0, e_phoff = 0, e_shoff = 0, e_flags = 0,
  e_ehsize = 0, e_phentsize = 0, e_phnum = 0, e_shentsize = 0, e_shnum = 0,
  e_shstrndx = 0}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;static void load_program(uint32_t filesz, uint32_t memsz, uint32_t paddr, uint32_t offset) {
  copy_from_disk((void *)paddr, filesz, offset);
  char *bss = (void *)(paddr + filesz);
  for (uint32_t i = filesz; i != memsz; i++) {
    *bss++ = 0;
  }
}

static void load_elf64(Elf64_Ehdr *elf) {
  Elf64_Phdr *ph = (Elf64_Phdr *)((char *)elf + elf-&amp;gt;e_phoff);
  for (int i = 0; i &amp;lt; elf-&amp;gt;e_phnum; i++, ph++) {
    load_program(
      (uint32_t)ph-&amp;gt;p_filesz,
      (uint32_t)ph-&amp;gt;p_memsz,
      (uint32_t)ph-&amp;gt;p_paddr,
      (uint32_t)ph-&amp;gt;p_offset
    );
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;load_elf() 根据 elf 文件的 program header 调用 load_program() 将各个段加载到内存中。load_program() 中的一个小细节是：filesz 和 memsz 的差值是 elf 为 .bss 节预留的空位，根据 C 程序的约定，操作系统有义务将其填充为 0。&lt;/p&gt;
&lt;p&gt;执行完 load_elf() 后，再查看 0x8000 附近的内存，可以看到已经被填上了内容：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;(gdb) p *elf64
$1 = {e_ident = &amp;quot;\177ELF\002\001\001\000\000\000\000\000\000\000\000&amp;quot;,
  e_type = 2, e_machine = 62, e_version = 1, e_entry = 1049360, e_phoff = 64,
  e_shoff = 152256, e_flags = 0, e_ehsize = 64, e_phentsize = 56, e_phnum = 2,
  e_shentsize = 64, e_shnum = 17, e_shstrndx = 16}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;if (elf32-&amp;gt;e_machine == EM_X86_64) {
  ((void(*)())(uint32_t)elf64-&amp;gt;e_entry)();
} else {
  ((void(*)())(uint32_t)elf32-&amp;gt;e_entry)();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后这两行，根据架构跳转到 elf 文件中 e_entry 所保存的入口函数地址。这里使用了 C 语言的技巧，将一个地址强制转换成一个函数指针并调用从而实现跳转。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 10: Application of State Machines</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec10/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec10/</guid>
      <description>&lt;h2 id=&#34;compilers-and-modern-cpu&#34;&gt;Compilers and Modern CPU&lt;/h2&gt;
&lt;p&gt;编译器的作用是将源代码状态机 $S$ 转换为二进制代码状态机 $C$：$C=Compile(S)$。只要两者的可观测行为严格一致，编译器可以随意修改指令执行的顺序，甚至修改指令内容。&lt;/p&gt;
&lt;p&gt;现代 CPU 本质上也是“编译器”：只要保证硬件状态机的可观测行为一致，它可以乱序执行，可以多发射，还可以将没有依赖关系的指令“并行”地执行，这就是指令级并行 (instruction level parallelism, ilp)。我们可以用一个例子感受超标量处理器 (CPI&amp;lt;1，平均每条指令所需的时钟周期小于 1) 的威力：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;time.h&amp;gt;

#define LOOP 1000000000ul

__attribute__((noinline)) void loop() {
  for (long i = 0; i &amp;lt; LOOP; i++) {
    asm volatile(
      &amp;quot;mov $1, %%rax;&amp;quot;
      &amp;quot;mov $1, %%rdi;&amp;quot;
      &amp;quot;mov $1, %%rsi;&amp;quot;
      &amp;quot;mov $1, %%rdx;&amp;quot;
      &amp;quot;mov $1, %%rcx;&amp;quot;
      &amp;quot;mov $1, %%r10;&amp;quot;
      &amp;quot;mov $1, %%r8;&amp;quot;
      &amp;quot;mov $1, %%r9;&amp;quot;
    :::&amp;quot;rax&amp;quot;, &amp;quot;rdi&amp;quot;, &amp;quot;rsi&amp;quot;, &amp;quot;rdx&amp;quot;, &amp;quot;rcx&amp;quot;, &amp;quot;r10&amp;quot;, &amp;quot;r8&amp;quot;, &amp;quot;r9&amp;quot;);
  }
}

int main() {
  clock_t st = clock();
  loop();
  clock_t ed = clock();
  double inst = LOOP * (8 + 2) / 1000000000;
  double ips = inst / ((ed - st) * 1.0 / CLOCKS_PER_SEC);
  printf(&amp;quot;%.2lfG instructions/s\n&amp;quot;, ips);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该代码的逻辑是在 loop() 中执行 8 条互相没有依赖的指令。即使使用最激进的优化，一次循环至少还有更新循环变量和跳转两条指令，因此一次循环至少 10 条指令。通过计算执行时间和指令条数来估算每秒钟可以执行的指令数。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Maybe a bug in GCC?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如下代码理论上也可以达到相同的效果。它将变量 i 绑定到寄存器 %rbx 上，从而确保和下面 8 条指令互不冲突。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;register volatile long i asm(&amp;quot;rbx&amp;quot;);
for (long i = 0; i &amp;lt; LOOP; i++) {
 asm volatile(
    &amp;quot;mov $1, %rax;&amp;quot;
    &amp;quot;mov $1, %rdi;&amp;quot;
    &amp;quot;mov $1, %rsi;&amp;quot;
    &amp;quot;mov $1, %rdx;&amp;quot;
    &amp;quot;mov $1, %rcx;&amp;quot;
    &amp;quot;mov $1, %r10;&amp;quot;
    &amp;quot;mov $1, %r8;&amp;quot;fang shi |
    &amp;quot;mov $1, %r9;&amp;quot;
 );
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但事实上，编译完成后使用反汇编查看，可以看到 $i$ 被绑定到了 %rax 上。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;笔者使用的计算机 CPU 型号如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Intel® Core™ i7-10710U CPU @ 1.10GHz × 12
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但运行该程序可以得到每秒钟能执行约 17G 条指令，CPI 远小于 1。这就是指令级并行的威力。&lt;/p&gt;
&lt;h2 id=&#34;tracer&#34;&gt;Tracer&lt;/h2&gt;
&lt;p&gt;我们总是希望可以在状态机执行的过程中观测状态机的行为，比如了解所有 system call 的执行时长，在某个状态停下来查看寄存器，PC 的值等等，于是我们有了 strace/gdb 等工具。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Shell 命令：strace&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在 strace 后加上 &lt;code&gt;-T&lt;/code&gt; 选项即可看到执行某个程序过程中所有系统调用的耗时。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们平时使用 GDB 通常是 step/next/stepi/watchpoint，但基于状态机思想， GDB 可以实现更多炫酷的功能。比如我们可以给某个状态打快照，下次可以直接从快照状态开始执行。再比如我们可以实现反向执行。&lt;/p&gt;
&lt;h3 id=&#34;time-travel-debugging&#34;&gt;Time-Travel Debugging&lt;/h3&gt;
&lt;p&gt;让 GDB 实现回退的功能，最直观的想法是保存每个时刻的快照。但运行时刻太多，快照要保存的内容也太多，这样做代价太大。&lt;/p&gt;
&lt;p&gt;事实上，一条指令对状态机的影响很有限：它可能只能改变很少的几个寄存器的值或者几个内存地址的值。因此我们可以记录一个初始的状态机，和每条指令执行前后状态机的 diff。这样代价就小得多。想要实现回退，我们只要将增量撤销即可。&lt;/p&gt;
&lt;p&gt;GDB 的回退和重放功能对一些 non-deterministic 的程序的调试极其有力。比如如下的程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// rdrand.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;

int main() {
  uint64_t volatile val = 48;
  asm volatile (&amp;quot;rdrand %0&amp;quot;: &amp;quot;=r&amp;quot;(val));
  printf(&amp;quot;rdrand returns %016lx\n&amp;quot;, val);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;rdrand 指令会生成一个随机数，从而使程序每次运行的结果无法预测。打开 GDB 后，使用 &lt;code&gt;record full&lt;/code&gt; 命令打开记录，这样就可以在适当的时刻使用 &lt;code&gt;rsi&lt;/code&gt; / &lt;code&gt;rs&lt;/code&gt; 命令倒退执行，且一旦执行过一次 rdrand 之后，多次倒退回去再执行，变量 val 随机到的值都不会改变。&lt;/p&gt;
&lt;p&gt;注：GDB 的反向执行不是万能的。对于一些比较复杂的指令 (例如一些系统调用)，记录状态机增量比较困难，GDB 没有实现这部分功能。&lt;/p&gt;
&lt;h3 id=&#34;record--replay&#34;&gt;Record &amp;amp; Replay&lt;/h3&gt;
&lt;p&gt;如果我们想要重现一个程序执行的行为，我们只需要记录 non-deterministic 的指令执行完成后的状态机状态—— deterministic 的指令是无需记录的：假设 $s_0$ 执行 10000 条确定指令后到达 $s_1$，那么我们只需要记下 $s_0$ 和 10000 即可重放这段执行。&lt;/p&gt;
&lt;p&gt;对于一个单线程的程序，我们需要记录的非确定事件包括系统调用，rdrand 等非确定指令等。Mozilla 的 rr 工具可以帮助我们记录并重放一个程序的执行过程。这对我们调试一些非确定程序的段错误极其有帮助。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Mozilla 的 rr 工具&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用命令 &lt;code&gt;rr record ./exec&lt;/code&gt; 即可记录运行程序 exec 的整个过程。使用 &lt;code&gt;rr replay&lt;/code&gt; 命令即可重放整个过程。rr 会打开一个 GDB，我们可以自由地打断点并调试之前记录的执行过程。&lt;/p&gt;
&lt;p&gt;rr 工具要求 perf_event_paranoid 的值小于等于 1，可以使用命令&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo sysctl kernel.perf_event_paranoid=1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改当前地 perf_event_paranoid 的值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于一个单处理器的操作系统，我们需要记录的非确定事件包括 I/O 操作，中断等等。有了这些记录我们便可以重放操作系统启动和运行的全过程。&lt;/p&gt;
&lt;h2 id=&#34;profiling&#34;&gt;Profiling&lt;/h2&gt;
&lt;p&gt;想要做好性能优化，我们需要知道时间花在了哪里，什么对象占用了空间……这要求我们对状态机的执行进行真实监测。但我们的监测不能太频繁，不能干扰到程序的正常工作。一个好的思路是每隔一段事件暂停程序，观察并记录状态机的信息，这样便可以得到统计意义的性能摘要。&lt;/p&gt;
&lt;p&gt;Linux perf 工具可以为我们提供一个程序运行的性能报告。以之前的 &lt;code&gt;ilp-demo.c&lt;/code&gt; 为例，输入命令 &lt;code&gt;perf stat ./ilp-demo&lt;/code&gt;，我们可以得到如下的精简报告，其中包括了上下文切换，缺页异常分支预测等多种信息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Performance counter stats for &#39;./ilp-demo&#39;:

              0.56 msec task-clock                #    0.449 CPUs utilized          
                 0      context-switches          #    0.000 K/sec                  
                 0      cpu-migrations            #    0.000 K/sec                  
                55      page-faults               #    0.098 M/sec                  
           975,780      cycles                    #    1.731 GHz                    
           751,657      instructions              #    0.77  insn per cycle         
           146,602      branches                  #  260.113 M/sec                  
             5,119      branch-misses             #    3.49% of all branches        

       0.001255936 seconds time elapsed

       0.001289000 seconds user
       0.000000000 seconds sys
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们还可以使用 &lt;code&gt;perf recode ./exec&lt;/code&gt; 和 &lt;code&gt;perf report&lt;/code&gt; 查看详细的报告。&lt;/p&gt;
&lt;p&gt;实际工程中的大部分情况满足“二八定律”：80%的时间消耗在非常集中的几处代码。因此用好 profiling 工具，有的放矢进行优化才是科学的方式。&lt;/p&gt;
&lt;h2 id=&#34;model-checker&#34;&gt;Model Checker&lt;/h2&gt;
&lt;p&gt;我们之前使用 model checker 检查并发 bug。事实上 model checker 可以检查更多我们想要的东西。比如如下程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;u32 x = rdrand();
u32 y = rdrand();
if (x &amp;gt; y)
  if (x * x + y * y == 65)
    bug();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们想知道理论上 bug 是否可能会被触发。一个朴素的想法是对每种 x 和 y 的可能取值建立状态，但这样状态会太多，无法检查。更高效的 model checker 会将相似状态“合并”，或者引入符号计算——上述例子中，对于 rdrand()，我们可以给 x，y 赋值 uint32，if 语句的约束条件也一并写入状态机，最后调用约束求解器 (SMT Solver) 即可检查 bug 是否会被触发。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 11: Processes in Operating Systems</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec11/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec11/</guid>
      <description>&lt;p&gt;在 &lt;code&gt;thread-os.c&lt;/code&gt; 中，操作系统启动后会初始化若干个线程 (的状态机)，或者说加载若干个程序。真正的操作系统启动后会创建第一个进程。如果查看 Linux 的源码，我们可以看到：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;if (!try_to_run_init_process(&amp;quot;/sbin/init&amp;quot;) ||
	    !try_to_run_init_process(&amp;quot;/etc/init&amp;quot;) ||
	    !try_to_run_init_process(&amp;quot;/bin/init&amp;quot;) ||
	    !try_to_run_init_process(&amp;quot;/bin/sh&amp;quot;))
		return 0;
panic(&amp;quot;No working init found.  Try passing init= option to kernel. &amp;quot;
	      &amp;quot;See Linux Documentation/admin-guide/init.rst for guidance.&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;内核会按照一个特定的顺序加载“第一个程序”，如果都无法加载，Linux kernel 会直接拒绝启动。&lt;/p&gt;
&lt;h2 id=&#34;a-minimal-linux&#34;&gt;A Minimal Linux&lt;/h2&gt;
&lt;p&gt;我们可以在 qemu 上调试 vmlinuz 内核。如下命令会启动一个没有图形界面，128M 内存的 linux 内核：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;qemu-system-x86_64 \
	  -nographic \
	  -serial mon:stdio \
	  -m 128 \
	  -kernel vmlinuz \
	  -initrd build/initramfs.cpio.gz \
	  -append &amp;quot;console=ttyS0 quiet acpi=off&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 &lt;code&gt;initramfs.cpio.gz&lt;/code&gt; 是内核启动时存放在内存中的一个很小的文件系统的镜像，它打包了如下目录结构中地 initramfs 中的内容。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;├── initramfs
│   ├── bin
│   │   └── busybox
│   └── init
├── Makefile
└── vmlinuz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;启动内核后我们会得到一个 shell，当前的环境很简陋，但我们仍然可以用 &lt;code&gt;/bin/busybox 命令&lt;/code&gt; 的方式使用一些 busybox 内置的命令，比如 ls 和 cat。&lt;/p&gt;
&lt;p&gt;操作系统启动的第一个进程是 init。init 是一个脚本，有一行命令：&lt;code&gt;/bin/busybox sh&lt;/code&gt;，它启动一个 shell。我们可以试试将 &lt;code&gt;/bin/busybox sh&lt;/code&gt; 换成 &lt;code&gt;/bin/busybox echo hello&lt;/code&gt;：可以看到操作系统确实打印了 hello，但随即报了 kernel panic。这是因为初始进程 init 返回了。&lt;/p&gt;
&lt;p&gt;尽管现在的环境很简陋，但我们执行一些简单的代码就可以获得丰富的体验：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;c1=&amp;quot;arch ash base64 cat chattr chgrp chmod chown conspy cp cpio cttyhack date dd df dmesg dnsdomainname dumpkmap echo ed egrep false fatattr fdflush fgrep fsync getopt grep gunzip gzip hostname hush ionice iostat ipcalc kbd_mode kill link linux32 linux64 ln login ls lsattr lzop makemime mkdir mknod mktemp more mount mountpoint mpstat mt mv netstat nice nuke pidof ping ping6 pipe_progress printenv ps pwd reformime resume rev rm rmdir rpm run-parts scriptreplay sed setarch setpriv setserial sh sleep stat stty su sync tar touch true umount uname usleep vi watch zcat&amp;quot;
c2=&amp;quot;[ [[ awk basename bc beep blkdiscard bunzip2 bzcat bzip2 cal chpst chrt chvt cksum clear cmp comm crontab cryptpw cut dc deallocvt diff dirname dos2unix dpkg dpkg-deb du dumpleases eject env envdir envuidgid expand expr factor fallocate fgconsole find flock fold free ftpget ftpput fuser groups hd head hexdump hexedit hostid id install ipcrm ipcs killall last less logger logname lpq lpr lsof lspci lsscsi lsusb lzcat lzma man md5sum mesg microcom mkfifo mkpasswd nc nl nmeter nohup nproc nsenter nslookup od openvt passwd paste patch pgrep pkill pmap printf pscan&amp;quot;
c3=&amp;quot;pstree pwdx readlink realpath renice reset resize rpm2cpio runsv runsvdir rx script seq setfattr setkeycodes setsid setuidgid sha1sum sha256sum sha3sum sha512sum showkey shred shuf smemcap softlimit sort split ssl_client strings sum sv svc svok tac tail taskset tcpsvd tee telnet test tftp time timeout top tr traceroute traceroute6 truncate ts tty ttysize udhcpc6 udpsvd unexpand uniq unix2dos unlink unlzma unshare unxz unzip uptime users uudecode uuencode vlock volname w wall wc wget which who whoami whois xargs xxd xz xzcat yes&amp;quot;
for cmd in $c1 $c2 $c3; do
  /bin/busybox ln -s /bin/busybox /bin/$cmd
done
mkdir -p /proc &amp;amp;&amp;amp; mount -t proc  none /proc
mkdir -p /sys  &amp;amp;&amp;amp; mount -t sysfs none /sys
export PS1=&#39;(linux) &#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在我们可以直接使用命令不再需要加 /bin/busybox 的前缀 (得益于代码中的软链接)，我们还挂载了 procfs 和 sysfs。可以使用 ps 等命令查看进程。此外，我们可以运行任何放入到文件系统中的程序：例如之前的示例代码 &lt;code&gt;minimal.S&lt;/code&gt; 和 &lt;code&gt;logisim.c&lt;/code&gt;，只要是静态链接得到的可执行文件都可以在我们的 minimal Linux 中直接运行。&lt;/p&gt;
&lt;p&gt;这一切说明操作系统没有什么神秘的：**内核创建了第一个进程 init，然后这个进程通过各种各样的系统调用就能创造全世界。**完成一切以后操作系统将退到幕后成为一个“中断处理程序”。此外，操作系统为应用程序提供各类 API，让应用程序创建/管理进程，地址空间，文件系统等。&lt;/p&gt;
&lt;h2 id=&#34;fork&#34;&gt;fork()&lt;/h2&gt;
&lt;p&gt;fork() 的含义非常简单：它会将当前进程的状态机完全复制一遍，作为当前进程的子进程。这两个进程几乎完全一样：相同的地址空间，相同的寄存器值…… (当然，进程号是不同的)，除了 fork() 的返回值在两个进程中不同：fork() 在父进程中返回子进程的进程号，在子进程中返回 0。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Fork Bomb&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;状态机的复制也需要消耗一定的资源。如下的一段代码可以让 OS 崩溃：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;:() { :|:&amp;amp; };:
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;将其格式化后可以看出它的原理：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;:() {
 : | : &amp;amp;
}; :
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;bash 允许冒号作为标识符。: 这个函数的作用是用 fork 创建两个自己，用管道连接起来，然后放到后台执行。这样这个脚本就会像链式反应一样不断生成很多函数，直至系统资源耗尽。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;example-fork-democ&#34;&gt;Example: &lt;code&gt;fork-demo.c&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// fork-demo.c
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;

int main() {
  pid_t pid1 = fork();
  pid_t pid2 = fork();
  pid_t pid3 = fork();
  printf(&amp;quot;Hello World from (%d, %d, %d)\n&amp;quot;, pid1, pid2, pid3);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行这段程序，我们可以看到所有的 8 种可能的结果：进程号是 0 / 真实值。我们可以画出状态机中的一条路径来理解这个输出 (即不考虑多个进程时程序的 non-deterministic 行为，总是挑选可以继续执行的进程号最小的进程走下一步)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://kristoff-starling.github.io/img/njuos-lec11.png&#34; alt=&#34;pic&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;example-fork-printfc&#34;&gt;Example: &lt;code&gt;fork-printf.c&lt;/code&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// fork-printf.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/wait.h&amp;gt;

int main(int argc, char *argv[]) {
  int n = 2;
  for (int i = 0; i &amp;lt; n; i++) {
    fork();
    printf(&amp;quot;Hello\n&amp;quot;);
  }
  for (int i = 0; i &amp;lt; n; i++) {
    wait(NULL);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从抽象的状态机的角度分析，刚开始只有一个进程，第一轮一个进程变成两个进程，并分别打印 hello；第二轮两个进程变成 4 个进程，并分别打印 hello，最后应该总共有 6 个 hello。&lt;/p&gt;
&lt;p&gt;运行该程序可以看到，终端上确实输出了 6 个 hello，但诡异的事情是：如果我们用管道或者重定向到文件的方式，都会得到 8 个 hello。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./fork-printf | cat    # 8个hello
./fork-printf &amp;gt; output # 8个hello
./fork-printf | wc -l  # 8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这件“诡异”的事情和 printf 的缓冲区有关。我们认为 printf 的语义是立即输出给定的字符串，但 printf 为了性能考虑 (尽可能少地与 io 交互)，会设置 buffer，将要输出的内容先预留在 buffer 中，待 buffer 满了 / 进程结束时再将 buffer 中的内容一并输出。&lt;/p&gt;
&lt;p&gt;printf 根据标准输出指向的文件不同会使用不同的 buffer。当 stdout 是 tty 时，printf 使用 line buffer，即遇到换行符会清空一次 buffer，所以当我们输出到终端时看到的结果是 6 个；当 stdout 是管道或者文件时，printf 使用 full buffer，只有 buffer 满了才会清空。在这种情况下，第一轮的两个进程不会输出 hello，而是会将 hello 保存在 buffer 中，第二轮两个进程变 4 个进程时，fork() 复制状态机，当然也会复制 buffer 里的内容，因此新生成的两个进程的 buffer 里自带一个 hello，再执行 printf 后，每个进程的 buffer 里都有两个 hello。进程结束时内核清空 buffer，于是 4 个进程每个打印两个 hello，最终有 8 个 hello。&lt;/p&gt;
&lt;p&gt;如果我们在程序开头加一句 &lt;code&gt;setbuf(stdout, NULL)&lt;/code&gt;，指定 stdout 不使用 buffer，或者在 printf() 之后加 &lt;code&gt;ffush(stdout)&lt;/code&gt; ，那么各种情况下我们都会得到 6 个 hello。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip: setbuf()&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;setbuf() 函数可以指定向某个文件输出时使用的 buffer。与之相关的还有 setvbuf() （可以用 &lt;code&gt;_IONBF&lt;/code&gt;  &lt;code&gt;_IOLBF&lt;/code&gt; &lt;code&gt;_IOFBF&lt;/code&gt; 制定无缓冲、行缓冲、全缓冲）等。&lt;/p&gt;
&lt;p&gt;使用 setbuf() 时要小心的一点是我们注册的 buffer 不能在输出流被关闭之前被释放，例如下面的程序就是错误的 (undefined behavior)：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int main ()
{
    char buf[64];
    setbuf(stdout, buf);
    printf(&amp;quot;Hello, world\n&amp;quot;);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;计算机系统里没有魔法。机器永远是对的。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;execve&#34;&gt;execve()&lt;/h2&gt;
&lt;p&gt;execve() 的作用是重置一个状态机，运行 execve() 的参数中所写的程序。如果该系统调用执行成功，它不会返回，它后面的指令也不会被执行。结合运用 fork() 和 execve()，我们便可以创建新的状态机并运行新的程序。execve() 的声明如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int execve(const char *filename, char * const argv, char * const envp);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 filename 为想要加载的程序，argv 为传给新程序入口函数的参数，envp 为环境变量列表。下面是一个简单的示例程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// execve-demo.c
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;

int main() {
  char * const argv[] = {
    &amp;quot;/bin/bash&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;env&amp;quot;, NULL,
  };
  char * const envp[] = {
    &amp;quot;HELLO=WORLD&amp;quot;, NULL,
  };
  execve(argv[0], argv, envp);
  printf(&amp;quot;Should not reach here!\n&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它使用 execve() 执行了命令 &lt;code&gt;/bin/bash -c env&lt;/code&gt; 来打印环境变量。运行该程序，我们可以看到我们指定的环境变量 HELLO=WORLD 被打印，且 &amp;ldquo;should not reach here&amp;rdquo; 没有被打印。&lt;/p&gt;
&lt;p&gt;系统中有很多有意思的环境变量。例如我们可以配置 &lt;code&gt;$AM_HOME&lt;/code&gt; 来简写目录；bash 中的环境变量 PS1 决定了命令行提示符长什么样子；execvp()/gcc 等会根据 &lt;code&gt;$PATH&lt;/code&gt; 中的目录一个一个去找有没有我们指定的程序 etc。我们可以 hack 这个行为：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;PATH= /bin/gcc program.c
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;便会看到&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc: fatal error: cannot execute ‘as’: execvp: No such file or directory
compilation terminated.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;_exit&#34;&gt;_exit()&lt;/h2&gt;
&lt;p&gt;exit() 用于销毁一个状态机。&lt;code&gt;_exit(int status)&lt;/code&gt; 会销毁当前状态机，并允许有一个返回值。子进程被销毁了会通知父进程。这其中有一些值得思考的问题，例如如果这是一个多线程程序，exit() 应当销毁当前的线程还是当前的进程？&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// exit-demo.c
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;time.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;

void func() {
  printf(&amp;quot;Goodbye, Cruel OS World!\n&amp;quot;);
}

int main(int argc, char *argv[]) {
  atexit(func);
  setvbuf(stdout, NULL, _IOFBF, 1024);
  printf(&amp;quot;Unflushed Buffer\n&amp;quot;);

  if (argc &amp;lt; 2) return EXIT_FAILURE;

  if (strcmp(argv[1], &amp;quot;exit&amp;quot;) == 0)
    exit(0);
  if (strcmp(argv[1], &amp;quot;_exit&amp;quot;) == 0)
    _exit(0);
  if (strcmp(argv[1], &amp;quot;__exit&amp;quot;) == 0)
    syscall(SYS_exit, 0);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;exit-demo.c&lt;/code&gt; 展示了各种不同的 exit 方法行为的不同，其中 atexit() 注册了一个在 exit() 的时候会调用的函数。各种运行方式的结果如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;命令&lt;/th&gt;
&lt;th&gt;执行内容&lt;/th&gt;
&lt;th&gt;系统调用&lt;/th&gt;
&lt;th&gt;是否调用 atexit&lt;/th&gt;
&lt;th&gt;输出内容&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;./exit-demo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;return EXIT_FAILURE&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;exit_group(1)&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;func &amp;amp; buffer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;./exit-demo exit&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;exit(0)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;exit_group(0)&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;func &amp;amp; buffer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;./exit-demo _exit&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;_exit(0)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;exit_group(0)&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;./exit-demo __exit&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;syscall(SYS_exit, 0)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;exit(0)&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;注：C 程序中的 exit(0) 是 &lt;code&gt;stdlib.h&lt;/code&gt; 中的 libc 函数。&lt;/p&gt;
&lt;p&gt;注：exit_group() 系统调用会终止当前进程的所有线程，而 exit() 系统调用只终止当前线程。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 12: Address Space of Processes</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec12/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec12/</guid>
      <description>&lt;h2 id=&#34;address-space&#34;&gt;Address Space&lt;/h2&gt;
&lt;p&gt;在 C 程序中，我们可以用指针访问任何可以访问的东西：比如 main() 函数的首地址，这个地址存储的内容就是 main() 的第一条指令。如果我们随便访问一个奇怪的地址，我们会得到段错误；如果我们往 main() 的首地址处写东西，我们也会得到段错误。&lt;/p&gt;
&lt;p&gt;命令行工具 pmap 可以帮助我们观察一个进程的地址空间。我们以最小的程序 &lt;code&gt;minimal.S&lt;/code&gt; 为例，在 GDB 中调试时可以用 &lt;code&gt;info inferiors&lt;/code&gt; 查看进程号，并用 &lt;code&gt;pmap pid&lt;/code&gt; 来查看地址空间：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;0000000000400000      4K r---- a.out
0000000000401000      4K r-x-- a.out
00007ffff7ff9000     16K r----   [ anon ]
00007ffff7ffd000      8K r-x--   [ anon ]
00007ffffffde000    132K rw---   [ stack ]
ffffffffff600000      4K --x--   [ anon ]
 total              168K
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;0x401000 之后的内容是代码段，这一段有可执行的权限。此外我们在栈上有环境变量，命令行参数等。&lt;/p&gt;
&lt;p&gt;我们可以通过 &lt;code&gt;strace pmap pid&lt;/code&gt; 来观察 pmap 是如何实现的。可以看到 pmap 使用了 openat() 系统调用来打开 procfs 中的 &lt;code&gt;/proc/pid/maps&lt;/code&gt; 文件。查看这个文件，我们能看到比 pmap 更丰富的地址空间信息。&lt;/p&gt;
&lt;h3 id=&#34;statically-link&#34;&gt;Statically Link&lt;/h3&gt;
&lt;p&gt;我们尝试查看一个静态链接的二进制文件 (空 main() 函数编译得到) 的地址空间：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;0000000000400000      4K r---- a.out
0000000000401000    560K r-x-- a.out
000000000048d000    160K r---- a.out
00000000004b5000     16K r---- a.out
00000000004b9000     12K rw--- a.out
00000000004bc000    140K rw---   [ anon ]
00007ffff7ff9000     16K r----   [ anon ]
00007ffff7ffd000      8K r-x--   [ anon ]
00007ffffffde000    132K rw---   [ stack ]
ffffffffff600000      4K --x--   [ anon ]
 total             1052K
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到的地址空间的内容更加丰富。第一个段是 ELF header，后面的可读可执行段是代码段，再后面有只读数据段等等。我们可以将其和 ELF 文件的 program header 进行对比：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Program Headers:
  Type           Offset             VirtAddr           PhysAddr
                 FileSiz            MemSiz              Flags  Align
  LOAD           0x0000000000000000 0x0000000000400000 0x0000000000400000
                 0x0000000000000528 0x0000000000000528  R      0x1000
  LOAD           0x0000000000001000 0x0000000000401000 0x0000000000401000
                 0x000000000008bf1d 0x000000000008bf1d  R E    0x1000
  LOAD           0x000000000008d000 0x000000000048d000 0x000000000048d000
                 0x0000000000027315 0x0000000000027315  R      0x1000
  LOAD           0x00000000000b4908 0x00000000004b5908 0x00000000004b5908
                 0x00000000000059e8 0x00000000000072b8  RW     0x1000 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到地址和权限都能对应上。计算机系统的世界里没有魔法。&lt;/p&gt;
&lt;h3 id=&#34;dynamically-link&#34;&gt;Dynamically Link&lt;/h3&gt;
&lt;p&gt;动态链接的结果会更复杂一些：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;555555554000-555555555000 r--p  103:0a  /home/starling/a.out
555555555000-555555556000 r-xp  103:0a  /home/starling/a.out
555555556000-555555557000 r--p  103:0a  /home/starling/a.out
555555557000-555555558000 r--p  103:0a  /home/starling/a.out
555555558000-555555559000 rw-p  103:0a  /home/starling/a.out
7ffff7dbe000-7ffff7dc0000 rw-p  00:00 0  // ???
7ffff7dc0000-7ffff7de6000 r--p  103:09  /usr/lib/x86_64-linux-gnu/libc-2.33.so
7ffff7de6000-7ffff7f51000 r-xp  103:09  /usr/lib/x86_64-linux-gnu/libc-2.33.so
7ffff7f51000-7ffff7f9d000 r--p  103:09  /usr/lib/x86_64-linux-gnu/libc-2.33.so
7ffff7f9d000-7ffff7fa0000 r--p  103:09  /usr/lib/x86_64-linux-gnu/libc-2.33.so
7ffff7fa0000-7ffff7fa3000 rw-p  103:09  /usr/lib/x86_64-linux-gnu/libc-2.33.so
7ffff7fa3000-7ffff7fae000 rw-p  00:00 0  // ???
7ffff7fc3000-7ffff7fc7000 r--p  00:00 0 [vvar]
7ffff7fc7000-7ffff7fc9000 r-xp  00:00 0 [vdso]
7ffff7fc9000-7ffff7fca000 r--p  103:09  /usr/lib/x86_64-linux-gnu/ld-2.33.so
7ffff7fca000-7ffff7ff1000 r-xp  103:09  /usr/lib/x86_64-linux-gnu/ld-2.33.so
7ffff7ff1000-7ffff7ffb000 r--p  103:09  /usr/lib/x86_64-linux-gnu/ld-2.33.so
7ffff7ffb000-7ffff7ffd000 r--p  103:09  /usr/lib/x86_64-linux-gnu/ld-2.33.so
7ffff7ffd000-7ffff7fff000 rw-p  103:09  /usr/lib/x86_64-linux-gnu/ld-2.33.so
7ffffffde000-7ffffffff000 rw-p  00:00 0 [stack]
ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0 [vsyscall]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们看到多了很多的段，比如 libc 库的段和加载器的段。可以引起我们关注的一个问题是：有两个没有名字的东西是什么？这两个段可读可写不可执行，是否有可能是 bss 段？我们可以做实验验证这一点：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;char ch[1 &amp;lt;&amp;lt; 30];
int main () {}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;再次运行并查看，可以看到没有名字的段变大了很多。再做一次实验：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;char ch[1 &amp;lt;&amp;lt; 30] = {1};
int main () {}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到这次编译变慢了很多，生成的可执行文件非常大。查看地址空间，匿名段上方多了一个很大的段，显然是可读可写数据段，匿名段的大小很小。因此我们可以确定没有名字的段就是 bss 段。&lt;/p&gt;
&lt;p&gt;另外一个有意思的问题是：vvar 段和 vdso 段是什么？&lt;/p&gt;
&lt;p&gt;我们有时候想要执行系统调用，但又不想陷入操作系统内核 (因为这样比较耗时)，vdso 提供了这样一些不陷入内核就可以完成系统调用功能的函数。一个典型的例子是 &lt;code&gt;__vdso_gettimeofday()&lt;/code&gt;。在使用时，我们并不需要加上 &lt;code&gt;__vdso&lt;/code&gt; 的前缀，编译器会自动帮我们链接到 vdso 函数。下面是一个例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// vdso.c
#include &amp;lt;sys/time.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;time.h&amp;gt;

double gettime() {
  struct timeval t;
  gettimeofday(&amp;amp;t, NULL); // trapless system call
  return t.tv_sec + t.tv_usec / 1000000.0;
}

int main() {
  printf(&amp;quot;Time stamp: %ld\n&amp;quot;, time(NULL)); // trapless system call
  double st = gettime();
  sleep(1);
  double ed = gettime();
  printf(&amp;quot;Time: %.6lfs\n&amp;quot;, ed - st);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;vdso.c&lt;/code&gt; 中调用了函数 time() 和 gettimeofday()，它们都不会陷入内核。我们可以用 GDB 调试它并查看汇编代码。我们发现 time() 函数的从一个奇怪的地方搬了一些数过来，这些数就构成了时间：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0x7ffff7fc7c00 &amp;lt;time&amp;gt;:      lea    -0x4b87(%rip),%rax               # 0x7ffff7fc3080
0x7ffff7fc7c07 &amp;lt;time+7&amp;gt;:    lea    -0x1b8e(%rip),%rdx               # 0x7ffff7fc6080
0x7ffff7fc7c0e &amp;lt;time+14&amp;gt;:   cmpl   $0x7fffffff,-0x4b94(%rip)        # 0x7ffff7fc3084
0x7ffff7fc7c18 &amp;lt;time+24&amp;gt;:   cmove  %rdx,%rax
0x7ffff7fc7c1c &amp;lt;time+28&amp;gt;:   mov    0x20(%rax),%rax
0x7ffff7fc7c20 &amp;lt;time+32&amp;gt;:   test   %rdi,%rdi
0x7ffff7fc7c23 &amp;lt;time+35&amp;gt;:   je     0x7ffff7fc7c28 &amp;lt;time+40&amp;gt;
0x7ffff7fc7c25 &amp;lt;time+37&amp;gt;:   mov    %rax,(%rdi)
0x7ffff7fc7c28 &amp;lt;time+40&amp;gt;:   ret 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果我们在 GDB 中直接用 &lt;code&gt;x&lt;/code&gt; 指令打印那个地址，会发现我们无权访问 (GDB 不允许我们访问另一个进程的地址空间)，但对照 &lt;code&gt;/proc/pid/maps&lt;/code&gt; 的结果，我们可以看到 time() 函数在 vdso 段，它所抓取的数据在 vvar 段。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;7ffff7fc3000-7ffff7fc7000 r--p 00000000 00:00 0                          [vvar]
7ffff7fc7000-7ffff7fc9000 r-xp 00000000 00:00 0                          [vdso]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该虚拟系统调用实现的原理不太复杂：操作系统在 vvar 段维护一个大致时间的变量，每过一会儿去更新一下，系统中所有的进程都可以使用 vvar 段的数据。&lt;/p&gt;
&lt;h2 id=&#34;managing-address-space&#34;&gt;Managing Address Space&lt;/h2&gt;
&lt;p&gt;进程的地址空间不是一成不变的，在进程执行过程中可以修改。如果我们用 GDB 调试一个动态链接的程序，用 starti 让其暂停在第一条汇编指令 (此时 PC 在加载器中)，再用 pmap 查看地址空间，可以看到此时只有 .so，还没有 libc 相关的段。但执行到 main() 函数时，地址空间中有了 libc 相关的段。&lt;/p&gt;
&lt;p&gt;增加/删除/修改地址空间需要系统调用的支持。Linux 提供了 mmap() 系统调用添加映射，munmap() 系统调用删除映射，mprotect() 函数修改映射的权限。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void *mmap(void *addr, size_t length, int prot, int flags,
                  int fd, off_t offset);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;手册中有对 mmap() 的详细描述，比如 addr 本身并不指定 mmap() 映射的地址，只会作为一个映射地址的参考；该函数返回的地址是实际映射的地址。有意思的一点是，mmap() 可以直接将文件中的一大块区域映射到地址空间中：事实上文件并不会被立刻搬入内存，而是在使用时才会将要使用的部分搬进来 (缺页异常)。(注：如果不想映射到文件，而只是开辟一段映射空间，可以在 flags 字段使用 MAP_ANONYMOUS，并将 fd 设置为 -1，操作系统会自动将这段填充为 0。)&lt;/p&gt;
&lt;p&gt;有了 mmap() 系统调用以后，操作系统的加载器变得非常好写：我们只需要根据 ELF 文件中所写的需要加载的内容一一调用 mmap() 即可。我们可以用 strace 观测一个程序加载、运行时的所有 mmap() 操作。&lt;/p&gt;
&lt;p&gt;有了文件映射之后，随之而来的是一系列一致性问题：进程对文件的修改是否需要立即生效？不同进程映射到同一个文件应当共享内存还是各自有本地副本？操作系统还提供了 msync() 系统调用处理同步相关的问题。这才是系统真正的复杂性。&lt;/p&gt;
&lt;p&gt;下面是两个 mmap() 的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// mmap-alloc.c
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;

#define GiB * (1024LL * 1024 * 1024)

int main() {
  volatile uint8_t *p = mmap(NULL, 3 GiB, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);
  printf(&amp;quot;mmap: %lx\n&amp;quot;, (uintptr_t)p);
  if ((intptr_t)p == -1) {
    perror(&amp;quot;cannot map&amp;quot;);
    exit(1);
  }
  *(int *)(p + 1 GiB) = 114;
  *(int *)(p + 2 GiB) = 514;
  printf(&amp;quot;Read get: %d\n&amp;quot;, *(int *)(p + 1 GiB));
  printf(&amp;quot;Read get: %d\n&amp;quot;, *(int *)(p + 2 GiB));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们用 mmap() 映射了一点 3G 的内存空间，并在其中某个位置写了东西，并访问这个位置。我们可以看到虽然我们映射了很大的一块空间，但这个系统调用只用了极短的时间 (一些延迟映射相关的技术)。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python3

# mmap-disk.py

import mmap, hexdump

with open(&#39;/dev/sda&#39;, &#39;rb&#39;) as fp:
    mm = mmap.mmap(fp.fileno(), prot=mmap.PROT_READ, length=128 &amp;lt;&amp;lt; 30)
    hexdump.hexdump(mm[:512])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以将整个磁盘映射到地址空间中，并打印第一个扇区的内容，可以看到结尾处标志 MBR 的 0x55aa。&lt;/p&gt;
&lt;h2 id=&#34;isolation-of-address-space&#34;&gt;Isolation of Address Space&lt;/h2&gt;
&lt;p&gt;虚拟内存机制为我们提供了内存隔离：每个进程只能在自己的地址空间映射中做事，访问别的进程的地址会触发段错误，或者说，在本地的地址空间中根本看不到别的进程的地址。（真的吗？）&lt;/p&gt;
&lt;h3 id=&#34;jinshan-drifter&#34;&gt;Jinshan Drifter&lt;/h3&gt;
&lt;p&gt;在访问检查不严格的程序中，其他进程有办法可以侵入，读取和修改数据。这里展示一个类似于“金山游侠”的红警外挂程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;stdbool.h&amp;gt;

#define LENGTH(arr)  (sizeof(arr) / sizeof(arr[0]))

int n, fd, pid;
uint64_t found[4096];
bool reset;

void scan(uint16_t val) {
  uintptr_t start, kb;
  char perm[16];
  FILE *fp = popen(&amp;quot;pmap -x $(pidof dosbox) | tail -n +3&amp;quot;, &amp;quot;r&amp;quot;); assert(fp);

  if (reset) n = 0;
  while (fscanf(fp, &amp;quot;%lx&amp;quot;, &amp;amp;start) == 1 &amp;amp;&amp;amp; (intptr_t)start &amp;gt; 0) {
    assert(fscanf(fp, &amp;quot;%ld%*ld%*ld%s%*[^\n]s&amp;quot;, &amp;amp;kb, perm) &amp;gt;= 1);
    if (perm[1] != &#39;w&#39;) continue;

    uintptr_t size = kb * 1024;
    char *mem = malloc(size); assert(mem);
    assert(lseek(fd, start, SEEK_SET) != (off_t)-1);
    assert(read(fd, mem, size) == size);
    for (int i = 0; i &amp;lt; size; i += 2) {
      uint16_t v = *(uint16_t *)(&amp;amp;mem[i]);
      if (reset) {
        if (val == v &amp;amp;&amp;amp; n &amp;lt; LENGTH(found)) found[n++] = start + i;
      } else {
        for (int j = 0; j &amp;lt; n; j++) {
	      if (found[j] == start + i &amp;amp;&amp;amp; v != val) found[j] = 0;
	    }
      }
    }
    free(mem);
  }
  pclose(fp);

  int s = 0;
  for (int i = 0; i &amp;lt; n; i++) {
    if (found[i] != 0) s++;
  }
  reset = false;
  printf(&amp;quot;There are %d match(es).\n&amp;quot;, s);
}

void overwrite(uint16_t val) {
  int s = 0;
  for (int i = 0; i &amp;lt; n; i++)
    if (found[i] != 0) {
      assert(lseek(fd, found[i], SEEK_SET) != (off_t)-1);
      write(fd, &amp;amp;val, 2);
      s++;
    }
  printf(&amp;quot;%d value(s) written.\n&amp;quot;, s);
}

int main() {
  char buf[32];
  setbuf(stdout, NULL);

  FILE *fp = popen(&amp;quot;pidof dosbox&amp;quot;, &amp;quot;r&amp;quot;);
  assert(fscanf(fp, &amp;quot;%d&amp;quot;, &amp;amp;pid) == 1);
  pclose(fp);

  sprintf(buf, &amp;quot;/proc/%d/mem&amp;quot;, pid);
  fd = open(buf, O_RDWR); assert(fd &amp;gt; 0);

  for (reset = true; !feof(stdin); ) {
    int val;
    printf(&amp;quot;(DOSBox %d) &amp;quot;, pid);
    if (scanf(&amp;quot;%s&amp;quot;, buf) &amp;lt;= 0) { close(fd); exit(0); }
    switch (buf[0]) {
      case &#39;q&#39;: close(fd); exit(0); break;
      case &#39;s&#39;: scanf(&amp;quot;%d&amp;quot;, &amp;amp;val); scan(val); break;
      case &#39;w&#39;: scanf(&amp;quot;%d&amp;quot;, &amp;amp;val); overwrite(val); break;
      case &#39;r&#39;: reset = true; printf(&amp;quot;Search results reset.\n&amp;quot;); break;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;popen() 函数的声明如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;FILE *popen(const char *command, const char *type);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它的作用是创建一个管道，fork 当前进程，并执行 shell 命令 command。type 字段指示了管道的数据流向，“r&amp;quot; 表示当前进程从管道读取 command 的输出，&amp;ldquo;w&amp;rdquo; 表示当前进程通过管道向 command 输出。&lt;/p&gt;
&lt;p&gt;main() 函数的主要工作是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用 popen() 执行命令 &lt;code&gt;pidof dosbox&lt;/code&gt;，获得正在运行的 dosbox 进程的进程号，并用 open() 函数打开该进程下的一个文件 &lt;code&gt;/proc/pid/mem&lt;/code&gt;，获得一个文件描述符 (open() 中的权限要设置为可读可写，因为我们既要读取游戏信息，又要修改数据)。根据 proc 的手册，我们可以通过这个文件访问该进程的地址空间信息。&lt;/li&gt;
&lt;li&gt;不断从 stdin (控制台) 读取用户输入，对于 &lt;code&gt;s val&lt;/code&gt; 型输入，在内存中尝试匹配所有的 val。对于 &lt;code&gt;w val&lt;/code&gt; 型输入，将之前匹配到的所有位置改写为 val。对于 &lt;code&gt;r&lt;/code&gt; ，重置之前的匹配结果，对于 &lt;code&gt;q&lt;/code&gt;，退出外挂程序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;scan() 函数负责在 dosbox 的地址空间中匹配所有的 val，其具体工作是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用 popen() 执行命令 &lt;code&gt;pmap $(pidof dosbox) | tail -n +3&lt;/code&gt;，&lt;code&gt;tail -n +3&lt;/code&gt; 可以指定从 pmap 输出结果的第 3 行开始读取。pmap 输出的第一行通常是进程号，第二行是 ELF 文件头，因此从第 3 行开始处理。&lt;/li&gt;
&lt;li&gt;while () 循环访问 dosbox 地址空间的所有可读可写段 (游戏中值得关注的数据，例如金钱、资源，一定是可以修改的)，访问这些段中的每个地址，看其是否等于 val 并修改 found[] 数组。found[] 数组记录了上一次 reset 以来满足所有匹配结果的地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;overwrite() 函数负责修改数据。它只要将 found[] 中所有地址处的数据改成我们想要的 val 即可。&lt;/p&gt;
&lt;p&gt;这个外挂需要动态使用：外挂刚开始也不知道存储金钱的地址在哪里，但我们可以不断花钱，并拿新的钱的剩余量去 scan，做若干轮之后我们就可以锁定金钱的地址。此时再修改该地址的值，便可以拥有钞能力。&lt;/p&gt;
&lt;h3 id=&#34;pseudo-hardware&#34;&gt;Pseudo-hardware&lt;/h3&gt;
&lt;p&gt;有一些类似 &amp;ldquo;2秒17枪&amp;rdquo; 的外挂可以以人类无法达到的速度大量重复执行任务。这类外挂可以通过写一个驱动模仿假的硬件，或者利用操作系统/窗口管理器的 API 实现。&lt;/p&gt;
&lt;h3 id=&#34;variable-speed-gear&#34;&gt;Variable Speed Gear&lt;/h3&gt;
&lt;p&gt;变速齿轮是另外一类常见的外挂，可以调节游戏的进度 (比如加快动画播放的速度，减小延迟等)。其实现的机制通常和代码注入有关：我们需要找到类似于 gettimeofday() 等时间相关 API 的函数位置，然后改写这部分代码，让它跳转到我们自己编写的函数，这样就可以任意调节时间了。&lt;/p&gt;
&lt;h3 id=&#34;hooking&#34;&gt;Hooking&lt;/h3&gt;
&lt;p&gt;我们不仅可以修改数据，还可以修改代码，这就是代码注入技术 (hooking)。下面是一个简单的给程序打热补丁 (dynamic software update) 的示例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;
#include &amp;lt;stdbool.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;

void foo()     { printf(&amp;quot;In old function %s\n&amp;quot;, __func__); }
void foo_new() { printf(&amp;quot;In new function %s\n&amp;quot;, __func__); }

struct jmp {
  uint32_t opcode: 8;
  int32_t  offset: 32;
} __attribute__((packed));

#define JMP(off) ((struct jmp) { 0xe9, off - sizeof(struct jmp) })
#define PG_SIZE sysconf(_SC_PAGESIZE)

static inline bool within_page(void *addr) {
  return (uintptr_t)addr % PG_SIZE + sizeof(struct jmp) &amp;lt;= PG_SIZE;
}

void DSU(void *old, void *new) {
  void *base = (void *)((uintptr_t)old &amp;amp; ~(PG_SIZE - 1));
  size_t len = PG_SIZE * (within_page(old) ? 1 : 2);
  int flags = PROT_WRITE | PROT_READ | PROT_EXEC;

  printf(&amp;quot;Dynamically updating...\n&amp;quot;); fflush(stdout);

  if (mprotect(base, len, flags) == 0) {
    *(struct jmp *)old = JMP((char *)new - (char *)old); // **PATCH**
    mprotect(base, len, flags &amp;amp; ~PROT_WRITE);
  } else {
    perror(&amp;quot;DSU fail&amp;quot;);
  }
}

int main() {
  foo();
  DSU(foo, foo_new);
  foo();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行这个程序，我们可以看到虽然两次调用的都是 foo()，但在执行过 DSU() 函数打补丁之后，第二次执行 foo() 其实跳转到了 foo_new() 执行。该程序的原理是改写 foo() 函数的第一条指令，在 foo 地址处写一个间接跳转指令跳到 foo_new()。为了实现这点，代码中的细节有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 mprotect() 系统调用修改 foo() 函数所在区域的权限。代码段本身是不可写的，我们要为其加上修改权限。这里的”区域“有一点微妙：如果我们要插入的跳转指令正好横跨了两个页面，则我们需要为连续两个页面开放修改权限。within_page() 函数判断了这一点。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;*(struct jmp *)old = JMP((char *)new - (char *)old);&lt;/code&gt; 是打补丁的核心语句。JMP 宏的原理是写上一个间接跳转的操作码，然后计算两个函数地址的 delta。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;protection&#34;&gt;Protection&lt;/h3&gt;
&lt;p&gt;防外挂的主要方法是保证控制流和数据流的完整性。事实上，大部分外挂都像是游戏程序的“调试器”：它们不断监听游戏状态并修改游戏数据/代码。我们可以对独立的进程/驱动做完整性检验，还可以拦截向本进程的 ReadProcessMemory 和 WriteProcessMemory 请求，发现后立刻拒绝执行并封号。&lt;/p&gt;
&lt;p&gt;其他的一些解决方法包括：从统计学的角度找出不符合规律的操作；让程序在云/沙盒中运行 (即“计算不再信任操作系统&amp;quot;)。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 13: System Calls and UNIX Shell</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec13/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec13/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;我们是操作系统用户，但操作系统 API 并不是我们作为人类用户直接使用的，那么“我们”到底应该怎么使用操作系统？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;shell&#34;&gt;Shell&lt;/h2&gt;
&lt;p&gt;我们需要一个与人类交互的程序，这就是 Shell。之所以叫做 shell，是因为它就像包裹住操作系统内核的一层“壳”：它向内使用系统调用与内核交互，向外与人类用户交互。(Shell 不一定是命令行终端！现在的图形界面也是一种 graphical shell。)&lt;/p&gt;
&lt;p&gt;Shell 本质上是一门 “把用户指令翻译成系统调用的编程语言”。(在 CLI 时代这一点体现得更明显)&lt;/p&gt;
&lt;h3 id=&#34;xv6-shell&#34;&gt;Xv6 Shell&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;关于 &lt;code&gt;-ffreestanding&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-ffreestanding
Assert that compilation targets a freestanding environment.  This implies -fno-builtin.  A
freestanding environment is one in which the standard library may not exist, and program
startup may not necessarily be at &amp;ldquo;main&amp;rdquo;.  The most obvious example is an OS kernel.  This is
equivalent to -fno-hosted.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;以上是 man gcc 中关于 &lt;code&gt;-ffreestanding&lt;/code&gt; 选项的说明。加上这个选项后，编译目标是一个类似于“裸机”的 freestanding 的环境。没有标准库，程序的入口不再是 main() 而是 _start()。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;sh-xv6.c&lt;/code&gt; 是一个零依赖的参考 xv6-riscv 实现的 shell，可以使用 &lt;code&gt;-ffreestanding&lt;/code&gt; 选项编译到 &lt;code&gt;.o&lt;/code&gt; 文件并直接用 ld 链接。为了实现零依赖，&lt;code&gt;sh-xv6.c&lt;/code&gt; 做出了如下的改动：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;sh-xv6.c&lt;/code&gt; 将 xv6 中的系统调用换成了如下利用 x86-64 syscall 指令的內联汇编代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// Minimum runtime library
long syscall(int num, ...) {
  va_list ap;
  va_start(ap, num);
  register long a0 asm (&amp;quot;rax&amp;quot;) = num;
  register long a1 asm (&amp;quot;rdi&amp;quot;) = va_arg(ap, long);
  register long a2 asm (&amp;quot;rsi&amp;quot;) = va_arg(ap, long);
  register long a3 asm (&amp;quot;rdx&amp;quot;) = va_arg(ap, long);
  register long a4 asm (&amp;quot;r10&amp;quot;) = va_arg(ap, long);
  va_end(ap);
  asm volatile(&amp;quot;syscall&amp;quot;
    : &amp;quot;+r&amp;quot;(a0) : &amp;quot;r&amp;quot;(a1), &amp;quot;r&amp;quot;(a2), &amp;quot;r&amp;quot;(a3), &amp;quot;r&amp;quot;(a4)
    : &amp;quot;memory&amp;quot;, &amp;quot;rcx&amp;quot;, &amp;quot;r8&amp;quot;, &amp;quot;r9&amp;quot;, &amp;quot;r11&amp;quot;);
  return a0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;x86-64 系统调用的各个参数的安放位置可以通过 &lt;code&gt;man 2 syscall&lt;/code&gt; 查阅。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;sh-xv6.c&lt;/code&gt; 将 xv6 中所有的 malloc() 替换成了如下的 zalloc()：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;static char mem[4096], *freem = mem;

void *zalloc(size_t sz) {
  assert(freem + sz &amp;lt; mem + sizeof(mem));
  void *ret = freem;
  freem += sz;
  return ret;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;xv6 的写法中 malloc() 没有对应的 free()，这是因为命令总是在 fork 出的子进程上完成的，子进程结束时会自动释放分配的内存。因此 zalloc() 使用了一个 4KB 的数组来模拟堆区，只管分配不管释放，这样 zalloc() 的语义和 malloc() 是相同的 (注：fork() 的时候，父子进程的 mem[] 数组是互不影响的！)。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;剩余的部分和 xv6 的 &lt;code&gt;sh.c&lt;/code&gt; 基本无异，代价解读见 Xv6 源码解读手册。&lt;/p&gt;
&lt;p&gt;近距离观测 &lt;code&gt;sh-xv6.c&lt;/code&gt; 的执行过程，我们有以下两种途径：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GDB。注意 GDB 默认追踪父进程，我们更希望关注子进程的行为，即指令执行的行为。可以通过 &lt;code&gt;set follow-fork-mode&lt;/code&gt; &lt;code&gt;set follow-exec-mode&lt;/code&gt; 等来修改 GDB 的追踪行为。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;strace。为了不将 shell 的输出和 strace 的输出混起来，我们可以这样做：使用命令&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;strace -f -o /tmp/strace.log  ./sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;将 strace 的输出打印到文件 &lt;code&gt;/tmp/strace.log&lt;/code&gt; 中，&lt;code&gt;-f&lt;/code&gt; 选项可以追踪所有子进程的系统调用。然后另开一个窗口执行&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;tail -f /tmp/strace.log
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 &lt;code&gt;-f&lt;/code&gt; 选项会 &amp;ldquo;output appended data as the file grows&amp;rdquo; (from &lt;code&gt;man tail&lt;/code&gt;)。配合 Tmux，我们将获得良好的 strace 观测体验。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-shell-programming-language&#34;&gt;The Shell Programming Language&lt;/h3&gt;
&lt;p&gt;使用 shell 本质上就是在编程。我们组合各种指令来完成复杂的任务。shell 提供基于文本替换的快速工作流的搭建：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;重定向：&lt;code&gt;cmd &amp;gt; /dev/null&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;顺序结构：&lt;code&gt;cmd1 ; cmd2&lt;/code&gt; (两者都执行)，&lt;code&gt;cmd1 &amp;amp;&amp;amp; cmd2&lt;/code&gt; (前者返回值为 0 才继续执行后者)，&lt;code&gt;cmd1 || cmd2&lt;/code&gt; (前者返回值为 1 才继续执行后者) etc.&lt;/li&gt;
&lt;li&gt;管道：&lt;code&gt;cmd1 | cmd2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;预处理：&lt;code&gt;$()&lt;/code&gt;  (将一个命令的输出作为另一个命令的参数)，&lt;code&gt;&amp;lt;()&lt;/code&gt; (将一个命令的输出重定向到一个文件，返回文件描述符作为另一个命令的参数) etc.&lt;/li&gt;
&lt;li&gt;环境变量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现代 GUI 能完成的事情绝大多数 CLI 也能完成，比如在图形界面中，我们通过点&amp;quot;叉&amp;quot; “最小化” 来管理前后台任务，窗口。在 CLI 中我们也有 job control。在执行命令时，我们可以在后面加上 &lt;code&gt;&amp;amp;&lt;/code&gt; 使其在后台执行；对于一个正在前台运行的程序，我们可以通过 &lt;code&gt;ctrl+z&lt;/code&gt; 将其暂时挂起，用 &lt;code&gt;bg %num&lt;/code&gt; 将指定进程放到后台执行；对于在后台运行的程序，我们可以用 &lt;code&gt;fg %num&lt;/code&gt; 将其拉到前台执行。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;UNIX shell 在自然语言、机器语言和1970s算力之间达到了一个优雅的平衡。但平衡意味着 UNIX shell 的设计也不是完美的。例如操作的优先级：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ls &amp;gt; a.txt | cat
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重定向和管道的优先级谁高？使用不同的 shell会得到不同的结果。(bash 不会打印到终端，zsh 会打印到终端 etc.)&lt;/p&gt;
&lt;p&gt;再例如文件名中的空格会带来很大的危险：如果使用命令 &lt;code&gt;vim &amp;quot;a b.txt&amp;quot;&lt;/code&gt;，事实上我们连续打开了 &lt;code&gt;a&lt;/code&gt; 和 &lt;code&gt;b.txt&lt;/code&gt;，这与我们的预期不同。这本质上是因为空格具有二义性：它有可能是分隔指令的符号。(Windows 的 powershell 有 object stream pipe，在管道中传递的东西不再是文本而是对象，这使得所有的东西都是 strongly typed 的，可以避免上述问题。)&lt;/p&gt;
&lt;p&gt;再比如，有些行为的意义可能是难以理解的：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo hello &amp;gt; /etc/a.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;无法执行，shell 会返回 permission denied。这时我们本能地在前面加上 sudo：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo echo hello &amp;gt; /etc/a.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;却发现仍然是 permission denied。联想 xv6-shell 中解析命令的机制，我们就不难理解这个问题的原因。shell 完成重定向输出的方法是：关闭 stdout 文件，打开 &lt;code&gt;/etc/a.txt&lt;/code&gt; 文件 (其文件描述符绑定为 1)，然后执行左边的指令。也就是说，sudo 只修饰了左边的执行，打开文件的过程没有获得高权限，所以报错。&lt;/p&gt;
&lt;h2 id=&#34;tty-and-job-control&#34;&gt;TTY and Job Control&lt;/h2&gt;
&lt;p&gt;我们还有一些疑问：例如没有任何程序在读键盘输入的情况下为什么 Ctrl+C 可以退出程序？为什么在有些应用 (e.g. vim) 中 Ctrl+C 不能退出？如果当前程序 fork 出了多个进程，Ctrl+C 会退出所有程序吗？Tmux 为什么能管理多个窗口？&lt;/p&gt;
&lt;p&gt;答案是终端。终端是 UNIX 操作系统中的一类非常特别的设备。命令行中有工具 tty 可以查看连接到标准输入的终端文件名。如果我们在 Tmux 的不同窗口中使用 tty 命令，可以看到不同的窗口连接到了不同的终端设备。我们甚至可以做一些有趣的事情：在一个窗口中 &lt;code&gt;echo hello &amp;gt; /dev/pts/other&lt;/code&gt;，hello 将显示在另一个窗口中。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么 &lt;code&gt;fork-printf.c&lt;/code&gt; 可以根据标准输出对象的不同选择不同的 buffer mode？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;通过 strace 观察，可以看到程序使用了 fstat() 系统调用查看 1 号文件 (标准输出) 的信息。在有重定向的版本的系统调用序列中，ioctl() 系统调用返回了 ENOTTY。&lt;/p&gt;
&lt;h3 id=&#34;session-process-group-and-signal&#34;&gt;Session, Process Group and Signal&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Ctrl+C 为什么能退出？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单来说，我们的终端负责识别 Ctrl+C 的按键组合，并给&lt;strong&gt;前台&lt;/strong&gt;进程发送一个 SIGINT 信号。前台程序有自由决定如何处理这个 SIGINT 信号，绝大部分的程序会在接收到 SIGINT 信号后退出，但我们也可以自己写一个 signal handler：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// signal-handler.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;signal.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;

void handler(int signum) {
  switch (signum) {
    case SIGINT:
      printf(&amp;quot;Received SIGINT!\n&amp;quot;);
      break;
    case SIGQUIT:
      printf(&amp;quot;Received SIGQUIT!\n&amp;quot;);
      exit(0);
      break;
  }
}

void cleanup() {
  printf(&amp;quot;atexit() cleanup\n&amp;quot;);
}

int main() {
  signal(SIGINT,  handler);
  signal(SIGQUIT, handler);
  atexit(cleanup);

  while (1) {
    char buf[4096];
    int nread = read(STDIN_FILENO, buf, sizeof(buf));
    buf[nread - 1] = &#39;\0&#39;;
    printf(&amp;quot;[%d] Got: %s\n&amp;quot;, getpid(), buf);
    if (nread &amp;lt; 0) {
      perror(&amp;quot;read&amp;quot;);
      exit(1);
    }
    sleep(1);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面的程序为 SIGINT 和 SIGQUIT 两个信号注册了处理函数。运行该程序，我们发现按下 Ctrl+C 时程序不会退出，而是输出 &lt;code&gt;Received SIGINT!&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这时有一个更有意思的问题：如果我们在 main() 函数开头执行一个 fork()，那么父子进程的标准输入和输出会连向同一个 tty，这时按下 Ctrl+C 终端会将 SIGINT 发送给哪个进程呢？经过实验我们发现：fork() 以后的 &lt;code&gt;signal-handler.c&lt;/code&gt; 在输入字符时，两个进程会争抢输入数据，呈现各打印了一部分内容的现象；如果按下 Ctrl+C，会出现两个 &lt;code&gt;Received SIGINT!&lt;/code&gt;。这说明 SIGINT 信号同时发送给了这两个进程。&lt;/p&gt;
&lt;p&gt;阅读 setpgid() 的手册，我们可以看到更系统的解读：&lt;/p&gt;
&lt;p&gt;当我们打开一个 shell 时，我们就创建了一个会话 (session)，这个会话有一个 controlling terminal。一个会话里面可以有若干个进程组 (process group) (注：shell 本身也是一个进程组，通常称为 session leader)，一个进程 fork() 得到的子进程和父进程同属一个进程组，execve() 不会改变一个进程所属的进程组。在任何时刻，一个会话里有且仅有一个前台 (foreground) 进程组，剩余的进程组都是后台进程组。当终端给会话发送一个信号时，前台进程组里的每个进程都会接收到这个信号。只有前台进程组中的进程可以从终端读取数据，如果后台进程尝试从终端读取数据，会接收到一个 SIGTTIN 信号，该信号会将后台进程挂起。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 14: C Library</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec14/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec14/</guid>
      <description>&lt;p&gt;&lt;code&gt;sh-xv6.c&lt;/code&gt; 可以在 freestanding 的环境下直接运行：我们最终使用 &lt;code&gt;ld sh-xv6.o -o sh&lt;/code&gt; 生成二进制文件，这意味着二进制文件中有且仅有 &lt;code&gt;sh-xv6.o&lt;/code&gt; 中的函数。&lt;/p&gt;
&lt;p&gt;我们平时在编写程序的时候显然不希望在 freestanding 的环境下编程——联想我们在 &lt;code&gt;sh-xv6.c&lt;/code&gt; 中，读取字符串都要用內联汇编的系统调用，这太糟糕了。我们自然而然地希望有一些封装好的库函数可以使用。&lt;/p&gt;
&lt;h2 id=&#34;libc-overview&#34;&gt;Libc: Overview&lt;/h2&gt;
&lt;h3 id=&#34;portability&#34;&gt;Portability&lt;/h3&gt;
&lt;p&gt;在 freestanding 环境下我们也有一些库可以使用。如果我们想写出可移植性强的代码，我们应该使用 libc 中提供的数据类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;比如我们要保存一个指针的值，瞎猜一个 &lt;code&gt;int&lt;/code&gt; &lt;code&gt;long&lt;/code&gt; 不是好的选择，我们应该用 &lt;code&gt;intptr_t&lt;/code&gt; (该类型在 &lt;code&gt;stdint.h&lt;/code&gt; 中定义)；比如我们想保存一个 4 字节的数据，应该使用 &lt;code&gt;int32_t&lt;/code&gt;。(&lt;code&gt;long&lt;/code&gt; 的长度是随架构变化的) 等等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;C 语言支持边长参数。例如 printf() 的声明是：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int printf(const char *format, ...);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 x86 架构中，参数是一个接着一个放在栈上的，因此在一些 i386 的代码中我们可能会看见下面的这种写法：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void **p = (void *)&amp;amp;fmt;
// use p[i] to get the address of the ith argument
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但 riscv64, x86-64 等架构是用寄存器传递参数的。为了写出可移植性更好的代码，我们应该使用 &lt;code&gt;va_list&lt;/code&gt; 类型，然后用 &lt;code&gt;va_start()&lt;/code&gt; &lt;code&gt;va_arg()&lt;/code&gt; &lt;code&gt;va_end()&lt;/code&gt; 等 API 去访问各个参数 (该类型在 &lt;code&gt;stdarg.h&lt;/code&gt; 中定义)。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;使用 libc 一定高效吗?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;不一定。GCC 的遗留问题使得使用 libc 编译出的汇编代码可能会“很笨”。例如 &lt;code&gt;sh-xv6.c&lt;/code&gt; 中关于系统调用的这段代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;long syscall(int num, ...) {
va_list ap;
va_start(ap, num);
register long a0 asm (&amp;quot;rax&amp;quot;) = num;
register long a1 asm (&amp;quot;rdi&amp;quot;) = va_arg(ap, long);
register long a2 asm (&amp;quot;rsi&amp;quot;) = va_arg(ap, long);
register long a3 asm (&amp;quot;rdx&amp;quot;) = va_arg(ap, long);
register long a4 asm (&amp;quot;r10&amp;quot;) = va_arg(ap, long);
va_end(ap);
asm volatile(&amp;quot;syscall&amp;quot;
 : &amp;quot;+r&amp;quot;(a0) : &amp;quot;r&amp;quot;(a1), &amp;quot;r&amp;quot;(a2), &amp;quot;r&amp;quot;(a3), &amp;quot;r&amp;quot;(a4)
 : &amp;quot;memory&amp;quot;, &amp;quot;rcx&amp;quot;, &amp;quot;r8&amp;quot;, &amp;quot;r9&amp;quot;, &amp;quot;r11&amp;quot;);
return a0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果我们分别为 1,2,3,4 个参数的系统调用写 4 个接口，像下面这样：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;long syscall4(long num, long a1, long a2, long a3, long a4) {
 long a0 = num;
 asm volatile(&amp;quot;syscall&amp;quot;
     : &amp;quot;+r&amp;quot;(a0) : &amp;quot;r&amp;quot;(a1), &amp;quot;r&amp;quot;(a2), &amp;quot;r&amp;quot;(a3), &amp;quot;r&amp;quot;(a4)
     : &amp;quot;memory&amp;quot;, &amp;quot;rcx&amp;quot;, &amp;quot;r8&amp;quot;, &amp;quot;r9&amp;quot;, &amp;quot;r11&amp;quot;);
 return a0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;观察两者在 -O2 优化下反汇编的结果，可以看到前者在寄存器和栈上来回倒腾数据，而后者只用了很少的代码就完成了工作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;printf() 的模式串中也涉及可移植性的问题。比如我们可能常常这么写程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int64_t a = 1;
printf(&amp;quot;%ld\n&amp;quot;, a);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但 &lt;code&gt;%ld&lt;/code&gt; 是用于打印一个 &lt;code&gt;long&lt;/code&gt; 长度的变量的，&lt;code&gt;long&lt;/code&gt; 的长度随架构变化而变化，上述代码在 32 位的架构上就会报 warning。&lt;code&gt;inttypes.h&lt;/code&gt; 其实为模式串的可移植性也设计了一套符号 (但很复杂)。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;convenience&#34;&gt;Convenience&lt;/h3&gt;
&lt;p&gt;并不是所有的系统调用都像 fork() 那样简单易用，因此库函数有义务将系统调用封装成更易用的样子，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;extern char **environ;
char *argv[] = {&amp;quot;echo&amp;quot;, &amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;, NULL, };
if (execve(argv[0], argc, environ) &amp;lt; 0) perror(&amp;quot;exec&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行上述程序，我们会得到 &lt;code&gt;exec: No such file or directory&lt;/code&gt;。这是因为 execve() 要求第一个参数必须是完整的 pathname。一些高情商的 API 是这样封装的：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;execlp(&amp;quot;echo&amp;quot;, &amp;quot;echo&amp;quot;, &amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;, NULL);
system(&amp;quot;echo hello world&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;exec() 家族的库函数有很多：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;l 系列的函数支持变长参数，我们不用单独开一个参数数组 argv[] 而可以直接把要传的参数放进去。与之相对地，v 系列的函数将参数保存好以后，将 argv[] 放到函数中即可，这对于多次使用同样参数很有利。&lt;/li&gt;
&lt;li&gt;p 系列的参数在第一个 pathname 中没有 &lt;code&gt;/&lt;/code&gt; 的情况下，会遍历 PATH 环境变量中的所有路径，将其接在文件名前面并尝试 execve()。&lt;/li&gt;
&lt;li&gt;e 系列可以不使用系统环境默认的环境变量，而是传入一个 envp[] 数组指定环境变量 (非 e 系列的函数默认以 &lt;code&gt;extern char *environ[]&lt;/code&gt; 的内容作为环境变量)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更多的内容可以查看手册。&lt;/p&gt;
&lt;h2 id=&#34;encapsulation-calculation&#34;&gt;Encapsulation: Calculation&lt;/h2&gt;
&lt;p&gt;纯计算的工作是我们大量使用并想要封装的，比如统计字符串的长度、给一段内存赋值等等。这看上去是非常简单的事情，但如果考虑到效率，安全性等因素，事情就变得复杂了。比如如下一段 memset 的实现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vodi *memset(void *s, int c, size_t n) {
    for (size_t i = 0; i &amp;lt; n; i++)
        ((char *)s)[i] = c;
    return s;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果有多个线程调用该程序，它能保证安全性吗？数据会互相覆盖吗？我们可以先用 libc 标准的 memset() 来测试一下多线程下的表现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// memset-race.c#include &amp;quot;thread.h&amp;quot;char buf[1 &amp;lt;&amp;lt; 30];void foo(int id) {  memset(buf, &#39;0&#39; + id, sizeof(buf) - 1);}int main() {  for (int i = 0; i &amp;lt; 4; i++)    create(foo);  join();  puts(buf);}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;多个线程同时对一段内存赋值，这是一个标准的数据竞争。运行这段程序我们可以看到 1,2,3,4 都有被输出。根据标准，标准库只对“标准库内部数据”的线程安全性负责 (比如 printf 的 buffer 是有锁保护的)，对外部数据库函数没有义务处理数据竞争。&lt;/p&gt;
&lt;p&gt;除此之外，封装的“好用”也是我们的一大目标。我们可以对比 C 语言的排序函数和 C++ 的排序函数：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void qsort(void *base, size_t nmemb, size_t size,                  int (*compar)(const void *, const void *));
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;sort(xs.begin(), xs.end(), [](auto &amp;amp;a, auto *b) {...});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到 C++ 的库函数明显更好用：我们可以直接用迭代器的 begin 和 end，还可以用 lambda 表达式把比较函数直接写在 sort() 里面。&lt;/p&gt;
&lt;h2 id=&#34;encapsulation-file-descriptors&#34;&gt;Encapsulation: File Descriptors&lt;/h2&gt;
&lt;p&gt;操作系统有义务封装对象 (比如终端，管道，文件 etc.) 并暴露合适的 API 给应用程序。由于 UNIX 秉持 everything is a file 的哲学，所以封装对象的核心就是文件描述符。&lt;/p&gt;
&lt;p&gt;考虑如下程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int main () {    FILE *fp = fopen(&amp;quot;a.txt&amp;quot;, &amp;quot;w&amp;quot;);    fprintf(fp, &amp;quot;Hello, world\n&amp;quot;);    return 0;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它会向 &lt;code&gt;a.txt&lt;/code&gt; 输出 Hello, world。这里的文件指针事实上指向的就是文件结构体。我们可以尝试用 GDB 调试这段代码，用 &lt;code&gt;p *fp&lt;/code&gt; 打印 fp 指针指向的内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{_flags = -72539004, _IO_read_ptr = 0x0, _IO_read_end = 0x0,   _IO_read_base = 0x0, _IO_write_base = 0x0, _IO_write_ptr = 0x0,   _IO_write_end = 0x0, _IO_buf_base = 0x0, _IO_buf_end = 0x0,   _IO_save_base = 0x0, _IO_backup_base = 0x0, _IO_save_end = 0x0,   _markers = 0x0, _chain = 0x7ffff7fa15e0 &amp;lt;_IO_2_1_stderr_&amp;gt;, _fileno = 3,   _flags2 = 0, _old_offset = 0, _cur_column = 0, _vtable_offset = 0 &#39;\000&#39;,   _shortbuf = &amp;quot;&amp;quot;, _lock = 0x555555559380, _offset = -1, _codecvt = 0x0,   _wide_data = 0x555555559390, _freeres_list = 0x0, _freeres_buf = 0x0,   __pad5 = 0, _mode = 0, _unused2 = &#39;\000&#39; &amp;lt;repeats 19 times&amp;gt;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到这是一个文件描述符为 3 的文件。如果我们用 &lt;code&gt;p *stdin/*stdout/*stderr&lt;/code&gt; 打印，也可以看到类似的内容，标准输入/输出/错误都是文件。&lt;/p&gt;
&lt;p&gt;另一个有意思的 API 是 popen()，它可以打开一个管道。这其实是一个设计的有缺陷的 API：手册中明确提到 UNIX pipe 是单向的：它有一个读口和一个写口，而文件指针 &lt;code&gt;FILE *&lt;/code&gt; 只能封装一个文件描述符，所以使用 popen() 必须指定从管道读还是写向管道。(现代的编程语言对管道 API 封装的更好。)&lt;/p&gt;
&lt;h2 id=&#34;encapsulation-utilities&#34;&gt;Encapsulation: Utilities&lt;/h2&gt;
&lt;h3 id=&#34;err&#34;&gt;err&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么 &lt;code&gt;cat nonexist.c&lt;/code&gt; &lt;code&gt;gcc nonexist.c&lt;/code&gt; 等命令输出的都是 &amp;ldquo;xxx: nonexist.c: No such file or directory&amp;rdquo;?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们也可以用库函数山寨一个类似的版本：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// err-message.c#include &amp;lt;err.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;int main (){	const char *filename = &amp;quot;nonexist.c&amp;quot;;	FILE *fp = fopen(filename, &amp;quot;r&amp;quot;);	if (!fp) warn(&amp;quot;%s&amp;quot;, filename);	return 0;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;err.h&lt;/code&gt; &lt;code&gt;errno.h&lt;/code&gt; 提供若干这样将错误信息输出到标准错误的函数，好用的函数还有 perror()，err() 等。err() 可以在输出错误信息后直接退出程序，如：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;fd = open(filename, O_RONLY, 0);if (fd == -1)    err(EXIT_FAILURE, &amp;quot;%s&amp;quot;, filename);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这些函数的原理是根据全局变量 errno 的数值，打印上一次错误的原因。手册中对于 errno 的解释为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;errno  is  defined  by  the ISO C standard to be a modifiable lvalue of type int, and must not be explicitly declared; errno may  be  a  macro. errno  is  thread-local;  setting  it in one thread does not affect its value in any other thread.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;值得注意的一点是 errno 是线程独享的 thread-local 变量。从这里我们可以看到协程相对于线程更轻量级体现在何处。&lt;/p&gt;
&lt;h3 id=&#34;environ&#34;&gt;environ&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// env.c#include &amp;lt;stdio.h&amp;gt;int main() {  extern char **environ;  for (char **env = environ; *env; env++) {    printf(&amp;quot;%s\n&amp;quot;, *env);  }}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;C 库函数为我们提供了一个指针 environ，通过它我们可以找到环境变量列表。一个自然的问题是：这个指针是什么时候指向正确的位置的？&lt;/p&gt;
&lt;p&gt;我们可能认为在 CPU reset 到 boot 完成期间 environ 就被设置好了，但考虑到一个程序的环境变量是在 execve() 的时候传进去的，不同程序可以不一样，这个变量显然应该是在进程加载启动时才设置的。&lt;/p&gt;
&lt;p&gt;我们可以用 GDB 观测这个行为。在静态加载下，用 &lt;code&gt;gdb ./env&lt;/code&gt; 启动上述程序并用 &lt;code&gt;starti&lt;/code&gt; 停在第一条汇编指令，查看 &lt;code&gt;p (char **)environ&lt;/code&gt; ，发现此时 environ 还是空指针。我们可以在 environ 上加监视点 &lt;code&gt;wa (char **)environ&lt;/code&gt; ，即可看到在 &lt;code&gt;__libc_start_main()&lt;/code&gt; 函数中修改了 environ。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么我动态链接时无法查看 environ 的信息？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;encapsulation-address-space&#34;&gt;Encapsulation: Address Space&lt;/h2&gt;
&lt;p&gt;libc 为我们封装好了地址空间。我们可以通过 mmaps() 修改地址空间映射，也可以通过 malloc() 和 free() 从堆区里申请/释放空间。&lt;/p&gt;
&lt;p&gt;想要优化 malloc()/free() 的性能，我们要对 workload 有正确的假设。指导思想：$O(n)$ 大小的对象分配后至少有 $\Omega(n)$ 的读写操作，否则就是 performance bug。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;越小的对象创建/分配越频繁 (e.g. 字符串，临时对象等，生存周期不长)&lt;/li&gt;
&lt;li&gt;较为频繁地分配中等大小对象 (e.g. 复杂的对象，较大的数组)&lt;/li&gt;
&lt;li&gt;低频率的大对象 (e.g. 巨大的容器，分配器；很长的生存周期)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;核心优化思想：Fast path + slow path，争取在 fast path 上做到 $O(1)$ (无锁或无 contention)。计算机系统的世界中处处是 fast path + slow path，比如 memory hierarchy。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 15: More about fork()</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec15/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec15/</guid>
      <description>&lt;h2 id=&#34;fork-semantics&#34;&gt;&lt;code&gt;fork()&lt;/code&gt; Semantics&lt;/h2&gt;
&lt;p&gt;fork() 的语义是将当前进程的状态机完整地复制一份，这两个进程除了 fork() 的返回值以外全部相同。&lt;/p&gt;
&lt;h3 id=&#34;file-descriptors&#34;&gt;File Descriptors&lt;/h3&gt;
&lt;p&gt;我们这里关注文件描述符：根据 fork() 的语义，子进程和父进程会拥有相同的文件描述符 (文件描述符可以理解为指向操作系统对象的指针)。execve() 会重置状态机，但会继承原进程持有的所有操作系统对象。这个设计使我们在 UNIX shell 中可以利用管道技术，在 execve() 之前修改 stdin, stdout 以完成进程之间数据的传输。&lt;!-- more --&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;execve() 会无条件继承所有的对象吗？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在 open() 的手册中，我们可以看到打开文件时有一个标志是 O_CLOEXEC，这样打开的文件在 execve() 的时候不会被继承。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;文件描述符其实不仅仅是指向对象的指针。我们在一个程序中写两句话&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;write(fd, &amp;quot;Hello&amp;quot;, 5);
write(fd, &amp;quot;World&amp;quot;, 5);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们得到的会是 &amp;ldquo;HelloWorld&amp;rdquo; 而不是 &amp;ldquo;World&amp;rdquo;，这说明文件描述符中还保存了一个对象当前的 offset。那么一个自然的问题是：如果我们 fork 出一个子线程，然后父子线程分别打印 Hello 和 World，我们会得到两个字符串还是一个字符串呢？我们可以写一个程序验证一下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// fork-fd.c
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;wait.h&amp;gt;

int main ()
{
    int fd = open(&amp;quot;a.txt&amp;quot;, O_RDWR | O_CREAT | O_TRUNC);
    int rt = fork();
    if (rt == 0)
        write(fd, &amp;quot;World&amp;quot;, 5);
    else
        write(fd, &amp;quot;Hello&amp;quot;, 5);
    wait(NULL);
    if (rt == 0) write(fd, &amp;quot;\n&amp;quot;, 1);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该程序会输出 &amp;ldquo;HelloWorld&amp;rdquo; (或者 &amp;ldquo;WorldHello&amp;rdquo;)，而不是只有五个字符。这说明 fork 之后的两个进程后续仍然是共享文件偏移的。这样的设计显然符合一个“正常“的程序员的需求。查阅 dup() 系统调用的手册，我们可以看到 dup() 获得的新文件描述符和被复制的文件描述符也是共享文件偏移的。&lt;/p&gt;
&lt;p&gt;共享偏移对操作系统内核提出了较强的挑战。内核必须非常小心，保证对文件描述符的操作是原子的 (在 &lt;code&gt;man 2 write&lt;/code&gt; 中可以看到 Linux 内核关于 file offset 的 bug 在内核 3.14 版本中才得到修复)。&lt;/p&gt;
&lt;h3 id=&#34;copy-on-write-fork&#34;&gt;Copy-on-write Fork&lt;/h3&gt;
&lt;p&gt;fork() 的语义是完整复制了状态机，但在实现层面，现代内核并不是立即复制所有的数据。fork() 有大量的场景都是为了启动一个新程序，即 fork() + execve() 的组合，这种情况下我们复制完的地址空间会立刻被新的程序镜像覆盖，复制工作就很浪费。&lt;/p&gt;
&lt;p&gt;现代内核普遍使用 copy-on-write fork (写时拷贝) 技术，即 fork() 时子进程完整复制父进程的页表，两者指向相同的页面，并暂时将页面的写权限去掉。这样之后如果父子进程读取数据，两者可以并行不悖。如果某个进程需要写数据，会因为没有写权限触发 page fault，内核的 page fault handler 发现这是一个 cow 页面，便会现场复制一个新的页面，让父子进程指向不同的页面，并把写权限恢复。&lt;/p&gt;
&lt;p&gt;cow fork 在实现层面还有一些细节，比如每个页面需要维护一个 reference count，之后对一个页面 malloc() 和 free() 的语义要做出一些修改，以及根据 ISA 确定如何在页表项中添加 cow 页面标志位等等。&lt;/p&gt;
&lt;p&gt;我们可以通过一个小程序感受 Linux 内核的 copy-on-write fork：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// cow-test.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;
#include &amp;lt;string.h&amp;gt;

#define NPROC 1000
#define MB 128
#define SIZE (MB * (1 &amp;lt;&amp;lt; 20))

#define xstr(s) str(s)
#define str(s) #s

int main() {
  char *data = malloc(SIZE); // 128MB shared memory
  memset(data, &#39;_&#39;, SIZE);

  for (int i = 0; i &amp;lt; NPROC - 1; i++) {
    if (fork() == 0) break;
  }

  // NPROC processes go here

  asm volatile(&amp;quot;.fill 1048576 * &amp;quot; xstr(MB) &amp;quot;, 1, 0x90&amp;quot;); // 128MB shared code

  unsigned int idx = 0;
  int fd = open(&amp;quot;/dev/urandom&amp;quot;, O_RDONLY); assert(fd &amp;gt; 0);
  read(fd, &amp;amp;idx, sizeof(idx));
  close(fd);
  idx %= 1048576 * MB;

  data[idx] = &#39;.&#39;;
  printf(&amp;quot;pid = %d, write data[%u]\n&amp;quot;, getpid(), idx);

  while (1) {
    sleep(1); // not terminate
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 &lt;code&gt;cow-test.c&lt;/code&gt; 中，我们用 fork() 创建了 1000 个子进程，每个进程都有一个大小为 128M 的代码区 (都是 nop 指令)，每个进程还会随机挑选一个位置进行修改。编译后，我们的可执行文件大小就在 128M 左右。如果内核使用普通的 fork，这个程序运行到一半就会因内存不足而崩溃。但事实上 Linux 运行的很好。这证明了 Linux 中使用了 cow fork 策略。&lt;/p&gt;
&lt;p&gt;cow fork 策略的一个推论便是：想要统计一个程序运行时占用的内存空间是一个伪命题 (比如操作系统里的 libc 代码只有一份，不知道有多少程序的页表指向了它)。&lt;/p&gt;
&lt;h2 id=&#34;state-machine-fork-and-magic&#34;&gt;State Machine, &lt;code&gt;fork()&lt;/code&gt; and Magic&lt;/h2&gt;
&lt;p&gt;fork() 可以完整复制状态机，这可以帮助我们完成很多炫酷的事情，比如开平行宇宙做 non-deterministic 的事情。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;errno.h&amp;gt;
#include &amp;lt;sys/wait.h&amp;gt;

#define DEST  &#39;+&#39;
#define EMPTY &#39;.&#39;

struct move {
  int x, y, ch;
} moves[] = {
  { 0, 1, &#39;&amp;gt;&#39; },
  { 1, 0, &#39;v&#39; },
  { 0, -1, &#39;&amp;lt;&#39; },
  { -1, 0, &#39;^&#39; },
};

char map[][512] = {
  &amp;quot;#######&amp;quot;,
  &amp;quot;#.#.#+#&amp;quot;,
  &amp;quot;#.....#&amp;quot;,
  &amp;quot;#.....#&amp;quot;,
  &amp;quot;#...#.#&amp;quot;,
  &amp;quot;#######&amp;quot;,
  &amp;quot;&amp;quot;,
};

void display();

void dfs(int x, int y) {
  if (map[x][y] == DEST) {
    display();
  } else {
    int nfork = 0;

    for (struct move *m = moves; m &amp;lt; moves + 4; m++) {
      int x1 = x + m-&amp;gt;x, y1 = y + m-&amp;gt;y;
      if (map[x1][y1] == DEST || map[x1][y1] == EMPTY) {
        int pid = fork(); assert(pid &amp;gt;= 0);
        if (pid == 0) { // map[][] copied
          map[x][y] = m-&amp;gt;ch;
          dfs(x1, y1);
          exit(0); // clobbered map[][] discarded
        } else {
          nfork++;
          waitpid(pid, NULL, 0); // wait here to serialize the search
        }
      }
    }

    while (nfork--) wait(NULL);
  }
}

int main() {
  dfs(1, 1);
}

void display() {
  for (int i = 0; ; i++) {
    for (const char *s = map[i]; *s; s++) {
      switch (*s) {
        case EMPTY: printf(&amp;quot;   &amp;quot;); break;
        case DEST : printf(&amp;quot; ○ &amp;quot;); break;
        case &#39;&amp;gt;&#39;  : printf(&amp;quot; → &amp;quot;); break;
        case &#39;&amp;lt;&#39;  : printf(&amp;quot; ← &amp;quot;); break;
        case &#39;^&#39;  : printf(&amp;quot; ↑ &amp;quot;); break;
        case &#39;v&#39;  : printf(&amp;quot; ↓ &amp;quot;); break;
        default   : printf(&amp;quot;▇▇▇&amp;quot;); break;
      }
    }
    printf(&amp;quot;\n&amp;quot;);
    if (strlen(map[i]) == 0) break;
  }
  fflush(stdout);
  sleep(1); // to see the effect of parallel search
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;dfs-fork.c&lt;/code&gt; 是一个走迷宫程序，不同于基本的 dfs 走迷宫，它的 dfs() 函数中每发现一个新的路，便会 fork 一个新的进程去做它，结尾处的 &lt;code&gt;sleep(1)&lt;/code&gt; 用于模拟一个耗时很长的任务。现在的 &lt;code&gt;dfs-fork.c&lt;/code&gt; 还不能做到并行，因为 dfs 函数中当前进程会 wait 一个分支的子进程结束才会探索下一个分支。但我们如果把 dfs 循环内的 wait 去掉，就可以观测到程序“秒”完成任务。&lt;/p&gt;
&lt;p&gt;fork() 相较于搜索-回溯还有一个好处：当我们探索一个分支失败时，我们不用一步一步撤回去，而是可以直接销毁当前进程，然后从之前保存的副本出发搜索新的分支。&lt;/p&gt;
&lt;h3 id=&#34;parallel-universe-skipping-initialization&#34;&gt;Parallel Universe: Skipping Initialization&lt;/h3&gt;
&lt;p&gt;以 NEMU 举例，我们可能需要运行很多个 benchmark，但 NEMU 的初始化过程很长，我们能不能只进行一次初始化，然后让多个 benchmark 共享这一次初始化呢？&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int main() {
    nemu_init();
    while (1) {
        file = get_start_request();
        if ((pid = fork()) == 0) {
            load_file();
            ...
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面一段 C 代码大致实现了我们的想法。我们在 init() 结束后，每次 fork 一个子进程做一个 benchmark，就可以让多个 benchmark 共享初始化刚结束时的状态机了。&lt;/p&gt;
&lt;p&gt;类似的思想在实际中也有广泛应用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Zygote Process：zygote 是受精卵的意思，这是 Android 里的一个机制。Java 程序启动需要加载很多的 class node，这个过程很慢，但事实上现在的 Android app 基本都是秒起的。这是因为 Android 的一个 zygote process 完成所有的初始化工作，然后每开一个 app 直接在 zygote process 的基础上 fork，设置一些权限、用户 id 之后很快就可以开始执行 app 代码。&lt;/li&gt;
&lt;li&gt;Chrome site isolation：Chrome 的每个标签页都是一个独立的进程，这其中也有共享初始化资源的技术，这让 chrome 的速度变得很快。&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;parallel-universe-backup-and-fault-tolerence&#34;&gt;Parallel Universe: Backup and Fault-tolerence&lt;/h3&gt;
&lt;p&gt;有了平行宇宙，我们就有了犯错的底气：我们可以时不时地对状态机 fork，如果某个时刻程序 crash 了，我们就恢复最近一次保存的状态机副本；如果到了下一个存档点仍然没有 crash，我们在 fork 出新的存档的同时可以把上一份存档销毁。&lt;/p&gt;
&lt;p&gt;平行宇宙还可以为我们提供容错机制：比如有一些并发 bug 触发的概率很小。那么如果某一次不幸地触发了并发 bug，我们可以利用存档点回到过去，然后再跑一遍，说不定就绕过了 bug 可以继续执行了。&lt;/p&gt;
&lt;h2 id=&#34;a-fork-in-the-road&#34;&gt;A &lt;code&gt;fork()&lt;/code&gt; in the Road&lt;/h2&gt;
&lt;p&gt;将状态机完整地复制一遍在早期是一件轻量级的事情，但现在随着系统中的机制越来越丰富，fork() 要做的事情越来越繁重：信号、线程、ptrace 等等。fork() 的语义也变得越来越复杂。比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有了信号机制后，当操作系统给进程发送信号时，子进程是否也接收到这个信号？答案是子进程也会接收到信号，这就设计了 process group 等一系列概念。&lt;/li&gt;
&lt;li&gt;当线程加入后，fork 是把当前进程的所有线程复制，还是只复制执行 fork 的线程？答案是后者。&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;POSIX 给出的一个更安全的创建子进程的 API 是 posix_spawn()：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int posix_spawn(pid_t *pid, const char *path,
                       const posix_spawn_file_actions_t *file_actions,
                       const posix_spawnattr_t *attrp,
                       char *const argv[], char *const envp[]);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它有相当复杂的参数。这是一个非常明显的 fork 后时代设计的 API，它打包执行 fork 和 execve，将执行过程分为 fork, pre-exec 和 exec 三个阶段，并在 pre-exec 阶段对 signal handler, file action 等东西做一系列设置。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A fork() in the Road&lt;/em&gt; 一文中提出了 fork() 的七宗罪：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fork is no longer simple - 要考虑的机制越来越多；&lt;/li&gt;
&lt;li&gt;Fork doesn’t compose - 比如 &lt;code&gt;fork-printf.c&lt;/code&gt;，将标准库中 buffer 的内容复制很可能不是程序员的初衷；&lt;/li&gt;
&lt;li&gt;Fork isn’t thread-safe&lt;/li&gt;
&lt;li&gt;Fork is insecure - fork() 出的子进程和父进程地址空间完全相同，打破了 ASLR；&lt;/li&gt;
&lt;li&gt;Fork is slow&lt;/li&gt;
&lt;li&gt;Fork doesn’t scale&lt;/li&gt;
&lt;li&gt;Fork encourages memory overcommit&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 16: Executable Files</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec16/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec16/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;本节课默认只有静态链接。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;可执行文件的本质&lt;strong&gt;描述状态机初始状态 (数据) 和迁移 (指令) 的数据结构&lt;/strong&gt;：可执行文件在 execve() 的时候使用，操作系统根据可执行文件的描述设置状态机并开始执行。&lt;!-- more --&gt;&lt;/p&gt;
&lt;p&gt;更具体地说，可执行文件是一个描述了状态机初始状态的数据结构。状态机的初始状态一般包括以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;寄存器：大部分寄存器的值由 ABI 规定 (比如哪些寄存器应该清零)，由操作系统负责设置。但也有一些重要的寄存器的值是可执行文件指定的，比如 PC 的值。&lt;/li&gt;
&lt;li&gt;地址空间 (内存)：由二进制文件和 ABI 共同决定，比如某一段数据应该放到内存中的哪里，以及 argv, envp 的内容。&lt;/li&gt;
&lt;li&gt;其他有用的信息 (比如调试信息)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;什么样的文件可以被执行？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个文件需要满足若干条件才能被执行。假设我们有源代码 &lt;code&gt;a.c&lt;/code&gt;，直接执行它 (&lt;code&gt;./a.c&lt;/code&gt;) 会获得 Permission denied (bash)，即使我们用 &lt;code&gt;chmod +x a.c&lt;/code&gt; 给其加上了执行权限，仍然不能正常执行。&lt;/p&gt;
&lt;p&gt;决定一个文件是否能执行的是 execve() 系统调用。我们可以用 strace 追踪加载 &lt;code&gt;a.c&lt;/code&gt; 的过程。如果 &lt;code&gt;a.c&lt;/code&gt; 没有被赋予可执行权限，我们得到的是 EACCES (Permission denied)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;execve(&amp;quot;./a.c&amp;quot;, [&amp;quot;./a.c&amp;quot;], 0x7fff24451760 /* 66 vars */) = -1 EACCES (Permission denied)
strace: exec: Permission denied
+++ exited with 1 +++
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果我们给 &lt;code&gt;a.c&lt;/code&gt; 赋予执行权限，得到的则是 ENOEXEC (目标文件的格式不是可识别的可执行文件格式)。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;execve(&amp;quot;./a.c&amp;quot;, [&amp;quot;./a.c&amp;quot;], 0x7ffe24eca680 /* 66 vars */) = -1 ENOEXEC (Exec format error)
strace: exec: Exec format error
+++ exited with 1 +++
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这时我们再阅读 execve() 的手册的 ERROR 部分，就会有更好的理解。手册告诉我们 EACCES 类型的错误不只是因为缺少执行权限，也可能是因为对象不是正常的文件类型，比如 &lt;code&gt;strace /dev/null&lt;/code&gt; 也会得到 EACCES。除了 EACCES 和 ENOEXEC 还有更多的错误类型，比如 E2BIG 表示参数/环境变量列表太长，ENOMEM 表示内核的内存空间不足等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;common-executable-file-formats&#34;&gt;Common Executable File Formats&lt;/h3&gt;
&lt;p&gt;Executable file 就是操作系统中的一个普通的对象。&lt;/p&gt;
&lt;p&gt;Windows 中使用的是 PE 格式 (Portable Executable)。&lt;/p&gt;
&lt;p&gt;UNIX/Linux 默认的可执行文件格式是 ELF (Executable Linkable Format)，但 UNIX/Linux 还支持 She-bang 格式的文件 (即文件开头有 &lt;code&gt;#!&lt;/code&gt; 的文件)。比如我们可以在一个 &lt;code&gt;.c&lt;/code&gt; 文件中书写&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/bin/python3
print(&#39;Hello&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;给它加上执行权限后它便可以用 python 解释器运行下面的代码并输出 Hello。更神奇的是 She-bang 后面还可以跟我们自己写的程序，例如我们书写下面的两个程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// args.c
int main (int argc, char *argv[]) {
    for (int i = 0; i &amp;lt; argc; i++) {
        printf(&amp;quot;argv[%d] = %s\n&amp;quot;, i, argv[i]);
    }
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#!./args
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第二个程序随便是什么类型 (不妨给其命名 &lt;code&gt;she-bang&lt;/code&gt;)。将第一个 C 程序编译出可执行文件 args 后，给第二个文件加上可执行权限后，输入 &lt;code&gt;./she-bang&lt;/code&gt; ，便可得到&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argv[0] = ./args
argv[1] = ./she-bang
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其实 she-bang 的原理可以理解为一个偷换参数的 execve()：我们在输入命令 &lt;code&gt;./file&lt;/code&gt; 的时候，本来传给 execve() 的参数是 &amp;ldquo;./file&amp;rdquo;，但如果 file 文件的开头是 she-bang：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!intepreter [optional-args]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;那么相当于给 execve() 传入了参数 &amp;ldquo;intepreter&amp;rdquo;,  &amp;ldquo;[optional-args]&amp;rdquo;, &amp;ldquo;file&amp;rdquo;。这部分在 execve() 的手册中也有叙述。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;关于 optional args 的有趣现象&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们即使在 she-bang 后跟多个空格分开的单词，也只能传一个参数。这是一个 UNIX 的历史遗留问题。比如我们将刚才的 she-bang 修改为&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!./args Hello OS World
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;则输出结果为&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;argv[0] = ./args
argv[1] = Hello OS World
argv[2] = ./she-bang
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;为什么我使用 &lt;code&gt;strace ./she-bang&lt;/code&gt; 观测，但没有看到显式的 “偷梁换柱” 现象？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在 linux kernel 的源码中，execve() 会调用 &lt;code&gt;do_open_execat(&amp;quot;./she-bang&amp;quot;)&lt;/code&gt;，里面有一个函数是 loadelf，有一个函数是 loadscript，在 load_script() 中，内核有权限打开一个文件并检查器开头是不是 &lt;code&gt;#!&lt;/code&gt;，如果是就会把后面的解释器路径读出来，然后递归地调用 &lt;code&gt;do_open_execat(&amp;quot;./args&amp;quot;)&lt;/code&gt;。因此这个“偷梁换柱”的过程是在 execve() 内部完成的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;parsing-executable-file&#34;&gt;Parsing Executable File&lt;/h2&gt;
&lt;p&gt;GNU binutils 提供了一系列与二进制文件打交道的工具。这些工具的本质都是查看/修改数据结构中的内容。&lt;/p&gt;
&lt;h3 id=&#34;debugging-information&#34;&gt;Debugging Information&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// segfault.c
#include &amp;lt;stddef.h&amp;gt;

void bar() {
  *(int *)NULL = 1;
}

void foo() {
  bar();
}

int main() {
  foo();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上述程序对一个空指针解引用，显然会发生段错误。如果我们用 GDB 调试，我们可以抓到出错的行。使用 &lt;code&gt;backtrace&lt;/code&gt; / &lt;code&gt;where&lt;/code&gt; 还可以打印出完整的函数调用序列，以及每个函数对应到源代码的行数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(gdb) where
#0  bar () at segfault.c:4
#1  0x0000555555555151 in foo () at segfault.c:8
#2  0x0000555555555166 in main () at segfault.c:12
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们还可以感受 addr2line 工具的威力：在可执行文件 segfault 中找到 foo() 函数对应的地址 ADDR，然后输入&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;addr2line ADDR segfault
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;便可以得到该地址对应到源代码 &lt;code&gt;segfault.c&lt;/code&gt; 中的行号：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~/os-demo/Lecture16/segfault.c:7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们针对二进制文件操作，却可以得到源代码相关的信息，这是因为我们的二进制文件中保留了调试信息 (当然，如果我们编译的时候不带 &lt;code&gt;-g&lt;/code&gt; 选项，使用 GDB backtrace 的时候就无法定位到源文件行号)。如果我们用 &lt;code&gt;readelf -S file&lt;/code&gt; 查看可执行文件 file 的 section header table，可以看到有 debug info 等节，这就是调试信息。&lt;/p&gt;
&lt;p&gt;现在调试信息采用的标准是 DWARF debugging standard。调试信息可以理解为将 assembly (机器状态) 映射到 &amp;ldquo;C语言世界&amp;rdquo; 状态的函数。我们 C 语言的形式语义是状态机之间的转移 (high level 的状态机，比如栈帧，行号等)，编译器的工作是将其翻译成汇编指令，汇编指令描述了更底层的状态机的转移 (memory, register etc.)，调试信息的作用就是将一个底层的状态机状态映射到 C 语言世界的一个状态机状态。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;编译器的“摆烂”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将机器状态映射到 C 语言状态是一件很困难的事情。比如我们可能有函数內联，这让 backtrace 变得困难；再比如比较激进的编译优化会在语义不变的前提下改写汇编程序而不是逐句翻译，这使得有些汇编状态其实根本找不到对应的 C 语言状态。因此，我们在调试时经常碰到各种各样不正确的调试信息，以及一些明明可以打印，却被摆烂的 &lt;code&gt;&amp;lt;optimized out&amp;gt;&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// popcount.c
#include &amp;lt;stdio.h&amp;gt;

__attribute__((noinline))
int popcount(int x) {
int s = 0;
int b0 = (x &amp;gt;&amp;gt; 0) &amp;amp; 1;
s += b0;
int b1 = (x &amp;gt;&amp;gt; 1) &amp;amp; 1;
s += b1;
int b2 = (x &amp;gt;&amp;gt; 2) &amp;amp; 1;
s += b2;
int b3 = (x &amp;gt;&amp;gt; 3) &amp;amp; 1;
s += b3;
return s;
}

int main() {
printf(&amp;quot;%d\n&amp;quot;, popcount(0b1101));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;popcount.c&lt;/code&gt; 可以正确地打印出一个数二进制表示中有多少个 1。但如果我们用 GDB 调试，在不开 O2 的情况下，我们刚进入 popcount() 时 &lt;code&gt;p x&lt;/code&gt; 会发现 GDB 输出了不正确的值 0。在开 O2 的情况下，我们运行到 popcount() 的 ret 时，会发现变量 s 被 optimized out 了，但 %eax 的值 3 是正确的……这都是错误或不得当的调试信息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;example-stack-unwinding&#34;&gt;Example: Stack Unwinding&lt;/h3&gt;
&lt;p&gt;这些功能其实并不神秘，利用 x86 架构的栈帧结构，我们也可以实现一个简易的 stack unwinding：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// unwind.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

const char *binary;

struct frame {
  struct frame *next; // push %rbp
  void *addr;         // call f (pushed retaddr)
};

void backtrace() {
  struct frame *f;
  char cmd[1024];
  extern char end;

  asm volatile (&amp;quot;movq %%rbp, %0&amp;quot; : &amp;quot;=g&amp;quot;(f));
  for (; f-&amp;gt;addr &amp;lt; (void *)&amp;amp;end; f = f-&amp;gt;next) {
    printf(&amp;quot;%016lx  &amp;quot;, (long)f-&amp;gt;addr); fflush(stdout);
    sprintf(cmd, &amp;quot;addr2line -e %s %p&amp;quot;, binary, f-&amp;gt;addr);
    system(cmd);
  }
}

void bar() {
  backtrace();
}

void foo() {
  bar();
}

int main(int argc, char *argv[]) {
  binary = argv[0];
  foo();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行代码 (不开优化)，我们确实可以得到一个完整的函数调用链：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;000000000040199e  /home/starling/os-demo/Lecture16/unwind.c:26
00000000004019b3  /home/starling/os-demo/Lecture16/unwind.c:30
00000000004019e1  /home/starling/os-demo/Lecture16/unwind.c:34
00000000004039b2  ??:?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;backtrace() 函数的实现原理很简单：我们默认该程序运行在 x86 架构上，x86 架构在调用一个函数时总是使用 call 指令，call 指令会向栈中写入返回地址，然后 PC 跳转到目标函数的第一条指令。目标函数的前两条指令一定是&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;push %rbp
mov %rsp, %rbp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行完了以后，栈上的内容为返回地址和旧 rbp 值，现在的 rbp 寄存器指向存储旧 rbp 值的地址。因此我们只要不断向前寻找 rbp 值，就可以实现栈帧的回溯，每次找 rbp 值上一个 8 字节区域的内容，就能找到返回地址，利用 addr2line 对这个返回地址定位，就能找到调用当前函数的 caller。&lt;/p&gt;
&lt;p&gt;上述示例代码使用一个 &lt;code&gt;struct frame&lt;/code&gt; 结构比较精巧地完成了这件事，它刚开始用一句內联汇编把 %rbp 的值放到了 f 中，f 的结构为&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct frame {
    struct frame *next;
    void *addr;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样 next 存储的正好是旧 rbp，addr 存储的正好是当前函数的返回地址 (栈是从上往下生长的)。&lt;code&gt;end&lt;/code&gt; 变量记录了代码段的结束位置，回溯到 end 之上就可以结束了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;GDB 的强大&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果我们使用 O2 优化，示例代码将不能正常工作，因为这些函数都被內联了，我们只能看到一层调用。但如果用 GDB 的 backtrace，我们仍然可以看到完整的函数调用链——这个调用过程是 GDB 虚构出来的正确信息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;linking-and-relocation&#34;&gt;Linking and Relocation&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// hello.c
void hello() {}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// main.c
void hello();

int f(int a, int b) {return a + b;}

int main () {
    hello();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上述两个文件分别编译成可重定位文件后，最后链接在一起就可以执行。我们关心 &lt;code&gt;main.c&lt;/code&gt; 到底是如何找到外部的 hello() 函数的地址的。如果我们查看 &lt;code&gt;main.o&lt;/code&gt; 的代码段信息：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-assembly&#34;&gt;0000000000000000 &amp;lt;f&amp;gt;:
   0:   f3 0f 1e fa             endbr64 
   4:   8d 04 37                lea    (%rdi,%rsi,1),%eax
   7:   c3                      ret

0000000000000000 &amp;lt;main&amp;gt;:
   0:   f3 0f 1e fa             endbr64 
   4:   48 83 ec 08             sub    $0x8,%rsp
   8:   31 c0                   xor    %eax,%eax
   a:   e8 00 00 00 00          call   f &amp;lt;main+0xf&amp;gt;
   f:   31 c0                   xor    %eax,%eax
  11:   48 83 c4 08             add    $0x8,%rsp
  15:   c3                      ret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;会看到像 f() 这样完全确定的函数编译器已经完全生成好了代码，编译器还没有填的是 call 后面的地址偏移，因为链接之前它不知道 hello() 在哪里，因此只能暂时填 0 摆烂。&lt;/p&gt;
&lt;p&gt;链接结束后 main() 在 0xb 处填写的 offset 应该满足下面的 assertion：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// hello.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;

void main();
void hello() {
    void *p = (void *)main + 0xa + 1;
    int32_t offset = *((int32_t *)p);
    assert((char *)main + 0xf + offset == (char *)hello);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(注：开始跳转的地址是 &lt;code&gt;main +0xf&lt;/code&gt; 是因为 x86 的 call 指令是从下一条指令的地址开始跳转的。)&lt;/p&gt;
&lt;p&gt;为了满足这个 assertion，我们容易计算出要填写的 offset 应该满足 $S+A-P$ 的格式，其中 $S$ 是目标函数的地址 (在这里是 &lt;code&gt;(void *)hello&lt;/code&gt;)，$A$ 是一个偏移量，(在这里是 $-4$)，$P$ 是下一条指令的地址 (在这里是 &lt;code&gt;(void *)main + 0xb&lt;/code&gt;)。如果我们用 readelf 查看 &lt;code&gt;main.o&lt;/code&gt; 的重定位表，可以看到&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  Offset          Info           Type           Sym. Value    Sym. Name + Addend
00000000000b  000c00000004 R_X86_64_PLT32    0000000000000000 hello - 4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里的  &amp;ldquo;Offset&amp;rdquo; 就是 $P$，&amp;ldquo;Addend&amp;rdquo; 就是 $A$，&amp;ldquo;Sym&amp;rdquo; 就是 $S$。&lt;/p&gt;
&lt;p&gt;因此，通俗来说，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;编译器 (gcc) 就是将 high-level semantics (C 语言) 转换成 low-level semantics (汇编)。&lt;/li&gt;
&lt;li&gt;汇编器 (as) 就是将 low-level semantics 转换成 binary semantics (状态机容器)，这个部分几乎是一一对应地翻译，对于暂时没法填的要留下重定位信息，重定位信息本质上就是对填写内容的 assertion。&lt;/li&gt;
&lt;li&gt;链接器 (ld) 负责合并所有容器，得到一个完整的状态机，除了我们指定的 &lt;code&gt;.o&lt;/code&gt; 文件外，链接器还会将一些 C Runtime Objects 链接进来。找不到符号/重复强符号的错误也是在链接阶段报出。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这种理解下，我们很容易设计一个自己的“简易二进制文件格式“：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct executable {
    uint32_t entry;
    struct segment *segments;
    struct reloc *relocs;
    struct symbol *symbols;
};
struct segment {uint32_t flags, size; char data[0];}
struct reloc {uint32_t S, A, P; const char *name;}
struct symbol {uint32_t offset, const char *name;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;随着各种需求的加入，我们就会慢慢理解 ELF 中各种信息设置的含义。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 17: Linking and Loading</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec17/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec17/</guid>
      <description>&lt;h2 id=&#34;static-loader&#34;&gt;Static Loader&lt;/h2&gt;
&lt;h3 id=&#34;loader-on-os&#34;&gt;Loader on OS&lt;/h3&gt;
&lt;p&gt;可执行文件是一个描述了状态机的初始状态的数据结构。加载器根据可执行文件的描述设置好初始状态机。我们很容易写一个静态加载器：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// loader-static.c
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;
#include &amp;lt;elf.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;

#define STK_SZ           (1 &amp;lt;&amp;lt; 20)
#define ROUND(x, align)  (void *)(((uintptr_t)x) &amp;amp; ~(align - 1))
#define MOD(x, align)    (((uintptr_t)x) &amp;amp; (align - 1))
#define push(sp, T, ...) ({ *((T*)sp) = (T)__VA_ARGS__; sp = (void *)((uintptr_t)(sp) + sizeof(T)); })

void execve_(const char *file, char *argv[], char *envp[]) {
  // WARNING: This execve_ does not free process resources.
  int fd = open(file, O_RDONLY);
  assert(fd &amp;gt; 0);
  Elf64_Ehdr *h = mmap(NULL, 4096, PROT_READ, MAP_PRIVATE, fd, 0);
  assert(h != (void *)-1);
  assert(h-&amp;gt;e_type == ET_EXEC &amp;amp;&amp;amp; h-&amp;gt;e_machine == EM_X86_64);

  Elf64_Phdr *pht = (Elf64_Phdr *)((char *)h + h-&amp;gt;e_phoff);
  for (int i = 0; i &amp;lt; h-&amp;gt;e_phnum; i++) {
    Elf64_Phdr *p = &amp;amp;pht[i];
    if (p-&amp;gt;p_type == PT_LOAD) {
      int prot = 0;
      if (p-&amp;gt;p_flags &amp;amp; PF_R) prot |= PROT_READ;
      if (p-&amp;gt;p_flags &amp;amp; PF_W) prot |= PROT_WRITE;
      if (p-&amp;gt;p_flags &amp;amp; PF_X) prot |= PROT_EXEC;
      void *ret = mmap(
        ROUND(p-&amp;gt;p_vaddr, p-&amp;gt;p_align),              // addr, rounded to ALIGN
        p-&amp;gt;p_memsz + MOD(p-&amp;gt;p_vaddr, p-&amp;gt;p_align),   // length
        prot,                                       // protection
        MAP_PRIVATE | MAP_FIXED,                    // flags, private &amp;amp; strict
        fd,                                         // file descriptor
        (uintptr_t)ROUND(p-&amp;gt;p_offset, p-&amp;gt;p_align)); // offset
      assert(ret != (void *)-1);
      memset((void *)(p-&amp;gt;p_vaddr + p-&amp;gt;p_filesz), 0, p-&amp;gt;p_memsz - p-&amp;gt;p_filesz);
    }
  }
  close(fd);

  static char stack[STK_SZ], rnd[16];
  void *sp = ROUND(stack + sizeof(stack) - 4096, 16);
  void *sp_exec = sp;
  int argc = 0;

  // argc
  while (argv[argc]) argc++;
  push(sp, intptr_t, argc);
  // argv[], NULL-terminate
  for (int i = 0; i &amp;lt;= argc; i++)
    push(sp, intptr_t, argv[i]);
  // envp[], NULL-terminate
  for (; *envp; envp++) {
    if (!strchr(*envp, &#39;_&#39;)) // remove some verbose ones
      push(sp, intptr_t, *envp);
  }
  // auxv[], AT_NULL-terminate
  push(sp, intptr_t, 0);
  push(sp, Elf64_auxv_t, { .a_type = AT_RANDOM, .a_un.a_val = (uintptr_t)rnd } );
  push(sp, Elf64_auxv_t, { .a_type = AT_NULL } );

  asm volatile(
    &amp;quot;mov $0, %%rdx;&amp;quot; // required by ABI
    &amp;quot;mov %0, %%rsp;&amp;quot;
    &amp;quot;jmp *%1&amp;quot; : : &amp;quot;a&amp;quot;(sp_exec), &amp;quot;b&amp;quot;(h-&amp;gt;e_entry));
}

int main(int argc, char *argv[], char *envp[]) {
  if (argc &amp;lt; 2) {
    fprintf(stderr, &amp;quot;Usage: %s file [args...]\n&amp;quot;, argv[0]);
    exit(1);
  }
  execve_(argv[1], argv + 1, envp);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;编译好 &lt;code&gt;loader-static.c&lt;/code&gt; 后，使用命令 &lt;code&gt;./loader ELF文件名&lt;/code&gt; 可以正确地加载并执行一个静态链接的 ELF 文件。我们可以用 strace 证明我们并没有在 loader 中使用 execve() 系统调用，但我们实现了 execve() 的功能。&lt;/p&gt;
&lt;p&gt;我们来仔细阅读这份代码：main() 函数的 execve_() 实现了 execve() 系统调用的功能。不过这个 execve_() 是我们自己实现的。execve_() 主要做了以下这些事：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;execve_() 获得的参数，file 是要打开的文件名，argv[] 和 envp[] 是参数列表和环境变量列表。我们打开文件并读出 ELF 文件头，对其进行一系列检查 (比如架构是否正确，类型是否是 EXEC 等)。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将要加载的段加载到内存中。我们遍历 ELF 文件的程序头表，将那些标有 &lt;code&gt;PT_LOAD&lt;/code&gt; 的段加载到指定位置 (即 &lt;code&gt;p-&amp;gt;p_vaddr&lt;/code&gt;)。我们使用 mmap() 来完成“加载”，它的本质是将地址空间中的一段区域映射到文件中。这里有一些比较琐碎的细节，比如在使用了 &lt;code&gt;MAP_FIXED&lt;/code&gt; 标志后，我们必须保证传给 mmap 的地址是对齐的，因此需要 ROUND()，对齐后我们加载的长度也相应要增加，因此有了第二行的 MOD()。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;关于 MAP_FIXED&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通常情况下，传给 mmap() 的第一个参数 addr 内核只是将其当作一个 hint，内核会尽量将要加载的内容放到 addr 附近，但不给出任何保证。但如果使用了 MAP_FIXED 标志，内核会将要加载的内容确定地放到 addr 位置，这种情况下，addr 要保证对齐。&lt;/p&gt;
&lt;p&gt;MAP_FIXED 标志一定要非常小心地使用，在不同的操作系统，内核版本，libc 版本下进程的地址空间布局可能有很大的差异，MAP_FIXED 会使程序的可移植性下降。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;还有一个小细节是：我们要将 &lt;code&gt;[p-&amp;gt;p_filesz, p-&amp;gt;p_memsz)&lt;/code&gt;  .bss 节的部分清零。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为程序准备一个运行时栈，这里我们直接开了 1 MiB 的数组作为栈，并保存了 argc 的地址待会传给 stack pointer (我们为各种参数准备了 4KiB 的空间)。接下来我们要将 argv[]，envp[]，aux[] 等放到栈上，这些内容都可以在 System V ABI Figure 3.9 的 Initial Process Stack 中找到。这里示例代码定义了一个非常优雅的宏 push()&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define push(sp, T, ...) ({ *((T*)sp) = (T)__VA_ARGS__; sp = (void *)((uintptr_t)(sp) + sizeof(T)); })
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它的作用是将当前参数放在 sp 的位置，并把 sp 加上 &lt;code&gt;sizeof(T)&lt;/code&gt; 移动到下一个空白位置。我们这里做出的一个小修改是不将带下划线的环境变量上栈，这可以帮助我们确信我们的程序对各种内容的掌控。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最后是几个內联汇编语句，完成的工作是根据 ABI 规定将 %rdx 设置为 0，将栈指针 %rsp 设置为 argc 的地址，最后根据 ELF 的入口地址将 PC 跳转过去 (此处带 &lt;code&gt;*&lt;/code&gt; 表示绝对跳转)。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个 loader 存在一个小问题：loader 本身也是一个 ELF，它运行起来的时候地址空间中本身就有自己的映射。我们进行新状态机的映射时可能会出现映射冲突的情况，如果强行映射可能会使 loader 崩溃。这时我们应该将 loader 的映射挪一个地方，但这会使 loader 的复杂度大幅上升。为了解决这个问题，我们采用的方法是让 loader 动态链接，动态链接和静态链接的地址空间通常差异很大，不会重叠。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Loader on OS 与操作系统设计&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是一个完全处在用户态的 loader——我们发现操作系统的 execve() 系统调用其实是多余的。我们在用户态通过 open(), mmap() 等系统调用可以实现 execve() 的功能。这不禁让我们思考：操作系统是不是应该把加载的过程从内核移出来，让用户对加载过程有更强的可定制性？……&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;boot-loader&#34;&gt;Boot Loader&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// bootmain.c
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;elf.h&amp;gt;
#include &amp;lt;x86/x86.h&amp;gt;

#define SECTSIZE 512
#define ARGSIZE  1024

static inline void wait_disk(void) {
  while ((inb(0x1f7) &amp;amp; 0xc0) != 0x40);
}

static inline void read_disk(void *buf, int sect) {
  wait_disk();
  outb(0x1f2, 1);
  outb(0x1f3, sect);
  outb(0x1f4, sect &amp;gt;&amp;gt; 8);
  outb(0x1f5, sect &amp;gt;&amp;gt; 16);
  outb(0x1f6, (sect &amp;gt;&amp;gt; 24) | 0xE0);
  outb(0x1f7, 0x20);
  wait_disk();
  for (int i = 0; i &amp;lt; SECTSIZE / 4; i ++) {
    ((uint32_t *)buf)[i] = inl(0x1f0);
  }
}

static inline void copy_from_disk(void *buf, int nbytes, int disk_offset) {
  uint32_t cur  = (uint32_t)buf &amp;amp; ~(SECTSIZE - 1);
  uint32_t ed   = (uint32_t)buf + nbytes;
  uint32_t sect = (disk_offset / SECTSIZE) + (ARGSIZE / SECTSIZE) + 1;
  for(; cur &amp;lt; ed; cur += SECTSIZE, sect ++)
    read_disk((void *)cur, sect);
}

static void load_program(uint32_t filesz, uint32_t memsz, uint32_t paddr, uint32_t offset) {
  copy_from_disk((void *)paddr, filesz, offset);
  char *bss = (void *)(paddr + filesz);
  for (uint32_t i = filesz; i != memsz; i++) {
    *bss++ = 0;
  }
}

static void load_elf64(Elf64_Ehdr *elf) {
  Elf64_Phdr *ph = (Elf64_Phdr *)((char *)elf + elf-&amp;gt;e_phoff);
  for (int i = 0; i &amp;lt; elf-&amp;gt;e_phnum; i++, ph++) {
    load_program(
      (uint32_t)ph-&amp;gt;p_filesz,
      (uint32_t)ph-&amp;gt;p_memsz,
      (uint32_t)ph-&amp;gt;p_paddr,
      (uint32_t)ph-&amp;gt;p_offset
    );
  }
}

static void load_elf32(Elf32_Ehdr *elf) {
  Elf32_Phdr *ph = (Elf32_Phdr *)((char *)elf + elf-&amp;gt;e_phoff);
  for (int i = 0; i &amp;lt; elf-&amp;gt;e_phnum; i++, ph++) {
    load_program(
      (uint32_t)ph-&amp;gt;p_filesz,
      (uint32_t)ph-&amp;gt;p_memsz,
      (uint32_t)ph-&amp;gt;p_paddr,
      (uint32_t)ph-&amp;gt;p_offset
    );
  }
}

void load_kernel(void) {
  Elf32_Ehdr *elf32 = (void *)0x8000;
  Elf64_Ehdr *elf64 = (void *)0x8000;
  int is_ap = boot_record()-&amp;gt;is_ap;

  if (!is_ap) {
    // load argument (string) to memory
    copy_from_disk((void *)MAINARG_ADDR, 1024, -1024);
    // load elf header to memory
    copy_from_disk(elf32, 4096, 0);
    if (elf32-&amp;gt;e_machine == EM_X86_64) {
      load_elf64(elf64);
    } else {
      load_elf32(elf32);
    }
  } else {
    // everything should be loaded
  }

  if (elf32-&amp;gt;e_machine == EM_X86_64) {
    ((void(*)())(uint32_t)elf64-&amp;gt;e_entry)();
  } else {
    ((void(*)())(uint32_t)elf32-&amp;gt;e_entry)();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;bootmain.c&lt;/code&gt; 是 AbstractMachine 中加载内核的代码。我们已经知道固件中的代码会帮我们把启动磁盘的第一个扇区 (512B) 的 MBR 搬到一个指定的位置并开始执行，上述代码就是主引导扇区的代码。我们的内核镜像第一个扇区是 MBR，第二、三个扇区存储了传给 main() 函数的参数，后面的部分是内核的 ELF，MBR 代码的工作和之前的 loader on OS 一样，将内核 ELF 中该加载的东西放到指定的地方。&lt;/p&gt;
&lt;p&gt;该代码和 loader on OS 不一样的地方在于：操作系统中我们有 mmap() 系统调用，可以将一段地址空间直接映射到文件中的内容，但在 boot loader 中我们没有操作系统。幸运的是我们有对于全部硬件资源的掌控：现在还没有虚拟地址，我们可以直接指定物理地址，指哪打哪。&lt;code&gt;bootmain.c&lt;/code&gt; 中的 read_disk() 函数负责将一个扇区的内容拷贝到 buf 数组中，从硬盘中读取数据的代码非常琐碎，需要参考硬件 I/O 相关的手册。copy_from_disk() 是对 read_disk() 的进一步封装，剩余的 load_program()，load_elf32/64() 的代码和 loader on OS 没有本质区别。&lt;/p&gt;
&lt;h3 id=&#34;linux-kernel-loader&#34;&gt;Linux Kernel Loader&lt;/h3&gt;
&lt;p&gt;Linux 内核没什么可怕的，只是我们之前写的 loader 的放大版本。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;学会使用正确的工具&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 vscode 调试代码，可以充分可视化；函数跳转，查找等会非常方便。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;dynamic-linking&#34;&gt;Dynamic Linking&lt;/h2&gt;
&lt;p&gt;随着库函数越来越大，我们希望项目能够在运行时再链接，这样我们不需要每个文件都链接 libc 库函数，节省内存空间。此外，如果我们的库函数要打一个安全补丁，在没有动态链接的情况下，系统中所有链接库的文件都要重新编译一遍 (非常可怕)，有了动态链接我们就可以免除这个麻烦。&lt;/p&gt;
&lt;p&gt;假设我们要实现一个自己的二进制文件格式，支持动态加载，那么我们需要有以下字段：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;DL_HEAD

LOAD(&amp;quot;libc.dl&amp;quot;) // 加载动态库
IMPORT(putchar) // 加载外部符号
EXPORT(hello)   // 为动态库导出本地符号
    
DL_CODE

hello:
	...
    CALL DSYM(putchar) // DSYM(func) 表示 func 是外部的函数

DL_END
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;假设我们有配套的编译器可以生成这种格式的位置无关代码。我们可以实现这种格式上的“全家桶”工具集：&lt;code&gt;gcc&lt;/code&gt; 对标 &lt;code&gt;ld&lt;/code&gt; ，&lt;code&gt;readdl&lt;/code&gt; 对标 &lt;code&gt;readelf&lt;/code&gt;，&lt;code&gt;objdump&lt;/code&gt; 对标 &lt;code&gt;objdump&lt;/code&gt;，&lt;code&gt;interp&lt;/code&gt; 用于执行：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// main.S
#include &amp;quot;dl.h&amp;quot;

DL_HEAD

LOAD(&amp;quot;libc.dl&amp;quot;)
LOAD(&amp;quot;libhello.dl&amp;quot;)
IMPORT(hello)
EXPORT(main)

DL_CODE

main:
  call DSYM(hello)
  call DSYM(hello)
  call DSYM(hello)
  call DSYM(hello)
  movq $0, %rax
  ret

DL_END
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;main.S&lt;/code&gt; 加载了 libc 库和 libhello 库，引入了 hello 符号，然后在 main() 函数中调用了 4 次 hello()。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// libhello.S
#include &amp;quot;dl.h&amp;quot;

DL_HEAD

LOAD(&amp;quot;libc.dl&amp;quot;)
IMPORT(putchar)
EXPORT(hello)

DL_CODE

hello:
  lea str(%rip), %rdi
  mov count(%rip), %eax
  push %rbx
  mov %rdi, %rbx
  inc %eax
  mov %eax, count(%rip)
  add $0x30, %eax
  movb %al, 0x6(%rdi)
loop:
  movsbl (%rbx),%edi
  test %dil,%dil
  je out
  call DSYM(putchar)
  inc  %rbx
  jmp loop
out:
  pop %rbx
  ret

str:
  .asciz &amp;quot;Hello X\n&amp;quot;

count:
  .int 0

DL_END
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;libhello.S&lt;/code&gt; 加载了 libc 库，引入了 putchar 符号，并为动态库提供了 hello() 函数。hello() 函数的功能很简单：每次调用 putchar() 输出字符串 &amp;ldquo;Hello X\n&amp;rdquo;，其中 X 会每轮 +1。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// libc.S
#include &amp;quot;dl.h&amp;quot;
#include &amp;lt;sys/syscall.h&amp;gt;

DL_HEAD

EXPORT(putchar)
EXPORT(exit)

DL_CODE

putchar:
  mov %dil, buf(%rip)
  mov $SYS_write, %rax
  mov $1, %rdi
  lea buf(%rip), %rsi
  mov $1, %rdx
  syscall
  ret
buf:
  .byte 0

exit:
  movq $SYS_exit, %rax
  syscall

DL_END
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;libc.S&lt;/code&gt; 为动态库提供了 putchar() 函数和 exit() 函数，putchar() 函数通过 write 系统调用输出字符，exit() 函数通过 exit 系统调用退出。&lt;/p&gt;
&lt;p&gt;利用全家桶工具 &lt;code&gt;dlbox.c&lt;/code&gt;，我们可以分别链接三个汇编文件，生成对应的 &lt;code&gt;.dl&lt;/code&gt; 文件：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./dlbox gcc main.S
./dlbox gcc libc.S
./dlbox gcc libhello.S
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以用 &lt;code&gt;readdl&lt;/code&gt; 工具查看 dl 文件的内容：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bas&#34;&gt;&amp;gt; ./dlbox readdl main.dl
DLIB file main.dl:

    LOAD  libc.dl
    LOAD  libhello.dl
  EXTERN  hello
000000c0  main
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到 &lt;code&gt;main.S&lt;/code&gt; 加载了 libc 和 libhello，导入了外部符号 hello，本地有一个符号 main。&lt;/p&gt;
&lt;p&gt;我们可以用 &lt;code&gt;objdump&lt;/code&gt; 工具查看反汇编代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;&amp;gt; ./dlbox objdump libc.dl
Disassembly of binary libc.dl:

0000000000000000 &amp;lt;putchar&amp;gt;:
00000000  40883D1F000000    mov [rel 0x26],dil
00000007  48C7C001000000    mov rax,0x1
0000000E  48C7C701000000    mov rdi,0x1
00000015  488D350A000000    lea rsi,[rel 0x26]
0000001C  48C7C201000000    mov rdx,0x1
00000023  0F05              syscall
00000025  C3                ret
00000026  00                db 0x00

0000000000000027 &amp;lt;exit&amp;gt;:
00000027  48C7C03C000000    mov rax,0x3c
0000002E  0F05              syscall
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(注：需要在本地安装 nasm 工具集。)&lt;/p&gt;
&lt;p&gt;最后，我们不需要将这些 dl 文件汇集在一起链接，就可以直接运行 main.dl：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;&amp;gt; ./dlbox interp main.dl
Hello 1
Hello 2
Hello 3
Hello 4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们现在关注这个动态加载器是如何实现的。首先看 &lt;code&gt;dl.h&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// dl.h
#define REC_SZ 32
#define DL_MAGIC &amp;quot;\x01\x14\x05\x14&amp;quot;

#ifdef __ASSEMBLER__
  #define DL_HEAD     __hdr: \
                      /* magic */    .ascii DL_MAGIC; \
                      /* file_sz */  .4byte (__end - __hdr); \
                      /* code_off */ .4byte (__code - __hdr)
  #define DL_CODE     .fill REC_SZ - 1, 1, 0; \
                      .align REC_SZ, 0; \
                      __code:
  #define DL_END      __end:

  #define RECORD(sym, off, name) \
    .align REC_SZ, 0; \
    sym .8byte (off); .ascii name

  #define IMPORT(sym) RECORD(sym:,           0, &amp;quot;?&amp;quot; #sym &amp;quot;\0&amp;quot;)
  #define EXPORT(sym) RECORD(    , sym - __hdr, &amp;quot;#&amp;quot; #sym &amp;quot;\0&amp;quot;)
  #define LOAD(lib)   RECORD(    ,           0, &amp;quot;+&amp;quot; lib  &amp;quot;\0&amp;quot;)
  #define DSYM(sym)   *sym(%rip)
#else
  #include &amp;lt;stdint.h&amp;gt;

  struct dl_hdr {
    char magic[4];
    uint32_t file_sz, code_off;
  };

  struct symbol {
    int64_t offset;
    char type, name[REC_SZ - sizeof(int64_t) - 1];
  };
#endif
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上半部分是给汇编看的，后半部分是给 C 语言看的 (即 &lt;code&gt;dlbox.h&lt;/code&gt;)。&lt;code&gt;dl.h&lt;/code&gt; 是对我们的 DIY 二进制文件格式的一个 specification。我们的二进制文件格式如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;header&lt;/th&gt;
&lt;th&gt;symbol1&lt;/th&gt;
&lt;th&gt;symbol2&lt;/th&gt;
&lt;th&gt;&amp;hellip;&lt;/th&gt;
&lt;th&gt;symboln&lt;/th&gt;
&lt;th&gt;00&amp;hellip;0&lt;/th&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;p&gt;其中每个部分都是 32 字节对齐的。header 的结构如 C 语言代码部分所示。header 中有一个 4B 的魔数用于检查文件格式，一个变量 &lt;code&gt;file_sz&lt;/code&gt; 记录整个文件的大小，一个变量 &lt;code&gt;code_off&lt;/code&gt; 记录代码段距离文件开头的 offset。通过汇编部分的宏可以看到，在汇编代码中添加了一些符号后这些值都是很容易算出的。&lt;/p&gt;
&lt;p&gt;比较关键的宏是 IMPORT()，EXPORT() 和 LOAD()。可以看到它们的本质是在符号表中添加一个表项。符号表的结构如 C 语言代码部分所示，前 8 个字节是这个符号所在位置与文件开头的 offset (如果这是一个外部符号则暂时填 0，加载的时候由动态加载器补全)，type 表示这是一个内部导出的符号，外部导入的符号还是要加载一个动态库。最后的 name[] 数组记录了名字。将这个结构体和宏定义对比起来看也很容易懂，这里值得注意的一个小细节是：&lt;code&gt;IMPORT(sym)&lt;/code&gt; 中，直接使用 sym 表示的是汇编文件中定义的 sym 符号，在前面加上 &lt;code&gt;#&lt;/code&gt; 才表示 sym 本身这个字符串。&lt;/p&gt;
&lt;p&gt;另外可以看到，DSYM() 宏是一个 PC 相对跳转。&lt;code&gt;DSYM(sym)&lt;/code&gt; 会被翻译为 &lt;code&gt;call *sym(%rip)&lt;/code&gt;。该指令的语义是 &lt;code&gt;PC = mem[next-pc + offset]&lt;/code&gt;。因此在汇编阶段 PC 和本文件符号表中的 sym 的差值 offset 就能确定。在加载时，随着符号表 sym 里面填写的地址被确定，&lt;code&gt;call&lt;/code&gt; 就能完成正确的跳转。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// dlbox.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;assert.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;stdbool.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;
#include &amp;lt;fcntl.h&amp;gt;
#include &amp;quot;dl.h&amp;quot;

#define SIZE 4096
#define LENGTH(arr) (sizeof(arr) / sizeof(arr[0]))

struct dlib {
  struct dl_hdr hdr;
  struct symbol *symtab; // borrowed spaces from header
  const char *path;
};

static struct dlib *dlopen(const char *path);

struct dlib *dlopen_chk(const char *path) {
  struct dlib *lib = dlopen(path);
  if (!lib) {
    fprintf(stderr, &amp;quot;Not a valid dlib file: %s.\n&amp;quot;, path);
    exit(1);
  }
  return lib;
}

// Implementation of binutils

void dl_gcc(const char *path) {
  char buf[256], *dot = strrchr(path, &#39;.&#39;);
  if (dot) {
    *dot = &#39;\0&#39;;
    sprintf(buf, &amp;quot;gcc -m64 -fPIC -c %s.S &amp;amp;&amp;amp; &amp;quot;
      &amp;quot;objcopy -S -j .text -O binary %s.o %s.dl&amp;quot;, path, path, path);
    system(buf);
  }
}


void dl_readdl(const char *path) {
  struct dlib *h = dlopen_chk(path);
  printf(&amp;quot;DLIB file %s:\n\n&amp;quot;, h-&amp;gt;path);
  for (struct symbol *sym = h-&amp;gt;symtab; sym-&amp;gt;type; sym++) {
    switch (sym-&amp;gt;type) {
      case &#39;+&#39;: printf(&amp;quot;    LOAD  %s\n&amp;quot;, sym-&amp;gt;name); break;
      case &#39;?&#39;: printf(&amp;quot;  EXTERN  %s\n&amp;quot;, sym-&amp;gt;name); break;
      case &#39;#&#39;: printf(   &amp;quot;%08lx  %s\n&amp;quot;, sym-&amp;gt;offset, sym-&amp;gt;name); break;
    }
  }
}

void dl_objdump(const char *path) {
  struct dlib *h = dlopen_chk(path);
  char *hc = (char *)h, cmd[64];
  FILE *fp = NULL;

  printf(&amp;quot;Disassembly of binary %s:\n&amp;quot;, h-&amp;gt;path);

  for (char *code = hc + h-&amp;gt;hdr.code_off; code &amp;lt; hc + h-&amp;gt;hdr.file_sz; code++) {
    for (struct symbol *sym = h-&amp;gt;symtab; sym-&amp;gt;type; sym++) {
      if (hc + sym-&amp;gt;offset == code) {
        int off = code - hc - h-&amp;gt;hdr.code_off;
        if (fp) pclose(fp);
        sprintf(cmd, &amp;quot;ndisasm - -b 64 -o 0x%08x\n&amp;quot;, off);
        fp = popen(cmd, &amp;quot;w&amp;quot;);
        printf(&amp;quot;\n%016x &amp;lt;%s&amp;gt;:\n&amp;quot;, off, sym-&amp;gt;name);
        fflush(stdout);
      }
    }
    if (fp) fputc(*code, fp);
  }
  if (fp) pclose(fp);
}

// binutils: interpreter
void dl_interp(const char *path) {
  struct dlib *h = dlopen_chk(path);
  int (*entry)() = NULL;
  for (struct symbol *sym = h-&amp;gt;symtab; sym-&amp;gt;type; sym++)
    if (strcmp(sym-&amp;gt;name, &amp;quot;main&amp;quot;) == 0)
      entry = (void *)((char *)h + sym-&amp;gt;offset);
  if (entry) {
    exit(entry());
  }
}

struct cmd {
  const char *cmd;
  void (*handler)(const char *path);
} commands[] = {
  { &amp;quot;gcc&amp;quot;,     dl_gcc },
  { &amp;quot;readdl&amp;quot;,  dl_readdl },
  { &amp;quot;objdump&amp;quot;, dl_objdump },
  { &amp;quot;interp&amp;quot;,  dl_interp },
  { &amp;quot;&amp;quot;,        NULL },
};

int main(int argc, char *argv[]) {
  if (argc &amp;lt; 3) {
    fprintf(stderr, &amp;quot;Usage: %s {gcc|readdl|objdump|interp} FILE...\n&amp;quot;, argv[0]);
    return 1;
  }

  for (struct cmd *cmd = &amp;amp;commands[0]; cmd-&amp;gt;handler; cmd++) {
    for (char **path = &amp;amp;argv[2]; *path &amp;amp;&amp;amp; strcmp(argv[1], cmd-&amp;gt;cmd) == 0; path++) {
      if (path != argv + 2) printf(&amp;quot;\n&amp;quot;);
      cmd-&amp;gt;handler(*path);
    }
  }
}

// Implementation of dlopen()

static struct symbol *libs[16], syms[128];

static void *dlsym(const char *name);
static void dlexport(const char *name, void *addr);
static void dlload(struct symbol *sym);

static struct dlib *dlopen(const char *path) {
  struct dl_hdr hdr;
  struct dlib *h;

  int fd = open(path, O_RDONLY);
  if (fd &amp;lt; 0) goto bad;
  if (read(fd, &amp;amp;hdr, sizeof(hdr)) &amp;lt; sizeof(hdr)) goto bad;
  if (strncmp(hdr.magic, DL_MAGIC, strlen(DL_MAGIC)) != 0) goto bad;

  h = mmap(NULL, hdr.file_sz, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE, fd, 0);
  if (h == (void *)-1) goto bad;

  h-&amp;gt;symtab = (struct symbol *)((char *)h + REC_SZ);
  h-&amp;gt;path = path;

  for (struct symbol *sym = h-&amp;gt;symtab; sym-&amp;gt;type; sym++) {
    switch (sym-&amp;gt;type) {
      case &#39;+&#39;: dlload(sym); break; // (recursively) load
      case &#39;?&#39;: sym-&amp;gt;offset = (uintptr_t)dlsym(sym-&amp;gt;name); break; // resolve
      case &#39;#&#39;: dlexport(sym-&amp;gt;name, (char *)h + sym-&amp;gt;offset); break; // export
    }
  }

  return h;

bad:
  if (fd &amp;gt; 0) close(fd);
  return NULL;
}

static void *dlsym(const char *name) {
  for (int i = 0; i &amp;lt; LENGTH(syms); i++)
    if (strcmp(syms[i].name, name) == 0)
      return (void *)syms[i].offset;
  assert(0);
}

static void dlexport(const char *name, void *addr) {
  for (int i = 0; i &amp;lt; LENGTH(syms); i++)
    if (!syms[i].name[0]) {
      syms[i].offset = (uintptr_t)addr; // load-time offset
      strcpy(syms[i].name, name);
      return;
    }
  assert(0);
}

static void dlload(struct symbol *sym) {
  for (int i = 0; i &amp;lt; LENGTH(libs); i++) {
    if (libs[i] &amp;amp;&amp;amp; strcmp(libs[i]-&amp;gt;name, sym-&amp;gt;name) == 0) return; // already loaded
    if (!libs[i]) {
      libs[i] = sym;
      dlopen(sym-&amp;gt;name); // load recursively
      return;
    }
  }
  assert(0);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;dlbox.c&lt;/code&gt; 实现了 dl 格式的工具全家桶。它有很多的功能都是借用了 GNU 工具链实现的。这其中最重要的函数是 dlopen()，它可以打开一个 &lt;code&gt;.dl&lt;/code&gt; 文件，将其中的内容解析出来，并返回一个 dlib 结构体，dlib 结构体的内容和之前绘制的二进制文件结构相同。&lt;/p&gt;
&lt;p&gt;dlopen() 做了如下的事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调用 open() 打开目标文件，从中读取了 &lt;code&gt;sizeof(dl_hdr)&lt;/code&gt; 的数据，即把文件头读了出来，进行魔数检查，并获得了整个文件的大小。&lt;/li&gt;
&lt;li&gt;利用 mmap() 系统调用将整个目标文件加载到内存中 (其本质是 copy-on-write 的，因此即使文件很大速度也很快)，将符号表首地址设置为 header 下面一个，设置好 &lt;code&gt;h-&amp;gt;path&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;遍历符号表，对于 EXPORT 类型调用 dlexport() 将当前符号加载时在内存中的绝对地址填写到数据结构中；对于 IMPORT 类型调用 dlsym() 在数据结构中查找地址并将本文件符号表中的 offset 填上正确的值；对于 LOAD 型调用 dlload() 加载一个新的文件，dlload() 的本质是递归地调用 dlopen()，不过它会记录当前已经打开过的文件，保证不会重复加载同一个动态库。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 dlopen() 的基础上， &lt;code&gt;gcc&lt;/code&gt; &lt;code&gt;readdl&lt;/code&gt; &lt;code&gt;objdump&lt;/code&gt; &lt;code&gt;interp&lt;/code&gt; 四个工具的实现是简单的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;gcc&lt;/code&gt; 工具实际上使用的是外部 &lt;code&gt;gcc&lt;/code&gt; 中的汇编器，我们要求汇编器生成 64 位架构的位置无关代码，然后用 &lt;code&gt;objcopy&lt;/code&gt; 工具把二进制文件的代码节复制出来，输出到一个 dl 文件中。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;readdl&lt;/code&gt; 工具首先调用 dlopen() 打开对应的文件，然后遍历整个符号表，根据 type 打印相应的信息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;objdump&lt;/code&gt; 工具首先调用 dlopen() 打开对应文件，然后把反汇编的工作交给 ndisasm 工具，&lt;code&gt;objdump&lt;/code&gt; 主要负责扫描符号表，看当前地址是不是一个新函数，并把函数名打印出来。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;interp&lt;/code&gt; 工具首先调用 dlopen() 打开对应文件，然后在符号表中寻找是 main 的符号，跳转到 main 的首地址开始执行，并将 main() 的返回值喂给 exit() 退出 dlbox。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们很快会发现我们设计的二进制文件格式有很多可改进的地方：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;我们的字符串名时常达不到上限，这使得二进制文件中有大量的 0。我们应该将所有的名字放在一个字符串常量池中，然后其他地方保存指向字符串的指针。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们每个 &lt;code&gt;.dl&lt;/code&gt; 文件中只有一个代码段，这个代码段是可读可写可执行的。我们希望有更多的代码段，不同的段有不同的权限，这就有了 program header table。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在我们自己的二进制文件格式中，来自外部库的函数需要在前面加上 DSYM() 以确保被编译成一个 &lt;code&gt;call *sym(%rip)&lt;/code&gt; 指令。但实际情况下我们写代码时并不会标注一个函数究竟时来自外部库的函数还是来自外部编译单元的函数——前者必须要到加载的时候才能确定位置，后者在链接的时候就能确定。因此我们不得不将所有的函数都编译成 DSYM() 的形式。这是一个万能的形式，但这种跳转相较于直接相对于 PC 的跳转多了一次访存，效率低。&lt;/p&gt;
&lt;p&gt;我们可以考虑这样一种处理方式：我们准备一个叫 PLT 的东西存储在可执行文件里，向函数 f 的跳转统一编译为静态的跳转到本文件的 f@plt() 函数的简单跳转。这样链接的时候如果发现 f() 其实是来自外部编译单元的函数，就修改一下跳转的目标函数；如果 f() 是外部库的函数，就在 f@plt() 中加一条 &lt;code&gt;jmp *off(%rip)&lt;/code&gt; 指令。这样我们编译时可以统一使用静态的跳转指令。加载时填写好各个 symbol 的加载时地址后，jmp 指令就可以正常工作了。&lt;/p&gt;
&lt;p&gt;这里存储各个 symbol 地址，在加载时填写的东西就叫 global offset table (GOT)，用于间接跳转的东西就叫 procedure linkage table (PLT)。我们独立发明了 PLT 和 GOT 的概念！&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 18: Xv6 Code Guide</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec18/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec18/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Xv6 中的 &lt;code&gt;.d&lt;/code&gt; &lt;code&gt;.sym&lt;/code&gt; &lt;code&gt;.asm&lt;/code&gt; 文件是什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;.d&lt;/code&gt; 文件描述了 Makefile 中文件所需的依赖关系。我们考虑如下程序：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-makefile&#34;&gt;a.o: a.c
	gcc -c a.c
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// a.c
#include &amp;quot;a.h&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// a.h
// Cannot compile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Makefile 的逻辑是：&lt;code&gt;a.o&lt;/code&gt; 依赖文件 &lt;code&gt;a.c&lt;/code&gt;，在执行 make 时，如果 &lt;code&gt;a.c&lt;/code&gt; 相较于上一次 make 发生过改动，则会再次执行编译指令，如果没有改动则不执行。但当我们的 &lt;code&gt;a.c&lt;/code&gt; include 了 &lt;code&gt;a.h&lt;/code&gt; 之后，实际上 &lt;code&gt;a.o&lt;/code&gt; 多了一个间接的依赖关系：当 &lt;code&gt;a.h&lt;/code&gt; 发生改动时，我们也应该重新执行编译指令。但很遗憾，除非在 Makefile 中添加 &lt;code&gt;a.h&lt;/code&gt; 依赖，否则 Makefile 不会自己做到这一点。&lt;/p&gt;
&lt;p&gt;大型项目中一个 C 程序可能有很多很多的 include。如果将这些 include 全部填到 Makefile 中，Makefile 将变得难以维护。因此我们利用编译器生成了 &lt;code&gt;.d&lt;/code&gt; 文件，&lt;code&gt;.d&lt;/code&gt; 文件中包含了一个程序依赖的头文件列表，且这个列表是 Makefile 可以直接解析的，这样我们解决了依赖问题。&lt;/p&gt;
&lt;h2 id=&#34;xv6-framework&#34;&gt;Xv6 Framework&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;/kernel&lt;/code&gt; 是内核代码，Makefile 会将所有的源代码文件编译后根据 &lt;code&gt;/kernel/kernel.ld&lt;/code&gt; 的链接脚本链接生成一个 &lt;code&gt;kernel&lt;/code&gt; 可执行文件。&lt;code&gt;/user&lt;/code&gt; 是用户程序代码，Makefile 会给将每个形如 &lt;code&gt;name.c&lt;/code&gt; 的用户程序编译生成一个 &lt;code&gt;_name&lt;/code&gt; 可执行文件。&lt;code&gt;/mkfs&lt;/code&gt; 是生成文件系统的代码，&lt;code&gt;/user&lt;/code&gt; 中所有下划线开头的可执行文件会被放入文件系统。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;工具的配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;好的工具会提升阅读代码的体验，使用 vscode 是一个很好的选择。为 vscode 添加正确的 &lt;code&gt;compile_command.json&lt;/code&gt; 可以使 vscode 正确地跳转。&lt;code&gt;compile_command.json&lt;/code&gt; 的原理是提供每个文件依赖的 include path。我们可以用 bear 工具直接爬 &lt;code&gt;make qemu&lt;/code&gt; 的信息，它会自动生成 &lt;code&gt;.json&lt;/code&gt; 文件。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;code-xv6-system-call&#34;&gt;Code: xv6 System Call&lt;/h2&gt;
&lt;p&gt;因为启动第一个进程的时候 xv6 还没有初始化文件系统，无法通过 exec() 系统调用来加载 image，所以 xv6 的第一个进程 initcode 是写死的一段汇编代码 (在 forkret() 中有初始化文件系统的相关代码)，具体的信息可以见 MIT 6.S081 Lecture 03。&lt;/p&gt;
&lt;p&gt;通过 &lt;code&gt;ecall&lt;/code&gt; 指令走 trampoline 然后进入 usertrap() 的流程可以见 MIT 6.S081 Lecture 6。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;为什么我在 GDB 中加断点 &lt;code&gt;b *0x0&lt;/code&gt; 会报错：&amp;ldquo;cannnot access memory?&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2020版之前的 xv6 需要在 &lt;code&gt;.gdbinit.tmpl-riscv&lt;/code&gt; 中添加一条配置：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;set riscv use-compressed-breakpoints yes
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 19: Context Switching</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec19/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec19/</guid>
      <description>&lt;p&gt;如果我们的用户程序有死循环，计算机并不会被卡死——因为操作系统有进程调度；但操作系统有对整个计算机完全的掌控权，如果在操作系统代码中加一个死循环，那计算机就真的卡死了。&lt;/p&gt;
&lt;h2 id=&#34;virtualization-of-cpus&#34;&gt;Virtualization of CPUs&lt;/h2&gt;
&lt;p&gt;每一个进程都是一个状态机，其中有寄存器、内存，看内存的 &amp;ldquo;VR 眼镜&amp;rdquo; (页表) 等等。操作系统是一个状态机的管理者：它要维护各个进程的状态机，此外内核对应的状态机也归 OS 管理。正在运行的状态机的状态保存在硬件上 (CPU, DRAM)，其他未运行的进程的状态机以某种方式被暂存起来。&lt;/p&gt;
&lt;p&gt;现代操作系统通常借助时钟中断，使用抢占式多任务的方式来在状态机之间切换。中断相当于一个强行插入的 ecall，打断正在运行的执行流。操作系统负责将这个进程当前的状态机从硬件上复制下来，挑选下一个准备执行的进程，然后将其状态机搬上硬件。&lt;/p&gt;
&lt;h2 id=&#34;code-xv6-trapframe--thread-switching&#34;&gt;Code: Xv6 trapframe &amp;amp; Thread Switching&lt;/h2&gt;
&lt;p&gt;该部分内容可以参考 MIT 6.S081 Lecture 6 和 Lecture 11。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 20: Scheduling</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec20/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec20/</guid>
      <description>&lt;p&gt;处理器调度问题的简单假设 (1960s)：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;系统中有一个处理器&lt;/li&gt;
&lt;li&gt;系统中有多个进程/线程共享 CPU
&lt;ul&gt;
&lt;li&gt;包括系统调用 (进程/线程的一部分在内核代码中)&lt;/li&gt;
&lt;li&gt;偶尔会等待 I/O 返回，不使用 CPU。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;policy&#34;&gt;Policy&lt;/h2&gt;
&lt;h3 id=&#34;round-robin&#34;&gt;Round-Robin&lt;/h3&gt;
&lt;p&gt;按照时间片轮转，轮流运行所有的进程/线程。&lt;/p&gt;
&lt;p&gt;问题：假设当前有一个前台的 vim 进程和很多计算型的后台进程，如果使用 round robin，很容易出现前台 vim 进程很卡的现象 (vim 进程一旦被切出去了，就要等一整轮才能获得一个时间片)。&lt;/p&gt;
&lt;p&gt;我们希望引入某种“优先级”，使得和用户交互比较频繁的前台进程可以获得更高的调度优先级，优化用户的使用体验。&lt;/p&gt;
&lt;h3 id=&#34;unix-niceness&#34;&gt;UNIX Niceness&lt;/h3&gt;
&lt;p&gt;UNIX 的 niceness 是一个 &lt;code&gt;-20 ... 19&lt;/code&gt; 的整数，nice 值越高的进程越”和善“，越容易让出 CPU。&lt;/p&gt;
&lt;p&gt;基于优先级的调度策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在一些实时的操作系统中 (尤其是物理相关，比如火箭/机械手 etc.)，CPU 会完全根据优先级，每次选择 niceness 最低的进程执行。这样的做法是有道理的：比如火箭要运行应急程序，我们自然不希望时钟中断后收集火箭运行数据的进程插入进来执行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在桌面操作系统中，让“坏人”霸占 CPU 的做法不太可取。在 Linux 中，niceness 相差 10，CPU 资源获得率相差大约 10 倍。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我们可以做一个实验来验证这一点：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;taskset -c 0 nice -n 19 yes &amp;gt; /dev/null &amp;amp;
taskset -c 0 nice -n  9 yes &amp;gt; /dev/null &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 taskset 命令可以指定让一个进程在某个 CPU 核上执行。创建这两个后台进程后，我们可以通过 top 来观测它们的 CPU 占用情况。&lt;/p&gt;
&lt;p&gt;// office hour: 为什么我使用这两个指令创建出的进程 nice 值是 14 和 19？&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mlfq-multi-level-feedback-queue&#34;&gt;MLFQ (Multi-level Feedback Queue)&lt;/h3&gt;
&lt;p&gt;仍然考虑 round-robin 在遇到一堆计算密集型线程和一个交互型线程时的问题。我们现在考虑：能否让操作系统观测进程的行为，然后动态地调整进程的优先级？这就是 MLFQ 的基本思想。&lt;/p&gt;
&lt;p&gt;操作系统观测每个进程对时间片的使用情况：如果一个进程每次都用满整个时间片，那么它是一个“坏进程”，我们就适当降低它的优先级；如果一个进程经常 sleep()，等待 I/O etc. CPU 占用比较小，那么它是一个“好进程”，我们就适当增加它的优先级。我们动态调整进程的优先级，为每种优先级创建一个 round robin 的队列。&lt;/p&gt;
&lt;p&gt;当然，一个纯粹的”坏进程”可以通过如下的方式来欺骗这样的策略：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;while (1) {
    compute();
    if (时间片快用完了) usleep(1);	
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此外，如果像 Vim 这样的高优先级进程过多，后台的计算进程可能就会几乎卡死；进程的“好坏”其实是动态变化的，不能“一棍子打死”等等。操作系统的设计者会试图补救这些问题，比如 priority boost 策略会每隔一段时间把所有进程的优先级拉平，使得进程有“重新做人”的机会。&lt;/p&gt;
&lt;p&gt;如果我们考虑进程之间的通信，这个问题就会变得更加复杂：假设进程中有 producer/consumer，以及其他的 &lt;code&gt;while(1)&lt;/code&gt; 线程，在 round-robin 中 producer/consumer 会频繁让出 CPU，这导致 &lt;code&gt;while(1)&lt;/code&gt; 获得了过多的运行时间；在 MLFQ 中，producer/consumer 因为频繁让出 CPU 会获得高优先级，但这种让出并不是出于人机交互的目的——producer/consumer 组合起来仍然是一个纯计算任务，因此它获得高优先级也是不合理的。&lt;/p&gt;
&lt;h3 id=&#34;cfs-complete-fair-scheduling&#34;&gt;CFS (Complete Fair Scheduling)&lt;/h3&gt;
&lt;p&gt;完全公平调度的指导思想很简单：让每个进程公平地享用 CPU。因此操作系统内核会记录每个进程运行的时间，每次调度器选择当前执行时间最少的进程执行。&lt;/p&gt;
&lt;p&gt;为了避免落入 round robin 的结局，CFS 通过类似于“变速齿轮”的方法实现优先级：每个进程实际上享用的是相同的虚拟运行时间 (vruntime)，但不同进程的虚拟运行时间和物理运行时间的比例不同：优先级高的进程一个单位的 vruntime 对应更长的物理时间，反之亦然。这种方式类似于变速齿轮是因为它实际上“欺骗”了进程：进程能直接感受到的物理时间是虚拟的。进程其实可以通过其他方式感知到“不对劲”：比如 &amp;ldquo;我 1s 怎么只执行了 1M 的指令？&amp;rdquo; 但现在的进程还没有这样的能力。&lt;/p&gt;
&lt;h4 id=&#34;cfs-complexity-new-processthread&#34;&gt;CFS Complexity: New Process/Thread&lt;/h4&gt;
&lt;p&gt;考虑如下一段代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;

int main () {
    setbuf(stdout, NULL);
    int pid = fork();
    if (pid &amp;lt; 0) perror(&amp;quot;fork&amp;quot;);
    else if (pid == 0)
        for (const char *s = &amp;quot;child&amp;quot;; *s; s++) putchar(*s);
    else
        for (const char *s = &amp;quot;parent&amp;quot;; *s; s++) putchar(*s);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在较新版本的 linux 内核中，多次运行上述程序会看到几乎总是 parent 先被打印。这是因为现在的内核是 parent first 的，曾经的内核版本是 child first，这其中存在一个权衡问题：绝大部分情况下 fork() 执行完会紧接着执行 execve()，我们的 fork() 是 copy-on-write 的，如果先执行子进程，有很大概率 execve() 会销毁原先的页表，这样父进程执行时就不需要额外的复制操作；但先执行子进程意味着当前 CPU 的 cache, TLB 等需要被全部刷新，这又会有一个立即可见的额外代价。&lt;/p&gt;
&lt;p&gt;除了 parent/child first 问题，另一个问题是：我们的 CFS 应该为这个新进程创建怎样的 vruntime? 早期的版本会给子进程较少的 vruntime，也就是让它有机会稍微多执行一点。但这个策略导致恶意程序可以疯狂 fork 子进程来占据 CPU，因此现在的内核代码中子进程继承父进程的 vruntime。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// linux kernel
static void task_fork_fair(struct task_struct *p) {
    ...
    if (curr) {
        update_curr(cfs_rq);
        se-&amp;gt;vruntime = curr-&amp;gt;vruntime; // &amp;lt;------------ here
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;cfs-complexity-io&#34;&gt;CFS Complexity: I/O&lt;/h4&gt;
&lt;p&gt;考虑如下场景：有一个进程等待了 1min 的 I/O 操作，这段时间内它一直处于 blocked 的状态，不会被调度上 CPU。那么 I/O 操作结束后，该进程的 vruntime 会显著低于别的进程。从而未来的相当长时间内 CPU 会被这个 I/O 进程独占，这显然不是我们想看到的情况。&lt;/p&gt;
&lt;p&gt;操作系统理应在 I/O 进程结束等待后将其 vruntime 补齐到一个基准点，这个基准点到地设置在哪里又是很有讲究的事。&lt;/p&gt;
&lt;h4 id=&#34;cfs-complexity-integer-overflow&#34;&gt;CFS Complexity: Integer Overflow&lt;/h4&gt;
&lt;p&gt;在一个需要长时间运行的系统中，我们即使用 &lt;code&gt;uint64_t&lt;/code&gt; 来存储 vruntime 也要面临溢出的问题。这意味着我们不能用 vruntime 的绝对大小来比较两个进程的优先级。&lt;/p&gt;
&lt;p&gt;Linux 中采取的解决方案是：保证任意时刻系统中最大的 vruntime 和 最小的 vruntime 之差不超过数轴的一半 (i.e. &lt;code&gt;UINT64_MAX / 2&lt;/code&gt; )。这样我们可以用比较相对大小的方式来解决问题：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// linux kernel
bool less(uint64_t a, uint64_t b) {
    return (int64_t)(a - b) &amp;lt; 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以考虑一下 a 是很小的正数 (溢出了一轮)，b 是很大的正数 (还没溢出) 的情况，此时应有 $a&amp;gt;b$。$a-b$ 的结果是小于 0 的，但由于这个值大于 &lt;code&gt;INT64_MAX&lt;/code&gt;，所以强制转换成 &lt;code&gt;int64_t&lt;/code&gt; 后会下溢出变成正的，从而正确实现功能 (非常 tricky 的代码)。&lt;/p&gt;
&lt;h4 id=&#34;cfs-complexity-implementation&#34;&gt;CFS Complexity: Implementation&lt;/h4&gt;
&lt;p&gt;我们要实现一个数据结构，支持高效的插入、删除、找最小值等。Linux 采取了主流的红黑树设计，但我们的数据结构要保证并行状态下的正确性，为了效率还不能上大锁……&lt;/p&gt;
&lt;h2 id=&#34;the-first-bug-on-mars&#34;&gt;The First Bug on Mars&lt;/h2&gt;
&lt;p&gt;在实时操作系统中，高优先级意味着必须先被调度。简单的调度处理可能会出现优先级反转的情况：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void high()   {sleep(1); mutex_lock();}
void medium() {while (1);}
void low()    {mutex_lock();}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;假设低优先级进程先执行，获得了锁；然后 medium() 到来，将 low() 踢出 CPU，low() 带着锁进入了睡眠；这时 high() 来了但发现无法获得锁——因为锁在 low() 手里。high() 因为锁的语义等待 low() 是可以接受的 (锁可能很快就被释放)，但 low() 在等待 medium()，这导致 high() 间接等待了一个与自己毫无关系的进程 medium()，这是不可接受的。&lt;/p&gt;
&lt;p&gt;这个 bug 在第一辆火星车上真实地发生过，这导致了火星车系统的重启。解决优先级反转地方法通常有优先级继承 (priority inheritance)/优先级提升 (priority ceiling)，简单来说，当 high() 因为锁资源等待时，low() 的优先级可以暂时提升到和 high() 一样高，这样很快 low() 就可以把 medium() 踢下 CPU 运行，释放了锁 high() 就可以正常执行了，low() 的优先级也恢复最低。&lt;/p&gt;
&lt;h2 id=&#34;multi-core-scheduling&#34;&gt;Multi-core Scheduling&lt;/h2&gt;
&lt;p&gt;多核处理器上的调度处于一个两难的境地：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果简单地将线程分配到处理器，那么容易出现“一核有难他核围观”的局面。&lt;/li&gt;
&lt;li&gt;如果简单地将线程安排到一个空闲处理器上，那么之前的 cache/TLB 就全部白给了。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;complexity-multi-user&#34;&gt;Complexity: Multi-user&lt;/h3&gt;
&lt;p&gt;假设用户 A 和 B 共用一台服务器，A 的程序只能单线程，而 B 的程序可以 1000 个线程，那就会出现 A 只获得了很少的资源的情况。糟糕的是，A 不能通过提高自己线程的优先级的方法来解决这个问题：在 Linux 中，非特权用户只能提升自己的 nice 值，不能降低。&lt;/p&gt;
&lt;p&gt;Linux 采用的解决方案是 namespaces control groups，大致思想是创建了“操作系统中的操作系统”，将属于一个用户的进程归成一组管理。&lt;/p&gt;
&lt;h3 id=&#34;complexity-biglittle-and-energy-consumption&#34;&gt;Complexity: Big.LITTLE and Energy Consumption&lt;/h3&gt;
&lt;p&gt;现在的 CPU 有大小核的概念：大核频率高，小核频率小，我们在调度的时候不得不将这些因素考虑进来。此外，现在的软件可以配置 CPU 的工作模式：CPU 的频率越低，它的延迟越高，但能耗越小，吞吐量越高。那么如何根据不同类型的任务调整 CPU 工作模式以及调度也是非常复杂的问题。&lt;/p&gt;
&lt;h3 id=&#34;complexity-non-uniform-memory-access&#34;&gt;Complexity: Non-Uniform Memory Access&lt;/h3&gt;
&lt;p&gt;共享内存在某种程度上只是一个假象。L1 Cache 花了巨大的代价才让各个 CPU 看到了共享的内存。多个线程在同一个/不同的核上跑，效率可能有很大的区别。&lt;/p&gt;
&lt;p&gt;在实际情况下，连”核心越多，速度越快”的假设都可能是错的。以 &lt;code&gt;sum-atomic.c&lt;/code&gt; 为例，如果我们用命令&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;tastset -c 0 ./sum-atomic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;来让 &lt;code&gt;sum-atomic.c&lt;/code&gt; 的所有线程只工作在一个核上，会发现运行时间竟小于多个核！调度器把程序当作黑盒的假设可能是不对的。&lt;/p&gt;
&lt;h3 id=&#34;complexity-cpu-hot-plug&#34;&gt;Complexity: CPU Hot-plug&lt;/h3&gt;
&lt;p&gt;现在的 CPU 支持热插拔，可能运行一会儿会发现多了一个或者少了一个……&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;调度是一个非常复杂的问题，将这个任务完全丢给操作系统的调度器是不合理的。一种可能的想法是：让程序提供一些 scheduling hints 来指导调度行为。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 21: OS Design</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec21/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec21/</guid>
      <description>&lt;p&gt;操作系统的设计：一组对象+访问对象的 API；操作系统的实现：一个 C 程序完成上面的设计&lt;/p&gt;
&lt;p&gt;我们关心的问题是：操作系统到底应该提供什么样的对象和 API？&lt;/p&gt;
&lt;h2 id=&#34;monolithic-kernel&#34;&gt;Monolithic Kernel&lt;/h2&gt;
&lt;p&gt;Unix 系列：
&lt;a href=&#34;https://pubs.opengroup.org/onlinepubs/9699919799/mindex.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Open Group Base Specifications Issue 7 (2018 Ed.)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Windows 系列：
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/apiindex/windows-api-list&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Windows API Index&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;不同的 API 系列可以互相模拟，于是有了 WSL 和 WINE。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Real Operating Systems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;真正的操作系统要考虑的事情总是比想象中的复杂。比如我们写一个简单的重命名函数：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void rename_file(char *oldname, char *newname) {
 char buf[SIZE];
 int fd = open(oldname, O_RONLY);
 fread(fd, buf);
 close(fd); delete(oldname);
 // &amp;lt;------------------
 fd = open(newname, O_CREAT | O_TRUNC | O_WONLY);
 write(fd, buf, sizeof(buf));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果在箭头指向的时刻操作系统突然掉电了，那么文件内容就全部丢失了！这显然是不合理的现象。阅读 rename() 系统调用的手册，可以看到手册保证了删除旧文件，创建新文件操作的原子性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;microkernel&#34;&gt;Microkernel&lt;/h2&gt;
&lt;p&gt;复杂系统的正确性难以保证。像 Linux 这样以 C 为主要语言的操作系统，C 的 undefined behavior 会给系统带来无穷的灾难：比如文件系统一旦出错，整个内核中的任何模块都可能受到损坏。&lt;/p&gt;
&lt;p&gt;微内核的想法是：将尽可能多的功能用普通进程实现，将问题隔离在进程级。比如文件操作，UNIX 的 write() 会陷入内核，但另一种想法是：调用一个 remote_write() 和一个 File server 交互，FS进程有访问磁盘的权限即可。&lt;/p&gt;
&lt;p&gt;一些好的想法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一些和状态机管理密切相关的系统调用没法被搬出内核：比如 fork(), mmap()。&lt;/li&gt;
&lt;li&gt;如果操作系统提供一个 mmio() 系统调用，让进程通过访问内存的方式来控制设备寄存器、磁盘 etc，那么设备驱动代码，文件系统代码都可以放在用户态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;赋予进程最少的权限，就能降低错误带来的影响。&lt;/p&gt;
&lt;h3 id=&#34;minix&#34;&gt;Minix&lt;/h3&gt;
&lt;p&gt;Minix 是一个具有跨时代意义的教学操作系统，它采取的是微内核设计。在 Minix 2.0 中，内核只提供了两个 API：send 和 receive。基于这两个系统调用，我们实现一些 RPC (remote procedure call) 来实现进程之间的通信。Kernel 里只有很少的状态机相关的机制：比如中断，异常，时钟驱动，内存映射 etc. 其他的功能，比如文件系统，设备驱动，网络 etc. 都在用户态。跨模块的调用会跨越进程边界 i.e. 地址空间的切换等，这样一个模块的错误就可以被隔离在本地，UB 不会波及到模块外部。&lt;/p&gt;
&lt;h3 id=&#34;sel4&#34;&gt;seL4&lt;/h3&gt;
&lt;p&gt;seL4 是第一个完成了正确性证明、运行时间上界证明的微内核。&lt;/p&gt;
&lt;p&gt;seL4 的证明思路大致如下：以 &lt;code&gt;thread-os.c&lt;/code&gt; 的 round-robin 调度器为例，首先我们用适合描述行为的语言建立一个模型 (这里以 python 为例, seL4 在这里实际上有两层建模)：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def rr_sched(cpu):
    cpu.threads = cpu.threads[1:] + cpu.threads[:1]
    assert anything_you_need
    return cpu.threads[0]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以用 model checker 确认这个 high level 语言编写的程序的正确性，然后我们希望证明 &lt;code&gt;thread-os.c&lt;/code&gt; 和 python 代码的行为等价性。除去访问硬件的部分 (AbstractMachine)，操作系统本质上是纯计算的程序 (数学模型)，因此我们只需要观测所有的 AM call 行为是否等价即可。如果我们使用被 verified 的编译器，我们还可以进一步证明 C 程序和汇编指令的等价性。&lt;/p&gt;
&lt;h2 id=&#34;unikernel&#34;&gt;UniKernel&lt;/h2&gt;
&lt;p&gt;很早的时候就有了 exokernel (外核) 的概念，即操作系统不应该有任何的策略，只需要提供最小的硬件抽象。在有了虚拟机的时代，这催生了 unikernel：将操作系统的内核代码和应用程序直接链接起来跑，因为硬件都是虚拟机抽象出来的，所以没有安全问题。这时的 OS 类似于一个 libOS 的功能。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 22: OSLab Speedrun</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec22/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec22/</guid>
      <description>&lt;h2 id=&#34;l1&#34;&gt;L1&lt;/h2&gt;
&lt;p&gt;一把大锁保平安策略：全局用一把锁，把所有需要保护的代码都用 &lt;code&gt;atomic {}&lt;/code&gt; 框起来。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define atomic \
	for (int __i = (lock(), 0); i &amp;lt; 1; unlock(), __i++)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个 for 循环的语义如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;lock();
__i = 0;	// C语言逗号表达式总是取后面的值
check i &amp;lt; 1 =&amp;gt; yes
body
__i++;
unlock();
check i &amp;lt; 1 =&amp;gt; no, break
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用这个 &lt;code&gt;atomic {}&lt;/code&gt; 我们要保证程序不能在 atomic 内部 break 或 return。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Programming Philosophy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在书写不是 performance bottle neck 的代码时，我们应该尽可能将代码写得简单，尽量不要写奇技淫巧，以牺牲可读性、可维护性为代价换取微不足道的性能。此外，我们应该在程序中添加足够的 assertion 来尽早抓取到 bug。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;l2&#34;&gt;L2&lt;/h2&gt;
&lt;p&gt;一个允许嵌套的大锁：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int locked;
void lock() {
    int c = cpu_current();
    bool i = ienabled();
    
    iset(false);
    nest[c]++;
    if (nest[c] == 1) {
        intena[c] = i;
        while (atomic_xchg(&amp;amp;locked, 1));
    }
}
void unlock() {
    int c = cpu_current();
    
    nest[c]--;
    if (nest[c] == 0) {
        atomic_xchg(&amp;amp;locked, 0);
        if (intena[c]) iset(true);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Programming Philosophy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在写代码的过程中，在一行里写很多表达式，让一行变得很长是一种 bad practice。我们可以适时地用一些临时变量保存一些值，这样可以大幅提高代码的可读性和可维护性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;线程创建：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct task {
    Context ctx[4];
    int nc;
    int stk[STK_SZ];
};
struct percpu {
    struct task *avail[NPROC];
    int n, c;
}percpu[MAX_CPU];
struct task *kcreate(void *entry, void *arg, int cpu) {
    struct task *t = kalloc(sizeof(struct task));
    atomic {
        t-&amp;gt;ctx[0] = *kcontext((Area){&amp;amp;t-&amp;gt;stk, &amp;amp;t-&amp;gt;stk + STK_SZ}, entry, arg);
        t-&amp;gt;nc = 1;
        percpu[cpu].avail[percpu[cpu].n++] = t;
    }
    return t;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一个最简单的 round-robin 调度器：保存当前线程的上下文，切换到下一个线程，返回目标线程的上下文。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define CPU (&amp;amp;percpu[cpu_current()])
#define current (CPU-&amp;gt;avail[CPU-&amp;gt;c])

Context *trap(Event ev, Context *ctx) {
    current-&amp;gt;ctx[current-&amp;gt;nc++] = *ctx;
    
    atomic {
        CPU-&amp;gt;c = (CPU-&amp;gt;c + 1) % (CPU -&amp;gt; n);
    }
    assert(!ienabled());
    
    return &amp;amp;(current-&amp;gt;ctx[--current.nc]);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;信号量最简单的语义就是：在没有资源的时候 yield()。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct semaphore {
    int count;
}
void sem_wait(sem_t *sem) {
    bool succ = false;
    while (!succ) {
        atomic {
            if (sem-&amp;gt;count &amp;gt; 0) {
                sem-&amp;gt;count--;
                succ = true;
            }
        }
        if (!succ) yield();
    }
}
void sem_post(sem_t *sem) {
    atomic {
        sem-&amp;gt;count++;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Programming Philosophy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上述的信号量实现是一个比较基础的实现。一个性能更好的实现是调用 sleep()，当前条件不满足的话就释放自旋锁并将自己加入一个等待队列，但这种实现就会引入更多可能错误的点。事实上，我们可以为各个模块都准备一份 functional 的代码 (非常简单，保证正确，类似于模型) 和一份注重性能的代码。当项目出现 bug 的时候，我们就将一个一个模块换回 dummy 的实现，从而快速定位问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;l3&#34;&gt;L3&lt;/h2&gt;
&lt;p&gt;ucreate 和 kcreate 结构差不多，这次我们使用 ucontext 创建初始上下文。我们假设代码段总是被加载到地址空间的开头。此外，现在 task 结构体中还需要加入一个地址空间 &lt;code&gt;AddrSpace as&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;task_t *ucreate(int cpu) {
    task_t *t = kalloc(sizeof(task_t));
    atomic {
        protect(&amp;amp;t-&amp;gt;as);
        t-&amp;gt;ctx[0] = *ucontext(&amp;amp;t-&amp;gt;as, (Area){&amp;amp;(t-&amp;gt;stk), &amp;amp;(t-&amp;gt;stk)+STK_SIZE}, &amp;amp;t-&amp;gt;as);
        t-&amp;gt;nc = 1;
        percpu[cpu].avail[percpu[cpu].n++] = t;
    }
    return t;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 os_trap 中，我们要检查更多的事件，例如 page fault，syscall 等：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;switch (ev.event) {
    case EVENT_PAGEFAULT: {
        pagefault(ev, ctx);
        break;
    }
    case EVENT_SYSCALL: {
        assert(current-&amp;gt;nc == 1);
        current-&amp;gt;ctx[0].GPRx = syscall(ctx);
        break;
    }
    case EVENT_ERROR: {
        panic();
        break;
    }
    default: break;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;缺页异常我们的处理是在虚拟地址空间中为当前虚拟地址映射一个物理页面。此外如果缺少的是第一个页面 (即 init 进程的代码段) 我们要把代码段拷贝进来。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void pgmap(task_t *t, void *va, void *pa) {
    t-&amp;gt;va[t-&amp;gt;np] = va;
    t-&amp;gt;pa[t-&amp;gt;np] = pa;
    t-&amp;gt;np++;
   	map(&amp;amp;t-&amp;gt;as, va, pa, MMAP_READ | MMAP_WRITE);
}
void pagefault(Event e, Context *c) {
    atomic {
        AddrSpace *as = &amp;amp;(current-&amp;gt;as);
        void *pa = kalloc(as-&amp;gt;pgsize);
        void *va = (void *)(e.ref &amp;amp; ~(as-&amp;gt;pgsize - 1L));
        
        if (va == as-&amp;gt;area.start) memcpy(pa, _init, _init_len);
		
        pgmap(current, va, pa);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;处理各种系统调用：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int syscall(Context *c) {
    int ret = 0;
    ise(true);
    switch (c-&amp;gt;GPRx) {
        case SYS_kputc: {
            putch(c-&amp;gt;GPR1);
            break;
        }
        case SYS_sleep: {
            uint64_t wakeup = io_read(AM_TIMER_UPTIME).us + 1000000L * c-&amp;gt;GPR1;
            while (io_read(AM_TIMER_UPTIME).us &amp;lt; wakeup) yield();
        }
        case SYS_fork: {
            atomic {
                struct task *t = ucreate(cpu_current());
                
                uintptr_t rsp0 = t-&amp;gt;ctx[0].rsp0;
                void *cr3 = t-&amp;gt;ctx[0].cr3;
                
                t-&amp;gt;ctx[0] = *c;
                t-&amp;gt;ctx[0].rsp0 = rsp0;
                t-&amp;gt;ctx[0].cr3 = cr3;	// 子进程的页表和内核栈不能复制父进程
                t-&amp;gt;ctx[0].GPRx = 0;		// 子进程的返回值应该是0
                
               	for (int i = 0; i &amp;lt; current-&amp;gt;np; i++) {
                    int sz = current-&amp;gt;as.pgsize;
                    void *va = current-&amp;gt;va[i];
                    void *pa = current-&amp;gt;pa[i];
                    void *npa = kalloc(sz);
                    memcpy(npa, pa, sz);
                    pgmap(t, va, npa);
                }
            }
        }
    }
    iset(false);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 23: 1Bit Storage</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec23/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec23/</guid>
      <description>&lt;p&gt;机器指令模型只有两种当前状态：寄存器和物理内存。这些状态在物理世界中应当有真实的对应。我们的需求是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以寻址：比如可以根据编号访问某个单元格。&lt;/li&gt;
&lt;li&gt;访问速度尽可能快 (甚至不惜掉电后丢失状态)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“当前状态”的存储&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;延迟线 (delay line)：像一根存储了数据的绳子不断地转，信号会随着时间衰减，因此数据会不断通过放大器来保持不丢失。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;磁芯内存 (Magnetic core)：类似于一个二维的小磁铁阵列，当给第 $i$ 行第 $j$ 列加电时，坐标在 $(i,j)$ 处的小磁铁就有足够大的电流可以旋转。磁芯内存是 non volatile memory - 掉电后 core 的信息是不会丢失的。但信息的改变依赖小磁铁转动这一物理动作，因此速度不够高。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Segmentation fault (core dumped)&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里的“核心已转储”的说法就是源自于磁芯内存。Linux 系统中默认的 core file size 是 0 (可以通过命令 &lt;code&gt;ulimit -a&lt;/code&gt; 查看)，可以通过 &lt;code&gt;ulimit -c size&lt;/code&gt; 来修改。&lt;/p&gt;
&lt;p&gt;此外，在 Ubuntu 系统中，我们还需要在 root 权限下通过&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo core &amp;gt; /proc/sys/kernel/core_pattern
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改对应文件。这样发生段错误后，系统将在程序当前目录下生成一个 core 文件。我们可以用 &lt;code&gt;segfault.c&lt;/code&gt; 做一个实验。段错误后，使用 &lt;code&gt;gdb segfault core&lt;/code&gt; 再次运行，就可以恢复 crash 的现场。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SRAM/DRAM：flip-flop&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;magnetism&#34;&gt;Magnetism&lt;/h2&gt;
&lt;p&gt;用小磁铁的方向来表示 0 和 1，不同方向的小磁铁会有不同方向的磁场，从而可以感应出不同方向的电流。此外，电流产生的磁场也可以用来修改小磁铁的方向。&lt;/p&gt;
&lt;h3 id=&#34;magnetic-tape-1928&#34;&gt;Magnetic Tape (1928)&lt;/h3&gt;
&lt;p&gt;磁带本质上是一个 1D 的存储设备，但我们可以通过把磁带卷起来使其变成一个近似 2D 的存储设备。因此可以在小空间内存放大量的 bit。在中间位置放一个读写头，然后通过机械转轮来定位当前读写的位置。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：便宜，容量大，存储时间相对较长&lt;/li&gt;
&lt;li&gt;缺点：完全无法随机读取 (只能靠机械转轮移动)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此磁带主要用于大量冷数据的长时间存储。&lt;/p&gt;
&lt;h3 id=&#34;magnetic-drum-1932&#34;&gt;Magnetic Drum (1932)&lt;/h3&gt;
&lt;p&gt;磁鼓一定程度解决了磁带无法随机读取的问题：将磁带一圈一圈绕在一个金属棒上，然后在棒子的侧面放很多读写头，这样读取一个 bit 的时间控制在棒子转一圈的时间之内。磁鼓的缺点是：占用的空间太大了&lt;/p&gt;
&lt;h3 id=&#34;hard-disk-1956&#34;&gt;Hard Disk (1956)&lt;/h3&gt;
&lt;p&gt;将磁带内卷在一个二维平面上，中间是转轴。磁盘中只有一个读写头，但读写头上有一个电动机，读写头的移动可以使其快速定位磁带的某个圈，磁带的旋转可以使圈上某个位置的信息到达读写头的位置。这样不仅速度快，而且占用体积大幅下降。&lt;/p&gt;
&lt;p&gt;工程上对磁盘还有一些优化，比如在 z 轴上排列若干个圆盘，放置多个读写头等等。此外磁盘中的每个盘实际上不是用磁带绕出来的，而是使用了更先进的生产工艺。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：便宜，容量大，有勉强可用的随机读取能力&lt;/li&gt;
&lt;li&gt;缺点：可靠性低，存在机械部件，磁头划伤盘片可能导致数据丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;磁盘是当今计算机系统的主力数据存储。&lt;/p&gt;
&lt;p&gt;磁盘当中有很多事情是可以调度的，从前这个调度由操作系统负责，但现在的磁盘越做越复杂，很多内部参数已经超出了操作系统的控制，因此现代的磁盘通常会有一个片上系统 (system on chip, SoC)，这种写死的固件负责磁盘中的调度算法。&lt;/p&gt;
&lt;h3 id=&#34;floppy-disk-1971&#34;&gt;Floppy Disk (1971)&lt;/h3&gt;
&lt;p&gt;能不能将盘片和读写头分开，从而实现数据移动？这就有了软盘。刚开始软盘真的是软的，后来的 3.5 英寸软盘为了可靠性已经是硬的了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：价格低，数据可移动&lt;/li&gt;
&lt;li&gt;缺点：由于是暴露的存储介质，所以可靠性低，且数据密度不能太大。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pits&#34;&gt;Pits&lt;/h2&gt;
&lt;p&gt;在一个平整的平面上挖一些坑，这样光照在平整的地方可以很好地反射，照在坑上就不能很好地反射，从而实现 0 和 1。&lt;/p&gt;
&lt;h3 id=&#34;compact-disk-cd-1980&#34;&gt;Compact Disk (CD, 1980)&lt;/h3&gt;
&lt;p&gt;在反射平面 (1) 上挖上粗糙的坑 (0)，激光扫过表面，就可以读出信息。CD 的一大问题在于只读性——挖坑容易填坑难。有一些例如 PCM (phase-change material) 的材料可以做出 rewritable disk。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;优点：价格低，容量大，可靠性很高&lt;/p&gt;
&lt;p&gt;光盘的一个很有意思的优点是它很容易通过“压盘”来复制：我们可以制作一个母盘，在该挖坑的地方凸起，然后一张平整盘往上一压就是一张盘。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缺点：随机读取能力不高，改写困难。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;electricity&#34;&gt;Electricity&lt;/h2&gt;
&lt;p&gt;之前的持久存储介质都有一个致命的缺陷：存在一些机械部件，机械部件可靠性不高且速度跟不上，要跟上电路的速度，我们必须用电来做存储介质。&lt;/p&gt;
&lt;h3 id=&#34;solid-state-drive-ssd-1991&#34;&gt;Solid State Drive (SSD, 1991)&lt;/h3&gt;
&lt;p&gt;Flash memory 的 floating gate 的充电放电实现了 0-1。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;优点：大规模集成电路价格低，容量很大；flash memory 的最大优势在于读写速度，而且它有一个不讲道理的特性：容量越大速度越快 (电路级并行)；可靠性非常高：没有机械部件，所以可以随便摔。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缺点：几乎无。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;usb-flash-disk-1999&#34;&gt;USB Flash Disk (1999)&lt;/h3&gt;
&lt;p&gt;迅速击败软盘，成为人手 $n$ 个的移动存储设备。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Flash memory 有一个关键的问题：放电会放不干净，一个 cell 经过了成千上万次读写操作后，剩余的电子就会多到好像是 1 的状态，这个 cell 成为了一个 dead cell。&lt;/p&gt;
&lt;p&gt;该问题的解决方法类似于虚拟内存：在 OS 眼中不论是 SSD 还是 HDD 都类似于一个大数组，但事实上 SSD 里面有一个小型的计算机系统：系统会根据每个 cell 的读写次数，将所谓的 “100号cell&amp;quot; 映射到一个其他的 cell，就像一个 MMU 一样。这样可以保证每个 cell 使用次数差不多，也可以绕开一些 dead cell。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 24: I/O Devices</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec24/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec24/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;用户直接使用的其实并不是计算设备，而是 I/O 设备。CPU 只是一个无情的指令执行器，我们希望计算机可以感知外部世界的状态，并对外实施动作。&lt;/p&gt;
&lt;p&gt;I/O 设备就是与 CPU 交换数据的一组接口。I/O 设备会提供“几条约定好功能的线”，CPU 与设备通过握手信号可以从线上读出或写入数据。通常来说，CPU 和 I/O 设备交互的数据主要有状态 (比如 CPU 查看打印机是否空闲)，指令 (比如 CPU 让显示屏发光) 和数据 (比如 CPU 告诉打印机应该打印什么)。&lt;/p&gt;
&lt;p&gt;从抽象层的角度来说，CPU 完全不需要管 I/O 设备内部是怎么实现的，CPU 可以直接使用指令 (in/out/mmio) 和设备交换数据。但各种设备的复杂性还是使得驱动代码成为操作系统内核中非常庞大、bug非常多的一部分代码。&lt;/p&gt;
&lt;h3 id=&#34;example-uart&#34;&gt;Example: UART&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define COM1 0x3f8

static int uart_init() {
  outb(COM1 + 2, 0);   // 控制器相关细节
  outb(COM1 + 3, 0x80);
  outb(COM1 + 0, 115200 / 9600);
  ...
}

static void uart_tx(AM_UART_TX_T *send) {
  outb(COM1, send-&amp;gt;data);
}

static void uart_rx(AM_UART_RX_T *recv) {
  recv-&amp;gt;data = (inb(COM1 + 5) &amp;amp; 0x1) ? inb(COM1) : -1;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这是 AbstractMachine 中关于串口的一部分实现。可以看到 CPU 和 IO 设备交互的基本方式是：CPU 通过 in/out 指令从设备寄存器中读取信息 (这里使用了 memory mapped io，设备寄存器是地址 COM1 开始的若干内存单元)。&lt;/p&gt;
&lt;h3 id=&#34;example-keyboard&#34;&gt;Example: Keyboard&lt;/h3&gt;
&lt;p&gt;键盘相较于串口更加复杂，现在的很多键盘是可编程的，比如我们可以软件控制 ScrollLock, CapsLock, NumLock 等灯的亮暗，可以设置按下按键时产生字符的重复速度等等。事实上 AM 采用的键盘接口只提供了两个设备寄存器，一个是数据 data (0x60)，一个是 status/command 复用的寄存器 (0x64)，各种丰富的功能都靠这两个寄存器的值的组合来实现，因此这其中有大量的约定/协议。我们的驱动程序相当于要完成这样一个 API：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int keyboard_handler(int *rega, int *regb);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;只有两个参数，但要识别出各种功能，所以代码相当难写。&lt;/p&gt;
&lt;h3 id=&#34;example-disk-controller&#34;&gt;Example: Disk Controller&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void readsect(void *dst, int sect) {
  waitdisk();
  out_byte(0x1f2, 1);          // sector count (1)
  out_byte(0x1f3, sect);       // sector
  out_byte(0x1f4, sect &amp;gt;&amp;gt; 8);  // cylinder (low)
  out_byte(0x1f5, sect &amp;gt;&amp;gt; 16); // cylinder (high)
  out_byte(0x1f6, (sect &amp;gt;&amp;gt; 24) | 0xe0); // drive
  out_byte(0x1f7, 0x20);       // command (write)
  waitdisk();
  for (int i = 0; i &amp;lt; SECTSIZE / 4; i ++)
    ((uint32_t *)dst)[i] = in_long(0x1f0); // data
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这段代码是 AbstractMachine 中的 readsect()。它的逻辑要比串口更加复杂一些，首先调用 waitdisk() 等待设备准备就绪，然后向设备控制寄存器写入一些数据控制磁盘向我们返回我们需要的数据 (这些内容是手册规定的)，写完 command 后我们再调用 waitdisk() 等待设备准备就绪，最终把数据给读出来。&lt;/p&gt;
&lt;h3 id=&#34;example-printer&#34;&gt;Example: Printer&lt;/h3&gt;
&lt;p&gt;如果要设计一个打印机对外接口，最简单的实现就是一个表示状态的寄存器 status 和一个传输打印数据流的寄存器 data。在这个简单的模型下，我们也可以做到一些很优雅的事情。&lt;/p&gt;
&lt;p&gt;PostScript 是一种描述页面布局的比较底层的编程语言。一个小例子如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-postscr&#34;&gt;%!
% http://www.cs.cmu.edu/afs/andrew/scs/cs/15-463/98/pub/www/assts/ps.html

72 72 scale	% scale coordinate system so units are inches, not points
2 2 translate	% put origin 2 inches from lower left of page

/Courier findfont .6 scalefont setfont
% current font is now Courier about .6 inches high
gsave	% save graphics state (coordinate system &amp;amp; stuff)
.5 setgray
60 rotate
0 0 moveto (Read the friendly manual) show
grestore	% restore previous graphics state

/Helvetica-Bold findfont .2 scalefont setfont
% current font is now slanted Helvetica about .2 inches high
0 4 moveto (Read the friendly source code) show

/Times-Italic findfont .5 scalefont setfont
% current font is now italic Times about .5 inches high
1 0 0 setrgbcolor
0 6 moveto (Search the friendly Web) show

showpage
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它可以指定画笔的位置、颜色、角度，指定字体、大小等等。由于它是矢量绘图，所以清晰度很高。&lt;/p&gt;
&lt;p&gt;我们完全可以以 PostScript 作为标准做一套完整的工具链：比如以 Latex 为前端，写一个编译器将 Latex 编译成 PostScript，然后我们给设备传输的字节流就是 PostScript 格式的数据。硬件设备里写一个 PostScript 的解释器将 PostScript 翻译成打印机物理硬件的动作。&lt;/p&gt;
&lt;p&gt;当然，像打印机这种有切实物理机械部件的设备，会有很多情况需要处理，比如卡纸，缺墨等等，因此打印机的手册相当相当长。&lt;/p&gt;
&lt;h2 id=&#34;bus-interrupt-controller-and-dma&#34;&gt;Bus, Interrupt Controller and DMA&lt;/h2&gt;
&lt;h3 id=&#34;bus&#34;&gt;Bus&lt;/h3&gt;
&lt;p&gt;如果我们的世界里只有鼠标，键盘，显示屏几个固定的 I/O 设备，那么将它们和 CPU 连起来的最简单的方式就是在 CPU 上留几个对应的接口——每个设备插一个。但 I/O 设备会越来越多，如果要让 CPU 支持未来可能出现的更多的 I/O 设备，我们就需要一个更聪明的实现方案。&lt;/p&gt;
&lt;p&gt;我们可以假设有这样一个特殊的 I/O 设备，它上面有若干个插槽，我们可以将各式各样的 I/O 设备插在上面。这个 I/O 设备负责管理插在它上面的其他 I/O 设备。CPU 只需要和这个 I/O 设备通信，当 CPU 需要某个设备的某个寄存器的值时，这个 I/O 设备就会到对应的插槽的对应的寄存器去找数据。这样一个提供设备的注册和地址到设备的转发的特殊 I/O 设备就是总线 (bus)。&lt;/p&gt;
&lt;p&gt;我们可以做的更彻底一点：我们把内存 DRAM 也连到总线上面，这样 CPU 就真的只需要和总线交互了。内存单元有对应的地址，我们可以给设备寄存器也编上地址，这样 CPU 和总线之间只需要一根地址线和一根数据线 (当然，其实还需要一根用于握手的控制线)，CPU 就可以通过一个简单的地址来任意读写内存和 I/O 设备上的数据。&lt;/p&gt;
&lt;p&gt;这里有一段示例代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// pci-probe.c
#include &amp;lt;am.h&amp;gt;
#include &amp;lt;klib.h&amp;gt;

static inline uint32_t inl(int port) {
  uint32_t data;
  asm volatile (&amp;quot;inl %1, %0&amp;quot; : &amp;quot;=a&amp;quot;(data) : &amp;quot;d&amp;quot;((uint16_t)port));
  return data;
}

static inline void outl(int port, uint32_t data) {
  asm volatile (&amp;quot;outl %%eax, %%dx&amp;quot; : : &amp;quot;a&amp;quot;(data), &amp;quot;d&amp;quot;((uint16_t)port));
}

uint32_t pciconf_read(uint32_t bus, uint32_t slot, uint32_t func, uint32_t offset) {
   uint32_t reg = (bus  &amp;lt;&amp;lt; 16) | (slot &amp;lt;&amp;lt; 11)
                | (func &amp;lt;&amp;lt; 8)  | (offset) | 0x80000000;
  outl(0xcf8, reg);
  return inl(0xcfc);
}

int main() {
  ioe_init();
  for (int bus = 0; bus &amp;lt; 256; bus ++) {
    for (int slot = 0; slot &amp;lt; 32; slot ++) {
      uint32_t info = pciconf_read(bus, slot, 0, 0);
      uint16_t id   = info &amp;gt;&amp;gt; 16, vendor = info &amp;amp; 0xffff;
      if (vendor != 0xffff) {
        printf(&amp;quot;%02d:%02d device %x by vendor %x&amp;quot;, bus, slot, id, vendor);
        if (id == 0x100e &amp;amp;&amp;amp; vendor == 0x8086) {
          printf(&amp;quot; &amp;lt;-- This is an Intel e1000 NIC card!&amp;quot;);
        }
        printf(&amp;quot;\n&amp;quot;);
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该代码扫描 PCI 总线上的每个插槽并检查上面是否有设备，此外它会额外指出以太网卡。运行该程序可以看到结果&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; 0: 0 device 1237 by vendor 8086
 0: 1 device 7000 by vendor 8086
 0: 2 device 1111 by vendor 1234
 0: 3 device 100e by vendor 8086 &amp;lt;-- This is an Intel e1000 NIC card!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们还可以通过 qemu 的选项来模拟出一些新的设备：&lt;code&gt;-device AC97&lt;/code&gt; 选项可以模拟出一个声卡。我们添加这个选项运行后，得到的结果确实多了一个设备：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; 0: 0 device 1237 by vendor 8086
 0: 1 device 7000 by vendor 8086
 0: 2 device 1111 by vendor 1234
 0: 3 device 100e by vendor 8086 &amp;lt;-- This is an Intel e1000 NIC card!
 0: 4 device 2415 by vendor 8086
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;interrupt-controller&#34;&gt;Interrupt Controller&lt;/h3&gt;
&lt;p&gt;CPU 是无情的执行指令和响应外部中断的机器。CPU 上有一个专门的 IRQ 引脚用来接收中断信号，接收到代表中断的电信号以后，CPU 会保存一些寄存器，然后根据中断向量表对应项跳转执行中断处理程序。以前 IRQ 引脚引出的线会接到一个 Intel 8259 PIC 上 (programmable interrupt controller)，这个可编程的中断控制器可以设置各种中断屏蔽，中断优先级等等。现在有了总线之后，IRQ 连到了总线上。现在的 CPU 中有一个 APIC 模块 (Advanced PIC)，其中 local APIC 每个 CPU 一个，负责处理时钟中断，IPI 等；I/O APIC 全局一个，负责处理设备中断。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Inter Processor Interrupt (IPI)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在多核处理器中，一个 CPU 核可以给另一个 CPU 核发送中断。比如在开机的时候，刚开始只有一个 CPU 核被唤醒，它执行完一些初始化操作后，就需要通过 IPI 来唤醒其他的 CPU 核开始并发执行。&lt;/p&gt;
&lt;p&gt;IPI 还有更多重要的用途。假设当前有两个 CPU 核，这两个核运行了两个线程，有独立的 cache 和 TLB，但共享内存。第一个核执行了一个 mmap 操作，将内存中的某一段做了映射。但这期间如果第二个核没有任何系统调用/中断，那么第二个核的 TLB 就没有更新！多核之间的内存可见性就消失了。因此第一个核需要发送一个 IPI 给第二个核来做一些更新，这个操作叫做 TLB shotdown。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;direct-memory-access-dma&#34;&gt;Direct Memory Access (DMA)&lt;/h3&gt;
&lt;p&gt;中断 I/O 相较于轮询 I/O 解决了一个问题：我们的 CPU 不用浪费时钟周期轮询等待 I/O 设备准备就绪，而是可以在设备准备好的时候给 CPU 发送一个中断信号。但我们还有一个问题没有解决：向设备传输数据这件事本身也是很慢的，比如我现在要将 1GiB 的数据写入磁盘，如果我的代码是这么写的：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (int i = 0; i &amp;lt; 1 GB / 4; i++)
    outl(PORT, ((uint32 *)buf)[i]);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;那这个拷贝过程要花相当长时间。事实上，由于电气特性的限制，CPU 和总线之间存在性能 gap：总线上的设备无法做到 CPU 那么快，这无疑浪费了 CPU 的时间。&lt;/p&gt;
&lt;p&gt;我们自然的想法是：如果我们有一个小 CPU 专门帮我们做数据拷贝就好了。它不需要通用 CPU 那么复杂，它只要能做 memcpy() 就行了，这样大 CPU 就可以被解放出来干别的事情。这就是 DMA，DMA 的本质就是一个专职 memcpy() 的小 CPU。DMA 支持从 memory 到 memory，从 memory 到 device(register)，从 device(register) 到 memory 等若干种 memcpy()，现在的 DMA 控制器直接连在总线和内存上。&lt;/p&gt;
&lt;h2 id=&#34;gpu-and-heterogeneous-computing&#34;&gt;GPU and Heterogeneous Computing&lt;/h2&gt;
&lt;p&gt;DMA 相当于一个专门执行 memcpy 的小 CPU。I/O 设备和计算机之间的边界逐渐模糊。我们能不能将一些其他任务交给小 cpu 做呢？显卡就是专门绘图的 I/O 设备。&lt;/p&gt;
&lt;p&gt;让 CPU 绘图会遇到一些性能瓶颈：以 NES 为例，如果我们要实现 60fps，就要在 10K 指令内完成一帧的绘制，而一帧的像素有 60K，这是不可能完成的任务。NES 的做法是：画面其实是用若干方块拼出来的，CPU 只需要描述将哪些方块放在什么位置，将这样一个脚本 (本质上和 PostScript) 一样发送给 NES Picture Processing Unit (PPU)，让 PPU 来完成图形显示。由于 PPU 只负责绘制图形，功能单一但算力强大，所以可以支持 60fps。&lt;/p&gt;
&lt;p&gt;现代的 GPU 是一个通用的计算设备：它是一个完整的众核多处理器系统，有很多很多 (远多于 CPU core) 的核心数量和一个很大的 memory (显存)，GPU 从 DMA 拉数据和要执行的代码放到 memory 里，然后完成计算后再将结果推出去。&lt;/p&gt;
&lt;p&gt;Dark Silicon Age 的到来意味着功耗成为限制 CPU 性能优化的瓶颈，CPU 的频率很难再往上提，CPU core 的数量也要受到 cache coherence 等因素的制约。因此现在很多的需求都是通过开发新的 system on chip (SoC) 来实现，比如神经网络相关的 NPU 等。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 25: Device Drivers</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec25/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec25/</guid>
      <description>&lt;p&gt;在操作系统眼里，I/O 设备 = 一组寄存器 + 一个控制协议。不同设备的控制协议千差万别，如果让软件直接和这些设备寄存器打交道，即使操作系统仔细地管理好访问权限，应用程序也很容易出错。所以我们的想法是：对不同的设备做一个抽象，使得上层应用可以通过尽可能统一的接口来访问设备。&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;I/O 设备最基本的需求就是 read 和 write。UNIX 世界里的设备通常分为两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;字符设备 (character device)，设备与 OS 之间传送的是字节流。我们可以把这种设备想象成一个管道。终端、打印机等都是典型的字符设备。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;块设备 (block device)，我们可以把这种设备想象成一个字符数组，这样的设备通常有 persistence 的需求，比如磁盘。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;显卡是一种什么样的设备？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;显卡中其实既有字节流 (比如控制信号修改显卡的参数)，又有字节数组 (显卡里面有显存)。(不过显存不是按照块设备的方式来抽象的)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;操作 I/O 设备，我们至少需要如下的三个 API：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;read：从设备的某个指定的位置读出数据 (如果是字符设备，则是从当前的最新位置)。&lt;/li&gt;
&lt;li&gt;write：向设备的某个指定的位置写入数据。&lt;/li&gt;
&lt;li&gt;ioctl：读取/设置设备的状态 (比如对于 GPU 来说，设置分辨率，对于打印机来说，检查纸张等)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;设备驱动程序的作用之一就是将这些统一的系统调用 API 翻译成对应到具体设备的寄存器的操作。在计算机系统的世界中这样的抽象层很多：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Shell 负责将人类发出的命令行指令翻译成底层的系统调用；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Driver 负责将系统调用翻译成设备相关的寄存器操作；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;……&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;计算机系统世界就是这样一层一层抽象垒起来的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;虚拟设备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在操作系统眼里，设备就是在执行系统调用的时候运行对应的驱动程序，操作系统不关心驱动程序究竟干了什么，因此我们可以有虚拟设备的概念：驱动程序可以真的和一个物理设备进行了交互，也可以只是模拟了一些行为。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/dev/null&lt;/code&gt; 就是一个典型的虚拟设备。它像一个黑洞一样，可以吃掉所有向它输出的内容。它的设备驱动程序非常简单：对于 write，不论写入的内容是什么，它直接返回一个写入成功即可。对于 read，不论要读入什么，也都直接返回。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;设备的复杂性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;虽然设备的数据传输是其“主要”的功能，但剩下的控制功能种类繁多：比如现代的键盘可以支持呼吸灯、跑马灯、按键编程，现代打印机可以控制打印质量、卡纸、清洁、自动装订等等。这些控制功能全部依赖 ioctl 系统调用，导致其中有无比复杂的 hidden specification。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;linux-device-drivers&#34;&gt;Linux Device Drivers&lt;/h2&gt;
&lt;p&gt;这里有一个非常简单的，用于“引爆核弹”的设备驱动：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// launcher.c
#include &amp;lt;linux/module.h&amp;gt;
#include &amp;lt;linux/kernel.h&amp;gt;
#include &amp;lt;linux/init.h&amp;gt;
#include &amp;lt;linux/cdev.h&amp;gt;
#include &amp;lt;linux/device.h&amp;gt;
#include &amp;lt;linux/fs.h&amp;gt;
#include &amp;lt;linux/uaccess.h&amp;gt;

#define MAX_DEV 2

static int dev_major = 0;
static struct class *lx_class = NULL;
static struct cdev cdev;

static ssize_t lx_read(struct file *, char __user *, size_t, loff_t *);
static ssize_t lx_write(struct file *, const char __user *, size_t, loff_t *);

static struct file_operations fops = {
  .owner = THIS_MODULE,
  .read = lx_read,
  .write = lx_write,
};

static struct nuke {
  struct cdev cdev;
} devs[MAX_DEV];

static int __init lx_init(void) {
  dev_t dev;
  int i;

  // allocate device range
  alloc_chrdev_region(&amp;amp;dev, 0, 1, &amp;quot;nuke&amp;quot;);

  // create device major number
  dev_major = MAJOR(dev);

  // create class
  lx_class = class_create(THIS_MODULE, &amp;quot;nuke&amp;quot;);

  for (i = 0; i &amp;lt; MAX_DEV; i++) {
    // register device
    cdev_init(&amp;amp;devs[i].cdev, &amp;amp;fops);
    cdev.owner = THIS_MODULE;
    cdev_add(&amp;amp;devs[i].cdev, MKDEV(dev_major, i), 1);
    device_create(lx_class, NULL, MKDEV(dev_major, i), NULL, &amp;quot;nuke%d&amp;quot;, i);
  }
  return 0;    
}

static void __exit lx_exit(void) {
  device_destroy(lx_class, MKDEV(dev_major, 0));
  class_unregister(lx_class);
  class_destroy(lx_class);
  unregister_chrdev_region(MKDEV(dev_major, 0), MINORMASK);
}

static ssize_t lx_read(struct file *file, char __user *buf, size_t count, loff_t *offset) {
  if (*offset != 0) {
    return 0;
  } else {
    uint8_t *data = &amp;quot;This is dangerous!\n&amp;quot;;
    size_t datalen = strlen(data);
    if (count &amp;gt; datalen) {
      count = datalen;
    }
    if (copy_to_user(buf, data, count)) {
      return -EFAULT;
    }
    *offset += count;
    return count;
  }
}

static ssize_t lx_write(struct file *file, const char __user *buf, size_t count, loff_t *offset) {
  char databuf[4] = &amp;quot;\0\0\0\0&amp;quot;;
  if (count &amp;gt; 4) {
    count = 4;
  }

  copy_from_user(databuf, buf, count);
  if (strncmp(buf, &amp;quot;\x01\x14\x05\x14&amp;quot;, 4) == 0) {
    const char *EXPLODE[] = {
      &amp;quot;    ⠀⠀⠀⠀⠀⠀⠀⠀⣀⣠⣀⣀⠀⠀⣀⣤⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠀⣀⣠⣤⣤⣾⣿⣿⣿⣿⣷⣾⣿⣿⣿⣿⣿⣶⣿⣿⣿⣶⣤⡀⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⢠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣶⡀⠀&amp;quot;,
      &amp;quot;    ⠀⢀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀&amp;quot;,
      &amp;quot;    ⠀⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠿⠟⠁⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠻⢿⡿⢿⣿⣿⣿⣿⠟⠛⠛⠋⣀⣀⠙⠻⠿⠿⠋⠻⢿⣿⣿⠟⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠀⠀⠀⠀⠈⠉⣉⣠⣴⣷⣶⣿⣿⣿⣿⣶⣶⣶⣾⣶⠀⠀⠀⠀⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠀⠀⠀⠀⠀⠀⠉⠛⠋⠈⠛⠿⠟⠉⠻⠿⠋⠉⠛⠁⠀⠀⠀⠀⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣶⣷⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠀⠀⠀⠀⢀⣀⣠⣤⣤⣤⣤⣶⣿⣿⣷⣦⣤⣤⣤⣤⣀⣀⠀⠀⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠀⠀⢰⣿⠛⠉⠉⠁⠀⠀⠀⢸⣿⣿⣧⠀⠀⠀⠀⠉⠉⠙⢻⣷⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠀⠀⠀⠙⠻⠷⠶⣶⣤⣤⣤⣿⣿⣿⣿⣦⣤⣤⣴⡶⠶⠟⠛⠁⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⣿⣿⣿⣿⣿⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀&amp;quot;,
      &amp;quot;    ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠒⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠓⠀⠀⠀⠀⠀⠀⠀⠀⠀&amp;quot;,
    };
    int i;

    for (i = 0; i &amp;lt; sizeof(EXPLODE) / sizeof(EXPLODE[0]); i++) {
      printk(&amp;quot;\033[01;31m%s\033[0m\n&amp;quot;, EXPLODE[i]);
    }
  } else {
    printk(&amp;quot;nuke: incorrect secret, cannot lanuch.\n&amp;quot;);
  }
  return count;
}

module_init(lx_init);
module_exit(lx_exit);
MODULE_LICENSE(&amp;quot;GPL&amp;quot;);
MODULE_AUTHOR(&amp;quot;jyy&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该驱动在 linux 系统启动后被编译成一个 &lt;code&gt;.ko&lt;/code&gt; 文件后“动态加载”，其中 lx_init() 和 lx_exit() 的内容非常琐碎 (所以驱动是 bug 重灾区！)，lx_read() 和 lx_write() 是 read()/write() 系统调用会使用的驱动函数。如果我们读 &lt;code&gt;/dev/nuke0&lt;/code&gt; 这个设备，会得到 “This is dangerous!&amp;quot;，如果我们向这个设备写入数据，lx_write() 会检查写入的数据是否是 SECRET，如果是就会打印核弹爆炸的图案。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;为什么 Linux 中有两种 ioctl?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在单处理器时代 Linux 中只有 ioctl，后来多处理器时代 Linux 内核加装了 big kernel lock (BKL)，ioctl 执行时默认持有 BKL，从而驱动的执行 (本身较慢) 会使得很多线程被阻塞。后来 Linux 推出了 unlocked_ioctl，高性能的驱动可以使用该 ioctl 来避免上锁，再后来 ioctl 被删除，只剩下 unlocked_ioctl。&lt;/p&gt;
&lt;p&gt;compact_ioctl 是在 64-bit 机器的兼容模式下运行 32-bit 程序时使用的 ioctl。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;programming-for-gpu&#34;&gt;Programming for GPU&lt;/h2&gt;
&lt;p&gt;GPU 使用的是一种 SIMT (single instruction multiple thread) 的架构：相当于 GPU 里有很多的 CPU core，每个 CPU core 有自己的寄存器，core 之间共享内存 (显存)，但使用同一个 &amp;ldquo;PC指针&amp;rdquo;。因此 GPU 适合处理大量计算的简单任务，众核的优势可以使得重复计算被并行分解。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// mandelbrot.cu
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;

#define MAX_ITER 100
#define DIM 12800
static uint32_t colors[MAX_ITER + 1];
static uint32_t data[DIM * DIM];

__device__ uint32_t mandelbrot(double x, double y) {
  double zr = 0, zi = 0, zrsqr = 0, zisqr = 0;
  int i;

  for (i = 0; i &amp;lt; MAX_ITER; i++) {
    zi = zr * zi * 2 + y;
    zr = zrsqr - zisqr + x;
    zrsqr = zr * zr;
    zisqr = zi * zi;
    if (zrsqr + zisqr &amp;gt; 4.0) break;
  }
  
  return i;
}

__global__ void mandelbrot_kernel(uint32_t *data, double xmin, double ymin, double step, uint32_t *colors) {
  int pix_per_thread = DIM * DIM / (gridDim.x * blockDim.x);
  int tId = blockDim.x * blockIdx.x + threadIdx.x;
  int offset = pix_per_thread * tId;
  for (int i = offset; i &amp;lt; offset + pix_per_thread; i++) {
    int x = i % DIM;
    int y = i / DIM;
    double cr = xmin + x * step;
    double ci = ymin + y * step;
    data[y * DIM + x]  = colors[mandelbrot(cr, ci)];
  }
  if (gridDim.x * blockDim.x * pix_per_thread &amp;lt; DIM * DIM
      &amp;amp;&amp;amp; tId &amp;lt; (DIM * DIM) - (blockDim.x * gridDim.x)) {
    int i = blockDim.x * gridDim.x * pix_per_thread + tId;
    int x = i % DIM;
    int y = i / DIM;
    double cr = xmin + x * step;
    double ci = ymin + y * step;
    data[y * DIM + x] = colors[mandelbrot(cr, ci)];
  }
}

int main() {
  float freq = 6.3 / MAX_ITER;
  for (int i = 0; i &amp;lt; MAX_ITER; i++) {
    char r = sin(freq * i + 3) * 127 + 128;
    char g = sin(freq * i + 5) * 127 + 128;
    char b = sin(freq * i + 1) * 127 + 128;
    colors[i] = b + 256 * g + 256 * 256 * r;
  }
  colors[MAX_ITER] = 0;

  uint32_t *dev_colors, *dev_data;
  cudaMalloc((void**)&amp;amp;dev_colors, sizeof(colors));
  cudaMalloc(&amp;amp;dev_data, sizeof(data));
  cudaMemcpy(dev_colors, colors, sizeof(colors), cudaMemcpyHostToDevice);

  double xcen = -0.5, ycen = 0, scale = 3;
  mandelbrot_kernel&amp;lt;&amp;lt;&amp;lt;512, 512&amp;gt;&amp;gt;&amp;gt;(dev_data, xcen - (scale / 2), ycen - (scale / 2), scale / DIM, dev_colors);

  cudaMemcpy(data, dev_data, sizeof(data), cudaMemcpyDeviceToHost);
  cudaFree(dev_data);
  cudaFree(dev_colors);

  FILE *fp = fopen(&amp;quot;mandelbrot.ppm&amp;quot;, &amp;quot;w&amp;quot;);
  fprintf(fp, &amp;quot;P6\n%d %d 255\n&amp;quot;, DIM, DIM);
  for (int i = 0; i &amp;lt; DIM * DIM; i++) {
    fputc((data[i] &amp;gt;&amp;gt; 16) &amp;amp; 0xff, fp);
    fputc((data[i] &amp;gt;&amp;gt;  8) &amp;amp; 0xff, fp);
    fputc((data[i] &amp;gt;&amp;gt;  0) &amp;amp; 0xff, fp);
  }
  
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;mandelbrot.cu&lt;/code&gt; 绘制了一个 $12800\times 12800$ (16亿像素) 的图片，每个像素迭代 100 次。程序中的 &lt;code&gt;__device__&lt;/code&gt; 使得代码可以被编译成 GPU 可以运行的语言。main() 函数中使用了几个 cuda 的 API：cudaMalloc() 在显存中申请了一些空间，cudaMemcpy() 把计算所需的数据拷贝了过去 (当然是通过 DMA)，cudaFree() 释放显存空间。这样庞大的计算量 GPU 只需要 1.7s 左右就可以完成。&lt;/p&gt;
&lt;p&gt;GPU 上有一套完整的工具链：比如 gcc &amp;ndash;&amp;gt; nvcc，objdump &amp;ndash;&amp;gt; cuobjdump，gdb &amp;ndash;&amp;gt; cuda-gdb，perf &amp;ndash;&amp;gt; nvprof 等等。全套工具链的实现都在驱动里，因此 NVIDIA 的驱动非常复杂。&lt;/p&gt;
&lt;h2 id=&#34;abstraction-of-storage-devices&#34;&gt;Abstraction of Storage Devices&lt;/h2&gt;
&lt;p&gt;存储设备属于块设备，数据块 (block) 是访问的最小单元，且不支持任意的随机访问。应用程序通常通过文件系统来读写存储设备。&lt;/p&gt;
&lt;p&gt;Linux 的 bio (Block I/O) layer 是文件系统和磁盘设备之间的接口。通常一次磁盘访问会包括多个块的读/写，因此 bio layer 中可以有一些调度策略，比如 Linux 总是优先满足 read 操作 (因为执行 read 的程序一般总是依赖数据继续执行)，延缓 write 操作 (只要没有超过 ddl)。&lt;/p&gt;
&lt;p&gt;简单来说，block I/O layer 的 API 是 bread()，bwrite() 和 bflush()，其中最后一个用于处理一些同步问题。我们的文件系统就是在 bio API 的基础上构建一个持久数据结构，并向上层应用提供更简单易用的接口。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 26: File System API</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec26/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec26/</guid>
      <description>&lt;h2 id=&#34;why-file-system&#34;&gt;Why File System?&lt;/h2&gt;
&lt;p&gt;如果设备直接将读/写/控制的接口暴露给应用程序，那么多个应用程序在并发地使用设备时很容易发生竞争。我们考虑下面的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// printf-race.c
#include &amp;lt;stdio.h&amp;gt;
#include &amp;quot;thread.h&amp;quot;

void use_printf(const char *s) {
  printf(&amp;quot;%s&amp;quot;, s);
}

void use_putchar(const char *s) {
  for (; *s; s++) {
    putchar(*s);
  }
}

void (*print)(const char *) = use_printf;

void Tworker() {
  char buf[128];
  int c = gettid() % 4 + 1;
  sprintf(buf, &amp;quot;\033[3%dm%d\033[0m&amp;quot;, c, c);
  while (1) {
    print(buf);
  }
}

int main(int argc, char *argv[]) {
  if (argc &amp;gt; 1) {
    print = use_putchar;
  }

  setbuf(stdout, NULL);
  for (int i = 0; i &amp;lt; 4; i++) {
    create(Tworker);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 &lt;code&gt;printf-race.c&lt;/code&gt; 中，我们创建了 4 个线程，每个线程通过 ANSI Escape Code 用某种颜色打印自己的线程号。如果我们直接运行 &lt;code&gt;./printf-race&lt;/code&gt;，线程会使用 use_printf() 调用库函数 printf() 输出，这时我们能看到正确的结果。但如果我们运行时添上一个参数，比如 &lt;code&gt;./printf-race xxx&lt;/code&gt;，那么线程会使用 use_putchar() 输出，这时我们就会看到大量的错误输出。产生错误的原因是：当 4 个线程并发/并行地使用 putchar() 输出时，它们的输出内容是交织在一起的，这就会导致 Escape Code 被隔断，从而产生预期之外的结果。printf() 函数使用 write 系统调用来输出给定内容，write 系统调用保证了它输出所有内容这个动作是原子的。&lt;/p&gt;
&lt;p&gt;即使我们在设备上面封装一层有原子性的 API，对于块设备我们仍然有难以解决的问题：多个应用程序都需要从磁盘中读写数据，这就像全班人要在一张很大的纸上各自写作业，那么如何保证大家写的内容不会互相覆盖？对于系统来说，如果一个程序出了 bug 会把整个磁盘全部写上垃圾，那就没得玩了。&lt;/p&gt;
&lt;p&gt;多个进程并发地使用内存会导致隔离被打破，我们引入了虚拟内存，给每个进程一个虚拟地址空间。在这里我们的思想是相似的：文件系统向下和物理设备 (磁盘) 打交道，向上为每个程序提供一个虚拟磁盘。虚拟磁盘就是一个可以读写的动态字节序列，我们可以直接把它想象成一个 &lt;code&gt;vector&amp;lt;char&amp;gt;&lt;/code&gt;。文件系统不仅需要维护这些 vector，还要负责管理虚拟磁盘的名称，负责检索和遍历。&lt;/p&gt;
&lt;h2 id=&#34;virtual-disk-naming-and-management&#34;&gt;Virtual Disk: Naming and Management&lt;/h2&gt;
&lt;p&gt;维护虚拟磁盘最简单的方法就是存储一堆 &lt;code&gt;名字-vector&amp;lt;char&amp;gt;&lt;/code&gt; 的键值对。但这样的形式非常不利于快速检索。因此文件系统采取了树形结构。&lt;/p&gt;
&lt;p&gt;Windows 的文件系统中，每个设备驱动器是一棵树，例如 C 盘，D 盘等。所谓的 “C 盘根目录” 就是 &lt;code&gt;C:\&lt;/code&gt;，根目录下面可以构建一个错综复杂的文件树。如果插入了 U 盘等外设，系统会为它分配一个新的盘符。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;为什么没有 &lt;code&gt;A:\&lt;/code&gt; 和 &lt;code&gt;B:\&lt;/code&gt;？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A 盘和 B 盘是曾经的软盘。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;UNIX/Linux 的文件树和 Windows 不同。Linux 中只有一个根 &lt;code&gt;/&lt;/code&gt;，更多的设备依靠 Linux 的挂载机制访问。Linux 的挂载类似于“目录树的拼接”，可以指定一个目录，将一个设备的目录树挂到该目录下面。比如当前我们有一个 &lt;code&gt;disk.img&lt;/code&gt; 文件，则我们使用&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo mount disk.img /mnt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之后，使用 &lt;code&gt;tree /mnt&lt;/code&gt; 就可以看到磁盘镜像 &lt;code&gt;disk.img&lt;/code&gt; 内的目录树结构。&lt;/p&gt;
&lt;p&gt;Linux 的 mount 命令基于 mount 系统调用实现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int mount(const char *source, const char *target,
          const char *filesystemtype, unsigned long mountflags,
          const void *data);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;mount 系统调用的接口更加复杂，除了要指定 source 和 target 外，还要指定文件系统的类型，挂载标志位等等。Linux 的 mount 命令使用起来容易一些，因为它可以自动监测文件系统 (busybox 的 mount 没有这个功能)。&lt;/p&gt;
&lt;p&gt;事实上，真正的 Linux 启动的过程中也是通过挂载完成了文件系统的初始化。我们在 Linux-minimal 里面模拟了这个过程：我们用 qemu 启动的 Linux 内核只包含一个非常小的“文件系统&amp;quot; initramfs，这个文件系统只有非常少的一些文件，而且是存放在内存中的。我们的 Linux-minimal 做了这样一个流程：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PATH=/bin
busybox mknod /dev/sda b 8 0
busybox mkdir -p /newroot
busybox mount -t ext2 /dev/sda /newroot
exec busybox switch_root /newroot/ /etc/init
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中第二行的命令使用 mknod 创建了一个设备文件 &lt;code&gt;/dev/sda&lt;/code&gt;，也就是真正的磁盘。第三个命令创建了一个目录 &lt;code&gt;/newroot&lt;/code&gt; (在 initramfs 中)，然后我们用 mount 命令将磁盘挂载到了 &lt;code&gt;/newroot&lt;/code&gt; 上，这时候我们的 &lt;code&gt;/newroot&lt;/code&gt; 其实就是真正意义上的根目录了。最后我们通过 switch_root 命令把 &lt;code&gt;/&lt;/code&gt; 切换到 &lt;code&gt;/newroot&lt;/code&gt; 上，并删除 initramfs 中的剩下那些多余的东西。&lt;/p&gt;
&lt;p&gt;一个比较微妙的问题是：我们对文件的抽象是磁盘上的一个虚拟磁盘，这个虚拟磁盘是在真实物理磁盘上虚拟出来的。但如果我们做挂载，那么被挂载目录的虚拟磁盘就不是在真实物理磁盘上虚拟出来的，而是在一个虚拟磁盘 (比如 &lt;code&gt;disk.img&lt;/code&gt;) 上虚拟出的虚拟磁盘，嵌套了两层。物理磁盘上的虚拟磁盘和虚拟磁盘上的虚拟磁盘显然应该有一些区别。Linux 的处理方式是创建一个 loopback (回环) 设备。回环设备的驱动会把对设备的 read/write 操作转化为对文件的 read/write 操作。我们可以通过 strace 来近距离观察 mount 的过程：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openat(AT_FDCWD, &amp;quot;/dev/loop-control&amp;quot;, O_RDWR | O_CLOEXEC) = 3
ioctl(3, LOOP_CTL_GET_FREE) = 1
close(3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当 Linux 想要创建一个回环设备时，它会先打开设备 &lt;code&gt;/dev/loop-control&lt;/code&gt;，然后通过 ioctl 获取一个当前空闲的回环设备号。这里的返回值是 1，所以待会儿创建的回环设备就是 &lt;code&gt;/dev/loop1&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openat(AT_FDCWD, &amp;quot;/tmp/demo/disk.img&amp;quot;, O_RDWR | O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/dev/loop1&amp;quot;, O_RDWR | O_CLOEXEC) = 4
ioctl(4, LOOP_SED_FD, 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，回环设备持有文件描述符 4，Linux 通过一个 ioctl 系统调用将其指向了 &lt;code&gt;disk.img&lt;/code&gt; 对应的文件描述符。这样后续对回环设备的读写操作会翻译成对 &lt;code&gt;disk.img&lt;/code&gt; 文件的读写操作。&lt;/p&gt;
&lt;h2 id=&#34;directory-api-system-calls&#34;&gt;Directory API (System Calls)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;创建一个目录：mkdir 系统调用，同时可以设置访问权限&lt;/li&gt;
&lt;li&gt;删除一个目录：rmdir 系统调用。注意 UNIX 中没有“递归删除”的系统调用。毕竟可以交给软件做的事情就不需要交给操作系统了。&lt;code&gt;rm -rf&lt;/code&gt; 会遍历目录递归删除。&lt;/li&gt;
&lt;li&gt;遍历一个目录：getdents 系统调用。getdents 在 glibc 中没有封装好的同名库函数。但我们可以使用 readdir() 函数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Linux 中的一个有趣的机制是链接。Linux 中的链接分硬链接和软链接两种。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果我们对一个文件创建一个硬链接，那么这相当于创建了两个“指针” (文件名)，它们指向同一个文件实体。如果修改了一个另一个呈现的内容也会变。如果我们用 &lt;code&gt;ls -i&lt;/code&gt; 查看两个文件的 inode 号，我们会发现硬链接的 inode 号和原文件是一样的。事实上，在硬链接创建后，我们无法区分出哪个是原体那个是后复制的。我们可以在 Linux 中通过 &lt;code&gt;ln a b&lt;/code&gt; 创建硬链接。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;软链接相当于一个“快捷方式”，当我们访问这个文件时，其实会跳转去访问另一个文件。软链接的使用非常灵活，它可以链接到一个目录 (硬链接只能链接文件)，可以跨文件系统，甚至可以链接到一个当前不存在的目录。我们可以在 Linux 中通过 &lt;code&gt;ln -s a b&lt;/code&gt; 创建软链接。&lt;/p&gt;
&lt;p&gt;软链接的任意性和灵活性使得我们的文件树变成了一个文件图，它甚至可以成环：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

# fish-dir.sh
# Create directories
mkdir -p A B C D E F

# Create automaton
ln -s ../B &#39;A/&amp;lt;&#39;
ln -s ../C &#39;B/&amp;gt;&#39;
ln -s ../D &#39;C/&amp;lt;&#39;
ln -s ../E &#39;A/&amp;gt;&#39;
ln -s ../F &#39;E/&amp;lt;&#39;
ln -s ../D &#39;F/&amp;gt;&#39;
ln -s ../A &#39;D/_&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以在文件系统中通过软链接创建一个之前 &lt;code&gt;fish.c&lt;/code&gt; 中的自动机。通过访问目录来模拟转移。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每个进程都有一个当前的工作目录，可以用 &lt;code&gt;pwd&lt;/code&gt; 命令查看。如果想要修改当前工作目录，则要使用 chdir 系统调用。一个有趣的事情是：像 cat, ls 等命令在 &lt;code&gt;/bin&lt;/code&gt; 下都有对应的可执行文件，但 cd 是没有的，这是因为 cd 是一个 shell 内置的命令——基本上所有的命令都是先 fork 出一个子进程再执行命令对应的可执行文件，但 cd 命令要修改的是当前进程的工作目录，显然不能用这种 fork 的方式。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;一个进程下的多个线程是共享 working directory，还是线程之间独立？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;working directory 是一个环境变量 &lt;code&gt;$PWD&lt;/code&gt;，环境变量是每个进程一份，因此线程之间共享 working directory。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;file-api-system-calls&#34;&gt;File API (System Calls)&lt;/h2&gt;
&lt;p&gt;我们通过 open/pipe 等系统调用可以获得文件描述符。文件描述符可以理解为指向文件的指针，供进程访问。事实上，文件描述符里还保存了当前访问文件的偏移量，比如&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int fd = open(&amp;quot;a.txt&amp;quot;, O_RDWR | O_TRUNC);
read(fd, buf, 512);
read(fd, buf, 512)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;第一次 read 读到的是前 512 字节，第二次 read 读到的就是后 512 字节。lseek 系统调用可以修改当前的文件偏移量。&lt;/p&gt;
&lt;p&gt;偏移量的管理其实有很多的复杂性：比如我们知道 fork 时子进程会继承父进程的文件描述符，那么如果 fork 之后父进程向文件写入 parent，子进程向文件写入 child，我们显然不希望获得 &amp;ldquo;childt&amp;rdquo;，因此在 fork 的设计中，父子进程的文件描述符共享偏移量。此外，操作系统的每个 API 都可能和其他 API 交互，open, execve, dup 等系统嗲用中偏移量的行为各不相同，open 甚至提供了一大堆 flag 设置偏移量的行为。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 27: FAT and UNIX File System</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec27/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec27/</guid>
      <description>&lt;p&gt;数据结构课的一些潜藏的假设：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;random access memory，word addressing (不同于磁盘，磁盘是以块为单位访问的)&lt;/li&gt;
&lt;li&gt;load/store 指令和计算指令执行的代价都是 $O(1)$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在块设备中，即使访问一个 byte 也需要将它所在的一整个 block 拿出来，因此内存中的数据结构用在磁盘上会造成极大的性能问题。&lt;/p&gt;
&lt;p&gt;块设备提供的设备抽象：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct block blocks[NBLK]; // 磁盘
void bread(int id, struct block *buf) {
  memcpy(buf, &amp;amp;blocks[id], sizeof(struct block));
}
void bwrite(int id, const struct block *buf) {
  memcpy(&amp;amp;blocks[id], buf, sizeof(struct block));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;bread() 将磁盘中的一个块拉到内存里，bwrite() 将内存中的一个块写入磁盘。&lt;/p&gt;
&lt;p&gt;我们的文件系统在 bread()/bwrite() 上一层层抽象出来：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们可以在 read/write 上实现两个 API：balloc() 和 bfree()，这样我们就把整个磁盘中所有的块管理了起来。&lt;/li&gt;
&lt;li&gt;在此基础上我们可以实现一个文件数据结构，它向上呈现一个可以随机访问、修改以及变长的 byte array (C++中的 vector 容器)，向下使用 balloc()/bfree() 申请 block 并把它们串起来。&lt;/li&gt;
&lt;li&gt;我们可以在文件的基础上实现目录：目录本身也是一个特殊的文件 (字节序列)，目录文件中存放了它里面有哪些文件以及它们的位置索引 (将 &lt;code&gt;vector&amp;lt;char&amp;gt;&lt;/code&gt; 当作 &lt;code&gt;vector&amp;lt;dir_entry&amp;gt;&lt;/code&gt; 来解读)。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;file-allocation-table-fat&#34;&gt;File Allocation Table (FAT)&lt;/h2&gt;
&lt;p&gt;在计算机使用软盘作为存储设备的年代，我们要在很少的存储空间上实现文件系统，因此链表是不二之选。关于链表，我们有以下两种设计：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;数据结构课上的经典设计：让每个块有数据和 next 指针两部分：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;struct block {
   	char data[NBLOCK];
    void *next;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这是一个很自然的想法，但有一些缺陷：比如每个 block 都有一点空间要用来存储指针，所以数据的对齐会不太好。一个更致命的缺陷是：我们在块设备上并不能 $O(1)$ 地去访问 next 指针，想要读取 next 我们要把整个 block 读出来。如果我们要执行一个 &lt;code&gt;lseek(SEEK_END)&lt;/code&gt;，我们得把整个文件读一遍，这非常糟糕，而且无法克服。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我们花费开头的几个 block，把所有的 next 指针全部存储在这些 block 中，后面的 block 专门存储数据。这个设计就非常好地利用了数据访问的局部性：当我们在随机访问一个文件是，我们需要快速通过 next 指针跳转，这种设计将 next 指针集中存放在一起，有利于提高访问效率。&lt;/p&gt;
&lt;p&gt;但这个设计在数据可靠性方面有比较大的问题：一方面，所有的 next 指针都存放在开头的几个 block 内，一旦这些 block 损坏，整个文件系统就完全损坏了 (每个文件的 block 链表都完全断开)，单个 block 损坏对全局的影响过大：另一方面，由于我们经常要 lseek，所以存放 next 指针的 block 又恰恰是我们读写最频繁的区域，也就是说它们损坏的几率要远高于其他 block。不过这个问题不是完全不可解决的：我们可以备份一些 next 指针数组在磁盘的其他地方，并准备一些应急预案。&lt;/p&gt;
&lt;p&gt;这个磁盘开头集中存放 next 指针的 block，就叫做 file allocation table (FAT)。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;若要了解 FAT 文件系统的细节，最好的方法便是 RTFM。
&lt;a href=&#34;http://jyywiki.cn/pages/OS/manuals/MSFAT-spec.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;有 FAT 的手册。&lt;/p&gt;
&lt;h2 id=&#34;ext2unix-file-system&#34;&gt;ext2/Unix File System&lt;/h2&gt;
&lt;p&gt;FAT 使用最简单的链表来管理每个文件的 data block，这使得大文件的随机访问比较慢。ext2 的设计一部分解决了这个问题：ext2 中的每个文件都有一个 inode：inode 存储了每个文件的 metadata，比如文件的大小、名称等，inode 会有一个区域叫做 direct block，这样对于小文件，其 data block 可以直接放在 direct block 里，对于大文件，其 data block 可以用类似页表的方式组织起来，这样随机访问效率非常高。&lt;/p&gt;
&lt;p&gt;所有文件的 inode 在磁盘上统一连续存储，这使得 inode 的索引非常方便，因此我们的目录文件只需要存储文件名到 inode 编号的 key-value mapping 即可。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 28: Reliability of Persistent Storage</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec28/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec28/</guid>
      <description>&lt;p&gt;内存在掉电后丢失数据是可以被接受的，但在持久化存储设备上我们必须保证数据的可靠性。硬盘损坏虽然是小概率事件，但只要有大量的重复 (比如数据中心)，这类事情还是经常发生的。我们希望即使发生这样的事情，系统仍然能照常运转。&lt;/p&gt;
&lt;h2 id=&#34;raid&#34;&gt;RAID&lt;/h2&gt;
&lt;p&gt;Redundant Array of Inexpensive Disks 的核心思想是：把多个 (不可靠的) 虚拟磁盘虚拟成一块非常可靠且性能极高的虚拟磁盘。RAID 的虚拟化是一种“反向”的虚拟化：我们之前接触的虚拟化，比如进程把一个 CPU 分时虚拟成多个 virtual CPU，虚拟内存把一份内存通过 MMU 虚拟成多个 virtual address space，文件把一个物理设备虚拟成多个 virtual disk……而 RAID 是 $多\to 1$ 的虚拟化。&lt;/p&gt;
&lt;p&gt;RAID 的 Fault Model 为：任何一块磁盘都可能突然坏掉，就好像“突然消失了”。&lt;/p&gt;
&lt;h3 id=&#34;raid-1&#34;&gt;RAID-1&lt;/h3&gt;
&lt;p&gt;最简单的想法：准备两块磁盘 $A$ 和 $B$，它们存储了同一份虚拟磁盘的镜像，这样损坏的概率就从 $p$ 变成了 $p^2$。该做法还能提升读取的效率：比如我要从虚拟磁盘中读取 10000 个 block，那么我可以从 $A$ 中读取前 5000 块，$B$ 中读取后 5000 块，只要 CPU core 个数足够，内存带宽足够，这件事是可以做到的 (不过该做法牺牲了一些存储空间)。&lt;/p&gt;
&lt;h3 id=&#34;raid-0&#34;&gt;RAID-0&lt;/h3&gt;
&lt;p&gt;如果我们不考虑容错，专注于提升性能：假设两块磁盘 $A$ 和 $B$，有 $A_1,A_2$，$B_1,B_2$ 四块。虚拟磁盘有 $V_1,V_2,V_3,V_4$ 四块。如果我们的映射是 $A_1\to V_1,A_2\to V_2,B_1\to A_3,B_2\to V_4$，那么如果我们读写前两个块，就只有 $A$ 在工作，$B$ 在摸鱼；如果我们采取交错映射：$A_1\to V_1,B_1\to V_2,A_2\to V_3,B_2\to V_4$，那么我们读取任意连续的两块都能让 $A,B$ 并行地工作，性能翻倍。&lt;/p&gt;
&lt;h3 id=&#34;raid-1-0&#34;&gt;(RAID-1)-0&lt;/h3&gt;
&lt;p&gt;当我们有多块盘的时候，令 $f(i,j)$ 表示第 $i$ 块物理盘的第 $j$ 个区域对应到虚拟磁盘的哪一个区域，这里的函数 $f$ 有很大的设计空间。比如当我们有 4 块盘的时候，我么可以将之前的两种设计方法综合起来，组合成一个 (RAID-1)-0。这个写法有点像函数的复合，我们每两块盘做一个 RAID-1，这样有两组 RAID-1，再把它们用 RAID-0 连起来，这样我们就兼顾了容量、容错和性能。&lt;/p&gt;
&lt;p&gt;这个做法有一个很有意思的点：我们可以保证任意一块物理盘出错都不会丢失信息，但我们不能保证两块盘出错时不会丢失信息——如果我们在两个 RAID-1 中各丢了一块盘，那么我们仍然能恢复信息；但如果我们丢失了第一个 RAID-1 中的所有两块盘，那么我们就真的丢失了数据。如果我们认为同时丢失了两块盘属于几乎不可能发生的小概率事件，那么这个 (RAID-1)-0 的做法似乎在容错方面就有一些“性能过剩”，有没有什么非常经济实惠的做法呢？&lt;/p&gt;
&lt;h3 id=&#34;raid-4&#34;&gt;RAID-4&lt;/h3&gt;
&lt;p&gt;一个块的信息可以抽象成一个 bit，于是这个问题等价于我们如何用最少的冗余信息来保证一个 bit 的错误和纠正。我们容易联想到可以用校验码来完成这件事。要保证可以纠一位错，我们只需要使用奇偶检验码即可。&lt;/p&gt;
&lt;p&gt;假设我们现在用 $A,B,C,D$ 四块盘组合出一个虚拟磁盘，则我们的映射为 $V_1\to A_1,V_2\to B_1,V_3\to C_1$，$D_1=V_1\oplus V_2\oplus V_3$。之后 $V_4,V_5,V_6$ 依次类推。这样如果 $A,B,C$ 三块盘中的某个损坏，我们可以用 $D$ 来恢复；如果 $D$ 损坏，我们没有丢失任何实际信息，再插一块新盘算一遍异或即可。&lt;/p&gt;
&lt;p&gt;RAID-4 在保证坏一块盘不会丢失数据的情况下将冗余数据量做到了最小，使得我们的虚拟磁盘容量大。此外，我们将 $V_1,V_2,\cdots$ 交错映射在多个盘上，这样我们在连续读取/写入时，可以同时把三块盘的性能拉满，并行度高。&lt;/p&gt;
&lt;p&gt;但这个设计有一个微妙的缺陷：它应对随机读写的效果较差。假设我们有多次随机的写操作，我们会发现每次写操作都要奇偶校验盘 $D$ 中的数据进行修改。此外因为 $D_i=A_i\oplus B_i\oplus C_i$，所以我们还没法直接去修改 $D_i$，假设我们现在要修改 $A_1$，那么我们必须先 &lt;code&gt;bread(A1, D1)&lt;/code&gt;，然后 &lt;code&gt;D1^=A1&lt;/code&gt;，将 &lt;code&gt;A1&lt;/code&gt; 修改为 &lt;code&gt;A1&#39;&lt;/code&gt; 后，&lt;code&gt;D1&#39;=D1^A1&#39;&lt;/code&gt;，最后 &lt;code&gt;bwrite(A1, D1)&lt;/code&gt;。每次随机写 (不论是 $A,B,C$ 中的哪一个盘)，我们都要对 $D$ 一读一写，奇偶校验盘成为了性能瓶颈。&lt;/p&gt;
&lt;h3 id=&#34;raid-5&#34;&gt;RAID-5&lt;/h3&gt;
&lt;p&gt;RAID-5 的设计非常聪明：我们不用单独安排一块盘作为奇偶校验盘，我们可以把奇偶检验的信息分散到各各盘上去，每块盘上既有数据也有校验：&lt;/p&gt;
&lt;img src=&#34;https://kristoff-starling.github.io/img/raid5.png&#34; alt=&#34;RAID5&#34; style=&#34;zoom: 33%;&#34; /&gt;
&lt;p&gt;在连续读写上，$n$ 块盘可以达到 $n-1$ 块的带宽 (每 $n$ 个 block 就有一个是冗余的校验 block)，在随机读上，由于每个盘都存储了数据，因此带宽接近 100%。在随机写上，校验信息的读写仍然是瓶颈，但由于校验信息的修改被平摊到了所有盘的头上，所以基本可以保证随着盘数量的增多效率提高，有 scalability。&lt;/p&gt;
&lt;h2 id=&#34;crash-consistency&#34;&gt;Crash Consistency&lt;/h2&gt;
&lt;p&gt;另一种 Fault model：磁盘并没有故障，但操作系统可能会 crash (比如掉电)。即使是文件系统中的简单操作也可能涉及若干个 block，如果我们在一轮操作的中途掉电，那么文件系统就会进入一个 inconsistent 的状态，这样的状态可能导致严重的错误或安全问题。磁盘本身无法直接支持原子操作 (all or nothing)，甚至为了效率它不会保证 bwrite 操作是按顺序进行的 (因此 block layer 还额外提供了 bflush 操作来保证数据落盘 (和并发中的 barrier(mfence) 是类似的) )。&lt;/p&gt;
&lt;h3 id=&#34;file-system-checking-fsck&#34;&gt;File System Checking (FSCK)&lt;/h3&gt;
&lt;p&gt;FSCK 的核心原理是当磁盘上出现 inconsistent 的现象时，根据磁盘上已有的信息恢复出“最可能”的数据结构。但这套方案不是完美的：有一些无法恢复的文件可能会被放入 lost&amp;amp;found 中，造成一些麻烦；此外，如果 fsck 执行过程中又发生掉电，可能会产生意想不到的后果。因此 FSCK 不是一个根本的解决方法。&lt;/p&gt;
&lt;h3 id=&#34;journaling&#34;&gt;Journaling&lt;/h3&gt;
&lt;p&gt;我们通常看文件系统的视角，比如目录树，是文件系统的直观表示，它是 crash unsafe 的。但如果我们从状态机视角去看文件系统，我们可以把文件系统看作一系列修改操作的序列。如果我们可以把这个 append-only 的序列存储下来，我们就可以在 crash 之后恢复出文件系统。&lt;/p&gt;
&lt;p&gt;因此我们的想法是：在数据结构修改操作发生时，先不去做实际的修改，而是记录下一条修改日志。当日志落盘后，根据日志内容修改实际的数据结构。这样如果发生 crash，我们可以重放日志 (redo log) 来恢复文件系统。&lt;/p&gt;
&lt;p&gt;在 bread(), bwrite() 和 bflush() 三个 API 的基础上我们可以写出一个 journal.append() 的伪代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Journal_append(operations)
    using bread() to find the end of current journal
    bwrite(Transaction_begin)
       for operation in operation: bwrite(operation)
       bflush() # 确保所有 operation 落盘
       bwrite(Transaction_end)
       bflush() # 确保 TxEnd 标记落盘
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;再之后我们就可以将日志的内容付诸实施，实施结束后删掉日志。如果实施的过程中掉电，重启后 TxEnd 标签将成为我们确认日至是否完整的唯一标志：因为我们有 bflush() 保证同步性，因此如果 TxEnd 标志存在，那么之前所有操作的信息一定已经写入了，我们可以安全地重放日志；如果 TxEnd 标志不存在，那我们就忽略这次日志，且这时日志中的操作尚未对数据结构产生真正影响。这样就做到了 all or nothing。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;OSLAB 中的小彩蛋&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了提高 journaling 的效率，很多系统做出了很多的优化。比如 git 采用 metadata journaling，提升效率的同时降低了一致性，这导致有时强行关闭虚拟机会导致 git repo 处于一个不一致的状态，因此 OSLAB 的 &lt;code&gt;Makefile.lab&lt;/code&gt; 中添加了一条命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;git:
    @git add $(shell find . -name &amp;quot;*.c&amp;quot;) $(shell find . -name &amp;quot;*.h&amp;quot;) -A --ignore-errors
    @while (test -e .git/index.lock); do sleep 0.1; done
    @(uname -a &amp;amp;&amp;amp; uptime) | git commit -F - -q --author=&#39;tracer-nju &amp;lt;tracer@nju.edu.cn&amp;gt;&#39; --no-verify --allow-empty
+   @sync
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;sync 的作用是 &amp;ldquo;synchronize cached writes to persistent storage&amp;rdquo;。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 29: Xv6 File System Implementation</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec29/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec29/</guid>
      <description>&lt;h2 id=&#34;review&#34;&gt;Review&lt;/h2&gt;
&lt;p&gt;文件系统 = 图书馆&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目录：图书馆操作，mkdir, rmdir, link, unlink etc.&lt;/li&gt;
&lt;li&gt;文件：图书，read, write, mmap etc.&lt;/li&gt;
&lt;li&gt;文件描述符 (offset)：书签，lseek etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- more --&gt;
&lt;p&gt;FAT：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;metadata&lt;/th&gt;
&lt;th&gt;FAT&lt;/th&gt;
&lt;th&gt;FAT&lt;/th&gt;
&lt;th&gt;data clusters&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;p&gt;FAT 区域存放文件链表的 next 指针。FAT 的一个缺点在于一个文件的信息散落在磁盘的各个地方。&lt;/p&gt;
&lt;p&gt;UNIX：&lt;/p&gt;
&lt;p&gt;磁盘中的一个区域存放所有文件的 inode。inode 里包括文件的几乎所有信息 (除了所有的 data block 以一个类页表的方式存储，inode 里存放了“页表”的根)，更好地利用了数据的 locality。&lt;/p&gt;
&lt;h2 id=&#34;mkfsmkfsc&#34;&gt;&lt;code&gt;/mkfs/mkfs.c&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;mkfs 的代码写的非常琐碎。RTFSC 的优雅姿势为：读代码的执行比读代码容易。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# trace.py
TRACED = &#39;bwrite balloc ialloc iappend rinode winode rsect wsect&#39;.split()
IGNORE = &#39;ip xp buf&#39;.split()

class trace(gdb.Breakpoint):
    def stop(self):
        f, bt = gdb.selected_frame(), []
        while f and f.is_valid():
            if (name := f.name()) in TRACED:
                lvars = [f&#39;{sym.name}={sym.value(f)}&#39;
                    for sym in f.block()
                    if sym.is_argument and sym.name not in IGNORE]
                bt.append(f&#39;\033[32m{name}\033[0m({&amp;quot;, &amp;quot;.join(lvars)})&#39;)
            f = f.older()
        print(&#39;    &#39; * (len(bt) - 1) + bt[0])
        return False # won&#39;t stop at this breakpoint

gdb.execute(&#39;set prompt off&#39;)
gdb.execute(&#39;set pagination off&#39;)
for fn in TRACED:
    trace(fn)
gdb.execute(&#39;run fs.img README user/_ls&#39;)
gdb.execute(&#39;quit&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面的一段代码可以帮我们自动在 &lt;code&gt;mkfs.c&lt;/code&gt; 中比较重要的 API 函数上打断点，并追踪栈帧打印函数调用链和关键参数。通过阅读 &lt;code&gt;mfks.c&lt;/code&gt; 的执行过程，我们可以更快地了解 mfks 大致做了哪些事情。&lt;/p&gt;
&lt;h2 id=&#34;buffer-cache&#34;&gt;Buffer Cache&lt;/h2&gt;
&lt;p&gt;内存中的 buffer cache 是磁盘的 cache，所有的读写操作都会经过 buffer cache，buffer cache 提供了和磁盘一样的接口 bread/bwrite，这样反复的读取/反复的写入不用每次都与磁盘交互，提高了效率。&lt;/p&gt;
&lt;p&gt;具体的代码细节见 Xv6 源码解读手册。&lt;/p&gt;
&lt;h2 id=&#34;log&#34;&gt;Log&lt;/h2&gt;
&lt;p&gt;Xv6 的 logging layer 保证了崩溃一致性。具体的代码细节可以见 Xv6 源码解读手册。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 30: Modern Storage System</title>
      <link>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec30/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://kristoff-starling.github.io/posts/coursenotes/nju-operating-system/lectures/lec30/</guid>
      <description>&lt;h2 id=&#34;abilities-and-limitations-of-fs&#34;&gt;Abilities and Limitations of FS&lt;/h2&gt;
&lt;p&gt;OJ 最简单的实现方式可以就是一个文件系统。比如 OS2022 课程的学生名单存放在 &lt;code&gt;/OS2022/students.csv&lt;/code&gt; 中，向 Lab1 提交的代码以一个压缩包的形式存放在 &lt;code&gt;/OS2022/L1/studentid/xxxxxxxx.tar.bz2&lt;/code&gt; 中。OJ 的前端和后端部署在不同的机器上，后端机器通过 ssh 连接前端，扫描文件系统寻找符合格式的提交拉回后台，评测以后发送一个 &lt;code&gt;.tar.bz2.result&lt;/code&gt; 文件给前端，前端就可以将评测结果显示出来。&lt;/p&gt;
&lt;p&gt;使用文件系统的最大好处是简单：我们有海量的 UNIX 工具/标准库可以处理文件。比如查询某个同学的提交可以使用如下 python 代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for f in wiki.UPLOAD_PATH.glob(
	f&#39;{course}/{module}/{stuid}/{file_pattern}&#39;):
    if not f.name.endswith(&#39;.result&#39;):
        # f是一个提交, do something
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;再比如添加了测试数据/更新了测试代码后我们只需要一行 UNIX 命令就可以开启 rejudge：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;find OS2022/L1 -name &amp;quot;*.result&amp;quot; | xargs rm
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;删除所有的 &lt;code&gt;.result&lt;/code&gt; 结尾的文件后，后端便会自动抓取没有对应 &lt;code&gt;.result&lt;/code&gt; 文件的提交压缩包评测，从而实现重测。&lt;/p&gt;
&lt;p&gt;文件系统的局限在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scalability 不好：任何一个页面的渲染都要遍历所有目录，对于庞大系统来说效率太低；&lt;/li&gt;
&lt;li&gt;可靠性低：几乎无法抵抗崩溃。比如后端完成评测后会通过 scp 命令将 &lt;code&gt;.result&lt;/code&gt; 文件传送到前端服务器，但如果传送的过程中网断了，那么文件系统无法做到 all or nothing，从而前端可能会处于一个 inconsistent 的状态， 比如已经创建了 &lt;code&gt;.result&lt;/code&gt; 文件但由于复制没有完成，文件是空的。这便是评测结果中 &amp;ldquo;server error&amp;rdquo; 的一种来源。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;relational-database&#34;&gt;Relational Database&lt;/h2&gt;
&lt;p&gt;所有的数据都可以以二维表的形式存储在数据库内。Structured Query Language (SQL) 用于描述需求，数据库引擎负责将需求翻译成具体的实现。比如如下的 SQL 语句：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT *
FROM students, submissions
WHERE students.sid == submissions.sid AND
	  submissions.course == &#39;OS2022&#39; AND
	  submissions.module == &#39;L1&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;它在功能上等价于&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for student in students:
    for submission in submissions:
        if students.sid == submissions.sid and submission.course == &#39;OS2022&#39; and submissions.module == &#39;L1&#39;:
            yield student, submission
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但要注意的是：SQL 只是一种 high level 的描述需求的语言，它底层的实现并不一定像这段 python 代码一样。比如在这个例子中，用双重循环在两个表单中 join 是非常低效的，数据库会使用数据结构 (hash, B tree etc.) 来优化实现。SQL 将上层需求和底层实现解耦，这样的设计有诸多好处，比如比较容易实现原子性：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;BEGIN WORK;
-- all or nothing
INSERT INTO students VALUES(...);
INSERT INTO students VALUES(...);
INSERT INTO students VALUES(...);
COMMIT;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;直到 commit 前，数据都不会真正落实。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;例子：稍大型的 Online Judge&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据库需要保证 ACID - Atomicity, Consistency, Isolation, Durability。对于数千个连接的并发事务，数据库要在保证并发正确性的基础上提升查询效率。一个典型的简单应用场景是 Online Judge：&lt;/p&gt;
&lt;center&gt;&lt;img src=&#34;https://kristoff-starling.github.io/img/APIO-OJ.png&#34; alt=&#34;APIO-OJ&#34; style=&#34;zoom:33%;&#34; /&gt;&lt;/center&gt;
&lt;p&gt;比赛中 Online Judge 评测结果的即时性要求很高，因此我们要组建一个小的分布式系统来并行地评测多组数据。上图所示系统的工作原理是：100 个 worker 负责评测，supervisor 负责给 worker 分配任务 (supervisor 会不断 ping 各个 worker 以了解机器实时的状态)，所有的数据都存储在 database 中。supervisor 和所有的 worker 与数据库相连。当 Online Judge 前端接收到一个新的提交后，他会把文件存储到数据库中，supervisor 会指挥一个 worker 把源代码从数据库拉到本地编译，并将可执行文件传回数据库。接着 supervisor 指挥一部分 worker 从数据库中获取可执行文件 (这一瞬间会产生一个很大的带宽)，然后执行对应的测试数据，worker 将执行结果发送给数据库保存。最后前端从数据库中查询所有测试点的运行结果并显示在网页上。&lt;/p&gt;
&lt;p&gt;从这个例子中我们可以看到数据库作为整个系统的存储枢纽，其可靠性，处理大量并发事务的效率等是整个系统能力的关键。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;distributed-system&#34;&gt;Distributed System&lt;/h2&gt;
&lt;p&gt;在新时代，存储系统需要应对海量的实时数据。构造一个 planet-scale 的数据库遭遇了前所未有的挑战。我们通常用 CAP Theorem 来衡量一个数据库的性能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Availability (A)：用户能否在短时间内迅速获取需要的数据&lt;/li&gt;
&lt;li&gt;Consistency (C)：系统是否处于一个一致的状态，同步是否正确 (比如先“取关”再“发送pyq”的操作顺序如果在地理上的另一个数据中心反序会造成严重的后果)。&lt;/li&gt;
&lt;li&gt;Partition Tolerance (P)：系统可以忍受怎样规模的延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分布式系统要面对的问题比“并发编程”要更加严峻：多个线程至少有一个共享的内存可以交换数据、实现同步，而分布式系统各个节点之间没有这样的共享资源；此外，分布式系统的假设是任何一个节点都可以在任何一个时刻“突然消失”。&lt;/p&gt;
&lt;p&gt;对分布式系统更友好的数据模型是 key-value (可以理解为 C++ 的 &lt;code&gt;std::map&amp;lt;&amp;gt;&lt;/code&gt;)。LevelDB 是 Google 开发的实现 key-value storage 的库。我们最基本的需求是增加/删除 key-value 对，以及对当前的状态打快照。LevelDB 使用类似于日志的想法，并不是维护一个“平衡树“，而是记录所有操作的内容。为了解决读放大的问题，LevelDB 构建了一个多级的类似于 memory hierarchy 的日志，读操作优先到 Level 0 的 tree 里寻找信息，找不到去下一层，以此类推。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
